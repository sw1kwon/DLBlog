{
 "cells": [
  {
   "cell_type": "raw",
   "id": "7a9ee665-7172-4c03-97f3-96393b519497",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"14wk-1: (강화학습) -- 4x4 Grid World 환경의 이해\"\n",
    "author: \"sw1kwon\"\n",
    "date: \"06/04/2025\"\n",
    "draft: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a69471c-9e33-40cb-9730-12a8e0fd6539",
   "metadata": {},
   "source": [
    "📘 **Note Format Guide**\n",
    "\n",
    "This format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\n",
    "\n",
    "| Type | What It Means | When I Use It |\n",
    "|------|----------------|----------------|\n",
    "| 📝 Lecture | Original material from the professor’s notes | When I’m referencing core concepts or provided code |\n",
    "| 🗣️ In-Class Note | Verbal explanations shared during the lecture | When I want to record something the professor said in class but didn’t include in the official notes |\n",
    "| ✍️ My Note | My thoughts, interpretations, or additional explanations | When I reflect on or explain something in my own words |\n",
    "| 🔬 Experiment | Code I tried out or changed to explore further | When I test variations or go beyond the original example |\n",
    "| ❓ Question | Questions I had while studying | When I want to revisit or research something more deeply |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cb55cc-5ba7-4587-af33-bb8bdecce2ce",
   "metadata": {},
   "source": [
    "📝\n",
    "🗣️\n",
    "✍️\n",
    "🔬\n",
    "❓"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45c85b5-7b40-497e-9188-53076414592e",
   "metadata": {
    "id": "4d47a7c9"
   },
   "source": [
    "# 1. 강의노트 원본 및 영상 링크"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9871ea5a-164d-4649-b118-800a3ea420b3",
   "metadata": {},
   "source": [
    "[https://guebin.github.io/DL2025/posts/14wk-1.html](https://guebin.github.io/DL2025/posts/14wk-1.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec70d12-2d53-494e-90a5-bc3b07727127",
   "metadata": {},
   "source": [
    "# 2. Imports 📝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d667404-aced-49db-b8c1-bb4e41eba4f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "#---#\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9c3d76-670a-4283-997c-cd4f5d373781",
   "metadata": {},
   "source": [
    "# 3. 지난시간 코드 복습 📝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0ad7cd-f74f-4d0a-9f48-41b4b234e676",
   "metadata": {},
   "source": [
    "`-` 클래스선언 \n",
    "\n",
    "- 수정사항: (1)  deque의 maxlen을 500000 으로 조정 (2) print하는 코드를 주석처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51ea8f17-ff1a-47a6-b30e-9c2e0ca9fdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld:\n",
    "    def __init__(self):\n",
    "        self.a2d = {\n",
    "            0: np.array([0,1]), # →\n",
    "            1: np.array([0,-1]), # ←  \n",
    "            2: np.array([1,0]),  # ↓\n",
    "            3: np.array([-1,0])  # ↑\n",
    "        }\n",
    "        self.state_space = gym.spaces.MultiDiscrete([4,4])\n",
    "        self.state = np.array([0,0])\n",
    "        self.reward = None\n",
    "        self.terminated = False\n",
    "    def step(self,action):\n",
    "        self.state = self.state + self.a2d[action]\n",
    "        s1,s2 = self.state\n",
    "        if (s1==3) and (s2==3):\n",
    "            self.reward = 100 \n",
    "            self.terminated = True\n",
    "        elif self.state in self.state_space:\n",
    "            self.reward = -1 \n",
    "            self.terminated = False\n",
    "        else:\n",
    "            self.reward = -10\n",
    "            self.terminated = True\n",
    "        # print(\n",
    "        #     f\"action = {action}\\t\"\n",
    "        #     f\"state = {self.state - self.a2d[action]} -> {self.state}\\t\"\n",
    "        #     f\"reward = {self.reward}\\t\"\n",
    "        #     f\"termiated = {self.terminated}\"\n",
    "        # )            \n",
    "        return self.state, self.reward, self.terminated\n",
    "    def reset(self):\n",
    "        self.state = np.array([0,0])\n",
    "        self.terminated = False\n",
    "        return self.state\n",
    "class RandomAgent:\n",
    "    def __init__(self):\n",
    "        self.state = np.array([0,0]) \n",
    "        self.action = None \n",
    "        self.reward = None \n",
    "        self.next_state = None\n",
    "        self.terminated = None\n",
    "        #---#\n",
    "        self.states = collections.deque(maxlen=500000)\n",
    "        self.actions = collections.deque(maxlen=500000)\n",
    "        self.rewards = collections.deque(maxlen=500000)\n",
    "        self.next_states = collections.deque(maxlen=500000)\n",
    "        self.terminations = collections.deque(maxlen=500000)\n",
    "        #---#\n",
    "        self.action_space = gym.spaces.Discrete(4)\n",
    "        self.n_experience = 0\n",
    "    def act(self):\n",
    "        self.action = self.action_space.sample()\n",
    "    def save_experience(self):\n",
    "        self.states.append(self.state)\n",
    "        self.actions.append(self.action)\n",
    "        self.rewards.append(self.reward)\n",
    "        self.next_states.append(self.next_state)\n",
    "        self.terminations.append(self.terminated)\n",
    "        self.n_experience = self.n_experience + 1\n",
    "    def learn(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8d55f9-775e-4645-b06b-1efd64e23572",
   "metadata": {},
   "source": [
    "`-` 메인코드 \n",
    "\n",
    "- 수정사항: 가독성을 위해 에피소드가 진행되는 for문의 구조를 수정함 (특히 step4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6ab87d-6eeb-45c2-a021-104704123024",
   "metadata": {},
   "source": [
    "- 🗣️\n",
    "    - 성공할 때까지 반복하게 됨 (for => while)\n",
    "    - score = score + player.reward 가 반복되긴 하지만 terminated 상황을 구분하기 위해 이렇게 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf5b849-087c-4b3b-be12-9f3e44d42749",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "마음에 들지 않지만 꼭 외워야 하는것 \n",
    "\n",
    "1. `env.step`은 항상 next_state, reward, terminated, truncated, info 를 리턴한다. -- 짐나지엄 라이브러리 규격때문\n",
    "2. `env.reset`은 환경을 초기화할 뿐만 아니라, state, info를 반환하는 기능도 있다.  -- 짐나지엄 라이브러리 규격때문\n",
    "3. `player`는 항상 `state`와 `next_state`를 구분해서 저장한다. (다른변수들은 그렇지 않음) 이는 강화학습이 MDP(마코프체인+행동+보상)구조를 따르게 때문에 생기는 고유한 특징이다. -- 이론적이 이유\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c64cfab-e57e-4889-8c2b-093c2291f17e",
   "metadata": {},
   "source": [
    "`-` 환경과 에이전트의 상호작용 이해를 위한 다이어그램: \n",
    "\n",
    "- <https://claude.ai/public/artifacts/7fad72b5-0946-47bd-a6cd-b33b21856590> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c9d509-233a-4086-9f11-457b60555ac0",
   "metadata": {},
   "source": [
    "# 4. GridWorld 환경의 이해 📝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4747fa5a-bbe5-4e4e-b2ff-628a8b2678c2",
   "metadata": {},
   "source": [
    "## A. 데이터 축적"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb363e2f-5faa-4a5a-bedd-3a69dd9e7ad7",
   "metadata": {},
   "source": [
    "`-` 랜덤에이전트를 이용해 무작위로 100,000 에피소드를 진행해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f808719-bb01-49d2-b064-c7d08c4347e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "player = RandomAgent()\n",
    "env = GridWorld()\n",
    "scores = [] \n",
    "score = 0 \n",
    "#\n",
    "for e in range(1,100000):\n",
    "    #---에피소드시작---#\n",
    "    while True:\n",
    "        # step1 -- 액션선택\n",
    "        player.act()\n",
    "        # step2 -- 환경반응 \n",
    "        player.next_state, player.reward, player.terminated = env.step(player.action)\n",
    "        # step3 -- 경험기록 & 학습 \n",
    "        player.save_experience()\n",
    "        player.learn()\n",
    "        # step4 --종료 조건 체크 & 후속 처리\n",
    "        if env.terminated:\n",
    "            score = score + player.reward\n",
    "            scores.append(score)\n",
    "            score = 0 \n",
    "            player.state = env.reset() \n",
    "            break\n",
    "        else: \n",
    "            score = score + player.reward            \n",
    "            player.state = player.next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2405d6f5-1807-4189-a4f4-e1d200de4d49",
   "metadata": {},
   "source": [
    ":::{.callout-important}\n",
    "\n",
    "***강의노트 수정 2025-06-12***\n",
    "\n",
    "노규호학생의 도움으로 예전강의의 오류를 발견하여 수정하였습니다. \n",
    "\n",
    "```Python\n",
    "# 수정전\n",
    "...\n",
    "        if env.terminated:\n",
    "            ...\n",
    "        else: \n",
    "            score = score + player.reward\n",
    "            scores.append(score)            \n",
    "            player.state = player.next_state\n",
    "            \n",
    "# 수정후\n",
    "        if env.terminated:\n",
    "            ...\n",
    "        else: \n",
    "            score = score + player.reward\n",
    "#            scores.append(score)            ### <--- 여기를 주석처리해야함!! \n",
    "            player.state = player.next_state\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef29fdf9-b027-4d88-8bd7-1e5c6d3b08d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326581"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player.n_experience"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498391b4-ea07-4889-9282-b1e01dd1edc3",
   "metadata": {},
   "source": [
    "- 🗣️\n",
    "    - 한 에피소드 당 평균 3번 정도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f82c761-757d-49b5-9e6e-2f953a246553",
   "metadata": {},
   "source": [
    "## B. 첫번째 `q_table`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd4f33f-53f4-47d5-805a-ce8af721388f",
   "metadata": {},
   "source": [
    "`-` 밴딧게임에서는 $q(a)$ 를 정의했었음. \n",
    "\n",
    "- $q(0) = 1$\n",
    "- $q(1) = 10$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f13669-e0ce-4c5e-a7bc-b12fc44b48a3",
   "metadata": {},
   "source": [
    "`-` 여기에서는 $q(s_1,s_2,a)$를 정의해야함! "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd16fe74-006c-4e6b-99ea-1eb13742a409",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "직관적으로 아래의 그림이 떠오름 \n",
    "![](https://github.com/guebin/DL2025/blob/main/posts/14wk-1-fig1.png?raw=true)\n",
    "\n",
    "그림에 대응하는 $q(s_1,s_2,a)$의 값은 아래와 같음\n",
    "\n",
    ":::{.panel-tabset}\n",
    "\n",
    "### $a=0$\n",
    "\n",
    "$a=0 \\Leftrightarrow \\text{\\tt action=right}$\n",
    "\n",
    "$$ \\begin{bmatrix}\n",
    "q(0,0,0) & q(0,1,0) & q(0,2,0) & q(0,3,0) \\\\ \n",
    "q(1,0,0) & q(1,1,0) & q(1,2,0) & q(1,3,0) \\\\ \n",
    "q(2,0,0) & q(2,1,0) & q(2,2,0) & q(2,3,0) \\\\ \n",
    "q(3,0,0) & q(3,1,0) &q(3,2,0) & q(3,3,0) \\\\ \n",
    "\\end{bmatrix} =  \\begin{bmatrix}\n",
    "-1 & -1 & -1 & -10 \\\\ \n",
    "-1 & -1 & -1 & -10 \\\\ \n",
    "-1 & -1 & -1 & -10 \\\\ \n",
    "-1 & -1 & 100 &  \\text{-} \\\\ \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "### $a=1$\n",
    "\n",
    "$a=1 \\Leftrightarrow \\text{\\tt action=left}$\n",
    "\n",
    "$$ \\begin{bmatrix}\n",
    "q(0,0,1) & q(0,1,1) & q(0,2,1) & q(0,3,1) \\\\ \n",
    "q(1,0,1) & q(1,1,1) & q(1,2,1) & q(1,3,1) \\\\ \n",
    "q(2,0,1) & q(2,1,1) & q(2,2,1) & q(2,3,1) \\\\ \n",
    "q(3,0,1) & q(3,1,1) &q(3,2,1) & q(3,3,1) \\\\ \n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "-10 & -1 & -1 & -1 \\\\ \n",
    "-10& -1 & -1 & -1 \\\\ \n",
    "-10 & -1 & -1 & -1 \\\\ \n",
    "-10 & -1 & -1 &  \\text{-} \\\\ \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "### $a=2$\n",
    "\n",
    "$a=2 \\Leftrightarrow \\text{\\tt action=down}$\n",
    "\n",
    "$$  \\begin{bmatrix}\n",
    "q(0,0,2) & q(0,1,2) & q(0,2,2) & q(0,3,2) \\\\ \n",
    "q(1,0,2) & q(1,1,2) & q(1,2,2) & q(1,3,2) \\\\ \n",
    "q(2,0,2) & q(2,1,2) & q(2,2,2) & q(2,3,2) \\\\ \n",
    "q(3,0,2) & q(3,1,2) &q(3,2,2) & q(3,3,2) \\\\ \n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "-1 & -1 & -1 & -1 \\\\ \n",
    "-1& -1 & -1 & -1 \\\\ \n",
    "-1 & -1 & -1 & 100\\\\ \n",
    "-10 & -10 & -10 &  \\text{-} \\\\ \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "### $a=3$\n",
    "\n",
    "$a=3 \\Leftrightarrow \\text{\\tt action=up}$\n",
    "\n",
    "$$  \\begin{bmatrix}\n",
    "q(0,0,3) & q(0,1,3) & q(0,2,3) & q(0,3,3) \\\\ \n",
    "q(1,0,3) & q(1,1,3) & q(1,2,3) & q(1,3,3) \\\\ \n",
    "q(2,0,3) & q(2,1,3) & q(2,2,3) & q(2,3,3) \\\\ \n",
    "q(3,0,3) & q(3,1,3) &q(3,2,3) & q(3,3,3) \\\\ \n",
    "\\end{bmatrix} =\\begin{bmatrix}\n",
    "-10 & -10 & -10 & -10\\\\ \n",
    "-1& -1 & -1 & -1 \\\\ \n",
    "-1 & -1 & -1 & -1 \\\\ \n",
    "-1 & -1 & -1 &  \\text{-} \\\\ \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    ":::\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83700793-9da0-4853-ad28-2c18a9839b41",
   "metadata": {},
   "source": [
    "`-` 데이터를 바탕으로 $q(s_1,s_2,a)$를 구해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe0a3b1-735e-439b-aa2e-784e493493e1",
   "metadata": {},
   "source": [
    "🗣️("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "069c4777-6bf5-4a8c-a129-38ce01833efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0]), np.int64(1), -10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player.states[0], player.actions[0], player.rewards[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c714ea9-cb99-4772-b89f-1266e304a419",
   "metadata": {},
   "source": [
    "q(0, 0, 1) = -10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58326d5-20e9-43ec-aac7-4a27bdae93af",
   "metadata": {},
   "source": [
    "✍️ 이 경우에 게임이 끝났음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45b7dbbe-da81-45b6-9deb-2c11c77aad88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0]), np.int64(2), -1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player.states[1], player.actions[1], player.rewards[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef7023c-8207-45fb-8b5c-8dfc643e963d",
   "metadata": {},
   "source": [
    "q(0, 0, 2) = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d8c96ae-872d-4c80-867f-937db97d1927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0]), np.int64(1), -10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player.states[2], player.actions[2], player.rewards[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bffc4b-9db4-41b4-a003-adc8756d5272",
   "metadata": {},
   "source": [
    "- q_table 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fd363b1-0e2b-4bd7-8ccb-f92989c94702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table = np.zeros([4,4,4])\n",
    "q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a188f9c9-735e-4dfc-bcea-97da025b141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (s1,s2), a, r in zip(player.states, player.actions, player.rewards):\n",
    "    q_table[s1,s2,a] = q_table[s1,s2,a] + r # [s1,s2,s3]에서 받은 보상(r)을 계속 더함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67c7cefb-7828-42de-be72-5c1103050683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-29987., -10133.,  -3694., -12710.],\n",
       "       [-10197.,  -7066.,  -3646., -14840.],\n",
       "       [ -3761.,  -3648.,  -2312.,  -9980.],\n",
       "       [ -1361.,  -1446.,  91000.,      0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table[:,:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d72983-5966-43a1-ab30-186617c3b8ae",
   "metadata": {},
   "source": [
    "```\n",
    "아래와 같은 경우를 기대하였으나 그렇지 않음\n",
    "-1 -1 -1 -10\n",
    "-1 -1 -1 -10\n",
    "-1 -1 -1 -10\n",
    "-1 -1 100 -\n",
    "count를 계산하여 평균을 구해야 할 것 같음\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59413e89-7051-4680-a65a-baf37c6c092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table = np.zeros([4,4,4])\n",
    "count = np.zeros([4,4,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28ec2166-2966-424e-8515-d6a7928ed165",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (s1,s2), a, r in zip(player.states, player.actions, player.rewards):\n",
    "    q_table[s1,s2,a] = q_table[s1,s2,a] + r\n",
    "    count[s1,s2,a] = count[s1,s2,a] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d547cf93-04db-4872-9aba-04febbb3b7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-29987., -10133.,  -3694., -12710.],\n",
       "       [-10197.,  -7066.,  -3646., -14840.],\n",
       "       [ -3761.,  -3648.,  -2312.,  -9980.],\n",
       "       [ -1361.,  -1446.,  91000.,      0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47ec5e98-9ec1-499e-9709-be05845fae6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29987., 10133.,  3694.,  1271.],\n",
       "       [10197.,  7066.,  3646.,  1484.],\n",
       "       [ 3761.,  3648.,  2312.,   998.],\n",
       "       [ 1361.,  1446.,   910.,     0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94f0cc64-3e81-48bd-8116-4cfbdba4956f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-29987., -10133.,  -3694., -12710.],\n",
       "       [-10197.,  -7066.,  -3646., -14840.],\n",
       "       [ -3761.,  -3648.,  -2312.,  -9980.],\n",
       "       [ -1361.,  -1446.,  91000.,      0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table[...,0] # 동일 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8829fea-7e52-40bf-a300-12ba3ff90ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29987., 10133.,  3694.,  1271.],\n",
       "       [10197.,  7066.,  3646.,  1484.],\n",
       "       [ 3761.,  3648.,  2312.,   998.],\n",
       "       [ 1361.,  1446.,   910.,     0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count[...,0] # 동일 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bdd8e3c-546b-429e-afb6-f78ee94eef54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-301600.,  -10110.,   -3881.,   -1306.],\n",
       "       [-101040.,   -6958.,   -3589.,   -1430.],\n",
       "       [ -38240.,   -3584.,   -2295.,    -913.],\n",
       "       [ -13030.,   -1492.,    -936.,       0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table[...,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1459283-4d9b-4cb3-80ae-95bfc6596f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30160., 10110.,  3881.,  1306.],\n",
       "       [10104.,  6958.,  3589.,  1430.],\n",
       "       [ 3824.,  3584.,  2295.,   913.],\n",
       "       [ 1303.,  1492.,   936.,     0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count[...,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e004e73-3230-4179-99c3-3d82550ac813",
   "metadata": {},
   "source": [
    "```\n",
    "q_table을 count로 나누면 아래와 같은 결과가 나올 것 같음\n",
    "-10 -1 -1 -1\n",
    "-10 -1 -1 -1\n",
    "-10 -1 -1 -1\n",
    "-10 -1 -1 -\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "797edbfd-102d-4c76-860d-69b6da159c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2313654/1678126644.py:1: RuntimeWarning: invalid value encountered in divide\n",
      "  q_table / count\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ -1., -10.,  -1., -10.],\n",
       "        [ -1.,  -1.,  -1., -10.],\n",
       "        [ -1.,  -1.,  -1., -10.],\n",
       "        [-10.,  -1.,  -1., -10.]],\n",
       "\n",
       "       [[ -1., -10.,  -1.,  -1.],\n",
       "        [ -1.,  -1.,  -1.,  -1.],\n",
       "        [ -1.,  -1.,  -1.,  -1.],\n",
       "        [-10.,  -1.,  -1.,  -1.]],\n",
       "\n",
       "       [[ -1., -10.,  -1.,  -1.],\n",
       "        [ -1.,  -1.,  -1.,  -1.],\n",
       "        [ -1.,  -1.,  -1.,  -1.],\n",
       "        [-10.,  -1., 100.,  -1.]],\n",
       "\n",
       "       [[ -1., -10., -10.,  -1.],\n",
       "        [ -1.,  -1., -10.,  -1.],\n",
       "        [100.,  -1., -10.,  -1.],\n",
       "        [ nan,  nan,  nan,  nan]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table / count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d814d476-fc06-4aa4-a123-1ada4156e5bc",
   "metadata": {},
   "source": [
    "- 없는 값이 존재함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4295ea1e-a1b5-4acc-99f6-9da49831edfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2313654/878353018.py:1: RuntimeWarning: invalid value encountered in divide\n",
      "  (q_table / count)[...,0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -1.,  -1.,  -1., -10.],\n",
       "       [ -1.,  -1.,  -1., -10.],\n",
       "       [ -1.,  -1.,  -1., -10.],\n",
       "       [ -1.,  -1., 100.,  nan]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(q_table / count)[...,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2c2b69-3651-4dc4-a3c0-353c2f0aced3",
   "metadata": {},
   "source": [
    "- nan 위치의 값은 원래 없으므로 count가 안 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08af55d1-55b0-4a13-85ad-8e7041aa0e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29987., 10133.,  3694.,  1271.],\n",
       "       [10197.,  7066.,  3646.,  1484.],\n",
       "       [ 3761.,  3648.,  2312.,   998.],\n",
       "       [ 1361.,  1446.,   910.,     0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count[...,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e776db-cf86-4784-a042-d804dd7a7074",
   "metadata": {},
   "source": [
    "- 0으로 나누는 것이 문제가 되므로 다음과 같이 하면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5aa8bcad-41ad-48c5-853a-db023439f183",
   "metadata": {},
   "outputs": [],
   "source": [
    "count[count == 0] = 0.000001\n",
    "q_table = q_table / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b57be1b3-0c43-4811-82c7-fa7860aa5919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.,  -1.,  -1., -10.],\n",
       "       [ -1.,  -1.,  -1., -10.],\n",
       "       [ -1.,  -1.,  -1., -10.],\n",
       "       [ -1.,  -1., 100.,   0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table[...,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f20b731-fa1d-4646-8188-5293323f315c",
   "metadata": {},
   "source": [
    ")🗣️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dc84ffd7-45da-47ae-94d7-16347398f1ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0]), 0, -1)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player.states[0], player.actions[0], player.rewards[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2f78c883-feca-45e1-bbdc-166cf754b4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table = np.zeros((4,4,4))\n",
    "count = np.zeros((4,4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "750322b8-bb46-4ac7-87fc-c54f1d3ef782",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory =  zip(player.states, player.actions, player.rewards)\n",
    "for (s1,s2), a, r in memory:\n",
    "    q_table[s1,s2,a] = q_table[s1,s2,a] + r\n",
    "    count[s1,s2,a] = count[s1,s2,a] + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bd64bf9d-eebe-4cc0-abc6-ba4bb934d7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "count[count==0] = 0.001 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e035d24e-a05a-45c3-9692-5c20719e7c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table = q_table / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e3c4df1d-8464-4a20-afc0-15d2e10a65a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ -1.,  -1.,  -1., -10.],\n",
       "        [ -1.,  -1.,  -1., -10.],\n",
       "        [ -1.,  -1.,  -1., -10.],\n",
       "        [ -1.,  -1., 100.,   0.]]),\n",
       " array([[-10.,  -1.,  -1.,  -1.],\n",
       "        [-10.,  -1.,  -1.,  -1.],\n",
       "        [-10.,  -1.,  -1.,  -1.],\n",
       "        [-10.,  -1.,  -1.,   0.]]),\n",
       " array([[ -1.,  -1.,  -1.,  -1.],\n",
       "        [ -1.,  -1.,  -1.,  -1.],\n",
       "        [ -1.,  -1.,  -1., 100.],\n",
       "        [-10., -10., -10.,   0.]]),\n",
       " array([[-10., -10., -10., -10.],\n",
       "        [ -1.,  -1.,  -1.,  -1.],\n",
       "        [ -1.,  -1.,  -1.,  -1.],\n",
       "        [ -1.,  -1.,  -1.,   0.]]))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table[...,0], q_table[...,1], q_table[...,2], q_table[...,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0e8ebf-cafc-4575-906c-3d73a9465a1e",
   "metadata": {},
   "source": [
    "`-` count를 사용하지 않는 방법은 없을까? -- 테크닉"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d221617e-b8b4-4c9e-9554-c097d583d22f",
   "metadata": {},
   "source": [
    "🗣️("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6232dacd-f471-49c0-95e9-71fadd691d9e",
   "metadata": {},
   "source": [
    "- `부스팅 알고리즘`을 잘 알면 이해하기 쉬움"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4389344f-01aa-4ade-ac83-746ee6472afc",
   "metadata": {},
   "source": [
    "```\n",
    "예시)\n",
    "어떤 액션을 했을 때 받는 보상 80 / 학습률: 0.1 / 초기값 50\n",
    "80 - 50 = 30\n",
    "50 + 3 = 53\n",
    "80 - 53 = 27\n",
    "53 + 2.7 = 55.7\n",
    "...\n",
    "80 근처로 가게 됨\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f1404b3-fe06-42f1-b35f-f49b90a783dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table = np.zeros([4,4,4])\n",
    "for (s1,s2), a, r in zip(player.states, player.actions, player.rewards):\n",
    "    qhat = q_table[s1,s2,a]\n",
    "    q = r\n",
    "    diff = q - qhat\n",
    "    q_table[s1,s2,a] = q_table[s1,s2,a] + 0.01*diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c73333d9-93a4-4e4e-9572-126bba60fbcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ -1.        , -10.        ,  -1.        , -10.        ],\n",
       "        [ -1.        ,  -1.        ,  -1.        , -10.        ],\n",
       "        [ -1.        ,  -1.        ,  -1.        , -10.        ],\n",
       "        [ -9.99997166,  -0.99999801,  -0.99999585,  -9.99998066]],\n",
       "\n",
       "       [[ -1.        , -10.        ,  -1.        ,  -1.        ],\n",
       "        [ -1.        ,  -1.        ,  -1.        ,  -1.        ],\n",
       "        [ -1.        ,  -1.        ,  -1.        ,  -1.        ],\n",
       "        [ -9.99999667,  -0.99999943,  -0.99999928,  -0.9999994 ]],\n",
       "\n",
       "       [[ -1.        , -10.        ,  -1.        ,  -1.        ],\n",
       "        [ -1.        ,  -1.        ,  -1.        ,  -1.        ],\n",
       "        [ -1.        ,  -1.        ,  -1.        ,  -1.        ],\n",
       "        [ -9.99955952,  -0.9998965 ,  99.99218879,  -0.99983567]],\n",
       "\n",
       "       [[ -0.99999885,  -9.99997946,  -9.99998584,  -0.99999546],\n",
       "        [ -0.99999951,  -0.99999969,  -9.9999924 ,  -0.99999986],\n",
       "        [ 99.98933337,  -0.99991786,  -9.99916195,  -0.99991703],\n",
       "        [  0.        ,   0.        ,   0.        ,   0.        ]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00996960-6c2f-4606-ba53-8610f1bd600a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.        , -1.        , -1.        , -9.99997166],\n",
       "       [-1.        , -1.        , -1.        , -9.99999667],\n",
       "       [-1.        , -1.        , -1.        , -9.99955952],\n",
       "       [-0.99999885, -0.99999951, 99.98933337,  0.        ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table[...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5b25cfe-093f-4065-933d-f9bfc8a7d0ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.  ,  -1.  ,  -1.  , -10.  ],\n",
       "       [ -1.  ,  -1.  ,  -1.  , -10.  ],\n",
       "       [ -1.  ,  -1.  ,  -1.  , -10.  ],\n",
       "       [ -1.  ,  -1.  ,  99.99,   0.  ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table[...,0].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25eb5ae-46f2-4689-b870-e468d4c6d03b",
   "metadata": {},
   "source": [
    ")🗣️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "323a393f-c8b0-47d0-872c-3e46f37ed682",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table = np.zeros((4,4,4))\n",
    "memory =  zip(player.states, player.actions, player.rewards)\n",
    "for (s1,s2), a, r in memory:\n",
    "    qhat = q_table[s1,s2,a] # 내가 생각했던갓\n",
    "    q = r # 실제값\n",
    "    diff = q-qhat # 차이\n",
    "    q_table[s1,s2,a] = q_table[s1,s2,a]  + 0.01*diff# update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5b395794-2199-42c4-84ae-3c55448b0c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ -1.  , -10.  ,  -1.  , -10.  ],\n",
       "        [ -1.  ,  -1.  ,  -1.  , -10.  ],\n",
       "        [ -1.  ,  -1.  ,  -1.  , -10.  ],\n",
       "        [-10.  ,  -1.  ,  -1.  , -10.  ]],\n",
       "\n",
       "       [[ -1.  , -10.  ,  -1.  ,  -1.  ],\n",
       "        [ -1.  ,  -1.  ,  -1.  ,  -1.  ],\n",
       "        [ -1.  ,  -1.  ,  -1.  ,  -1.  ],\n",
       "        [-10.  ,  -1.  ,  -1.  ,  -1.  ]],\n",
       "\n",
       "       [[ -1.  , -10.  ,  -1.  ,  -1.  ],\n",
       "        [ -1.  ,  -1.  ,  -1.  ,  -1.  ],\n",
       "        [ -1.  ,  -1.  ,  -1.  ,  -1.  ],\n",
       "        [-10.  ,  -1.  ,  99.99,  -1.  ]],\n",
       "\n",
       "       [[ -1.  , -10.  , -10.  ,  -1.  ],\n",
       "        [ -1.  ,  -1.  , -10.  ,  -1.  ],\n",
       "        [ 99.99,  -1.  , -10.  ,  -1.  ],\n",
       "        [  0.  ,   0.  ,   0.  ,   0.  ]]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9f539f-1f55-40d3-8e23-fd1ac256953f",
   "metadata": {},
   "source": [
    "## C. 첫번째 `q_table`보다 나은 것?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9f0335-3958-43b2-bfee-43eaede1cab2",
   "metadata": {},
   "source": [
    "`-` 첫번째 `q_table`을 알고있다고 가정하자. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74bee9ac-afc0-4970-b6d9-f4ec23ea0bef",
   "metadata": {},
   "source": [
    "![](https://github.com/guebin/DL2025/blob/main/posts/14wk-1-fig1.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806f93fe-649f-43ab-8def-35356e0b50e6",
   "metadata": {},
   "source": [
    "`-` 정책시각화 (합리적인 행동) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e51f9ad5-16fe-4d27-a94f-6342de087b2b",
   "metadata": {},
   "source": [
    "![](https://github.com/guebin/DL2025/blob/main/posts/14wk-1-fig2.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0524ca-d047-461b-bf3d-eedcf888ca5e",
   "metadata": {},
   "source": [
    "`-` 이게 최선의 정책일까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7eb1b5-7eda-49f7-9b05-5683c5e454c4",
   "metadata": {},
   "source": [
    "- 🗣️\n",
    "    - 큰 숫자 따라가기?\n",
    "    - (2,2)에서 오른쪽과 아래는 -1 이 아니라 99로 수정?\n",
    "        - 오른쪽이나 아래로 가면 100이 보장이 되어 있음\n",
    "    - (1,2)에서 왼쪽과 아래쪽은 reward가 똑같은 것이 맞는가?\n",
    "        - 아래로 가면 99가 보장이 되어 있으므로 98로 수정?\n",
    "    - 이런 식으로 100점을 기준으로 점차 재조정이 되어야 할 것 같음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
