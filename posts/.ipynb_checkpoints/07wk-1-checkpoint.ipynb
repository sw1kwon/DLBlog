{
 "cells": [
  {
   "cell_type": "raw",
   "id": "aeff2ac3-8f9f-4111-ab0c-7e897c0b0ea5",
   "metadata": {
    "id": "87b5cded-346b-4915-acf5-b5ec93a5207d",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"07wk-1: (합성곱신경망) -- CNN 자랑, CNN 핵심레이어\"\n",
    "author: \"sw1kwon\"\n",
    "date: \"04/16/2025\"\n",
    "draft: false\n",
    "freeze: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b3093d-091e-49f1-b3fe-a9a733b69bcd",
   "metadata": {},
   "source": [
    "📘 **Note Format Guide**\n",
    "\n",
    "This format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\n",
    "\n",
    "| Type | What It Means | When I Use It |\n",
    "|------|----------------|----------------|\n",
    "| 📝 Lecture | Original material from the professor’s notes | When I’m referencing core concepts or provided code |\n",
    "| 🗣️ In-Class Note | Verbal explanations shared during the lecture | When I want to record something the professor said in class but didn’t include in the official notes |\n",
    "| ✍️ My Note | My thoughts, interpretations, or additional explanations | When I reflect on or explain something in my own words |\n",
    "| 🔬 Experiment | Code I tried out or changed to explore further | When I test variations or go beyond the original example |\n",
    "| ❓ Question | Questions I had while studying | When I want to revisit or research something more deeply |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd36d7c-7f11-4047-bce8-f68bb2d11125",
   "metadata": {},
   "source": [
    "📝\n",
    "🗣️\n",
    "✍️\n",
    "🔬\n",
    "❓"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc0f75e-d071-4a36-9361-9e6e3315114f",
   "metadata": {
    "id": "4d47a7c9"
   },
   "source": [
    "# 1. 강의노트 원본 및 영상 링크"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2022995-d5c8-426e-a7e2-4b87e0e2f96f",
   "metadata": {},
   "source": [
    "[https://guebin.github.io/DL2025/posts/07wk-1.html](https://guebin.github.io/DL2025/posts/07wk-1.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e00ad8a-bcde-4f06-ac26-e8a142320d97",
   "metadata": {},
   "source": [
    "- 🗣️\n",
    "    - softmax: [네모,네모,네모] -> [세모1,세모2,세모3] -> [세모1/세모합,세모2/세모합,세모3,세모합]\n",
    "    - sig: [네모,0] -exp-> [세모,1] -> [세모/(세모+1), 1/(세모+1)] # [1일 확률, 1이 아닐 확률=0일 확률] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab007f32-eec3-4423-9f1f-3ca9d2430f7c",
   "metadata": {},
   "source": [
    "# 2. Imports 📝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a23eda9f-1ff4-4876-bd3a-8b220e35250d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fd04db1-6ade-411a-a68c-196b14ab4e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (4.5, 3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f8f606-6da4-41de-82b8-fe1138958b80",
   "metadata": {},
   "source": [
    "# 3. CNN 자랑 📝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c14e280-6117-4557-a0c0-a926aff01038",
   "metadata": {},
   "source": [
    "## A. 성능좋음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14753de9-3e94-487f-b611-719a8d0a40f9",
   "metadata": {},
   "source": [
    "*Fashion MNIST*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fe9710c-bc46-46e1-8155-82a1d0bcf729",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True)\n",
    "train_dataset = torch.utils.data.Subset(train_dataset, range(5000))\n",
    "test_dataset = torch.utils.data.Subset(test_dataset, range(1000))\n",
    "to_tensor = torchvision.transforms.ToTensor()\n",
    "X = torch.stack([to_tensor(img) for img, lbl in train_dataset]).to(\"cuda:0\")\n",
    "y = torch.tensor([lbl for img, lbl in train_dataset])\n",
    "y = torch.nn.functional.one_hot(y).float().to(\"cuda:0\")\n",
    "XX = torch.stack([to_tensor(img) for img, lbl in test_dataset]).to(\"cuda:0\")\n",
    "yy = torch.tensor([lbl for img, lbl in test_dataset])\n",
    "yy = torch.nn.functional.one_hot(yy).float().to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a115fbdf-b412-44d8-b6f4-eb1218a2b65f",
   "metadata": {},
   "source": [
    "🗣️("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d0e6f0e-6a73-451d-9348-11c433a56c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 1, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape # 시간이 오래 걸려서 줄임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80a73961-4973-4c7b-b55c-22c8586104c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5000, 10]), torch.Size([1000, 1, 28, 28]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, XX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5d02b2-1c21-4b8f-ab12-a6d6def27a06",
   "metadata": {},
   "source": [
    ")🗣️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e450164a-3725-4555-90f2-f8eeb636c3c1",
   "metadata": {},
   "source": [
    "*발악수준으로 설계한 신경망*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd524c9a-2199-4a35-9efa-0955a504acd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784,2048),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(2048,10)\n",
    ").to(\"cuda\")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78bc42de-25c4-4b13-a971-5ba37069790a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoc in range(1,500):\n",
    "    #1\n",
    "    logits = net(X)\n",
    "    #2\n",
    "    loss = loss_fn(logits, y) \n",
    "    #3\n",
    "    loss.backward()\n",
    "    #4 \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc1fc32e-ad06-479b-a8b8-a619cae128cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net(X).argmax(axis=1) == y.argmax(axis=1)).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9489994-f78f-4a63-8bb1-1e4e1d428c17",
   "metadata": {},
   "source": [
    "- 🗣️ 학습으로는 개선될 것이 없음 (오버피팅의 끝) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01450879-8ac7-44f8-be93-4079bf854c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8530, device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net(XX).argmax(axis=1) == yy.argmax(axis=1)).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653917d4-c4a9-4245-a73b-4085a3676ae8",
   "metadata": {},
   "source": [
    "*대충대충 설계한 합성곱신경망*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12902d8d-1338-4b0e-8a05-82b80c6f0f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1,16,2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(2704,10),\n",
    ").to(\"cuda\")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70a14c97-9892-40ca-bb0a-218665ce7f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoc in range(1,500):\n",
    "    #1\n",
    "    logits = net(X)\n",
    "    #2\n",
    "    loss = loss_fn(logits, y) \n",
    "    #3\n",
    "    loss.backward()\n",
    "    #4 \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74ae9baa-0c42-4907-8931-b7820b38e02a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9666, device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net(X).argmax(axis=1) == y.argmax(axis=1)).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2edf232-acd1-44be-acd7-0ed7919d18c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8710, device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net(XX).argmax(axis=1) == yy.argmax(axis=1)).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f32848c-bb21-4b2b-aa3b-5bba8751be76",
   "metadata": {},
   "source": [
    "- 🗣️ 오버피팅도 전보다 덜 함, test acc도 개선"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a0f648-16d9-4f71-90d4-93a18f70eff4",
   "metadata": {},
   "source": [
    "🗣️("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c91c75-3482-4f7f-87db-e8038b6d3bcd",
   "metadata": {},
   "source": [
    "- 2704"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd0ee88b-fa70-469e-b385-f02eab6f1b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 16, kernel_size=(2, 2), stride=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Flatten(start_dim=1, end_dim=-1)\n",
       "  (4): Linear(in_features=2704, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10b2d3c1-e5f8-455b-b7e7-a5447cdbdb88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 16, kernel_size=(2, 2), stride=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Flatten(start_dim=1, end_dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bebb1532-3678-4bfa-bcfa-6abb71248ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4116, 0.4116, 0.4116,  ..., 0.6122, 0.5657, 0.2136],\n",
       "        [0.4116, 0.4128, 0.4128,  ..., 0.7154, 0.0000, 0.0000],\n",
       "        [0.4116, 0.4116, 0.4116,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.4116, 0.4116, 0.4116,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.4116, 0.4116, 0.4116,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.4116, 0.4116, 0.4116,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[:-1](X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d9c580e-856d-41e9-b521-ddaf39410409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 2704])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[:-1](X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e4c86f-0261-4fc8-b1cc-a7236d5b9f70",
   "metadata": {},
   "source": [
    "- 아무거나 써놓고 error 보고 고쳐도 됨\n",
    "- 참고) GPU error 나면 Kernel 재시작"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9202797a-d6d2-4218-a0d7-7fdac2460c29",
   "metadata": {},
   "source": [
    ")🗣️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02f3a9c-ff84-4a20-9d4c-cde55195c144",
   "metadata": {},
   "source": [
    "## B. 파라메터적음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e911c113-326a-4881-a76c-31de38511900",
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784,2048),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(2048,10)\n",
    ")\n",
    "net2 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1,16,2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(2704,10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21c69c42-cfa0-42f8-b845-b0c11beb9cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=2048, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01dcd521-fda7-45ab-ba99-6d93d928d0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 784])\n",
      "torch.Size([2048])\n",
      "torch.Size([10, 2048])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "net1_params = list(net1.parameters())\n",
    "print(net1_params[0].shape)\n",
    "print(net1_params[1].shape)\n",
    "print(net1_params[2].shape)\n",
    "print(net1_params[3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aec66ee3-8cba-42ec-ac63-9902d448be59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1628170"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2048*784 + 2048 + 10*2048 + 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1531c0ce-a512-4a04-84db-e262a18c63c0",
   "metadata": {},
   "source": [
    "🗣️("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55c29620-5fa4-4c07-888e-a8b3a542dfb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7f542f6dbcf0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1.parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afa00ad-2d6b-4fc5-b98f-8ac382269500",
   "metadata": {},
   "source": [
    "- generator: next가 됨 / for문을 돌리기 편한 list 비슷한 형태 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec632ad9-a284-4c8a-835d-8b2be57f36c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0290,  0.0095, -0.0319,  ..., -0.0157, -0.0290, -0.0092],\n",
       "        [-0.0115, -0.0210, -0.0033,  ..., -0.0106, -0.0276, -0.0034],\n",
       "        [-0.0270, -0.0204,  0.0075,  ..., -0.0183, -0.0071,  0.0063],\n",
       "        ...,\n",
       "        [ 0.0150, -0.0349,  0.0023,  ...,  0.0235,  0.0061,  0.0350],\n",
       "        [-0.0234, -0.0295, -0.0202,  ..., -0.0353, -0.0169, -0.0149],\n",
       "        [-0.0315,  0.0171, -0.0010,  ..., -0.0192, -0.0257,  0.0305]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(net1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c2682f6-0580-46bf-8e07-9b3279f13172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0290,  0.0095, -0.0319,  ..., -0.0157, -0.0290, -0.0092],\n",
       "         [-0.0115, -0.0210, -0.0033,  ..., -0.0106, -0.0276, -0.0034],\n",
       "         [-0.0270, -0.0204,  0.0075,  ..., -0.0183, -0.0071,  0.0063],\n",
       "         ...,\n",
       "         [ 0.0150, -0.0349,  0.0023,  ...,  0.0235,  0.0061,  0.0350],\n",
       "         [-0.0234, -0.0295, -0.0202,  ..., -0.0353, -0.0169, -0.0149],\n",
       "         [-0.0315,  0.0171, -0.0010,  ..., -0.0192, -0.0257,  0.0305]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0101, -0.0294,  0.0133,  ...,  0.0234,  0.0283, -0.0351],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.2926e-02, -9.9654e-03, -1.9394e-02,  ..., -4.1905e-05,\n",
       "          -1.8466e-02, -1.9714e-02],\n",
       "         [-5.3193e-03,  1.1461e-02,  4.5922e-03,  ..., -2.1761e-02,\n",
       "           2.1826e-02,  1.1969e-02],\n",
       "         [-4.7551e-03, -2.1131e-02, -6.7052e-03,  ...,  2.1758e-02,\n",
       "           9.4742e-03, -6.0024e-04],\n",
       "         ...,\n",
       "         [ 8.4402e-03,  3.9834e-03, -2.1895e-02,  ...,  3.9969e-03,\n",
       "           1.6158e-02, -1.3650e-02],\n",
       "         [-2.0990e-02,  5.0413e-05,  2.1427e-02,  ..., -1.6232e-02,\n",
       "          -5.4801e-03,  9.2220e-04],\n",
       "         [ 4.4055e-03,  3.9634e-03,  1.7039e-03,  ...,  1.1729e-02,\n",
       "           5.9133e-03, -1.3802e-02]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0117,  0.0112, -0.0121, -0.0206, -0.0110, -0.0080,  0.0154,  0.0140,\n",
       "          0.0115,  0.0209], requires_grad=True)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d289463a-355c-4148-b194-9b1f3f9aeaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 784])\n",
      "torch.Size([2048])\n",
      "torch.Size([10, 2048])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "net1_params = list(net1.parameters())\n",
    "print(net1_params[0].shape)\n",
    "print(net1_params[1].shape) # bias\n",
    "print(net1_params[2].shape) # what\n",
    "print(net1_params[3].shape) # bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c791cf-6005-4fee-83fc-fcab01a92e28",
   "metadata": {},
   "source": [
    ")🗣️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4f26b6-3015-4e16-a9c4-a64e76c51f21",
   "metadata": {},
   "source": [
    "- 🗣️ net에 parameter가 많다: 비싸다 (net은 GPU에 다 올릴 수 밖에 없음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b5e86eb-a5f9-4da4-8cb4-84a04876611f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 16, kernel_size=(2, 2), stride=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Flatten(start_dim=1, end_dim=-1)\n",
       "  (4): Linear(in_features=2704, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab3ab386-9733-4774-a69e-d1ecfa3a0d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 2, 2])\n",
      "torch.Size([16])\n",
      "torch.Size([10, 2704])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "net2_params = list(net2.parameters())\n",
    "print(net2_params[0].shape)\n",
    "print(net2_params[1].shape)\n",
    "print(net2_params[2].shape) # what\n",
    "print(net2_params[3].shape) # bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b26e67d-6cdd-4cf3-abda-ae08a8f0717a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27130"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16*1*2*2 + 16 + 10*2704 + 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aca79559-d330-435b-8f11-e37fe802cd4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01666287918337766"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "27130/1628170"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e222542-468e-4d0e-848f-76ab0176f5ea",
   "metadata": {},
   "source": [
    "- 🗣️ 대충 만들었는데 성능도 좋음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422e5ccf-e8d8-43d2-b907-ca980f114af5",
   "metadata": {},
   "source": [
    "🗣️("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97af9b98-29fb-413d-a6b9-523c46890d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "net2_params = list(net2.parameters())\n",
    "print(net2_params[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91fd074-3217-4e7c-839f-fb9ee22c940a",
   "metadata": {},
   "source": [
    "- 차원이 많음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08f7525-4ee4-4d5f-a9ca-11dff1587ad7",
   "metadata": {},
   "source": [
    ")🗣️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd614f84-c17c-42f1-9bbc-9df3bc5b9d6d",
   "metadata": {},
   "source": [
    "## C. 유명함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f6f64e-5a98-4949-a109-488e0dc940d9",
   "metadata": {},
   "source": [
    "`-` <https://brunch.co.kr/@hvnpoet/109> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1609bfbf-29a7-4861-a77d-f44295e096ea",
   "metadata": {},
   "source": [
    "🗣️("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7a7132-2772-4c25-85dc-ec654c9616e4",
   "metadata": {},
   "source": [
    "- 딥러닝슈퍼스타 -- 힌튼, 르쿤, 벤지오, 응\n",
    "    - 힌튼 -- DBN(사이언스) ---> 깊은신경망을 만들어도 학습할 수 있다.\n",
    "        - 관심X\n",
    "    - 힌튼 대학원생: 알렉스 --> CIFAR10(이미지 데이터)\n",
    "        - 다른 대학원생: 공모전 제안 -> 나갔음\n",
    "    - 1. 내 컴퓨터가 너무 느림 --> GPU\n",
    "      2. 오버피팅 --> 드랍아웃\n",
    "      3. local min, 기울기소멸, ... (Adam 개발 전) --> 렐루(벤지오 연구실 개발) 사용\n",
    "    - 1등 <-- 1%만 올려도 대단한데 10%를 올림 (2012년)\n",
    "    - 2014 <-- Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae16542c-37f6-4ead-b9f0-6a45b98e5667",
   "metadata": {},
   "source": [
    "- 요즘은 더 좋은 트랜스포머가 나오긴 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5064396-fb54-4bde-81ab-0d2ba911eb50",
   "metadata": {},
   "source": [
    ")🗣️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97df4546-ba92-4f1f-ac14-1475521a4005",
   "metadata": {},
   "source": [
    "# 4. CNN 핵심레이어 📝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6ae0ea-de67-4f39-8b82-593d1d4cce8e",
   "metadata": {},
   "source": [
    "- 🗣️\n",
    "    - 합성곱신경망 = 컨볼루셔널 뉴럴 네트워크 = CNN\n",
    "    - 지금까지 배운 것) (linr -> relu) // (linr -> relu) // ...\n",
    "    - CNN) (conv -> relu -> mp) // (conv -> relu -> mp) // ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e058dc3b-644c-47e2-8e46-b0cf68ffe487",
   "metadata": {},
   "source": [
    "## A. `torch.nn.ReLU`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4670cd-fbd1-401c-8a0e-3b66348bf35a",
   "metadata": {},
   "source": [
    "**(예시1) 연산방법**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8febd906-09cd-4149-8a77-72534f09f999",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.randn(1,1,4,4) # (4,4) 흑백이미지 한장\n",
    "relu = torch.nn.ReLU()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5238d4af-83cf-4b63-a500-f2e9fc9ed81b",
   "metadata": {},
   "source": [
    "🗣️ (obs, channel, (img size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43ac5812-7567-463e-b85c-7c20c275f86b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.4381,  0.2449, -0.6420,  2.6874],\n",
       "          [ 0.7790,  1.0558,  0.7939,  0.1099],\n",
       "          [ 0.3492,  1.7610,  1.6032,  2.4212],\n",
       "          [ 0.5416, -0.2153, -1.2772,  0.6885]]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d4e9a60-e441-45e4-9564-f26e5fa9c0d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.4381, 0.2449, 0.0000, 2.6874],\n",
       "          [0.7790, 1.0558, 0.7939, 0.1099],\n",
       "          [0.3492, 1.7610, 1.6032, 2.4212],\n",
       "          [0.5416, 0.0000, 0.0000, 0.6885]]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0118ae45-a90c-48d8-84ba-12c77aabbe4a",
   "metadata": {},
   "source": [
    "## B. `torch.nn.MaxPool2d`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b952f7-b3c4-45af-9752-a320e614016c",
   "metadata": {},
   "source": [
    "**(예시1) 연산방법, kernel_size 의 의미**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b40e6bd-3381-4fac-be81-dff04f98d65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.rand(1,1,4,4)\n",
    "mp = torch.nn.MaxPool2d(kernel_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "67141542-1a21-4f25-8434-25ca56676d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.8921, 0.4222, 0.5778, 0.2707],\n",
       "          [0.6921, 0.5627, 0.5356, 0.1048],\n",
       "          [0.5356, 0.7699, 0.9047, 0.5911],\n",
       "          [0.3617, 0.5345, 0.1218, 0.4772]]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1cf8428a-3ac8-47b9-b140-e884bd358063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.8921, 0.5778],\n",
       "          [0.7699, 0.9047]]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7d4fcd-1be0-4fc1-9e97-70c0c9875a4a",
   "metadata": {},
   "source": [
    "🗣️ 2*2 window를 만든 뒤 max 값을 적음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d40495-871c-4980-a517-731a242438d5",
   "metadata": {},
   "source": [
    "**(예시2) 이미지크기와 딱 맞지않는 커널일경우?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38e3cbb7-20b6-415d-8beb-ef16777f03fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.rand(1,1,5,5)\n",
    "mp = torch.nn.MaxPool2d(kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db714739-83a4-4586-917a-0e984d5f84a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.9560, 0.4947, 0.1591, 0.2606, 0.9130],\n",
       "          [0.0603, 0.1255, 0.6520, 0.2504, 0.8759],\n",
       "          [0.7544, 0.5927, 0.5319, 0.2390, 0.2883],\n",
       "          [0.9470, 0.8519, 0.3501, 0.0725, 0.3881],\n",
       "          [0.7203, 0.0753, 0.8360, 0.1287, 0.9515]]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9418733f-e2cb-42c3-a8fd-0304a8f64a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.9560]]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cf5f8a-6eb8-4668-a038-faf5dd99b4f7",
   "metadata": {},
   "source": [
    "- 🗣️ version마다 다름\n",
    "    - pytorch는 나머지를 그냥 버림\n",
    "    - 나머지 중 max를 적기도 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1a3761-7ccf-4acd-99af-98c82d4b0184",
   "metadata": {},
   "source": [
    "**(예시3) 정사각형이 아닌 커널**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "59e7c7bd-d2f7-40ee-81d5-5eca722f8a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.rand(1,1,4,4)\n",
    "mp = torch.nn.MaxPool2d(kernel_size=(4,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "75471fce-5d35-4142-8471-bbfb7e333241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.4283, 0.9998, 0.3532, 0.3085],\n",
       "          [0.3278, 0.8575, 0.3331, 0.9769],\n",
       "          [0.0239, 0.2457, 0.8468, 0.8224],\n",
       "          [0.9593, 0.1292, 0.5930, 0.3652]]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a765efff-95d7-4fe1-b628-ade4d17cf759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.9998, 0.9769]]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b91d08a-ab10-4a37-9f7e-793c4db8c04e",
   "metadata": {},
   "source": [
    "## C. `torch.nn.Conv2d`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704ee6f1-7d2e-41dd-86a1-241383759151",
   "metadata": {},
   "source": [
    "**(예시1) 연산방법, stride=2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cef2ebc5-0bd6-4641-b598-980495912e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.rand(1,1,4,4) # (?, in_channels, ?, ?) \n",
    "conv = torch.nn.Conv2d(in_channels=1,out_channels=1,kernel_size=2,stride=2) # stride=2: window를 2칸 움직이라는 뜻 (바로 위의 예시와 비슷)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bf9ae376-c7cb-437d-b3af-72dca6f5beb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.7679, 0.3459, 0.6509, 0.7905],\n",
       "          [0.1166, 0.8762, 0.9373, 0.8573],\n",
       "          [0.5778, 0.8702, 0.9686, 0.5854],\n",
       "          [0.1373, 0.3530, 0.0529, 0.0139]]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "efbc1fe7-9282-437d-bb76-203f82359058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.1106, -0.1898],\n",
       "          [ 0.0529, -0.0976]]]], grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9a485c-0058-4557-b8b6-c9fa6e2c51d0",
   "metadata": {},
   "source": [
    "??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c63f1d3-f8a8-4343-94ec-7f6b085c09a7",
   "metadata": {},
   "source": [
    "🗣️ 바로 유추하기 어려움"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6f9e67-d08c-4293-acc8-7911bf60ef9e",
   "metadata": {},
   "source": [
    "🗣️("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "49a88b40-82ca-4c07-9c97-804009cc136c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.7679, 0.3459],\n",
       "           [0.1166, 0.8762]]]]),\n",
       " tensor([[[[0.7679, 0.3459, 0.6509, 0.7905],\n",
       "           [0.1166, 0.8762, 0.9373, 0.8573],\n",
       "           [0.5778, 0.8702, 0.9686, 0.5854],\n",
       "           [0.1373, 0.3530, 0.0529, 0.0139]]]]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[:, :, :2, :2], img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eaa62929-0d5a-445e-a0bb-e3b4863719d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.6509, 0.7905],\n",
       "           [0.9373, 0.8573]]]]),\n",
       " tensor([[[[0.7679, 0.3459, 0.6509, 0.7905],\n",
       "           [0.1166, 0.8762, 0.9373, 0.8573],\n",
       "           [0.5778, 0.8702, 0.9686, 0.5854],\n",
       "           [0.1373, 0.3530, 0.0529, 0.0139]]]]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[:, :, :2, 2:], img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "472e2dbd-ae53-4bcb-9ad1-962193738895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.5778, 0.8702],\n",
       "           [0.1373, 0.3530]]]]),\n",
       " tensor([[[[0.7679, 0.3459, 0.6509, 0.7905],\n",
       "           [0.1166, 0.8762, 0.9373, 0.8573],\n",
       "           [0.5778, 0.8702, 0.9686, 0.5854],\n",
       "           [0.1373, 0.3530, 0.0529, 0.0139]]]]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[:, :, 2:, :2], img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6028c2d3-d3f5-4c8a-83ba-b68d08d01c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.9686, 0.5854],\n",
       "           [0.0529, 0.0139]]]]),\n",
       " tensor([[[[0.7679, 0.3459, 0.6509, 0.7905],\n",
       "           [0.1166, 0.8762, 0.9373, 0.8573],\n",
       "           [0.5778, 0.8702, 0.9686, 0.5854],\n",
       "           [0.1373, 0.3530, 0.0529, 0.0139]]]]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[:, :, 2:, 2:], img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8c45e1b-48fd-4744-bab4-2629d46f9665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.1106, -0.1898],\n",
       "          [ 0.0529, -0.0976]]]], grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(img) # 미분꼬리표 -> parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6d1ac65d-8bbe-4f6b-ab68-740f8c8c7123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.0218,  0.2400],\n",
       "           [-0.4914,  0.3394]]]]),\n",
       " tensor([-0.1958]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight.data, conv.bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7ff60584-fbe0-4213-b706-8683d7220ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.7679, 0.3459],\n",
       "           [0.1166, 0.8762]]]]),\n",
       " tensor([[[[0.7679, 0.3459, 0.6509, 0.7905],\n",
       "           [0.1166, 0.8762, 0.9373, 0.8573],\n",
       "           [0.5778, 0.8702, 0.9686, 0.5854],\n",
       "           [0.1373, 0.3530, 0.0529, 0.0139]]]]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[:, :, :2, :2], img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "11f3f48b-1e24-430c-963a-740471624647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.01674022"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.0218 * 0.7679"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2cddf414-dcf4-4d9a-bd43-495f896d4b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.0167,  0.0830],\n",
       "           [-0.0573,  0.2974]]]]),\n",
       " tensor([[[[0.7679, 0.3459, 0.6509, 0.7905],\n",
       "           [0.1166, 0.8762, 0.9373, 0.8573],\n",
       "           [0.5778, 0.8702, 0.9686, 0.5854],\n",
       "           [0.1373, 0.3530, 0.0529, 0.0139]]]]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[:, :, :2, :2]*conv.weight.data, img # 행렬 곱이 아니라 원소 별로 곱함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dff3d484-68d6-49b1-a707-27a66d513761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1106]),\n",
       " tensor([[[[ 0.1106, -0.1898],\n",
       "           [ 0.0529, -0.0976]]]], grad_fn=<ConvolutionBackward0>))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(img[:, :, :2, :2]*conv.weight.data).sum()+conv.bias.data, conv(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "198bab9c-bf52-40fa-9b1e-803e09371812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.1898]),\n",
       " tensor([[[[ 0.1106, -0.1898],\n",
       "           [ 0.0529, -0.0976]]]], grad_fn=<ConvolutionBackward0>))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(img[:, :, :2, 2:]*conv.weight.data).sum()+conv.bias.data, conv(img) # 두번째 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f0124f95-eac0-4850-9206-a0f138b86c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0529]),\n",
       " tensor([[[[ 0.1106, -0.1898],\n",
       "           [ 0.0529, -0.0976]]]], grad_fn=<ConvolutionBackward0>))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(img[:, :, 2:, :2]*conv.weight.data).sum()+conv.bias.data, conv(img) # 세번째 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9259bc97-6935-47b7-8f7d-6b96e1746fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0976]),\n",
       " tensor([[[[ 0.1106, -0.1898],\n",
       "           [ 0.0529, -0.0976]]]], grad_fn=<ConvolutionBackward0>))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(img[:, :, 2:, 2:]*conv.weight.data).sum()+conv.bias.data, conv(img) # 네번째 값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbc9777-99f0-436b-bbd5-49a6ae8a5e92",
   "metadata": {},
   "source": [
    ")🗣️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2024823-4a92-46a5-bc0b-f3ec76845228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.3095,  0.0207],\n",
       "           [-0.3130,  0.2836]]]]),\n",
       " tensor([-0.2675]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight.data, conv.bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55d1ae50-24af-4d69-92e9-f0cc10d4e128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.3077]),\n",
       " tensor([[[[-0.3077, -0.4760],\n",
       "           [ 0.0550, -0.0650]]]], grad_fn=<ConvolutionBackward0>))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(img[:,  :,  :2,  :2] * conv.weight.data).sum()+conv.bias.data, conv(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7829de3b-8838-4d76-9b31-105b640592f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.4760]),\n",
       " tensor([[[[-0.3077, -0.4760],\n",
       "           [ 0.0550, -0.0650]]]], grad_fn=<ConvolutionBackward0>))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(img[:,  :,  :2,  2:] * conv.weight.data).sum()+conv.bias.data, conv(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eda894f1-a747-405f-a175-4ad30951d666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0550]),\n",
       " tensor([[[[-0.3077, -0.4760],\n",
       "           [ 0.0550, -0.0650]]]], grad_fn=<ConvolutionBackward0>))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(img[:,  :,  2:,  :2] * conv.weight.data).sum()+conv.bias.data, conv(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8569a21b-051c-443a-a0c0-2bd3aef5753f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0650]),\n",
       " tensor([[[[-0.3077, -0.4760],\n",
       "           [ 0.0550, -0.0650]]]], grad_fn=<ConvolutionBackward0>))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(img[:,  :,  2:,  2:] * conv.weight.data).sum()+conv.bias.data, conv(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
