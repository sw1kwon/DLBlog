<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="sw1kwon">
<meta name="dcterms.date" content="2025-05-19">

<title>11wk-2: (순환신경망) – abc, abcd, 임베딩 공간의 이해, AbAcAd, 겹장(덧장) – DeepLearning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-0626ff4d7a71b55c8707dcae1d04a9b6.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-3f453be5ec2ee49e579b43b94346acdb.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">DeepLearning</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">11wk-2: (순환신경망) – <code>abc</code>, <code>abcd</code>, 임베딩 공간의 이해, <code>AbAcAd</code>, 겹장(덧장)</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>sw1kwon </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">May 19, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#강의노트-원본-및-영상-링크" id="toc-강의노트-원본-및-영상-링크" class="nav-link active" data-scroll-target="#강의노트-원본-및-영상-링크">1. 강의노트 원본 및 영상 링크 📝</a></li>
  <li><a href="#imports" id="toc-imports" class="nav-link" data-scroll-target="#imports">2. Imports 📝</a></li>
  <li><a href="#예비학습" id="toc-예비학습" class="nav-link" data-scroll-target="#예비학습">3. 예비학습 📝</a>
  <ul class="collapse">
  <li><a href="#a.-tanh" id="toc-a.-tanh" class="nav-link" data-scroll-target="#a.-tanh">A. <code>tanh</code></a></li>
  <li><a href="#b.-softmax" id="toc-b.-softmax" class="nav-link" data-scroll-target="#b.-softmax">B. <code>softmax</code></a></li>
  </ul></li>
  <li><a href="#abc" id="toc-abc" class="nav-link" data-scroll-target="#abc">4. <code>abc</code> 📝</a>
  <ul class="collapse">
  <li><a href="#a.-data" id="toc-a.-data" class="nav-link" data-scroll-target="#a.-data">A. Data</a></li>
  <li><a href="#b.-mlp-하나의-은닉노드" id="toc-b.-mlp-하나의-은닉노드" class="nav-link" data-scroll-target="#b.-mlp-하나의-은닉노드">B. MLP – 하나의 은닉노드</a></li>
  <li><a href="#c.-mlp-두개의-은닉노드" id="toc-c.-mlp-두개의-은닉노드" class="nav-link" data-scroll-target="#c.-mlp-두개의-은닉노드">C. MLP – 두개의 은닉노드</a></li>
  </ul></li>
  <li><a href="#abcd" id="toc-abcd" class="nav-link" data-scroll-target="#abcd">5. <code>abcd</code> 📝</a>
  <ul class="collapse">
  <li><a href="#a.-data-1" id="toc-a.-data-1" class="nav-link" data-scroll-target="#a.-data-1">A. Data</a></li>
  <li><a href="#b.-mlp-하나의-은닉노드-1" id="toc-b.-mlp-하나의-은닉노드-1" class="nav-link" data-scroll-target="#b.-mlp-하나의-은닉노드-1">B. MLP – 하나의 은닉노드</a></li>
  <li><a href="#c.-mlp-두개의-은닉노드-1" id="toc-c.-mlp-두개의-은닉노드-1" class="nav-link" data-scroll-target="#c.-mlp-두개의-은닉노드-1">C. MLP – 두개의 은닉노드</a></li>
  <li><a href="#d.-비교실험" id="toc-d.-비교실험" class="nav-link" data-scroll-target="#d.-비교실험">D. 비교실험</a></li>
  </ul></li>
  <li><a href="#boldsymbol-h-에-대하여-starstarstar" id="toc-boldsymbol-h-에-대하여-starstarstar" class="nav-link" data-scroll-target="#boldsymbol-h-에-대하여-starstarstar">6. <span class="math inline">\({\boldsymbol h}\)</span> 에 대하여 (<span class="math inline">\(\star\star\star\)</span>) 📝</a></li>
  <li><a href="#abacad-실패" id="toc-abacad-실패" class="nav-link" data-scroll-target="#abacad-실패">7. <code>AbAcAd</code> – 실패 📝</a>
  <ul class="collapse">
  <li><a href="#a.-data-2" id="toc-a.-data-2" class="nav-link" data-scroll-target="#a.-data-2">A. Data</a></li>
  <li><a href="#b.-mlp-두개의-은닉노드-실패" id="toc-b.-mlp-두개의-은닉노드-실패" class="nav-link" data-scroll-target="#b.-mlp-두개의-은닉노드-실패">B. MLP – 두개의 은닉노드 (실패)</a></li>
  <li><a href="#c.-discussions" id="toc-c.-discussions" class="nav-link" data-scroll-target="#c.-discussions">C. Discussions</a></li>
  </ul></li>
  <li><a href="#겹장덧장" id="toc-겹장덧장" class="nav-link" data-scroll-target="#겹장덧장">8. 겹장(덧장) 📝</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>📘 <strong>Note Format Guide</strong></p>
<p>This format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 15%">
<col style="width: 42%">
<col style="width: 42%">
</colgroup>
<thead>
<tr class="header">
<th>Type</th>
<th>What It Means</th>
<th>When I Use It</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>📝 Lecture</td>
<td>Original material from the professor’s notes</td>
<td>When I’m referencing core concepts or provided code</td>
</tr>
<tr class="even">
<td>🗣️ In-Class Note</td>
<td>Verbal explanations shared during the lecture</td>
<td>When I want to record something the professor said in class but didn’t include in the official notes</td>
</tr>
<tr class="odd">
<td>✍️ My Note</td>
<td>My thoughts, interpretations, or additional explanations</td>
<td>When I reflect on or explain something in my own words</td>
</tr>
<tr class="even">
<td>🔬 Experiment</td>
<td>Code I tried out or changed to explore further</td>
<td>When I test variations or go beyond the original example</td>
</tr>
<tr class="odd">
<td>❓ Question</td>
<td>Questions I had while studying</td>
<td>When I want to revisit or research something more deeply</td>
</tr>
</tbody>
</table>
<p>📝 🗣️ ✍️ 🔬 ❓</p>
<section id="강의노트-원본-및-영상-링크" class="level1">
<h1>1. 강의노트 원본 및 영상 링크 📝</h1>
<p><a href="https://guebin.github.io/DL2025/posts/11wk-2.html">https://guebin.github.io/DL2025/posts/11wk-2.html</a></p>
</section>
<section id="imports" class="level1">
<h1>2. Imports 📝</h1>
<div id="4d6ef052-5169-45c9-9087-74dc7215d78e" class="cell" data-tags="[]" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="예비학습" class="level1">
<h1>3. 예비학습 📝</h1>
<p>🗣️(</p>
<pre><code>추천시스템
--(1) MF-based: SVD(행렬분해)  overfit, underfit에서 조금 자유로움 (표현력이 거의 무한대)
--(2) NN-based:               overfit, underfit 조정 필요</code></pre>
<p>)🗣️</p>
<section id="a.-tanh" class="level2">
<h2 class="anchored" data-anchor-id="a.-tanh">A. <code>tanh</code></h2>
<p>🗣️(</p>
<ul>
<li>활성화 함수
<ul>
<li>출력이 -1 ~ 1 =&gt; 반대 느낌을 해석 가능 (-1, 1)</li>
<li>(Sigmoid: 0 ~ 1) =&gt; 확률로 해석 가능</li>
</ul></li>
</ul>
<p>)🗣️</p>
<div id="9b32eeb1-a325-48b5-b2dc-58763fd0d463" class="cell" data-execution_count="84">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.linspace(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>,<span class="dv">1001</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>tanh <span class="op">=</span> torch.nn.Tanh()</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>plt.plot(x,tanh(x).data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11wk-2_files/figure-html/cell-3-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="b.-softmax" class="level2">
<h2 class="anchored" data-anchor-id="b.-softmax">B. <code>softmax</code></h2>
<p>🗣️(</p>
<ul>
<li>활성화 함수
<ul>
<li>logit을 가지고 실질적인 prob로 바꾸는 함수</li>
<li>참고
<ul>
<li>y가 2개의 클래스가 아니라 여러 개의 클래스를 갖고 있을 때</li>
<li>binary cross entropy를 쓰지 않고 cross entropy를 사용</li>
</ul></li>
</ul></li>
</ul>
<div id="c1df2de1-87bd-4127-95de-f0862854407c" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>logits <span class="op">=</span> torch.randn((<span class="dv">10</span>,<span class="dv">5</span>))</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>logits</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>tensor([[-1.2261,  0.4259, -0.1552,  0.1053, -0.7315],
        [ 0.1195, -1.2003,  0.0711, -0.4024,  0.0612],
        [ 1.6710, -0.1026,  0.0664, -1.9638, -1.5250],
        [-0.1543, -0.4821, -0.2287, -0.4783, -1.5374],
        [ 0.0277, -1.7424,  1.6880, -1.5535, -0.9432],
        [-1.4717,  1.1867,  0.6488,  1.0316,  0.1506],
        [-0.6202, -1.4209, -0.3404,  0.7866, -0.4144],
        [-0.7437, -1.8049, -1.8204,  0.1902, -1.0927],
        [-0.6898, -0.6155, -1.4422, -1.6997,  2.8129],
        [ 0.5973, -2.2392, -0.3642,  1.2237,  1.0233]])</code></pre>
</div>
</div>
<div id="945f6ac1-16e5-4624-b7e0-5faefd73049f" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>probs <span class="op">=</span> torch.nn.functional.softmax(logits,dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>probs <span class="co"># 확률값이 나옴</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>tensor([[0.0687, 0.3583, 0.2004, 0.2600, 0.1126],
        [0.2662, 0.0711, 0.2536, 0.1580, 0.2511],
        [0.6954, 0.1180, 0.1398, 0.0184, 0.0285],
        [0.2760, 0.1989, 0.2562, 0.1996, 0.0692],
        [0.1425, 0.0243, 0.7499, 0.0293, 0.0540],
        [0.0245, 0.3490, 0.2038, 0.2989, 0.1238],
        [0.1237, 0.0556, 0.1637, 0.5051, 0.1520],
        [0.2026, 0.0701, 0.0690, 0.5154, 0.1429],
        [0.0277, 0.0298, 0.0130, 0.0101, 0.9194],
        [0.2065, 0.0121, 0.0789, 0.3863, 0.3162]])</code></pre>
</div>
</div>
<ul>
<li>가로로 더하면 1</li>
</ul>
<div id="ed841c2f-956d-4add-8c3c-acb67d99039b" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>probs <span class="op">=</span> torch.nn.functional.softmax(logits,dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>probs <span class="co"># 세로로 더하면 1 (참고)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>tensor([[0.0241, 0.1949, 0.0663, 0.0886, 0.0201],
        [0.0925, 0.0383, 0.0831, 0.0533, 0.0444],
        [0.4364, 0.1149, 0.0827, 0.0112, 0.0091],
        [0.0703, 0.0786, 0.0616, 0.0494, 0.0090],
        [0.0844, 0.0223, 0.4186, 0.0169, 0.0162],
        [0.0188, 0.4170, 0.1481, 0.2236, 0.0485],
        [0.0441, 0.0307, 0.0551, 0.1750, 0.0276],
        [0.0390, 0.0209, 0.0125, 0.0964, 0.0140],
        [0.0412, 0.0688, 0.0183, 0.0146, 0.6951],
        [0.1491, 0.0136, 0.0538, 0.2710, 0.1161]])</code></pre>
</div>
</div>
<p>)🗣️</p>
<div id="36ffcaea-67f9-445e-9bd4-9d35a41f8d31" class="cell" data-execution_count="86">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>logits <span class="op">=</span> torch.randn((<span class="dv">10</span>,<span class="dv">5</span>))</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>logits</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="86">
<pre><code>tensor([[ 0.6408, -0.2422,  1.3521,  1.1399, -0.3036],
        [-0.5242, -0.3710, -0.3861, -0.5475,  3.1393],
        [ 0.5174, -1.3213,  3.1802, -0.6713,  0.5917],
        [ 0.0931,  1.0697,  0.6469, -1.1904, -0.1057],
        [-1.3722,  0.4665, -0.7705, -0.6630, -1.1054],
        [ 1.2289,  1.4994, -0.9319,  0.8154, -0.2033],
        [-0.3431,  0.3966, -0.9672, -1.6696,  0.7154],
        [ 0.4969, -0.6918,  1.1579, -2.4760,  0.1766],
        [ 0.8880, -0.0768,  1.5095, -0.2842,  0.4944],
        [ 0.2732, -2.0850, -0.5531,  0.1073, -0.1218]])</code></pre>
</div>
</div>
<div id="fb1f7e14-aa94-4c67-8009-6a79ed3f8647" class="cell" data-execution_count="89">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>probs <span class="op">=</span> torch.nn.functional.softmax(logits,dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>probs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="89">
<pre><code>tensor([[0.1823, 0.0754, 0.3712, 0.3002, 0.0709],
        [0.0231, 0.0269, 0.0265, 0.0226, 0.9009],
        [0.0593, 0.0094, 0.8494, 0.0181, 0.0638],
        [0.1540, 0.4090, 0.2680, 0.0427, 0.1263],
        [0.0803, 0.5050, 0.1466, 0.1632, 0.1049],
        [0.3007, 0.3941, 0.0346, 0.1988, 0.0718],
        [0.1475, 0.3091, 0.0790, 0.0392, 0.4252],
        [0.2489, 0.0758, 0.4820, 0.0127, 0.1807],
        [0.2366, 0.0901, 0.4404, 0.0733, 0.1596],
        [0.3275, 0.0310, 0.1434, 0.2775, 0.2206]])</code></pre>
</div>
</div>
</section>
</section>
<section id="abc" class="level1">
<h1>4. <code>abc</code> 📝</h1>
<p>🗣️(</p>
<pre><code>a b c a b c a b c a ???
단어1 단어2 단어3 ... ....... ???
이런 것을 맞추고 싶음

회귀분석: X, y가 아주 명확
이미지자료분석: X가 복잡해도 X로 y를 clear하게 맞출 수 있음
추천시스템: 회귀분석과 비슷한 setting으로 바꿀 수 있음
abcabc: 억지로 X, y로 만들 수 있음
a 입력 b 출력, b 입력 c 출력 ...
"b" &lt;--- net("a")
"c" &lt;--- net("b")

다음과 같이 데이터 정리 가능
X y
a b
b c
c a
a b
...
...
항상 X가 먼저 나오므로 X를 이전 시점, y를 다음 시점으로 볼 수도 있음

참고)
통계학: AR 모형
텍스트 마이닝``
a b c a b c a b c a ???
단어1 단어2 단어3 ... ....... ???
이런 것을 맞추고 싶음

회귀분석: X, y가 아주 명확
이미지자료분석: X가 복잡해도 X로 y를 clear하게 맞출 수 있음
추천시스템: 회귀분석과 비슷한 setting으로 바꿀 수 있음
abcabc: 억지로 X, y로 만들 수 있음
a 입력 b 출력, b 입력 c 출력 ...
"b" &lt;--- net("a")
"c" &lt;--- net("b")

다음과 같이 데이터 정리 가능
X y
a b
b c
c a
a b
...
...
항상 X가 먼저 나오므로 X를 이전 시점, y를 다음 시점으로 볼 수도 있음

기존 데이터를 쪼개서 과거의 내가 미래의 나를 맞추게 함

참고)
통계학: AR 모형
텍스트 마이닝: N-gram</code></pre>
<p>)🗣️</p>
<section id="a.-data" class="level2">
<h2 class="anchored" data-anchor-id="a.-data">A. Data</h2>
<div id="1d6ec4ae-6122-4e52-b852-c44fe4f12e4a" class="cell" data-tags="[]" data-execution_count="7">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>txt <span class="op">=</span> <span class="bu">list</span>(<span class="st">'abc'</span><span class="op">*</span><span class="dv">100</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>txt[:<span class="dv">10</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>['a', 'b', 'c', 'a', 'b', 'c', 'a', 'b', 'c', 'a']</code></pre>
</div>
</div>
<div id="685a44dd-27b6-427a-b6f1-7c18f9a5765f" class="cell" data-tags="[]" data-execution_count="8">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>df_train <span class="op">=</span> pd.DataFrame({<span class="st">'x'</span>: txt[:<span class="op">-</span><span class="dv">1</span>], <span class="st">'y'</span>: txt[<span class="dv">1</span>:]})</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>df_train[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">x</th>
<th data-quarto-table-cell-role="th">y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>a</td>
<td>b</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>b</td>
<td>c</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>c</td>
<td>a</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>a</td>
<td>b</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>b</td>
<td>c</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="afe1e823-016b-447a-84f7-1a59ba848a6d" class="cell" data-tags="[]" data-execution_count="9">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor(df_train.x.<span class="bu">map</span>({<span class="st">'a'</span>:<span class="dv">0</span>,<span class="st">'b'</span>:<span class="dv">1</span>,<span class="st">'c'</span>:<span class="dv">2</span>}))</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.tensor(df_train.y.<span class="bu">map</span>({<span class="st">'a'</span>:<span class="dv">0</span>,<span class="st">'b'</span>:<span class="dv">1</span>,<span class="st">'c'</span>:<span class="dv">2</span>}))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="9fd3bffb-ba32-46e0-b372-91314e6f93f0" class="cell" data-execution_count="101">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># x,y </span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 원래는 이 형식이 틀림</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 그런데 y는 onehot 안해도 알아서 토치에서 해주므로 length-n 벡터형태로 정리해도 무방</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 그리고 x는 onehot+linr를 쓰지않고 임베딩을 쓰려고 마음먹었으면 length-n 벡터형태로 정리해도 무방</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>🗣️(</p>
<div id="f02bd95a-83e4-4c3f-8c3e-622e44464465" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>tensor([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2,
        0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2,
        0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2,
        0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2,
        0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2,
        0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2,
        0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2,
        0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2,
        0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2,
        0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2,
        0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2,
        0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2,
        0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1])</code></pre>
</div>
</div>
<div id="2da82fe3-f36d-4516-89b7-cf195bf49909" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>y</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>tensor([1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,
        1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,
        1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,
        1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,
        1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,
        1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,
        1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,
        1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,
        1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,
        1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,
        1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,
        1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,
        1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2])</code></pre>
</div>
</div>
<p>)🗣️</p>
</section>
<section id="b.-mlp-하나의-은닉노드" class="level2">
<h2 class="anchored" data-anchor-id="b.-mlp-하나의-은닉노드">B. MLP – 하나의 은닉노드</h2>
<p>🗣️(</p>
<pre><code>X --- hidden layer ---&gt; y
nx3 --  nx1  -- nx3

1인 이유: hidden node의 수를 가능한 작게 만들고 싶음
첫번째(3-&gt;1) linear transform (embedding)
두번째(1-&gt;3) linear transform을 연속으로 하면 표현력에 문제가 생기므로
중간에 비선형 변환 (보통은 ReLU를 쓰나 여기서는 Tanh)
</code></pre>
<div id="420b1ab7-4509-4211-bf8a-73330c7eaf2e" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>    torch.nn.Embedding(num_embeddings<span class="op">=</span><span class="dv">3</span>, embedding_dim<span class="op">=</span><span class="dv">1</span>), <span class="co"># one hot + linear</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.Tanh(), <span class="co"># 출력이 -1~1이면 문자 등을 표현할 때 좋다고 하고 일단 넘어감</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">1</span>,<span class="dv">3</span>)</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss() <span class="co"># logit을 받는다는 의미 (net 마지막에 softmax 없어도 됨)</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters(),lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 복잡하게 하려면 network 모드도 바꾸고 batch도 만들 수 있으나 데이터가 단순하여 간단하게 해도 잘 맞음</span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a><span class="co">#---#</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">#1 </span></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>    netout <span class="op">=</span> net(x) <span class="co"># logit</span></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">#2 </span></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(netout,y)</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>    <span class="co">#3</span></span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>    <span class="co">#4</span></span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="c4a1c8e0-a649-47f1-9636-7ac46825f2a5" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># netout # logit 값</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="176c286f-6fea-4a71-9f43-0bb0979eebe3" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># netout.argmax(axis=1) # y에 대한 예측을 보려면</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="30081e38-54f0-47de-98cf-c93146b590ee" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>netout.argmax(axis<span class="op">=</span><span class="dv">1</span>)[:<span class="dv">5</span>], y[:<span class="dv">5</span>] <span class="co"># 실제 y와 비교</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>(tensor([1, 2, 0, 1, 2]), tensor([1, 2, 0, 1, 2]))</code></pre>
</div>
</div>
<ul>
<li>다 맞추는데 진짜 학습이 잘 되었을까?</li>
</ul>
<p>)🗣️</p>
<p><code>-</code> 적합</p>
<div id="69d9751f-3847-4136-b449-383c1b695ea1" class="cell" data-execution_count="140">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.Embedding(num_embeddings<span class="op">=</span><span class="dv">3</span>, embedding_dim<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>    torch.nn.Tanh(), </span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">1</span>,<span class="dv">3</span>)</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters(),lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a><span class="co">#---#</span></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">#1 </span></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>    netout <span class="op">=</span> net(x)</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">#2 </span></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(netout,y)</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">#3</span></span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>    <span class="co">#4</span></span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="b2f77bac-f478-4fea-908e-c49f3b71829b" class="cell" data-execution_count="141">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>netout.argmax(axis<span class="op">=</span><span class="dv">1</span>)[:<span class="dv">5</span>], y[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="141">
<pre><code>(tensor([1, 2, 0, 1, 2]), tensor([1, 2, 0, 1, 2]))</code></pre>
</div>
</div>
<p><code>-</code> 결과시각화</p>
<p>🗣️(</p>
<div id="35c3020a-5abe-4164-b3f5-a28e66fdea65" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>net <span class="co"># Embedding도 쪼개려면 one hot + linear로 할 수 있지만 하나로 치면</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>Sequential(
  (0): Embedding(3, 1)
  (1): Tanh()
  (2): Linear(in_features=1, out_features=3, bias=True)
)</code></pre>
</div>
</div>
<div id="19ab835f-f3f7-41d1-b763-c165e9a3356b" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>ebdd <span class="op">=</span> net[<span class="dv">0</span>]</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>tanh <span class="op">=</span> net[<span class="dv">1</span>]</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> net[<span class="dv">2</span>]</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="co"># ebdd,tanh,linr = net 동일</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="d1a6c643-a3b4-48df-939d-5cfcb8b3560d" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>linr(tanh(ebdd(x))).data[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>tensor([[-5.4318,  2.8601,  0.9936],
        [-0.7939, -0.4841,  1.2590],
        [ 3.9698, -3.9191,  1.5316],
        [-5.4318,  2.8601,  0.9936],
        [-0.7939, -0.4841,  1.2590]])</code></pre>
</div>
</div>
<div id="750de8e7-a2d1-47b5-8e3b-5ef79f8d5945" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>net(x).data[:<span class="dv">5</span>] <span class="co"># 위와 동일</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>tensor([[-5.4318,  2.8601,  0.9936],
        [-0.7939, -0.4841,  1.2590],
        [ 3.9698, -3.9191,  1.5316],
        [-5.4318,  2.8601,  0.9936],
        [-0.7939, -0.4841,  1.2590]])</code></pre>
</div>
</div>
<div id="ef706343-ba70-42f7-9851-ecf55d367c7e" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ebdd(x) # n x 1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="2a7ae8ba-434c-44b5-ba36-273f635d9c18" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># tanh(ebdd(x)) # 출력이 -1 ~ 1로 눌림</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="673310e6-963f-4b96-910b-d74532dd6246" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> tanh(ebdd(x)) <span class="co"># hidden</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="33c52862-91e5-49cd-9ff6-c054b3a1e947" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># torch.nn.functional.one_hot(x) # n x 3, 사실은 이게 x</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="4bc243c8-f7de-4bd5-bf97-ce988275770e" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.nn.functional.one_hot(x) <span class="co"># X라고 하면</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> tanh(ebdd(x)) <span class="co"># tanh(linr(X))와 동일</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="6a0b9a03-5a97-425f-b04c-85845301d209" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>X.shape, h.shape <span class="co"># 이 둘을 합치면</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>(torch.Size([299, 3]), torch.Size([299, 1]))</code></pre>
</div>
</div>
<div id="bfb165c0-0586-4f21-a6d2-64951a234296" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.nn.functional.one_hot(x)</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> tanh(ebdd(x))</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>mat <span class="op">=</span> torch.concat([X,h], axis<span class="op">=</span><span class="dv">1</span>).data</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="d26dd51a-f3a9-40ef-812a-a05ba29f4f0a" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>mat.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>torch.Size([299, 4])</code></pre>
</div>
</div>
<div id="8e23bd81-e17b-4c36-95ed-2c814e3415c8" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>mat[:<span class="dv">8</span>,:].shape <span class="co"># mat[:8]과 동일</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>torch.Size([8, 4])</code></pre>
</div>
</div>
<div id="2db8bf31-9281-4ff8-99ac-fcac118c9920" class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.nn.functional.one_hot(x)</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> tanh(ebdd(x))</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>mat <span class="op">=</span> torch.concat([X,h], axis<span class="op">=</span><span class="dv">1</span>).data</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>mat[:<span class="dv">8</span>] <span class="co"># column0~2: 입력 / column3: 결과</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>tensor([[ 1.0000,  0.0000,  0.0000, -0.9840],
        [ 0.0000,  1.0000,  0.0000, -0.0065],
        [ 0.0000,  0.0000,  1.0000,  0.9976],
        [ 1.0000,  0.0000,  0.0000, -0.9840],
        [ 0.0000,  1.0000,  0.0000, -0.0065],
        [ 0.0000,  0.0000,  1.0000,  0.9976],
        [ 1.0000,  0.0000,  0.0000, -0.9840],
        [ 0.0000,  1.0000,  0.0000, -0.0065]])</code></pre>
</div>
</div>
<div id="8fae9c80-3dd9-47a4-af89-642448e13fe2" class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(mat[:<span class="dv">8</span>])</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11wk-2_files/figure-html/cell-35-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="d36e870a-0e28-45dd-b98c-d7e45863777a" class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(mat[:<span class="dv">6</span>], vmin<span class="op">=-</span><span class="dv">1</span>, vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11wk-2_files/figure-html/cell-36-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="3d228d42-7cda-4319-90b6-fecb563968d4" class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>plt.matshow(mat[:<span class="dv">6</span>], vmin<span class="op">=-</span><span class="dv">1</span>, vmax<span class="op">=</span><span class="dv">1</span>, cmap<span class="op">=</span><span class="st">"bwr"</span>)</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11wk-2_files/figure-html/cell-37-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>해석
<ul>
<li>X(col0~2)는 one hot encoding 되어 있음 (-1 불가)</li>
<li>h는 -1, 0, 1로 나옴</li>
</ul></li>
<li>h가 yhat으로 나가는 과정</li>
</ul>
<div id="1572348a-f185-438f-9c22-b878ed1c1579" class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.nn.functional.one_hot(x)</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> tanh(ebdd(x))</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>netout <span class="op">=</span> linr(h) <span class="co"># net(x)와 동일</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="b9f4360c-2231-4276-83ab-fa0d1c4ab672" class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># netout # logit , n x 3</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="05fb633f-de78-42a2-a61b-34f71adc0eec" class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>netout.<span class="bu">max</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="44">
<pre><code>tensor(3.9698, grad_fn=&lt;MaxBackward1&gt;)</code></pre>
</div>
</div>
<ul>
<li>시각화를 위해 max로 나누면 (누르는 효과)</li>
</ul>
<div id="af1054bd-45c3-49a7-96ea-af138b3036f0" class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="co"># netout/netout.max()</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="b815c3e4-0a0b-431d-8884-e0cb0695c246" class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>mat <span class="op">=</span> torch.concat([X,h, netout<span class="op">/</span>netout.<span class="bu">max</span>()], axis<span class="op">=</span><span class="dv">1</span>).data</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>plt.matshow(mat[:<span class="dv">6</span>], vmin<span class="op">=-</span><span class="dv">1</span>, vmax<span class="op">=</span><span class="dv">1</span>, cmap<span class="op">=</span><span class="st">"bwr"</span>)</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11wk-2_files/figure-html/cell-42-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>해석
<ul>
<li>col 0~2: X</li>
<li>col 3: h</li>
<li>col 4~6: netout = logits
<ul>
<li>빨간 값이 제일 큼 (최댓값으로 나눴기 때문에)</li>
<li>첫번째 경우(a): 0 1 0 =&gt; b</li>
<li>두번째 경우(b): c</li>
<li>세번째 경우(c): a</li>
</ul></li>
<li>weight가 잘 맞춰져서 y가 그럴듯하게 나오고 있음</li>
</ul></li>
<li>yhat을 구하려면</li>
</ul>
<div id="767332a3-e8d5-46fa-b8ac-bd52ab55e811" class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.nn.functional.one_hot(x)</span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> tanh(ebdd(x))</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>netout <span class="op">=</span> logits <span class="op">=</span> linr(h)</span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> torch.nn.functional.softmax(netout,dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a>mat <span class="op">=</span> torch.concat([X,h,netout<span class="op">/</span>netout.<span class="bu">max</span>(),yhat],axis<span class="op">=</span><span class="dv">1</span>).data</span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a>plt.matshow(mat[:<span class="dv">6</span>], vmin<span class="op">=-</span><span class="dv">1</span>, vmax<span class="op">=</span><span class="dv">1</span>, cmap<span class="op">=</span><span class="st">"bwr"</span>)</span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11wk-2_files/figure-html/cell-43-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>해석
<ul>
<li>col 0~2: X</li>
<li>col 3: h</li>
<li>col 4~6: netout = logits</li>
<li>col 7~9: 확률값 (파란색 불가)
<ul>
<li>7: a라고 예측할 확률</li>
<li>8: b라고 예측할 확률</li>
<li>9: c라고 예측할 확률</li>
</ul></li>
<li>예측이 잘 되어 있는 것 같은데 확률값이 어떻게 나와있나보면
<ul>
<li>빨간색을 제외한 부분이 0이 아닌 경우도 있어 여지가 생김</li>
</ul></li>
<li>logits을 살펴보면
<ul>
<li>4: a 구분 (나쁘지 않음)</li>
<li>파란색 (a 아님) 흰색 (모름) 빨간색 (a 맞음)</li>
<li>5: b 구분 (나쁘지 않음)</li>
<li>6: c 구분 (파란색이 없어서 구분이 애매함)</li>
</ul></li>
<li>4,5,6을 같이보면
<ul>
<li>c의 경우는 애매한 결과만 나옴</li>
<li>row1의 경우 4,5가 ?이기 때문에 결과적으로 c가 나옴</li>
<li>row2의 경우 b는 절대 아님, a가 c보다 강함</li>
</ul></li>
<li>c는 객관식을 맞추는 느낌</li>
<li>a,b는 정확하게 판단</li>
</ul></li>
</ul>
<div id="473897f4-5057-4b6e-b99f-3442a81204b3" class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.Embedding(num_embeddings<span class="op">=</span><span class="dv">3</span>, embedding_dim<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a>    torch.nn.Tanh(), </span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">1</span>,<span class="dv">3</span>)</span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters(),lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a><span class="co">#---#</span></span>
<span id="cb64-10"><a href="#cb64-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb64-11"><a href="#cb64-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">#1 </span></span>
<span id="cb64-12"><a href="#cb64-12" aria-hidden="true" tabindex="-1"></a>    netout <span class="op">=</span> net(x)</span>
<span id="cb64-13"><a href="#cb64-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">#2 </span></span>
<span id="cb64-14"><a href="#cb64-14" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(netout,y)</span>
<span id="cb64-15"><a href="#cb64-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">#3</span></span>
<span id="cb64-16"><a href="#cb64-16" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb64-17"><a href="#cb64-17" aria-hidden="true" tabindex="-1"></a>    <span class="co">#4</span></span>
<span id="cb64-18"><a href="#cb64-18" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb64-19"><a href="#cb64-19" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="3e6ece9e-d179-46e5-b84a-e453806a4e18" class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>ebdd,tanh,linr <span class="op">=</span> net</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="43088bcf-9c2e-4165-9e93-611dea9d3fd1" class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.nn.functional.one_hot(x)</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> tanh(ebdd(x))</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>netout <span class="op">=</span> logits <span class="op">=</span> linr(h)</span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> torch.nn.functional.softmax(netout,dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a>mat <span class="op">=</span> torch.concat([X,h,netout<span class="op">/</span>netout.<span class="bu">max</span>(),yhat],axis<span class="op">=</span><span class="dv">1</span>).data</span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a>plt.matshow(mat[:<span class="dv">6</span>], vmin<span class="op">=-</span><span class="dv">1</span>, vmax<span class="op">=</span><span class="dv">1</span>, cmap<span class="op">=</span><span class="st">"bwr"</span>)</span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">2.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb66-9"><a href="#cb66-9" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">3.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb66-10"><a href="#cb66-10" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">6.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb66-11"><a href="#cb66-11" aria-hidden="true" tabindex="-1"></a>plt.xticks(ticks<span class="op">=</span>[<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">9</span>],labels<span class="op">=</span>[<span class="vs">r"$x_a$"</span>,<span class="vs">r"$x_b$"</span>,<span class="vs">r"$x_c$"</span>,<span class="vs">r"$h$"</span>,<span class="vs">r"$out_a$"</span>,<span class="vs">r"$out_b$"</span>,<span class="vs">r"$out_c$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_a$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_b$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_c$"</span>])<span class="op">;</span></span>
<span id="cb66-12"><a href="#cb66-12" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/tmp/ipykernel_2844881/1114894007.py:12: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11wk-2_files/figure-html/cell-46-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<pre><code>col6의 경우 애매함 (맞춰도 객관식 소거법 같은 방식)

이유? h (col4)가 0인 경우가 있음
col 5~7 : h(col4) * weight + bias
그러나 h 가 0이면 weight가 의미가 없음 (network 표현력의 핵심은 weight)

h가 1, -1, 0으로 나올 수 밖에 없는 이유?
a,b,c 3개를 표현해야하는데 -1(a) ,1(c) 은 이미 있으므로 하나(b)는 0을 할 수 밖에 없음 (-1 및 1과 구분하려면)
다른 조합도 마찬가지

해결책?
h를 하나 더 만들면 됨 (node를 2개 사용)</code></pre>
<p>)🗣️</p>
<div id="fb62250c-51b1-4003-ad7d-70719ecc0d45" class="cell" data-execution_count="142">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>ebdd,tanh,linr <span class="op">=</span> net</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="0d405311-b184-4313-b097-df13c4a528c6" class="cell" data-execution_count="143">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.nn.functional.one_hot(x)</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> tanh(ebdd(x))</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a>netout <span class="op">=</span> logits <span class="op">=</span> linr(h)</span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> torch.nn.functional.softmax(netout,dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a>mat <span class="op">=</span> torch.concat([X,h,netout<span class="op">/</span>netout.<span class="bu">max</span>(),yhat],axis<span class="op">=</span><span class="dv">1</span>).data</span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a>plt.matshow(mat[:<span class="dv">6</span>], vmin<span class="op">=-</span><span class="dv">1</span>, vmax<span class="op">=</span><span class="dv">1</span>, cmap<span class="op">=</span><span class="st">"bwr"</span>)</span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">2.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">3.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb70-10"><a href="#cb70-10" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">6.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb70-11"><a href="#cb70-11" aria-hidden="true" tabindex="-1"></a>plt.xticks(ticks<span class="op">=</span>[<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">9</span>],labels<span class="op">=</span>[<span class="vs">r"$x_a$"</span>,<span class="vs">r"$x_b$"</span>,<span class="vs">r"$x_c$"</span>,<span class="vs">r"$h$"</span>,<span class="vs">r"$out_a$"</span>,<span class="vs">r"$out_b$"</span>,<span class="vs">r"$out_c$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_a$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_b$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_c$"</span>])<span class="op">;</span></span>
<span id="cb70-12"><a href="#cb70-12" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/tmp/ipykernel_906200/1114894007.py:12: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11wk-2_files/figure-html/cell-48-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><code>-</code> 시각화결과해석: 학습이 잘 된것 같지만 깔끔하지 않음.</p>
<ul>
<li>netout 을 보는 요령: 가장 빨간부분이 예측값이 된다.</li>
<li>문제1: <span class="math inline">\(out_b\)</span>의 경우 애매한 색깔만 있음. 네트워크가 정답을 잘 모른다는 의미.</li>
<li>문제1의 원인: <span class="math inline">\(out_b\)</span>의 경우에 대응하는 <span class="math inline">\({\boldsymbol h}\)</span>를 살펴보니 흰색임. 이것은 값이 0이라는 의미인데 이때는 <span class="math inline">\({\boldsymbol h}\)</span> 에 걸리는 선형변환 <span class="math inline">\(linr\)</span> 의 weight 가 의미없고 bias만 의미있기 때문에 특징을 잡기에 불리하다.</li>
<li>문제2: <span class="math inline">\({\boldsymbol h}\)</span>가 흰색이면(=0이 나오면) 불리하며, 확실한 색을 가지고 있는것이 유리함. 그렇지만 확실한 색인 빨강 파랑은 이미 차지된 상태라서 어쩔수 없이 흰색으로 선택된 것.</li>
<li>문제2를 해결하는 방법: <span class="math inline">\(a,b,c\)</span>라는 세문자를 표현하기에 <span class="math inline">\((-1,1)\)</span>사이의 숫자는 너무 불리함..</li>
</ul>
</section>
<section id="c.-mlp-두개의-은닉노드" class="level2">
<h2 class="anchored" data-anchor-id="c.-mlp-두개의-은닉노드">C. MLP – 두개의 은닉노드</h2>
<p>🗣️(</p>
<div id="8234591d-4fa4-43ec-84e1-e43e99777367" class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.Embedding(num_embeddings<span class="op">=</span><span class="dv">3</span>, embedding_dim<span class="op">=</span><span class="dv">2</span>),</span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a>    torch.nn.Tanh(), </span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">2</span>,<span class="dv">3</span>)</span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb72-7"><a href="#cb72-7" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb72-8"><a href="#cb72-8" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters(),lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb72-9"><a href="#cb72-9" aria-hidden="true" tabindex="-1"></a><span class="co">#---#</span></span>
<span id="cb72-10"><a href="#cb72-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb72-11"><a href="#cb72-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">#1 </span></span>
<span id="cb72-12"><a href="#cb72-12" aria-hidden="true" tabindex="-1"></a>    netout <span class="op">=</span> net(x)</span>
<span id="cb72-13"><a href="#cb72-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">#2 </span></span>
<span id="cb72-14"><a href="#cb72-14" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(netout,y)</span>
<span id="cb72-15"><a href="#cb72-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">#3</span></span>
<span id="cb72-16"><a href="#cb72-16" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb72-17"><a href="#cb72-17" aria-hidden="true" tabindex="-1"></a>    <span class="co">#4</span></span>
<span id="cb72-18"><a href="#cb72-18" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb72-19"><a href="#cb72-19" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="18ce67ae-09c3-4f9b-b11b-a4ec4b8d950e" class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>ebdd, tanh, linr <span class="op">=</span> net</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="f6571df5-8b53-4909-aa17-76d874dc48e1" class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.nn.functional.one_hot(x)</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> tanh(ebdd(x))</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>netout <span class="op">=</span> logits <span class="op">=</span> linr(h)</span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> torch.nn.functional.softmax(netout,dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a>mat <span class="op">=</span> torch.concat([X,h,netout<span class="op">/</span>netout.<span class="bu">max</span>(),yhat],axis<span class="op">=</span><span class="dv">1</span>).data</span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a>plt.matshow(mat[:<span class="dv">6</span>], vmin<span class="op">=-</span><span class="dv">1</span>, vmax<span class="op">=</span><span class="dv">1</span>, cmap<span class="op">=</span><span class="st">"bwr"</span>)</span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb74-8"><a href="#cb74-8" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">2.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb74-9"><a href="#cb74-9" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">4.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb74-10"><a href="#cb74-10" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">7.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb74-11"><a href="#cb74-11" aria-hidden="true" tabindex="-1"></a>plt.xticks(ticks<span class="op">=</span>[<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">9</span>,<span class="dv">10</span>],labels<span class="op">=</span>[<span class="vs">r"$x_a$"</span>, <span class="vs">r"$x_b$"</span>, <span class="vs">r"$x_c$"</span>,<span class="vs">r"$h_1$"</span>,<span class="vs">r"$h_2$"</span>,<span class="vs">r"$out_a$"</span>,<span class="vs">r"$out_b$"</span>,<span class="vs">r"$out_c$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y_a}</span><span class="vs">$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y_b}</span><span class="vs">$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y_c}</span><span class="vs">$"</span>])<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11wk-2_files/figure-html/cell-51-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>해석
<ul>
<li>깔끔하고 명확한 결과</li>
<li>X가 a일 경우: 파랑, 빨강</li>
<li>X가 b일 경우: 빨강, 파랑</li>
<li>X가 c일 경우: 빨강, 빨강</li>
<li>심지어 파랑, 파랑 매핑은 사용하지 않음</li>
</ul></li>
</ul>
<p>)🗣️</p>
<p><code>-</code> 적합</p>
<div id="0e5af920-af3c-4fb1-af9a-c704e2779c6e" class="cell" data-execution_count="144">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.Embedding(num_embeddings<span class="op">=</span><span class="dv">3</span>, embedding_dim<span class="op">=</span><span class="dv">2</span>),</span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a>    torch.nn.Tanh(), </span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">2</span>,<span class="dv">3</span>)</span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb75-8"><a href="#cb75-8" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters(),lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb75-9"><a href="#cb75-9" aria-hidden="true" tabindex="-1"></a><span class="co">#---#</span></span>
<span id="cb75-10"><a href="#cb75-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb75-11"><a href="#cb75-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">#1 </span></span>
<span id="cb75-12"><a href="#cb75-12" aria-hidden="true" tabindex="-1"></a>    netout <span class="op">=</span> net(x)</span>
<span id="cb75-13"><a href="#cb75-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">#2 </span></span>
<span id="cb75-14"><a href="#cb75-14" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(netout,y)</span>
<span id="cb75-15"><a href="#cb75-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">#3</span></span>
<span id="cb75-16"><a href="#cb75-16" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb75-17"><a href="#cb75-17" aria-hidden="true" tabindex="-1"></a>    <span class="co">#4</span></span>
<span id="cb75-18"><a href="#cb75-18" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb75-19"><a href="#cb75-19" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="722eba4f-f1f4-4f6e-899c-3210aac62e5f" class="cell" data-execution_count="145">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>netout.argmax(axis<span class="op">=</span><span class="dv">1</span>)[:<span class="dv">5</span>], y[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="145">
<pre><code>(tensor([1, 2, 0, 1, 2]), tensor([1, 2, 0, 1, 2]))</code></pre>
</div>
</div>
<p><code>-</code> 결과시각화</p>
<div id="3ee7b9e4-e285-477c-9145-a6d75c76496d" class="cell" data-execution_count="149">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a>ebdd, tanh, linr <span class="op">=</span> net </span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.nn.functional.one_hot(x)</span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> tanh(ebdd(x))</span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a>netout <span class="op">=</span> logits <span class="op">=</span> linr(h)</span>
<span id="cb78-5"><a href="#cb78-5" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> torch.nn.functional.softmax(netout,dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb78-6"><a href="#cb78-6" aria-hidden="true" tabindex="-1"></a>mat <span class="op">=</span> torch.concat([X,h,netout<span class="op">/</span>netout.<span class="bu">max</span>(),yhat],axis<span class="op">=</span><span class="dv">1</span>).data</span>
<span id="cb78-7"><a href="#cb78-7" aria-hidden="true" tabindex="-1"></a>plt.matshow(mat[:<span class="dv">6</span>], vmin<span class="op">=-</span><span class="dv">1</span>, vmax<span class="op">=</span><span class="dv">1</span>, cmap<span class="op">=</span><span class="st">"bwr"</span>)</span>
<span id="cb78-8"><a href="#cb78-8" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb78-9"><a href="#cb78-9" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">2.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb78-10"><a href="#cb78-10" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">4.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb78-11"><a href="#cb78-11" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">7.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb78-12"><a href="#cb78-12" aria-hidden="true" tabindex="-1"></a>plt.xticks(ticks<span class="op">=</span>[<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">9</span>,<span class="dv">10</span>],labels<span class="op">=</span>[<span class="vs">r"$x_a$"</span>, <span class="vs">r"$x_b$"</span>, <span class="vs">r"$x_c$"</span>,<span class="vs">r"$h_1$"</span>,<span class="vs">r"$h_2$"</span>,<span class="vs">r"$out_a$"</span>,<span class="vs">r"$out_b$"</span>,<span class="vs">r"$out_c$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y_a}</span><span class="vs">$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y_b}</span><span class="vs">$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y_c}</span><span class="vs">$"</span>])<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11wk-2_files/figure-html/cell-54-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><code>-</code> 시각화결과해석: 깔끔함. netout의 가장 빨간부분도 너무 명확함. <span class="math inline">\({\boldsymbol h}\)</span>가 0이 아닌 값으로 학습되어있음</p>
<ul>
<li>x=a <span class="math inline">\(\Rightarrow\)</span> h=(파,빨) <span class="math inline">\(\Rightarrow\)</span> y=b</li>
<li>x=b <span class="math inline">\(\Rightarrow\)</span> h=(빨,파) <span class="math inline">\(\Rightarrow\)</span> y=c</li>
<li>x=c <span class="math inline">\(\Rightarrow\)</span> h=(빨,빨) <span class="math inline">\(\Rightarrow\)</span> y=a</li>
<li>h = (파,파) 는 사용하지 않음. –&gt; 문자열 d를 하나 더 쓸수 있는 공간이 <span class="math inline">\(h\)</span>에 있다고 해석할 수 있음..</li>
</ul>
</section>
</section>
<section id="abcd" class="level1">
<h1>5. <code>abcd</code> 📝</h1>
<section id="a.-data-1" class="level2">
<h2 class="anchored" data-anchor-id="a.-data-1">A. Data</h2>
<div id="2e1d352e-9d02-47e2-a3d9-668102247735" class="cell" data-tags="[]" data-execution_count="60">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>txt <span class="op">=</span> <span class="bu">list</span>(<span class="st">'abcd'</span><span class="op">*</span><span class="dv">100</span>)</span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a>txt[:<span class="dv">10</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="60">
<pre><code>['a', 'b', 'c', 'd', 'a', 'b', 'c', 'd', 'a', 'b']</code></pre>
</div>
</div>
<div id="73a966dd-d3e8-420b-8404-088efbf97efc" class="cell" data-tags="[]" data-execution_count="61">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a>df_train <span class="op">=</span> pd.DataFrame({<span class="st">'x'</span>:txt[:<span class="op">-</span><span class="dv">1</span>], <span class="st">'y'</span>:txt[<span class="dv">1</span>:]})</span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a>df_train[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="61">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">x</th>
<th data-quarto-table-cell-role="th">y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>a</td>
<td>b</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>b</td>
<td>c</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>c</td>
<td>d</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>d</td>
<td>a</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>a</td>
<td>b</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="a5b20e3e-4ca9-48fa-9433-51658fbaca01" class="cell" data-tags="[]" data-execution_count="62">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor(df_train.x.<span class="bu">map</span>({<span class="st">'a'</span>:<span class="dv">0</span>, <span class="st">'b'</span>:<span class="dv">1</span>, <span class="st">'c'</span>:<span class="dv">2</span>, <span class="st">'d'</span>:<span class="dv">3</span>}))</span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.tensor(df_train.y.<span class="bu">map</span>({<span class="st">'a'</span>:<span class="dv">0</span>, <span class="st">'b'</span>:<span class="dv">1</span>, <span class="st">'c'</span>:<span class="dv">2</span>, <span class="st">'d'</span>:<span class="dv">3</span>}))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="b.-mlp-하나의-은닉노드-1" class="level2">
<h2 class="anchored" data-anchor-id="b.-mlp-하나의-은닉노드-1">B. MLP – 하나의 은닉노드</h2>
<p>🗣️(</p>
<ul>
<li>두개의 은닉노드가 필요하겠지만 전에 흰색을 활용했던 것처럼 어떻게 해서 잘 짜맞추면 하나로도 할 수 있지 않을까?
<ul>
<li>ex) 빨강, 분홍, 하늘, 파랑</li>
</ul></li>
</ul>
<div id="3191c578-5269-4610-9b93-0a23783997df" class="cell" data-execution_count="63">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.Embedding(num_embeddings<span class="op">=</span><span class="dv">4</span>, embedding_dim<span class="op">=</span><span class="dv">1</span>), <span class="co"># 4차원</span></span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a>    torch.nn.Tanh(), </span>
<span id="cb83-5"><a href="#cb83-5" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">1</span>,<span class="dv">4</span>)</span>
<span id="cb83-6"><a href="#cb83-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb83-7"><a href="#cb83-7" aria-hidden="true" tabindex="-1"></a>ebdd,tanh,linr <span class="op">=</span> net </span>
<span id="cb83-8"><a href="#cb83-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-9"><a href="#cb83-9" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb83-10"><a href="#cb83-10" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters(),lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb83-11"><a href="#cb83-11" aria-hidden="true" tabindex="-1"></a><span class="co">#---#</span></span>
<span id="cb83-12"><a href="#cb83-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb83-13"><a href="#cb83-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">#1 </span></span>
<span id="cb83-14"><a href="#cb83-14" aria-hidden="true" tabindex="-1"></a>    netout <span class="op">=</span> net(x)</span>
<span id="cb83-15"><a href="#cb83-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">#2 </span></span>
<span id="cb83-16"><a href="#cb83-16" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(netout,y)</span>
<span id="cb83-17"><a href="#cb83-17" aria-hidden="true" tabindex="-1"></a>    <span class="co">#3</span></span>
<span id="cb83-18"><a href="#cb83-18" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb83-19"><a href="#cb83-19" aria-hidden="true" tabindex="-1"></a>    <span class="co">#4</span></span>
<span id="cb83-20"><a href="#cb83-20" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb83-21"><a href="#cb83-21" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="b28235c1-d3cd-451f-9597-500d5feb6fb6" class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>ebdd,tanh,linr <span class="op">=</span> net</span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.nn.functional.one_hot(x)</span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> tanh(ebdd(x)).data</span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a>netout <span class="op">=</span> linr(tanh(ebdd(x))).data</span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> torch.nn.functional.softmax(net(x),dim<span class="op">=</span><span class="dv">1</span>).data</span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a>mat <span class="op">=</span> torch.concat([X,h,netout<span class="op">/</span>netout.<span class="bu">max</span>(),yhat],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb84-7"><a href="#cb84-7" aria-hidden="true" tabindex="-1"></a><span class="co">#---#</span></span>
<span id="cb84-8"><a href="#cb84-8" aria-hidden="true" tabindex="-1"></a>plt.matshow(mat[:<span class="dv">10</span>, :],cmap<span class="op">=</span><span class="st">"bwr"</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb84-9"><a href="#cb84-9" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb84-10"><a href="#cb84-10" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">3.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb84-11"><a href="#cb84-11" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">4.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb84-12"><a href="#cb84-12" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">8.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb84-13"><a href="#cb84-13" aria-hidden="true" tabindex="-1"></a>plt.xticks(</span>
<span id="cb84-14"><a href="#cb84-14" aria-hidden="true" tabindex="-1"></a>    ticks<span class="op">=</span>[<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">9</span>,<span class="dv">10</span>,<span class="dv">11</span>,<span class="dv">12</span>],</span>
<span id="cb84-15"><a href="#cb84-15" aria-hidden="true" tabindex="-1"></a>    labels<span class="op">=</span>[</span>
<span id="cb84-16"><a href="#cb84-16" aria-hidden="true" tabindex="-1"></a>        <span class="vs">r"$x_a$"</span>,<span class="vs">r"$x_b$"</span>,<span class="vs">r"$x_c$"</span>,<span class="vs">r"$x_d$"</span>,</span>
<span id="cb84-17"><a href="#cb84-17" aria-hidden="true" tabindex="-1"></a>        <span class="vs">r"$h$"</span>,</span>
<span id="cb84-18"><a href="#cb84-18" aria-hidden="true" tabindex="-1"></a>        <span class="vs">r"$out_a$"</span>,<span class="vs">r"$out_b$"</span>,<span class="vs">r"$out_c$"</span>,<span class="vs">r"$out_d$"</span>,</span>
<span id="cb84-19"><a href="#cb84-19" aria-hidden="true" tabindex="-1"></a>        <span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_a$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_b$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_c$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_d$"</span>]</span>
<span id="cb84-20"><a href="#cb84-20" aria-hidden="true" tabindex="-1"></a>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11wk-2_files/figure-html/cell-59-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>잘 안됨(특히 X가 c,d일 때)</li>
<li>계속 해봐도 마찬가지로 잘 안됨</li>
<li>잘 되는 weight 초기값을 찾아서 사용하면 되긴 함 (많은 시행착오 끝에)</li>
</ul>
<div id="cbec0ea0-a07c-4e0b-a22e-71f96b926160" class="cell" data-execution_count="65">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.Embedding(num_embeddings<span class="op">=</span><span class="dv">4</span>, embedding_dim<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a>    torch.nn.Tanh(), </span>
<span id="cb85-5"><a href="#cb85-5" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">1</span>,<span class="dv">4</span>)</span>
<span id="cb85-6"><a href="#cb85-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb85-7"><a href="#cb85-7" aria-hidden="true" tabindex="-1"></a>ebdd,tanh,linr <span class="op">=</span> net </span>
<span id="cb85-8"><a href="#cb85-8" aria-hidden="true" tabindex="-1"></a>ebdd.weight.data <span class="op">=</span> torch.tensor([[<span class="op">-</span><span class="fl">0.3333</span>],[<span class="op">-</span><span class="fl">2.5000</span>],[<span class="fl">5.0000</span>],[<span class="fl">0.3333</span>]])</span>
<span id="cb85-9"><a href="#cb85-9" aria-hidden="true" tabindex="-1"></a>linr.weight.data <span class="op">=</span> torch.tensor([[<span class="fl">1.5000</span>],[<span class="op">-</span><span class="fl">6.0000</span>],[<span class="op">-</span><span class="fl">2.0000</span>],[<span class="fl">6.0000</span>]])</span>
<span id="cb85-10"><a href="#cb85-10" aria-hidden="true" tabindex="-1"></a>linr.bias.data <span class="op">=</span> torch.tensor([<span class="fl">0.1500</span>, <span class="op">-</span><span class="fl">2.0000</span>,  <span class="fl">0.1500</span>, <span class="op">-</span><span class="fl">2.000</span>])</span>
<span id="cb85-11"><a href="#cb85-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-12"><a href="#cb85-12" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb85-13"><a href="#cb85-13" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters(),lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb85-14"><a href="#cb85-14" aria-hidden="true" tabindex="-1"></a><span class="co">#---#</span></span>
<span id="cb85-15"><a href="#cb85-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb85-16"><a href="#cb85-16" aria-hidden="true" tabindex="-1"></a>    <span class="co">#1 </span></span>
<span id="cb85-17"><a href="#cb85-17" aria-hidden="true" tabindex="-1"></a>    netout <span class="op">=</span> net(x)</span>
<span id="cb85-18"><a href="#cb85-18" aria-hidden="true" tabindex="-1"></a>    <span class="co">#2 </span></span>
<span id="cb85-19"><a href="#cb85-19" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(netout,y)</span>
<span id="cb85-20"><a href="#cb85-20" aria-hidden="true" tabindex="-1"></a>    <span class="co">#3</span></span>
<span id="cb85-21"><a href="#cb85-21" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb85-22"><a href="#cb85-22" aria-hidden="true" tabindex="-1"></a>    <span class="co">#4</span></span>
<span id="cb85-23"><a href="#cb85-23" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb85-24"><a href="#cb85-24" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="b55f9af3-dc9b-404a-b8a2-a97ad3a2471c" class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>ebdd,tanh,linr <span class="op">=</span> net</span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.nn.functional.one_hot(x)</span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> tanh(ebdd(x)).data</span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>netout <span class="op">=</span> linr(tanh(ebdd(x))).data</span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> torch.nn.functional.softmax(net(x),dim<span class="op">=</span><span class="dv">1</span>).data</span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a>mat <span class="op">=</span> torch.concat([X,h,netout<span class="op">/</span>netout.<span class="bu">max</span>(),yhat],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a><span class="co">#---#</span></span>
<span id="cb86-8"><a href="#cb86-8" aria-hidden="true" tabindex="-1"></a>plt.matshow(mat[:<span class="dv">10</span>, :],cmap<span class="op">=</span><span class="st">"bwr"</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb86-9"><a href="#cb86-9" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb86-10"><a href="#cb86-10" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">3.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb86-11"><a href="#cb86-11" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">4.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb86-12"><a href="#cb86-12" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">8.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb86-13"><a href="#cb86-13" aria-hidden="true" tabindex="-1"></a>plt.xticks(</span>
<span id="cb86-14"><a href="#cb86-14" aria-hidden="true" tabindex="-1"></a>    ticks<span class="op">=</span>[<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">9</span>,<span class="dv">10</span>,<span class="dv">11</span>,<span class="dv">12</span>],</span>
<span id="cb86-15"><a href="#cb86-15" aria-hidden="true" tabindex="-1"></a>    labels<span class="op">=</span>[</span>
<span id="cb86-16"><a href="#cb86-16" aria-hidden="true" tabindex="-1"></a>        <span class="vs">r"$x_a$"</span>,<span class="vs">r"$x_b$"</span>,<span class="vs">r"$x_c$"</span>,<span class="vs">r"$x_d$"</span>,</span>
<span id="cb86-17"><a href="#cb86-17" aria-hidden="true" tabindex="-1"></a>        <span class="vs">r"$h$"</span>,</span>
<span id="cb86-18"><a href="#cb86-18" aria-hidden="true" tabindex="-1"></a>        <span class="vs">r"$out_a$"</span>,<span class="vs">r"$out_b$"</span>,<span class="vs">r"$out_c$"</span>,<span class="vs">r"$out_d$"</span>,</span>
<span id="cb86-19"><a href="#cb86-19" aria-hidden="true" tabindex="-1"></a>        <span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_a$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_b$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_c$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_d$"</span>]</span>
<span id="cb86-20"><a href="#cb86-20" aria-hidden="true" tabindex="-1"></a>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11wk-2_files/figure-html/cell-61-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>생각했던대로 빨강, 분홍, 하늘, 파랑 으로 구분되긴 함</li>
<li>확률들이 깔끔하진 않음</li>
<li>이렇게 하는 것보다 당연히 두 개의 은닉 노드를 사용하는 것이 깔끔</li>
</ul>
<p>)🗣️</p>
<p><code>-</code> 적합</p>
<div id="2045716d-8d31-4201-98b7-9baa4d1e26ef" class="cell" data-execution_count="164">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.Embedding(num_embeddings<span class="op">=</span><span class="dv">4</span>, embedding_dim<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a>    torch.nn.Tanh(), </span>
<span id="cb87-5"><a href="#cb87-5" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">1</span>,<span class="dv">4</span>)</span>
<span id="cb87-6"><a href="#cb87-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb87-7"><a href="#cb87-7" aria-hidden="true" tabindex="-1"></a>ebdd,tanh,linr <span class="op">=</span> net </span>
<span id="cb87-8"><a href="#cb87-8" aria-hidden="true" tabindex="-1"></a>ebdd.weight.data <span class="op">=</span> torch.tensor([[<span class="op">-</span><span class="fl">0.3333</span>],[<span class="op">-</span><span class="fl">2.5000</span>],[<span class="fl">5.0000</span>],[<span class="fl">0.3333</span>]])</span>
<span id="cb87-9"><a href="#cb87-9" aria-hidden="true" tabindex="-1"></a>linr.weight.data <span class="op">=</span> torch.tensor([[<span class="fl">1.5000</span>],[<span class="op">-</span><span class="fl">6.0000</span>],[<span class="op">-</span><span class="fl">2.0000</span>],[<span class="fl">6.0000</span>]])</span>
<span id="cb87-10"><a href="#cb87-10" aria-hidden="true" tabindex="-1"></a>linr.bias.data <span class="op">=</span> torch.tensor([<span class="fl">0.1500</span>, <span class="op">-</span><span class="fl">2.0000</span>,  <span class="fl">0.1500</span>, <span class="op">-</span><span class="fl">2.000</span>])</span>
<span id="cb87-11"><a href="#cb87-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-12"><a href="#cb87-12" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb87-13"><a href="#cb87-13" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters(),lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb87-14"><a href="#cb87-14" aria-hidden="true" tabindex="-1"></a><span class="co">#---#</span></span>
<span id="cb87-15"><a href="#cb87-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb87-16"><a href="#cb87-16" aria-hidden="true" tabindex="-1"></a>    <span class="co">#1 </span></span>
<span id="cb87-17"><a href="#cb87-17" aria-hidden="true" tabindex="-1"></a>    netout <span class="op">=</span> net(x)</span>
<span id="cb87-18"><a href="#cb87-18" aria-hidden="true" tabindex="-1"></a>    <span class="co">#2 </span></span>
<span id="cb87-19"><a href="#cb87-19" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(netout,y)</span>
<span id="cb87-20"><a href="#cb87-20" aria-hidden="true" tabindex="-1"></a>    <span class="co">#3</span></span>
<span id="cb87-21"><a href="#cb87-21" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb87-22"><a href="#cb87-22" aria-hidden="true" tabindex="-1"></a>    <span class="co">#4</span></span>
<span id="cb87-23"><a href="#cb87-23" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb87-24"><a href="#cb87-24" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><code>-</code> 결과시각화</p>
<div id="3afc472d-c018-4330-95f1-cef07785d3e5" class="cell" data-execution_count="165">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>ebdd,tanh,linr <span class="op">=</span> net</span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.nn.functional.one_hot(x)</span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> tanh(ebdd(x)).data</span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a>netout <span class="op">=</span> linr(tanh(ebdd(x))).data</span>
<span id="cb88-5"><a href="#cb88-5" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> torch.nn.functional.softmax(net(x),dim<span class="op">=</span><span class="dv">1</span>).data</span>
<span id="cb88-6"><a href="#cb88-6" aria-hidden="true" tabindex="-1"></a>mat <span class="op">=</span> torch.concat([X,h,netout<span class="op">/</span>netout.<span class="bu">max</span>(),yhat],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb88-7"><a href="#cb88-7" aria-hidden="true" tabindex="-1"></a><span class="co">#---#</span></span>
<span id="cb88-8"><a href="#cb88-8" aria-hidden="true" tabindex="-1"></a>plt.matshow(mat[:<span class="dv">10</span>, :],cmap<span class="op">=</span><span class="st">"bwr"</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb88-9"><a href="#cb88-9" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb88-10"><a href="#cb88-10" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">3.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb88-11"><a href="#cb88-11" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">4.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb88-12"><a href="#cb88-12" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">8.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb88-13"><a href="#cb88-13" aria-hidden="true" tabindex="-1"></a>plt.xticks(</span>
<span id="cb88-14"><a href="#cb88-14" aria-hidden="true" tabindex="-1"></a>    ticks<span class="op">=</span>[<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">9</span>,<span class="dv">10</span>,<span class="dv">11</span>,<span class="dv">12</span>],</span>
<span id="cb88-15"><a href="#cb88-15" aria-hidden="true" tabindex="-1"></a>    labels<span class="op">=</span>[</span>
<span id="cb88-16"><a href="#cb88-16" aria-hidden="true" tabindex="-1"></a>        <span class="vs">r"$x_a$"</span>,<span class="vs">r"$x_b$"</span>,<span class="vs">r"$x_c$"</span>,<span class="vs">r"$x_d$"</span>,</span>
<span id="cb88-17"><a href="#cb88-17" aria-hidden="true" tabindex="-1"></a>        <span class="vs">r"$h$"</span>,</span>
<span id="cb88-18"><a href="#cb88-18" aria-hidden="true" tabindex="-1"></a>        <span class="vs">r"$out_a$"</span>,<span class="vs">r"$out_b$"</span>,<span class="vs">r"$out_c$"</span>,<span class="vs">r"$out_d$"</span>,</span>
<span id="cb88-19"><a href="#cb88-19" aria-hidden="true" tabindex="-1"></a>        <span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_a$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_b$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_c$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_d$"</span>]</span>
<span id="cb88-20"><a href="#cb88-20" aria-hidden="true" tabindex="-1"></a>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11wk-2_files/figure-html/cell-63-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="c.-mlp-두개의-은닉노드-1" class="level2">
<h2 class="anchored" data-anchor-id="c.-mlp-두개의-은닉노드-1">C. MLP – 두개의 은닉노드</h2>
<p>🗣️(</p>
<div id="d2b88fb1-9d10-4ffa-a695-d48e2a5d22aa" class="cell" data-execution_count="69">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="co">#torch.manual_seed(43052)</span></span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.Embedding(num_embeddings<span class="op">=</span><span class="dv">4</span>, embedding_dim<span class="op">=</span><span class="dv">2</span>),</span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a>    torch.nn.Tanh(), </span>
<span id="cb89-5"><a href="#cb89-5" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">2</span>,<span class="dv">4</span>)</span>
<span id="cb89-6"><a href="#cb89-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb89-7"><a href="#cb89-7" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb89-8"><a href="#cb89-8" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters(),lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb89-9"><a href="#cb89-9" aria-hidden="true" tabindex="-1"></a><span class="co">#---#</span></span>
<span id="cb89-10"><a href="#cb89-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb89-11"><a href="#cb89-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">#1 </span></span>
<span id="cb89-12"><a href="#cb89-12" aria-hidden="true" tabindex="-1"></a>    netout <span class="op">=</span> net(x)</span>
<span id="cb89-13"><a href="#cb89-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">#2 </span></span>
<span id="cb89-14"><a href="#cb89-14" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(netout,y)</span>
<span id="cb89-15"><a href="#cb89-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">#3</span></span>
<span id="cb89-16"><a href="#cb89-16" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb89-17"><a href="#cb89-17" aria-hidden="true" tabindex="-1"></a>    <span class="co">#4</span></span>
<span id="cb89-18"><a href="#cb89-18" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb89-19"><a href="#cb89-19" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="d9be2748-29c6-4a4b-849e-1bc348177ad1" class="cell" data-execution_count="70">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>ebdd,tanh,linr <span class="op">=</span> net</span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.nn.functional.one_hot(x)</span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> tanh(ebdd(x)).data</span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a>netout <span class="op">=</span> linr(tanh(ebdd(x))).data</span>
<span id="cb90-5"><a href="#cb90-5" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> torch.nn.functional.softmax(net(x),dim<span class="op">=</span><span class="dv">1</span>).data</span>
<span id="cb90-6"><a href="#cb90-6" aria-hidden="true" tabindex="-1"></a>mat <span class="op">=</span> torch.concat([X,h,netout<span class="op">/</span>netout.<span class="bu">max</span>(),yhat],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb90-7"><a href="#cb90-7" aria-hidden="true" tabindex="-1"></a><span class="co">#---#</span></span>
<span id="cb90-8"><a href="#cb90-8" aria-hidden="true" tabindex="-1"></a>plt.matshow(mat[:<span class="dv">10</span>, :],cmap<span class="op">=</span><span class="st">"bwr"</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb90-9"><a href="#cb90-9" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb90-10"><a href="#cb90-10" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">3.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb90-11"><a href="#cb90-11" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">5.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb90-12"><a href="#cb90-12" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">9.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb90-13"><a href="#cb90-13" aria-hidden="true" tabindex="-1"></a>plt.xticks(</span>
<span id="cb90-14"><a href="#cb90-14" aria-hidden="true" tabindex="-1"></a>    ticks<span class="op">=</span>[<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">9</span>,<span class="dv">10</span>,<span class="dv">11</span>,<span class="dv">12</span>,<span class="dv">13</span>],</span>
<span id="cb90-15"><a href="#cb90-15" aria-hidden="true" tabindex="-1"></a>    labels<span class="op">=</span>[</span>
<span id="cb90-16"><a href="#cb90-16" aria-hidden="true" tabindex="-1"></a>        <span class="vs">r"$x_a$"</span>,<span class="vs">r"$x_b$"</span>,<span class="vs">r"$x_c$"</span>,<span class="vs">r"$x_d$"</span>,</span>
<span id="cb90-17"><a href="#cb90-17" aria-hidden="true" tabindex="-1"></a>        <span class="vs">r"$h_1$"</span>,<span class="vs">r"$h_2$"</span>,</span>
<span id="cb90-18"><a href="#cb90-18" aria-hidden="true" tabindex="-1"></a>        <span class="vs">r"$out_a$"</span>,<span class="vs">r"$out_b$"</span>,<span class="vs">r"$out_c$"</span>,<span class="vs">r"$out_d$"</span>,</span>
<span id="cb90-19"><a href="#cb90-19" aria-hidden="true" tabindex="-1"></a>        <span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_a$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_b$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_c$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_d$"</span>]</span>
<span id="cb90-20"><a href="#cb90-20" aria-hidden="true" tabindex="-1"></a>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11wk-2_files/figure-html/cell-65-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>돌릴 때마다 결과가 달라지긴 하지만 (흰색이 나오는 경우도 있음) 대체적으로 깔끔하게 됨</li>
<li>h의 dimension이 커지면 표현에 유리하기 때문</li>
</ul>
<p>)🗣️</p>
<p><code>-</code> 적합</p>
<div id="0f876f1b-8f79-4ebe-a3c5-cf8d5a0f5ead" class="cell" data-execution_count="170">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="co">#torch.manual_seed(43052)</span></span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.Embedding(num_embeddings<span class="op">=</span><span class="dv">4</span>, embedding_dim<span class="op">=</span><span class="dv">2</span>),</span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a>    torch.nn.Tanh(), </span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">2</span>,<span class="dv">4</span>)</span>
<span id="cb91-6"><a href="#cb91-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb91-7"><a href="#cb91-7" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb91-8"><a href="#cb91-8" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters(),lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb91-9"><a href="#cb91-9" aria-hidden="true" tabindex="-1"></a><span class="co">#---#</span></span>
<span id="cb91-10"><a href="#cb91-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb91-11"><a href="#cb91-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">#1 </span></span>
<span id="cb91-12"><a href="#cb91-12" aria-hidden="true" tabindex="-1"></a>    netout <span class="op">=</span> net(x)</span>
<span id="cb91-13"><a href="#cb91-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">#2 </span></span>
<span id="cb91-14"><a href="#cb91-14" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(netout,y)</span>
<span id="cb91-15"><a href="#cb91-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">#3</span></span>
<span id="cb91-16"><a href="#cb91-16" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb91-17"><a href="#cb91-17" aria-hidden="true" tabindex="-1"></a>    <span class="co">#4</span></span>
<span id="cb91-18"><a href="#cb91-18" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb91-19"><a href="#cb91-19" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><code>-</code> 결과시각화</p>
<div id="3655ef6e-ea16-4d46-8728-a052ac83ff8f" class="cell" data-execution_count="171">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>ebdd,tanh,linr <span class="op">=</span> net</span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.nn.functional.one_hot(x)</span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> tanh(ebdd(x)).data</span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a>netout <span class="op">=</span> linr(tanh(ebdd(x))).data</span>
<span id="cb92-5"><a href="#cb92-5" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> torch.nn.functional.softmax(net(x),dim<span class="op">=</span><span class="dv">1</span>).data</span>
<span id="cb92-6"><a href="#cb92-6" aria-hidden="true" tabindex="-1"></a>mat <span class="op">=</span> torch.concat([X,h,netout<span class="op">/</span>netout.<span class="bu">max</span>(),yhat],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb92-7"><a href="#cb92-7" aria-hidden="true" tabindex="-1"></a><span class="co">#---#</span></span>
<span id="cb92-8"><a href="#cb92-8" aria-hidden="true" tabindex="-1"></a>plt.matshow(mat[:<span class="dv">10</span>, :],cmap<span class="op">=</span><span class="st">"bwr"</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb92-9"><a href="#cb92-9" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb92-10"><a href="#cb92-10" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">3.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb92-11"><a href="#cb92-11" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">5.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb92-12"><a href="#cb92-12" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">9.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb92-13"><a href="#cb92-13" aria-hidden="true" tabindex="-1"></a>plt.xticks(</span>
<span id="cb92-14"><a href="#cb92-14" aria-hidden="true" tabindex="-1"></a>    ticks<span class="op">=</span>[<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">9</span>,<span class="dv">10</span>,<span class="dv">11</span>,<span class="dv">12</span>,<span class="dv">13</span>],</span>
<span id="cb92-15"><a href="#cb92-15" aria-hidden="true" tabindex="-1"></a>    labels<span class="op">=</span>[</span>
<span id="cb92-16"><a href="#cb92-16" aria-hidden="true" tabindex="-1"></a>        <span class="vs">r"$x_a$"</span>,<span class="vs">r"$x_b$"</span>,<span class="vs">r"$x_c$"</span>,<span class="vs">r"$x_d$"</span>,</span>
<span id="cb92-17"><a href="#cb92-17" aria-hidden="true" tabindex="-1"></a>        <span class="vs">r"$h_1$"</span>,<span class="vs">r"$h_2$"</span>,</span>
<span id="cb92-18"><a href="#cb92-18" aria-hidden="true" tabindex="-1"></a>        <span class="vs">r"$out_a$"</span>,<span class="vs">r"$out_b$"</span>,<span class="vs">r"$out_c$"</span>,<span class="vs">r"$out_d$"</span>,</span>
<span id="cb92-19"><a href="#cb92-19" aria-hidden="true" tabindex="-1"></a>        <span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_a$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_b$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_c$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_d$"</span>]</span>
<span id="cb92-20"><a href="#cb92-20" aria-hidden="true" tabindex="-1"></a>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11wk-2_files/figure-html/cell-67-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="d.-비교실험" class="level2">
<h2 class="anchored" data-anchor-id="d.-비교실험">D. 비교실험</h2>
<p>🗣️(</p>
<ul>
<li>사용자 정의 network 이용
<ul>
<li>Net1: 히든 노드 1 (4 -&gt; 1)</li>
<li>Net2: 히든 노드 2 (4 -&gt; 2)</li>
</ul></li>
</ul>
<div id="c33310fb-d439-4550-a78b-a2ad9153a9e4" class="cell" data-tags="[]" data-execution_count="71">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Net1(torch.nn.Module):</span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true" tabindex="-1"></a>        <span class="co">## 우리가 yhat을 구할때 사용할 레이어를 정의 </span></span>
<span id="cb93-5"><a href="#cb93-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ebdd <span class="op">=</span> torch.nn.Embedding(<span class="dv">4</span>,<span class="dv">1</span>)</span>
<span id="cb93-6"><a href="#cb93-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tanh <span class="op">=</span> torch.nn.Tanh()</span>
<span id="cb93-7"><a href="#cb93-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linr <span class="op">=</span> torch.nn.Linear(<span class="dv">1</span>,<span class="dv">4</span>)</span>
<span id="cb93-8"><a href="#cb93-8" aria-hidden="true" tabindex="-1"></a>        <span class="co">## 정의 끝</span></span>
<span id="cb93-9"><a href="#cb93-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>,X):</span>
<span id="cb93-10"><a href="#cb93-10" aria-hidden="true" tabindex="-1"></a>        <span class="co">## yhat을 어떻게 구할것인지 정의 </span></span>
<span id="cb93-11"><a href="#cb93-11" aria-hidden="true" tabindex="-1"></a>        ebdd_x <span class="op">=</span> <span class="va">self</span>.ebdd(x)</span>
<span id="cb93-12"><a href="#cb93-12" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.tanh(ebdd_x)</span>
<span id="cb93-13"><a href="#cb93-13" aria-hidden="true" tabindex="-1"></a>        netout <span class="op">=</span> <span class="va">self</span>.linr(h)</span>
<span id="cb93-14"><a href="#cb93-14" aria-hidden="true" tabindex="-1"></a>        <span class="co">## 정의 끝</span></span>
<span id="cb93-15"><a href="#cb93-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> netout</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="5cfdf89b-0653-4f76-aeac-6f08fc8e1e56" class="cell" data-tags="[]" data-execution_count="72">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Net2(torch.nn.Module):</span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a>        <span class="co">## 우리가 yhat을 구할때 사용할 레이어를 정의 </span></span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ebdd <span class="op">=</span> torch.nn.Embedding(<span class="dv">4</span>,<span class="dv">2</span>)</span>
<span id="cb94-6"><a href="#cb94-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tanh <span class="op">=</span> torch.nn.Tanh()</span>
<span id="cb94-7"><a href="#cb94-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linr <span class="op">=</span> torch.nn.Linear(<span class="dv">2</span>,<span class="dv">4</span>)</span>
<span id="cb94-8"><a href="#cb94-8" aria-hidden="true" tabindex="-1"></a>        <span class="co">## 정의 끝</span></span>
<span id="cb94-9"><a href="#cb94-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>,X):</span>
<span id="cb94-10"><a href="#cb94-10" aria-hidden="true" tabindex="-1"></a>        <span class="co">## yhat을 어떻게 구할것인지 정의 </span></span>
<span id="cb94-11"><a href="#cb94-11" aria-hidden="true" tabindex="-1"></a>        ebdd_x <span class="op">=</span> <span class="va">self</span>.ebdd(x)</span>
<span id="cb94-12"><a href="#cb94-12" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.tanh(ebdd_x)</span>
<span id="cb94-13"><a href="#cb94-13" aria-hidden="true" tabindex="-1"></a>        netout <span class="op">=</span> <span class="va">self</span>.linr(h)</span>
<span id="cb94-14"><a href="#cb94-14" aria-hidden="true" tabindex="-1"></a>        <span class="co">## 정의 끝</span></span>
<span id="cb94-15"><a href="#cb94-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> netout</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>시각화는 h와 yhat만 함 (25개의 초기값으로)</li>
</ul>
<div id="58c76bd3-923e-4847-9d66-083c026a27a2" class="cell" data-tags="[]" data-execution_count="74">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">5</span>,<span class="dv">5</span>,figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">10</span>))</span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb95-3"><a href="#cb95-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb95-4"><a href="#cb95-4" aria-hidden="true" tabindex="-1"></a>        net <span class="op">=</span> Net1()</span>
<span id="cb95-5"><a href="#cb95-5" aria-hidden="true" tabindex="-1"></a>        optimizr <span class="op">=</span> torch.optim.Adam(net.parameters(),lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb95-6"><a href="#cb95-6" aria-hidden="true" tabindex="-1"></a>        loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb95-7"><a href="#cb95-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb95-8"><a href="#cb95-8" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 1 </span></span>
<span id="cb95-9"><a href="#cb95-9" aria-hidden="true" tabindex="-1"></a>            netout <span class="op">=</span> net(x)</span>
<span id="cb95-10"><a href="#cb95-10" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 2 </span></span>
<span id="cb95-11"><a href="#cb95-11" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_fn(netout,y)</span>
<span id="cb95-12"><a href="#cb95-12" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 3 </span></span>
<span id="cb95-13"><a href="#cb95-13" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb95-14"><a href="#cb95-14" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 4 </span></span>
<span id="cb95-15"><a href="#cb95-15" aria-hidden="true" tabindex="-1"></a>            optimizr.step()</span>
<span id="cb95-16"><a href="#cb95-16" aria-hidden="true" tabindex="-1"></a>            optimizr.zero_grad()</span>
<span id="cb95-17"><a href="#cb95-17" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> net.tanh(net.ebdd(x)).data</span>
<span id="cb95-18"><a href="#cb95-18" aria-hidden="true" tabindex="-1"></a>        yhat <span class="op">=</span> torch.nn.functional.softmax(net(x),dim<span class="op">=</span><span class="dv">1</span>).data</span>
<span id="cb95-19"><a href="#cb95-19" aria-hidden="true" tabindex="-1"></a>        mat <span class="op">=</span> torch.concat([h,yhat],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb95-20"><a href="#cb95-20" aria-hidden="true" tabindex="-1"></a>        ax[i][j].matshow(mat[:<span class="dv">6</span>, :],cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb95-21"><a href="#cb95-21" aria-hidden="true" tabindex="-1"></a>        ax[i][j].axvline(<span class="fl">0.5</span>,color<span class="op">=</span><span class="st">'lime'</span>)</span>
<span id="cb95-22"><a href="#cb95-22" aria-hidden="true" tabindex="-1"></a>        ax[i][j].set_xticks(ticks<span class="op">=</span>[<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>],labels<span class="op">=</span>[<span class="vs">r"$h$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_a$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_b$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_c$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_d$"</span>])</span>
<span id="cb95-23"><a href="#cb95-23" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="st">"# of hidden nodes = 1"</span>, size<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb95-24"><a href="#cb95-24" aria-hidden="true" tabindex="-1"></a>fig.tight_layout()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11wk-2_files/figure-html/cell-70-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>잘 된 경우가 거의 없음</li>
<li>잘 되더라도 깔끔하진 않음</li>
</ul>
<div id="a88b735a-3e3a-47ea-b684-ca73e3d5f40b" class="cell" data-tags="[]" data-execution_count="73">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">5</span>,<span class="dv">5</span>,figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">10</span>))</span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb96-3"><a href="#cb96-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb96-4"><a href="#cb96-4" aria-hidden="true" tabindex="-1"></a>        net <span class="op">=</span> Net2()</span>
<span id="cb96-5"><a href="#cb96-5" aria-hidden="true" tabindex="-1"></a>        optimizr <span class="op">=</span> torch.optim.Adam(net.parameters(),lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb96-6"><a href="#cb96-6" aria-hidden="true" tabindex="-1"></a>        loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb96-7"><a href="#cb96-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb96-8"><a href="#cb96-8" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 1 </span></span>
<span id="cb96-9"><a href="#cb96-9" aria-hidden="true" tabindex="-1"></a>            netout <span class="op">=</span> net(x)</span>
<span id="cb96-10"><a href="#cb96-10" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 2 </span></span>
<span id="cb96-11"><a href="#cb96-11" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_fn(netout,y)</span>
<span id="cb96-12"><a href="#cb96-12" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 3 </span></span>
<span id="cb96-13"><a href="#cb96-13" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb96-14"><a href="#cb96-14" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 4 </span></span>
<span id="cb96-15"><a href="#cb96-15" aria-hidden="true" tabindex="-1"></a>            optimizr.step()</span>
<span id="cb96-16"><a href="#cb96-16" aria-hidden="true" tabindex="-1"></a>            optimizr.zero_grad()</span>
<span id="cb96-17"><a href="#cb96-17" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> net.tanh(net.ebdd(x)).data</span>
<span id="cb96-18"><a href="#cb96-18" aria-hidden="true" tabindex="-1"></a>        yhat <span class="op">=</span> torch.nn.functional.softmax(net(x),dim<span class="op">=</span><span class="dv">1</span>).data</span>
<span id="cb96-19"><a href="#cb96-19" aria-hidden="true" tabindex="-1"></a>        mat <span class="op">=</span> torch.concat([h,yhat],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb96-20"><a href="#cb96-20" aria-hidden="true" tabindex="-1"></a>        ax[i][j].matshow(mat[:<span class="dv">6</span>, :],cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb96-21"><a href="#cb96-21" aria-hidden="true" tabindex="-1"></a>        ax[i][j].axvline(<span class="fl">1.5</span>,color<span class="op">=</span><span class="st">'lime'</span>)</span>
<span id="cb96-22"><a href="#cb96-22" aria-hidden="true" tabindex="-1"></a>        ax[i][j].set_xticks(ticks<span class="op">=</span>[<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>],labels<span class="op">=</span>[<span class="vs">r"$h_1$"</span>,<span class="vs">r"$h_2$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_a$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_b$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_c$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_d$"</span>])</span>
<span id="cb96-23"><a href="#cb96-23" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="st">"# of hidden nodes = 2"</span>, size<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb96-24"><a href="#cb96-24" aria-hidden="true" tabindex="-1"></a>fig.tight_layout()        </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11wk-2_files/figure-html/cell-71-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>거의 clear하게 구분 됨</li>
<li>강의 영상에서는 모든 경우가 clear 함</li>
</ul>
<p>)🗣️</p>
<div id="fc37fb99-0fcd-4852-8200-050d01fb275c" class="cell" data-tags="[]" data-execution_count="172">
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Net1(torch.nn.Module):</span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb97-3"><a href="#cb97-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb97-4"><a href="#cb97-4" aria-hidden="true" tabindex="-1"></a>        <span class="co">## 우리가 yhat을 구할때 사용할 레이어를 정의 </span></span>
<span id="cb97-5"><a href="#cb97-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ebdd <span class="op">=</span> torch.nn.Embedding(<span class="dv">4</span>,<span class="dv">1</span>)</span>
<span id="cb97-6"><a href="#cb97-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tanh <span class="op">=</span> torch.nn.Tanh()</span>
<span id="cb97-7"><a href="#cb97-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linr <span class="op">=</span> torch.nn.Linear(<span class="dv">1</span>,<span class="dv">4</span>)</span>
<span id="cb97-8"><a href="#cb97-8" aria-hidden="true" tabindex="-1"></a>        <span class="co">## 정의 끝</span></span>
<span id="cb97-9"><a href="#cb97-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>,X):</span>
<span id="cb97-10"><a href="#cb97-10" aria-hidden="true" tabindex="-1"></a>        <span class="co">## yhat을 어떻게 구할것인지 정의 </span></span>
<span id="cb97-11"><a href="#cb97-11" aria-hidden="true" tabindex="-1"></a>        ebdd_x <span class="op">=</span> <span class="va">self</span>.ebdd(x)</span>
<span id="cb97-12"><a href="#cb97-12" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.tanh(ebdd_x)</span>
<span id="cb97-13"><a href="#cb97-13" aria-hidden="true" tabindex="-1"></a>        netout <span class="op">=</span> <span class="va">self</span>.linr(h)</span>
<span id="cb97-14"><a href="#cb97-14" aria-hidden="true" tabindex="-1"></a>        <span class="co">## 정의 끝</span></span>
<span id="cb97-15"><a href="#cb97-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> netout</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="153ae171-f396-4ff4-9c9e-987d1b71f250" class="cell" data-tags="[]" data-execution_count="173">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Net2(torch.nn.Module):</span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb98-4"><a href="#cb98-4" aria-hidden="true" tabindex="-1"></a>        <span class="co">## 우리가 yhat을 구할때 사용할 레이어를 정의 </span></span>
<span id="cb98-5"><a href="#cb98-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ebdd <span class="op">=</span> torch.nn.Embedding(<span class="dv">4</span>,<span class="dv">2</span>)</span>
<span id="cb98-6"><a href="#cb98-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tanh <span class="op">=</span> torch.nn.Tanh()</span>
<span id="cb98-7"><a href="#cb98-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linr <span class="op">=</span> torch.nn.Linear(<span class="dv">2</span>,<span class="dv">4</span>)</span>
<span id="cb98-8"><a href="#cb98-8" aria-hidden="true" tabindex="-1"></a>        <span class="co">## 정의 끝</span></span>
<span id="cb98-9"><a href="#cb98-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>,X):</span>
<span id="cb98-10"><a href="#cb98-10" aria-hidden="true" tabindex="-1"></a>        <span class="co">## yhat을 어떻게 구할것인지 정의 </span></span>
<span id="cb98-11"><a href="#cb98-11" aria-hidden="true" tabindex="-1"></a>        ebdd_x <span class="op">=</span> <span class="va">self</span>.ebdd(x)</span>
<span id="cb98-12"><a href="#cb98-12" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.tanh(ebdd_x)</span>
<span id="cb98-13"><a href="#cb98-13" aria-hidden="true" tabindex="-1"></a>        netout <span class="op">=</span> <span class="va">self</span>.linr(h)</span>
<span id="cb98-14"><a href="#cb98-14" aria-hidden="true" tabindex="-1"></a>        <span class="co">## 정의 끝</span></span>
<span id="cb98-15"><a href="#cb98-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> netout</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="35221938-77dc-491d-bc45-1f0fa903edf6" class="cell" data-tags="[]" data-execution_count="174">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">5</span>,<span class="dv">5</span>,figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">10</span>))</span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb99-3"><a href="#cb99-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb99-4"><a href="#cb99-4" aria-hidden="true" tabindex="-1"></a>        net <span class="op">=</span> Net1()</span>
<span id="cb99-5"><a href="#cb99-5" aria-hidden="true" tabindex="-1"></a>        optimizr <span class="op">=</span> torch.optim.Adam(net.parameters(),lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb99-6"><a href="#cb99-6" aria-hidden="true" tabindex="-1"></a>        loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb99-7"><a href="#cb99-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb99-8"><a href="#cb99-8" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 1 </span></span>
<span id="cb99-9"><a href="#cb99-9" aria-hidden="true" tabindex="-1"></a>            netout <span class="op">=</span> net(x)</span>
<span id="cb99-10"><a href="#cb99-10" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 2 </span></span>
<span id="cb99-11"><a href="#cb99-11" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_fn(netout,y)</span>
<span id="cb99-12"><a href="#cb99-12" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 3 </span></span>
<span id="cb99-13"><a href="#cb99-13" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb99-14"><a href="#cb99-14" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 4 </span></span>
<span id="cb99-15"><a href="#cb99-15" aria-hidden="true" tabindex="-1"></a>            optimizr.step()</span>
<span id="cb99-16"><a href="#cb99-16" aria-hidden="true" tabindex="-1"></a>            optimizr.zero_grad()</span>
<span id="cb99-17"><a href="#cb99-17" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> net.tanh(net.ebdd(x)).data</span>
<span id="cb99-18"><a href="#cb99-18" aria-hidden="true" tabindex="-1"></a>        yhat <span class="op">=</span> torch.nn.functional.softmax(net(x),dim<span class="op">=</span><span class="dv">1</span>).data</span>
<span id="cb99-19"><a href="#cb99-19" aria-hidden="true" tabindex="-1"></a>        mat <span class="op">=</span> torch.concat([h,yhat],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb99-20"><a href="#cb99-20" aria-hidden="true" tabindex="-1"></a>        ax[i][j].matshow(mat[:<span class="dv">6</span>, :],cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb99-21"><a href="#cb99-21" aria-hidden="true" tabindex="-1"></a>        ax[i][j].axvline(<span class="fl">0.5</span>,color<span class="op">=</span><span class="st">'lime'</span>)</span>
<span id="cb99-22"><a href="#cb99-22" aria-hidden="true" tabindex="-1"></a>        ax[i][j].set_xticks(ticks<span class="op">=</span>[<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>],labels<span class="op">=</span>[<span class="vs">r"$h$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_a$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_b$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_c$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_d$"</span>])</span>
<span id="cb99-23"><a href="#cb99-23" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="st">"# of hidden nodes = 1"</span>, size<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb99-24"><a href="#cb99-24" aria-hidden="true" tabindex="-1"></a>fig.tight_layout()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11wk-2_files/figure-html/cell-74-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="616a48c3-a7a2-46e1-b204-ab760b9d4fc8" class="cell" data-tags="[]" data-execution_count="175">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">5</span>,<span class="dv">5</span>,figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">10</span>))</span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a>        net <span class="op">=</span> Net2()</span>
<span id="cb100-5"><a href="#cb100-5" aria-hidden="true" tabindex="-1"></a>        optimizr <span class="op">=</span> torch.optim.Adam(net.parameters(),lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb100-6"><a href="#cb100-6" aria-hidden="true" tabindex="-1"></a>        loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb100-7"><a href="#cb100-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb100-8"><a href="#cb100-8" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 1 </span></span>
<span id="cb100-9"><a href="#cb100-9" aria-hidden="true" tabindex="-1"></a>            netout <span class="op">=</span> net(x)</span>
<span id="cb100-10"><a href="#cb100-10" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 2 </span></span>
<span id="cb100-11"><a href="#cb100-11" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_fn(netout,y)</span>
<span id="cb100-12"><a href="#cb100-12" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 3 </span></span>
<span id="cb100-13"><a href="#cb100-13" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb100-14"><a href="#cb100-14" aria-hidden="true" tabindex="-1"></a>            <span class="co">## 4 </span></span>
<span id="cb100-15"><a href="#cb100-15" aria-hidden="true" tabindex="-1"></a>            optimizr.step()</span>
<span id="cb100-16"><a href="#cb100-16" aria-hidden="true" tabindex="-1"></a>            optimizr.zero_grad()</span>
<span id="cb100-17"><a href="#cb100-17" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> net.tanh(net.ebdd(x)).data</span>
<span id="cb100-18"><a href="#cb100-18" aria-hidden="true" tabindex="-1"></a>        yhat <span class="op">=</span> torch.nn.functional.softmax(net(x),dim<span class="op">=</span><span class="dv">1</span>).data</span>
<span id="cb100-19"><a href="#cb100-19" aria-hidden="true" tabindex="-1"></a>        mat <span class="op">=</span> torch.concat([h,yhat],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb100-20"><a href="#cb100-20" aria-hidden="true" tabindex="-1"></a>        ax[i][j].matshow(mat[:<span class="dv">6</span>, :],cmap<span class="op">=</span><span class="st">'bwr'</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb100-21"><a href="#cb100-21" aria-hidden="true" tabindex="-1"></a>        ax[i][j].axvline(<span class="fl">1.5</span>,color<span class="op">=</span><span class="st">'lime'</span>)</span>
<span id="cb100-22"><a href="#cb100-22" aria-hidden="true" tabindex="-1"></a>        ax[i][j].set_xticks(ticks<span class="op">=</span>[<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>],labels<span class="op">=</span>[<span class="vs">r"$h_1$"</span>,<span class="vs">r"$h_2$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_a$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_b$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_c$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_d$"</span>])</span>
<span id="cb100-23"><a href="#cb100-23" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="st">"# of hidden nodes = 2"</span>, size<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb100-24"><a href="#cb100-24" aria-hidden="true" tabindex="-1"></a>fig.tight_layout()        </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11wk-2_files/figure-html/cell-75-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="boldsymbol-h-에-대하여-starstarstar" class="level1">
<h1>6. <span class="math inline">\({\boldsymbol h}\)</span> 에 대하여 (<span class="math inline">\(\star\star\star\)</span>) 📝</h1>
<p>🗣️(</p>
<pre><code>  x     X       h
a 0  1 0 0 0  -1 1
b 1  0 1 0 0   1 1
c 2  0 0 1 0   1 -1
d 3  0 0 0 1  -1 -1</code></pre>
<ul>
<li>h는 입력에 대한 또 다른 표현
<ul>
<li>one hot encoding보다 dimension이 기본적으로 작음</li>
<li>잘 안 쓰는 이유: True 값을 모름 (hidden feature)</li>
<li>a,b,c,d가 서로 독립적이지 않으면 -1, 1 로 embedding 하기가 어려움</li>
<li>예전에는 관련 분야 전문가가 수치를 지정하였지만</li>
<li>AI가 나온 다음에는 있다고 치고 학습을 함</li>
</ul></li>
</ul>
<p>)🗣️</p>
<p><code>-</code> <span class="math inline">\({\boldsymbol h}\)</span>는 사실 문자열 “abcd”들을 숫자로 바꾼 표현이라 해석할 수 있음. 즉 원핫인코딩과 다른 또 다른 형태의 숫자표현이라 해석할 수 있다.</p>
<p><code>-</code> 사실 <span class="math inline">\({\boldsymbol h}\)</span>는 원핫인코딩보다 약간 더 (1) 액기스만 남은 느낌 + (2) 숙성된 느낌을 준다</p>
<ul>
<li>(why1) <span class="math inline">\({\boldsymbol h}\)</span>는 <span class="math inline">\({\boldsymbol x}\)</span> 보다 <span class="math inline">\({\boldsymbol y}\)</span>를 예측함에 좀 더 직접적인 역할을 한다. 즉 <span class="math inline">\({\boldsymbol x}\)</span> 숫자보다 <span class="math inline">\({\boldsymbol h}\)</span> 숫자가 잘 정리되어 있고 (차원이 낮고) 입력의 특징을 잘 정리한 (추천시스템의 MBTI처럼) 의미있는 숫자이다.</li>
<li>(why2) <span class="math inline">\({\boldsymbol x}\)</span>는 학습없이 그냥 얻어지는 숫자표현이지만, <span class="math inline">\({\boldsymbol h}\)</span>는 학습을 통하여 고치고 고치고 고친 숫자표현이다.</li>
</ul>
</section>
<section id="abacad-실패" class="level1">
<h1>7. <code>AbAcAd</code> – 실패 📝</h1>
<p>🗣️(</p>
<pre><code>A b A c A d A b

A 다음에는 b,c,d 중 하나
bcd 다음에는 A

A와 bcd는 유사성 때문에 구분이 잘 되지 않음 (공간이 있어도)</code></pre>
<p>)🗣️</p>
<section id="a.-data-2" class="level2">
<h2 class="anchored" data-anchor-id="a.-data-2">A. Data</h2>
<div id="533e00f2-64bc-4ea4-bd54-4d85b324aee8" class="cell" data-tags="[]" data-execution_count="75">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a>txt <span class="op">=</span> <span class="bu">list</span>(<span class="st">'AbAcAd'</span><span class="op">*</span><span class="dv">50</span>)</span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a>txt[:<span class="dv">10</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="75">
<pre><code>['A', 'b', 'A', 'c', 'A', 'd', 'A', 'b', 'A', 'c']</code></pre>
</div>
</div>
<div id="1e9369a9-d347-4155-a8bc-46f1e53cdc50" class="cell" data-tags="[]" data-execution_count="76">
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a>df_train <span class="op">=</span> pd.DataFrame({<span class="st">'x'</span>:txt[:<span class="op">-</span><span class="dv">1</span>], <span class="st">'y'</span>:txt[<span class="dv">1</span>:]})</span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a>df_train[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="76">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">x</th>
<th data-quarto-table-cell-role="th">y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>A</td>
<td>b</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>b</td>
<td>A</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>A</td>
<td>c</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>c</td>
<td>A</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>A</td>
<td>d</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="18f7b39a-e434-45df-bd4f-321ec6ba44a4" class="cell" data-tags="[]" data-execution_count="77">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor(df_train.x.<span class="bu">map</span>({<span class="st">'A'</span>:<span class="dv">0</span>,<span class="st">'b'</span>:<span class="dv">1</span>,<span class="st">'c'</span>:<span class="dv">2</span>,<span class="st">'d'</span>:<span class="dv">3</span>}))</span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.tensor(df_train.y.<span class="bu">map</span>({<span class="st">'A'</span>:<span class="dv">0</span>,<span class="st">'b'</span>:<span class="dv">1</span>,<span class="st">'c'</span>:<span class="dv">2</span>,<span class="st">'d'</span>:<span class="dv">3</span>}))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="a2f52d78-aefa-49fa-a443-e5cb51ecf67c" class="cell" data-tags="[]" data-execution_count="78">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>x[:<span class="dv">8</span>],y[:<span class="dv">8</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="78">
<pre><code>(tensor([0, 1, 0, 2, 0, 3, 0, 1]), tensor([1, 0, 2, 0, 3, 0, 1, 0]))</code></pre>
</div>
</div>
</section>
<section id="b.-mlp-두개의-은닉노드-실패" class="level2">
<h2 class="anchored" data-anchor-id="b.-mlp-두개의-은닉노드-실패">B. MLP – 두개의 은닉노드 (실패)</h2>
<p>🗣️(</p>
<div id="ea5bca0a-6bb6-41a0-9d03-27a686b05e90" class="cell" data-execution_count="79">
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb109-2"><a href="#cb109-2" aria-hidden="true" tabindex="-1"></a>    torch.nn.Embedding(<span class="dv">4</span>,<span class="dv">2</span>),</span>
<span id="cb109-3"><a href="#cb109-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.Tanh(),</span>
<span id="cb109-4"><a href="#cb109-4" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">2</span>,<span class="dv">4</span>)</span>
<span id="cb109-5"><a href="#cb109-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb109-6"><a href="#cb109-6" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb109-7"><a href="#cb109-7" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters(),lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb109-8"><a href="#cb109-8" aria-hidden="true" tabindex="-1"></a><span class="co">#---#</span></span>
<span id="cb109-9"><a href="#cb109-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb109-10"><a href="#cb109-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#1</span></span>
<span id="cb109-11"><a href="#cb109-11" aria-hidden="true" tabindex="-1"></a>    netout <span class="op">=</span> net(x)</span>
<span id="cb109-12"><a href="#cb109-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">#2</span></span>
<span id="cb109-13"><a href="#cb109-13" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(netout,y)</span>
<span id="cb109-14"><a href="#cb109-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">#3</span></span>
<span id="cb109-15"><a href="#cb109-15" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb109-16"><a href="#cb109-16" aria-hidden="true" tabindex="-1"></a>    <span class="co">#4 </span></span>
<span id="cb109-17"><a href="#cb109-17" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb109-18"><a href="#cb109-18" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="c52afe29-fdc1-4ba6-ac53-2de44105a58b" class="cell" data-execution_count="80">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a>ebdd,tanh,linr <span class="op">=</span> net</span>
<span id="cb110-2"><a href="#cb110-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.nn.functional.one_hot(x)</span>
<span id="cb110-3"><a href="#cb110-3" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> tanh(ebdd(x)).data</span>
<span id="cb110-4"><a href="#cb110-4" aria-hidden="true" tabindex="-1"></a>netout <span class="op">=</span> linr(tanh(ebdd(x))).data</span>
<span id="cb110-5"><a href="#cb110-5" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> torch.nn.functional.softmax(net(x),dim<span class="op">=</span><span class="dv">1</span>).data</span>
<span id="cb110-6"><a href="#cb110-6" aria-hidden="true" tabindex="-1"></a>mat <span class="op">=</span> torch.concat([X,h,netout<span class="op">/</span>netout.<span class="bu">max</span>(),yhat],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb110-7"><a href="#cb110-7" aria-hidden="true" tabindex="-1"></a><span class="co">#---#</span></span>
<span id="cb110-8"><a href="#cb110-8" aria-hidden="true" tabindex="-1"></a>plt.matshow(mat[:<span class="dv">10</span>, :],cmap<span class="op">=</span><span class="st">"bwr"</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb110-9"><a href="#cb110-9" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb110-10"><a href="#cb110-10" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">3.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb110-11"><a href="#cb110-11" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">5.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb110-12"><a href="#cb110-12" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">9.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb110-13"><a href="#cb110-13" aria-hidden="true" tabindex="-1"></a>plt.xticks(</span>
<span id="cb110-14"><a href="#cb110-14" aria-hidden="true" tabindex="-1"></a>    ticks<span class="op">=</span>[<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">9</span>,<span class="dv">10</span>,<span class="dv">11</span>,<span class="dv">12</span>,<span class="dv">13</span>],</span>
<span id="cb110-15"><a href="#cb110-15" aria-hidden="true" tabindex="-1"></a>    labels<span class="op">=</span>[</span>
<span id="cb110-16"><a href="#cb110-16" aria-hidden="true" tabindex="-1"></a>        <span class="vs">r"$x_A$"</span>,<span class="vs">r"$x_b$"</span>,<span class="vs">r"$x_c$"</span>,<span class="vs">r"$x_d$"</span>,</span>
<span id="cb110-17"><a href="#cb110-17" aria-hidden="true" tabindex="-1"></a>        <span class="vs">r"$h_1$"</span>,<span class="vs">r"$h_2$"</span>,</span>
<span id="cb110-18"><a href="#cb110-18" aria-hidden="true" tabindex="-1"></a>        <span class="vs">r"$out_A$"</span>,<span class="vs">r"$out_b$"</span>,<span class="vs">r"$out_c$"</span>,<span class="vs">r"$out_d$"</span>,</span>
<span id="cb110-19"><a href="#cb110-19" aria-hidden="true" tabindex="-1"></a>        <span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_A$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_b$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_c$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_d$"</span>]</span>
<span id="cb110-20"><a href="#cb110-20" aria-hidden="true" tabindex="-1"></a>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11wk-2_files/figure-html/cell-81-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>row0에서 yhat b,c,d의 확률은 전부 1/3 (yhat A,b,c,d를 다 더하면 1이므로)
<ul>
<li>A 다음에 b,c,d 중 뭐가 나올지 모르겠다는 의미</li>
</ul></li>
<li>b,c,d 다음 A가 나오는 것은 잘 맞춤</li>
<li>즉 embedding 공간은 널널하지만 b,c,d를 같은 문자로 보고 있음 (A / bcd)</li>
</ul>
<div id="9a9a5546-0514-4ac1-ac2b-8112c580d7f6" class="cell" data-execution_count="81">
<div class="sourceCode cell-code" id="cb111"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a>df_train</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="81">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">x</th>
<th data-quarto-table-cell-role="th">y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>A</td>
<td>b</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>b</td>
<td>A</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>A</td>
<td>c</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>c</td>
<td>A</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>A</td>
<td>d</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">294</td>
<td>A</td>
<td>b</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">295</td>
<td>b</td>
<td>A</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">296</td>
<td>A</td>
<td>c</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">297</td>
<td>c</td>
<td>A</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">298</td>
<td>A</td>
<td>d</td>
</tr>
</tbody>
</table>

<p>299 rows × 2 columns</p>
</div>
</div>
</div>
<ul>
<li>x가 A이면 y가 b,c,d 중 하나로 나오므로</li>
</ul>
<p>)🗣️</p>
<p><code>-</code> 적합</p>
<div id="a4d8fc43-6495-4ec3-89ed-d47a3c2f4b45" class="cell" data-execution_count="187">
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true" tabindex="-1"></a>    torch.nn.Embedding(<span class="dv">4</span>,<span class="dv">2</span>),</span>
<span id="cb112-3"><a href="#cb112-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.Tanh(),</span>
<span id="cb112-4"><a href="#cb112-4" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">2</span>,<span class="dv">4</span>)</span>
<span id="cb112-5"><a href="#cb112-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb112-6"><a href="#cb112-6" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb112-7"><a href="#cb112-7" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters(),lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb112-8"><a href="#cb112-8" aria-hidden="true" tabindex="-1"></a><span class="co">#---#</span></span>
<span id="cb112-9"><a href="#cb112-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb112-10"><a href="#cb112-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#1</span></span>
<span id="cb112-11"><a href="#cb112-11" aria-hidden="true" tabindex="-1"></a>    netout <span class="op">=</span> net(x)</span>
<span id="cb112-12"><a href="#cb112-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">#2</span></span>
<span id="cb112-13"><a href="#cb112-13" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(netout,y)</span>
<span id="cb112-14"><a href="#cb112-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">#3</span></span>
<span id="cb112-15"><a href="#cb112-15" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb112-16"><a href="#cb112-16" aria-hidden="true" tabindex="-1"></a>    <span class="co">#4 </span></span>
<span id="cb112-17"><a href="#cb112-17" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb112-18"><a href="#cb112-18" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><code>-</code> 결과시각화</p>
<div id="9134a985-d6a6-4588-9c41-0176e7659f22" class="cell" data-execution_count="188">
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a>ebdd,tanh,linr <span class="op">=</span> net</span>
<span id="cb113-2"><a href="#cb113-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.nn.functional.one_hot(x)</span>
<span id="cb113-3"><a href="#cb113-3" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> tanh(ebdd(x)).data</span>
<span id="cb113-4"><a href="#cb113-4" aria-hidden="true" tabindex="-1"></a>netout <span class="op">=</span> linr(tanh(ebdd(x))).data</span>
<span id="cb113-5"><a href="#cb113-5" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> torch.nn.functional.softmax(net(x),dim<span class="op">=</span><span class="dv">1</span>).data</span>
<span id="cb113-6"><a href="#cb113-6" aria-hidden="true" tabindex="-1"></a>mat <span class="op">=</span> torch.concat([X,h,netout<span class="op">/</span>netout.<span class="bu">max</span>(),yhat],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb113-7"><a href="#cb113-7" aria-hidden="true" tabindex="-1"></a><span class="co">#---#</span></span>
<span id="cb113-8"><a href="#cb113-8" aria-hidden="true" tabindex="-1"></a>plt.matshow(mat[:<span class="dv">10</span>, :],cmap<span class="op">=</span><span class="st">"bwr"</span>,vmin<span class="op">=-</span><span class="dv">1</span>,vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb113-9"><a href="#cb113-9" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb113-10"><a href="#cb113-10" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">3.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb113-11"><a href="#cb113-11" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">5.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb113-12"><a href="#cb113-12" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="fl">9.5</span>,color<span class="op">=</span><span class="st">"lime"</span>)</span>
<span id="cb113-13"><a href="#cb113-13" aria-hidden="true" tabindex="-1"></a>plt.xticks(</span>
<span id="cb113-14"><a href="#cb113-14" aria-hidden="true" tabindex="-1"></a>    ticks<span class="op">=</span>[<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">9</span>,<span class="dv">10</span>,<span class="dv">11</span>,<span class="dv">12</span>,<span class="dv">13</span>],</span>
<span id="cb113-15"><a href="#cb113-15" aria-hidden="true" tabindex="-1"></a>    labels<span class="op">=</span>[</span>
<span id="cb113-16"><a href="#cb113-16" aria-hidden="true" tabindex="-1"></a>        <span class="vs">r"$x_A$"</span>,<span class="vs">r"$x_b$"</span>,<span class="vs">r"$x_c$"</span>,<span class="vs">r"$x_d$"</span>,</span>
<span id="cb113-17"><a href="#cb113-17" aria-hidden="true" tabindex="-1"></a>        <span class="vs">r"$h_1$"</span>,<span class="vs">r"$h_2$"</span>,</span>
<span id="cb113-18"><a href="#cb113-18" aria-hidden="true" tabindex="-1"></a>        <span class="vs">r"$out_A$"</span>,<span class="vs">r"$out_b$"</span>,<span class="vs">r"$out_c$"</span>,<span class="vs">r"$out_d$"</span>,</span>
<span id="cb113-19"><a href="#cb113-19" aria-hidden="true" tabindex="-1"></a>        <span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_A$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_b$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_c$"</span>,<span class="vs">r"$\hat</span><span class="sc">{y}</span><span class="vs">_d$"</span>]</span>
<span id="cb113-20"><a href="#cb113-20" aria-hidden="true" tabindex="-1"></a>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11wk-2_files/figure-html/cell-84-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>100번 시도해봤자 100번 망함</li>
</ul>
</section>
<section id="c.-discussions" class="level2">
<h2 class="anchored" data-anchor-id="c.-discussions">C. Discussions</h2>
<p>🗣️(</p>
<pre><code>hello

h--&gt;e
e--&gt;l
l--&gt;l/o???
o--&gt;h

해결책: 2개를 보고 예측
he--&gt;l
el--&gt;l
ll--&gt;o
lo--&gt;h

한계: 2개로 예측 안되는 문자열, 몇개로 예측된다고 정할 수 없는 문자열

=&gt; 순환신경망</code></pre>
<p>)🗣️</p>
<p><code>-</code> 왜 망했을까?</p>
<p><code>-</code> <code>hello</code><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> 문자열을 맞출 수 있을까?</p>
<ul>
<li>이전시점을 많이 고려하면 맞출수는 있음.</li>
<li>그러나 이러한 방법들(AR, N-grams)은 한계가 뚜렷 <span class="math inline">\(\to\)</span> 순환신경망의 등장</li>
</ul>
</section>
</section>
<section id="겹장덧장" class="level1">
<h1>8. 겹장(덧장) 📝</h1>
<p>🗣️(</p>
<pre><code>3년전, 2년전, 햇간장을 가지고 -- 음식 --&gt; 간장계란밥

4년전 간장도 넣고 싶은데 유통 기한이 3년이라면 4년전 간장을 가지고는 음식을 못함

=&gt; 씨간장

간장 --&gt; 500년동안 묵히지 X
올해 간장 중 일부에 작년 간장을 넣으면 나중에 작년 간장의 맛을 갖게 됨

1년차 간장
2년차 간장 + 1년차간장살짝섞음 ==&gt; 1년차 맛이 남
3년차 간장 + (2년차 간장 + 1년차간장살짝섞음) ==&gt; 1,2년차맛이 같이 남
...</code></pre>
<p>)🗣️</p>
<p><strong><em><a href="https://www.joongang.co.kr/article/24087690#home">수백년전통을 이어가는 방법</a></em></strong></p>
<pre><code>“1리터에 500만원에 낙찰된 적 있습니다.”
“2kg에 1억원 정도 추산됩니다.”
“20여 종 종자장을 블렌딩해 100ml에 5000만원씩 분양 예정입니다.”

모두 씨간장(종자장) 가격에 관한 실제 일화다.

(중략...)

위스키나 와인처럼 블렌딩을 하기도 한다. 
새로 담근 간장에 씨간장을 넣거나, 씨간장독에 햇간장을 넣어 맛을 유지하기도 한다. 
이를 겹장(또는 덧장)이라 한다. 
몇몇 종갓집에선 씨간장 잇기를 몇백 년째 해오고 있다. 
매년 새로 간장을 담가야 이어갈 수 있으니 불씨 꺼트리지 않는 것처럼 굉장히 어려운 일이다.
이렇게 하는 이유는 집집마다 내려오는 고유 장맛을 잃지 않기 위함이다. 
씨간장이란 그만큼 소중한 주방의 자산이며 정체성이다.</code></pre>
<p>덧장: 새로운간장을 만들때, 옛날간장을 섞어서 만듦</p>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>2015년 Andrej Karpathy(안드레이 카파시)의 “전설적인” 블로그 <a href="https://karpathy.github.io/2015/05/21/rnn-effectiveness/" class="uri">https://karpathy.github.io/2015/05/21/rnn-effectiveness/</a> 에 담긴 예제<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>