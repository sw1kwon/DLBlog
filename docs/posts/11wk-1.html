<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="sw1kwon">
<meta name="dcterms.date" content="2025-05-14">

<title>11wk-1: (추천시스템) – Embedding 레이어, 사용자정의 네트워크, MF-based 추천시스템을 넘어서 – DeepLearning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-0626ff4d7a71b55c8707dcae1d04a9b6.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-3f453be5ec2ee49e579b43b94346acdb.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">DeepLearning</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">11wk-1: (추천시스템) – Embedding 레이어, 사용자정의 네트워크, MF-based 추천시스템을 넘어서</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>sw1kwon </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">May 14, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#강의노트-원본-및-영상-링크" id="toc-강의노트-원본-및-영상-링크" class="nav-link active" data-scroll-target="#강의노트-원본-및-영상-링크">1. 강의노트 원본 및 영상 링크 📝</a></li>
  <li><a href="#imports" id="toc-imports" class="nav-link" data-scroll-target="#imports">2. Imports 📝</a></li>
  <li><a href="#torch.nn.embedding" id="toc-torch.nn.embedding" class="nav-link" data-scroll-target="#torch.nn.embedding">3. <code>torch.nn.Embedding</code> 📝</a>
  <ul class="collapse">
  <li><a href="#a.-임베딩레이어" id="toc-a.-임베딩레이어" class="nav-link" data-scroll-target="#a.-임베딩레이어">A. 임베딩레이어</a></li>
  <li><a href="#b.-mf-based-추천시스템-재설계" id="toc-b.-mf-based-추천시스템-재설계" class="nav-link" data-scroll-target="#b.-mf-based-추천시스템-재설계">B. MF-based 추천시스템 재설계</a></li>
  </ul></li>
  <li><a href="#사용자정의-네트워크" id="toc-사용자정의-네트워크" class="nav-link" data-scroll-target="#사용자정의-네트워크">4. 사용자정의 네트워크 📝</a>
  <ul class="collapse">
  <li><a href="#a.-사용자정의-네트워크-사용법" id="toc-a.-사용자정의-네트워크-사용법" class="nav-link" data-scroll-target="#a.-사용자정의-네트워크-사용법">A. 사용자정의 네트워크 사용법</a></li>
  <li><a href="#b.-mf-based-추천시스템-재설계-1" id="toc-b.-mf-based-추천시스템-재설계-1" class="nav-link" data-scroll-target="#b.-mf-based-추천시스템-재설계-1">B. MF-based 추천시스템 재설계</a></li>
  </ul></li>
  <li><a href="#mf-based-추천시스템을-넘어서" id="toc-mf-based-추천시스템을-넘어서" class="nav-link" data-scroll-target="#mf-based-추천시스템을-넘어서">5. MF-based 추천시스템을 넘어서 📝</a>
  <ul class="collapse">
  <li><a href="#a.-nn-based-방식" id="toc-a.-nn-based-방식" class="nav-link" data-scroll-target="#a.-nn-based-방식">A. NN-based 방식</a></li>
  <li><a href="#b.-ncf-he2017neural" id="toc-b.-ncf-he2017neural" class="nav-link" data-scroll-target="#b.-ncf-he2017neural">B. NCF <span class="citation" data-cites="he2017neural">[@he2017neural]</span></a></li>
  </ul></li>
  <li><a href="#appendix-선택학습" id="toc-appendix-선택학습" class="nav-link" data-scroll-target="#appendix-선택학습">Appendix – 선택학습 📝</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>📘 <strong>Note Format Guide</strong></p>
<p>This format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 15%">
<col style="width: 42%">
<col style="width: 42%">
</colgroup>
<thead>
<tr class="header">
<th>Type</th>
<th>What It Means</th>
<th>When I Use It</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>📝 Lecture</td>
<td>Original material from the professor’s notes</td>
<td>When I’m referencing core concepts or provided code</td>
</tr>
<tr class="even">
<td>🗣️ In-Class Note</td>
<td>Verbal explanations shared during the lecture</td>
<td>When I want to record something the professor said in class but didn’t include in the official notes</td>
</tr>
<tr class="odd">
<td>✍️ My Note</td>
<td>My thoughts, interpretations, or additional explanations</td>
<td>When I reflect on or explain something in my own words</td>
</tr>
<tr class="even">
<td>🔬 Experiment</td>
<td>Code I tried out or changed to explore further</td>
<td>When I test variations or go beyond the original example</td>
</tr>
<tr class="odd">
<td>❓ Question</td>
<td>Questions I had while studying</td>
<td>When I want to revisit or research something more deeply</td>
</tr>
</tbody>
</table>
<p>📝 🗣️ ✍️ 🔬 ❓</p>
<section id="강의노트-원본-및-영상-링크" class="level1">
<h1>1. 강의노트 원본 및 영상 링크 📝</h1>
<p><a href="https://guebin.github.io/DL2025/posts/11wk-1.html">https://guebin.github.io/DL2025/posts/11wk-1.html</a></p>
</section>
<section id="imports" class="level1">
<h1>2. Imports 📝</h1>
<div id="d4dccddc-6409-4355-b92e-5d8ed3aa0238" class="cell" data-tags="[]" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="fd700095-93c4-479a-816f-276e5ab9cc32" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'figure.figsize'</span>] <span class="op">=</span> (<span class="fl">4.5</span>, <span class="fl">3.0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cf484d33-01b9-4a68-92d0-c8cfafe68961" class="cell" data-execution_count="269">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 지난시간복습</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 남여 출연자 -&gt; 궁합점수 </span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co">## train </span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># X1     X2  --&gt; y</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 영식, 보람: 0.5 </span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 영호, 하니: 4.5</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co">## test </span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co"># X1     X2  --&gt; y</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 영호, 보람: ???</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="co">#---#</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co"># 학습은 "X1: 영식 --&gt; 2 --&gt; [0,0,1,0,...0] --&gt; linr([0,0,1,0,...0]) 특징추출" 이런식으로 진행되는데, </span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 이중에서 linr(onehot(x)) 의 패턴이 반복적으로 네트워크에서 사용된다. </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="torch.nn.embedding" class="level1">
<h1>3. <code>torch.nn.Embedding</code> 📝</h1>
<section id="a.-임베딩레이어" class="level2">
<h2 class="anchored" data-anchor-id="a.-임베딩레이어">A. 임베딩레이어</h2>
<p><code>-</code> 모티브: <code>torch.nn.functional.one_hot</code> + <code>torch.nn.Linear</code> 를 매번 쓰는건 너무 귀찮지 않어?</p>
<p>🗣️(</p>
<div id="726054ed-a89e-4607-97a1-bdafaddab396" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="co">#x  = ['옥순', '영숙', '하니', '옥순', '영숙'] </span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">0</span>,<span class="dv">1</span>])</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">3</span>,<span class="dv">1</span>,bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>linr(torch.nn.functional.one_hot(x).<span class="bu">float</span>())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>tensor([[-0.2002],
        [-0.4890],
        [ 0.2081],
        [-0.2002],
        [-0.4890]], grad_fn=&lt;MmBackward0&gt;)</code></pre>
</div>
</div>
<ul>
<li>지난 시간까지는 위처럼 했음</li>
</ul>
<div id="cbbcd1db-36e8-415a-b328-aab77c1d8244" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co">#x  = ['옥순', '영숙', '하니', '옥순', '영숙'] </span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">0</span>,<span class="dv">1</span>])</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.nn.functional.one_hot(x).<span class="bu">float</span>()</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">3</span>,<span class="dv">1</span>,bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>linr(X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>tensor([[-0.2002],
        [-0.4890],
        [ 0.2081],
        [-0.2002],
        [-0.4890]], grad_fn=&lt;MmBackward0&gt;)</code></pre>
</div>
</div>
<div id="3ea2517f-d35e-46ba-a9cf-7489b205074f" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>x, X</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>(tensor([0, 1, 2, 0, 1]),
 tensor([[1., 0., 0.],
         [0., 1., 0.],
         [0., 0., 1.],
         [1., 0., 0.],
         [0., 1., 0.]]))</code></pre>
</div>
</div>
<div id="a3884898-0918-4a39-a790-883060132e63" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>linr.weight</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>Parameter containing:
tensor([[-0.2002, -0.4890,  0.2081]], requires_grad=True)</code></pre>
</div>
</div>
<div id="8eada47c-899f-461d-a536-76ac5f636160" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">@</span> linr.weight.T</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>tensor([[-0.2002],
        [-0.4890],
        [ 0.2081],
        [-0.2002],
        [-0.4890]], grad_fn=&lt;MmBackward0&gt;)</code></pre>
</div>
</div>
<p>)🗣️</p>
<div id="08abc61d-1cc6-4576-8e51-95df6c116af6" class="cell" data-execution_count="276">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co">#x  = ['옥순', '영숙', '하니', '옥순', '영숙'] </span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">0</span>,<span class="dv">1</span>])</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.nn.functional.one_hot(x).<span class="bu">float</span>()</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">3</span>,<span class="dv">1</span>,bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>linr(X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="276">
<pre><code>tensor([[-0.2002],
        [-0.4890],
        [ 0.2081],
        [-0.2002],
        [-0.4890]], grad_fn=&lt;MmBackward0&gt;)</code></pre>
</div>
</div>
<p><code>-</code> 계산방식</p>
<ul>
<li><p><span class="math inline">\({\boldsymbol x}= \begin{bmatrix} 0 \\ 1 \\ 2 \\ 0 \\ 1 \end{bmatrix} \Longrightarrow {\bf X}= \begin{bmatrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1 \\ 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \end{bmatrix}\)</span></p></li>
<li><p><span class="math inline">\(\text{linr}({\bf X})= \begin{bmatrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1 \\ 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \end{bmatrix}\begin{bmatrix} -0.2002 \\ -0.4890 \\ 0.2081 \end{bmatrix} = \begin{bmatrix} -0.2002 \\ -0.4890 \\ 0.2081 \\ -0.2002 \\ -0.4890 \end{bmatrix}\)</span></p></li>
</ul>
<p><code>-</code> <code>torch.nn.functional.one_hot</code> + <code>torch.nn.Linear</code> 를 함께처리해주는 레이어 <code>torch.nn.Embedding</code> 존재</p>
<p>🗣️(</p>
<ul>
<li>다른 방식으로 할 수도 있음</li>
</ul>
<div id="d0014a7d-eccd-4417-8648-ef2539077632" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="co">#x  = ['옥순', '영숙', '하니', '옥순', '영숙'] </span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">0</span>,<span class="dv">1</span>])</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>ebdd <span class="op">=</span> torch.nn.Embedding(<span class="dv">3</span>,<span class="dv">1</span>)</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>ebdd(x) <span class="co"># 이렇게 하면 숫자들이 나옴 (위와는 다름)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>tensor([[-0.8178],
        [-0.7052],
        [-0.5843],
        [-0.8178],
        [-0.7052]], grad_fn=&lt;EmbeddingBackward0&gt;)</code></pre>
</div>
</div>
<div id="f7663ca7-4d62-468b-85b8-5c4139786c16" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co">#x  = ['옥순', '영숙', '하니', '옥순', '영숙'] </span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">0</span>,<span class="dv">1</span>])</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>ebdd <span class="op">=</span> torch.nn.Embedding(<span class="dv">3</span>,<span class="dv">1</span>)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>ebdd(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>tensor([[-0.6179],
        [ 1.9949],
        [-0.4724],
        [-0.6179],
        [ 1.9949]], grad_fn=&lt;EmbeddingBackward0&gt;)</code></pre>
</div>
</div>
<div id="32e3af41-4828-4100-b0bf-e980d7d3c0bf" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>ebdd.weight</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>Parameter containing:
tensor([[-0.6179],
        [ 1.9949],
        [-0.4724]], requires_grad=True)</code></pre>
</div>
</div>
<div id="347f53e4-377e-4405-8cd5-d5cdf9ca31fb" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>linr.weight</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>Parameter containing:
tensor([[-0.2002, -0.4890,  0.2081]], requires_grad=True)</code></pre>
</div>
</div>
<div class="sourceCode" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>ebdd.weight.data <span class="op">=</span> torch.tensor([[<span class="op">-</span><span class="fl">0.2002</span>],[<span class="op">-</span><span class="fl">0.4890</span>],[<span class="fl">0.2081</span>]]) <span class="co"># 이전 linr의 parameter로 덮어쓰면</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="5844ac1d-51e6-4555-89ac-b8fe4ff26c6f" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="co">#x  = ['옥순', '영숙', '하니', '옥순', '영숙'] </span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">0</span>,<span class="dv">1</span>])</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>ebdd <span class="op">=</span> torch.nn.Embedding(<span class="dv">3</span>,<span class="dv">1</span>)</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>ebdd.weight.data <span class="op">=</span> torch.tensor([[<span class="op">-</span><span class="fl">0.2002</span>],[<span class="op">-</span><span class="fl">0.4890</span>],[<span class="fl">0.2081</span>]])</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>ebdd(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>tensor([[-0.2002],
        [-0.4890],
        [ 0.2081],
        [-0.2002],
        [-0.4890]], grad_fn=&lt;EmbeddingBackward0&gt;)</code></pre>
</div>
</div>
<div id="2040c647-1250-4413-9383-16077c3bb60e" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>linr(X) <span class="co"># 위와 동일</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>tensor([[-0.2002],
        [-0.4890],
        [ 0.2081],
        [-0.2002],
        [-0.4890]], grad_fn=&lt;MmBackward0&gt;)</code></pre>
</div>
</div>
<ul>
<li>Embedding에는 one hot encoding 후 linr 을 할 때의 차원을 넣어주면 됨</li>
</ul>
<p>)🗣️</p>
<div id="6dc36ae6-8747-4d34-b821-592c6f6d0eb9" class="cell" data-execution_count="288">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co">#x  = ['옥순', '영숙', '하니', '옥순', '영숙'] </span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">0</span>,<span class="dv">1</span>])</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>ebdd <span class="op">=</span> torch.nn.Embedding(<span class="dv">3</span>,<span class="dv">1</span>)</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>ebdd.weight.data <span class="op">=</span> torch.tensor([[<span class="op">-</span><span class="fl">0.2002</span>],[<span class="op">-</span><span class="fl">0.4890</span>],[<span class="fl">0.2081</span>]])</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>ebdd(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="288">
<pre><code>tensor([[-0.2002],
        [-0.4890],
        [ 0.2081],
        [-0.2002],
        [-0.4890]], grad_fn=&lt;EmbeddingBackward0&gt;)</code></pre>
</div>
</div>
<ul>
<li><p><span class="math inline">\(\text{ebdd}({\boldsymbol x})= \text{linr}\big(\text{onehot}({\boldsymbol x})\big) = \begin{bmatrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1 \\ 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \end{bmatrix}\begin{bmatrix} -0.2002 \\ -0.4890 \\ 0.2081 \end{bmatrix} = \begin{bmatrix} -0.2002 \\ -0.4890 \\ 0.2081 \\ -0.2002 \\ -0.4890 \end{bmatrix}\)</span></p></li>
<li><p>우리가 이전에 구현했던 코드 “onehot + linr” 와 “ebdd”는 정확하게 동일한 동작을 수행함.</p></li>
</ul>
<p><code>-</code> 결론: 아래의 두개의 코드는 같다.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>x<span class="op">=</span> torch.tensor([<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">0</span>,<span class="dv">1</span>])</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="co">## 코드1 </span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>linr <span class="op">=</span> torch.nn.Linear(<span class="dv">3</span>,<span class="dv">1</span>) </span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>linr(torch.nn.functional.one_hot(x))</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="co">## 코드2 </span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>ebdd <span class="op">=</span> torch.nn.Embedding(<span class="dv">3</span>,<span class="dv">1</span>)</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>ebdd(x) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="b.-mf-based-추천시스템-재설계" class="level2">
<h2 class="anchored" data-anchor-id="b.-mf-based-추천시스템-재설계">B. MF-based 추천시스템 재설계</h2>
<p>아래의 자료를 활용하여 추천시스템을 설계하고자한다.</p>
<div id="31e8b32c-b5e7-4265-bdc9-f40af1d9497c" class="cell" data-tags="[]" data-execution_count="19">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>df_view <span class="op">=</span> pd.read_csv(<span class="st">'https://raw.githubusercontent.com/guebin/DL2025/main/posts/iamsolo.csv'</span>,index_col<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>df_view</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">영식(IN)</th>
<th data-quarto-table-cell-role="th">영철(IN)</th>
<th data-quarto-table-cell-role="th">영호(IS)</th>
<th data-quarto-table-cell-role="th">광수(IS)</th>
<th data-quarto-table-cell-role="th">상철(EN)</th>
<th data-quarto-table-cell-role="th">영수(EN)</th>
<th data-quarto-table-cell-role="th">규빈(ES)</th>
<th data-quarto-table-cell-role="th">다호(ES)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">옥순(IN)</td>
<td>NaN</td>
<td>4.02</td>
<td>3.45</td>
<td>3.42</td>
<td>0.84</td>
<td>1.12</td>
<td>0.43</td>
<td>0.49</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">영자(IN)</td>
<td>3.93</td>
<td>3.99</td>
<td>3.63</td>
<td>3.43</td>
<td>0.98</td>
<td>0.96</td>
<td>0.52</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">정숙(IS)</td>
<td>3.52</td>
<td>3.42</td>
<td>4.05</td>
<td>4.06</td>
<td>0.39</td>
<td>NaN</td>
<td>0.93</td>
<td>0.99</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">영숙(IS)</td>
<td>3.43</td>
<td>3.57</td>
<td>NaN</td>
<td>3.95</td>
<td>0.56</td>
<td>0.52</td>
<td>0.89</td>
<td>0.89</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">순자(EN)</td>
<td>1.12</td>
<td>NaN</td>
<td>0.59</td>
<td>0.43</td>
<td>4.01</td>
<td>4.16</td>
<td>3.52</td>
<td>3.38</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">현숙(EN)</td>
<td>0.94</td>
<td>1.05</td>
<td>0.32</td>
<td>0.45</td>
<td>4.02</td>
<td>3.78</td>
<td>NaN</td>
<td>3.54</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">서연(ES)</td>
<td>0.51</td>
<td>0.56</td>
<td>0.88</td>
<td>0.89</td>
<td>3.50</td>
<td>3.64</td>
<td>4.04</td>
<td>4.10</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">보람(ES)</td>
<td>0.48</td>
<td>0.51</td>
<td>1.03</td>
<td>NaN</td>
<td>3.52</td>
<td>4.00</td>
<td>3.82</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">하니(I)</td>
<td>4.85</td>
<td>4.82</td>
<td>NaN</td>
<td>4.98</td>
<td>4.53</td>
<td>4.39</td>
<td>4.45</td>
<td>4.52</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="7dead91a-88b7-47dc-8890-688c61a1cf39" class="cell" data-tags="[]" data-execution_count="20">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>df_train <span class="op">=</span> df_view.stack().reset_index().set_axis([<span class="st">'W'</span>,<span class="st">'M'</span>,<span class="st">'y'</span>],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>여성인덱스 <span class="op">=</span> {<span class="st">'옥순(IN)'</span>:<span class="dv">0</span>, <span class="st">'영자(IN)'</span>:<span class="dv">1</span>, <span class="st">'정숙(IS)'</span>:<span class="dv">2</span>, <span class="st">'영숙(IS)'</span>:<span class="dv">3</span>, <span class="st">'순자(EN)'</span>:<span class="dv">4</span>, <span class="st">'현숙(EN)'</span>:<span class="dv">5</span>, <span class="st">'서연(ES)'</span>:<span class="dv">6</span>, <span class="st">'보람(ES)'</span>:<span class="dv">7</span>, <span class="st">'하니(I)'</span>:<span class="dv">8</span>}</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>남성인덱스 <span class="op">=</span> {<span class="st">'영식(IN)'</span>:<span class="dv">0</span>, <span class="st">'영철(IN)'</span>:<span class="dv">1</span>, <span class="st">'영호(IS)'</span>:<span class="dv">2</span>, <span class="st">'광수(IS)'</span>:<span class="dv">3</span>, <span class="st">'상철(EN)'</span>:<span class="dv">4</span>, <span class="st">'영수(EN)'</span>:<span class="dv">5</span>, <span class="st">'규빈(ES)'</span>:<span class="dv">6</span>, <span class="st">'다호(ES)'</span>:<span class="dv">7</span>}</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>x1 <span class="op">=</span> torch.tensor(df_train[<span class="st">'W'</span>].<span class="bu">map</span>(여성인덱스)) <span class="co"># length-n int vector </span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>x2 <span class="op">=</span> torch.tensor(df_train[<span class="st">'M'</span>].<span class="bu">map</span>(남성인덱스)) <span class="co"># length-n int vector </span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.tensor(df_train[<span class="st">'y'</span>]).<span class="bu">float</span>().reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>) <span class="co"># (n,1) float vector</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>임베딩레이어를 활용하여 MF-based 추천시스템을 설계하라.</p>
<p>(풀이)</p>
<p>🗣️(</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 지난 시간에는 x1이 one hot encoding 된 형태</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>X1 <span class="op">=</span> torch.nn.functional.one_hot(x1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="179cb334-fd6c-4c6c-9502-4510d3c8a380" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>x1 <span class="co"># 이제는 이 상태에서 바로 학습을 시키려고 함 (임베딩 레이어 활용)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3,
        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6,
        6, 6, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8])</code></pre>
</div>
</div>
<ul>
<li>이전 시간 코드를 참고하여 수정하면</li>
</ul>
<div class="sourceCode" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co">#----#</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>l1 <span class="op">=</span> torch.nn.Linear(<span class="dv">9</span>,<span class="dv">2</span>,bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>l2 <span class="op">=</span> torch.nn.Linear(<span class="dv">8</span>,<span class="dv">2</span>,bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>b1 <span class="op">=</span> torch.nn.Linear(<span class="dv">9</span>,<span class="dv">1</span>,bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>b2 <span class="op">=</span> torch.nn.Linear(<span class="dv">8</span>,<span class="dv">1</span>,bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> <span class="bu">list</span>(l1.parameters()) <span class="op">+</span> <span class="bu">list</span>(l2.parameters())  <span class="op">+</span> <span class="bu">list</span>(b1.parameters()) <span class="op">+</span> <span class="bu">list</span>(b2.parameters())</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(params) </span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>sig <span class="op">=</span> torch.nn.Sigmoid()</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a><span class="co">#----#</span></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step1</span></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>    W_features <span class="op">=</span> l1(X1) </span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>    M_features <span class="op">=</span> l2(X2)</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>    W_bias <span class="op">=</span> b1(X1)</span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a>    M_bias <span class="op">=</span> b2(X2)</span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> sig((W_features <span class="op">*</span> M_features).<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>) <span class="op">+</span> W_bias <span class="op">+</span> M_bias)<span class="op">*</span><span class="dv">5</span></span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step2</span></span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y)</span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a>    <span class="co">#stpe3</span></span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step4</span></span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="c5bf0c86-caff-45dd-8c24-7618d9c071d6" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co">#df_view</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>ebdd1 <span class="op">=</span> torch.nn.Embedding(<span class="dv">9</span>,<span class="dv">2</span>)</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>ebdd2 <span class="op">=</span> torch.nn.Embedding(<span class="dv">8</span>,<span class="dv">2</span>)</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>b1 <span class="op">=</span> torch.nn.Embedding(<span class="dv">9</span>,<span class="dv">1</span>)</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>b2 <span class="op">=</span> torch.nn.Embedding(<span class="dv">8</span>,<span class="dv">1</span>)</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> <span class="bu">list</span>(ebdd1.parameters()) <span class="op">+</span> <span class="bu">list</span>(ebdd2.parameters())  <span class="op">+</span> <span class="bu">list</span>(b1.parameters()) <span class="op">+</span> <span class="bu">list</span>(b2.parameters())</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(params)</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>sig <span class="op">=</span> torch.nn.Sigmoid()</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a><span class="co">#----#</span></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5000</span>):</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step1</span></span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>    W_features <span class="op">=</span> ebdd1(x1) </span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>    M_features <span class="op">=</span> ebdd2(x2) </span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a>    W_bias <span class="op">=</span> b1(x1)</span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>    M_bais <span class="op">=</span> b2(x2)</span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> sig((W_features <span class="op">*</span> M_features).<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>) <span class="op">+</span> W_bias <span class="op">+</span> M_bais)<span class="op">*</span><span class="dv">5</span></span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step2</span></span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y)</span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step3</span></span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step4</span></span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="4f1a1c46-a289-45ad-8633-e4b925354a96" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>y[:<span class="dv">5</span>], yhat[:<span class="dv">5</span>] <span class="co"># 그럭저럭 잘 맞추고 있음</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>(tensor([[4.0200],
         [3.4500],
         [3.4200],
         [0.8400],
         [1.1200]]),
 tensor([[3.6066],
         [3.6236],
         [3.6976],
         [0.7890],
         [0.8583]], grad_fn=&lt;SliceBackward0&gt;))</code></pre>
</div>
</div>
<p>)🗣️</p>
<div id="bf857cf7-4cfd-4b14-9c82-0afd328ab514" class="cell" data-execution_count="325">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co">#df_view</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>ebdd1 <span class="op">=</span> torch.nn.Embedding(<span class="dv">9</span>,<span class="dv">2</span>)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>ebdd2 <span class="op">=</span> torch.nn.Embedding(<span class="dv">8</span>,<span class="dv">2</span>)</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>b1 <span class="op">=</span> torch.nn.Embedding(<span class="dv">9</span>,<span class="dv">1</span>)</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>b2 <span class="op">=</span> torch.nn.Embedding(<span class="dv">8</span>,<span class="dv">1</span>)</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> <span class="bu">list</span>(ebdd1.parameters()) <span class="op">+</span> <span class="bu">list</span>(ebdd2.parameters())  <span class="op">+</span> <span class="bu">list</span>(b1.parameters()) <span class="op">+</span> <span class="bu">list</span>(b2.parameters())</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(params)</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>sig <span class="op">=</span> torch.nn.Sigmoid()</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a><span class="co">#----#</span></span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5000</span>):</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step1</span></span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>    W_features <span class="op">=</span> ebdd1(x1) </span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a>    M_features <span class="op">=</span> ebdd2(x2) </span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a>    W_bias <span class="op">=</span> b1(x1)</span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a>    M_bais <span class="op">=</span> b2(x2)</span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> sig((W_features <span class="op">*</span> M_features).<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>) <span class="op">+</span> W_bias <span class="op">+</span> M_bais)<span class="op">*</span><span class="dv">5</span></span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step2</span></span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y)</span>
<span id="cb41-20"><a href="#cb41-20" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step3</span></span>
<span id="cb41-21"><a href="#cb41-21" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb41-22"><a href="#cb41-22" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step4</span></span>
<span id="cb41-23"><a href="#cb41-23" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb41-24"><a href="#cb41-24" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="d599ac5b-22d9-48b5-8c60-ddb6cd5ffab3" class="cell" data-execution_count="326">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>y[:<span class="dv">5</span>], yhat[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="326">
<pre><code>(tensor([[4.0200],
         [3.4500],
         [3.4200],
         [0.8400],
         [1.1200]]),
 tensor([[3.9809],
         [3.4865],
         [3.4730],
         [0.8163],
         [0.9715]], grad_fn=&lt;SliceBackward0&gt;))</code></pre>
</div>
</div>
</section>
</section>
<section id="사용자정의-네트워크" class="level1">
<h1>4. 사용자정의 네트워크 📝</h1>
<p>🗣️(</p>
<ul>
<li>yhat을 간단히 구하고 싶음</li>
</ul>
<div class="sourceCode" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co">#----#</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5000</span>):</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step1</span></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># W_features = ebdd1(x1) </span></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># M_features = ebdd2(x2) </span></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># W_bias = b1(x1)</span></span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># M_bais = b2(x2)</span></span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># yhat = sig((W_features * M_features).sum(axis=1).reshape(-1,1) + W_bias + M_bais)*5</span></span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> net(x1,x2) <span class="co"># 이런 식으로</span></span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step2</span></span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y)</span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step3</span></span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step4</span></span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>)🗣️</p>
<section id="a.-사용자정의-네트워크-사용법" class="level2">
<h2 class="anchored" data-anchor-id="a.-사용자정의-네트워크-사용법">A. 사용자정의 네트워크 사용법</h2>
<p><code># 예비학습1</code>: <code>net(X)</code>와 사실 <code>net.forward(X)</code>는 같다.</p>
<p>🗣️(</p>
<div id="86ab4abd-895b-4d3d-8dac-f5c5cd7aca37" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">1</span>,<span class="dv">1</span>),</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.Sigmoid()</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="491385ff-d7a5-4736-a2ba-9bc9a97775b4" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.randn(<span class="dv">5</span>,<span class="dv">1</span>)</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>net(X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>tensor([[0.5705],
        [0.7858],
        [0.8796],
        [0.8451],
        [0.8138]], grad_fn=&lt;SigmoidBackward0&gt;)</code></pre>
</div>
</div>
<div id="693bcd3b-eec4-4195-932b-e516bd508119" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>net.forward(X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>tensor([[0.5705],
        [0.7858],
        [0.8796],
        [0.8451],
        [0.8138]], grad_fn=&lt;SigmoidBackward0&gt;)</code></pre>
</div>
</div>
<ul>
<li>net(X)과 net.forward(X)는 동일</li>
<li>net.forward(X)는 function이어서 이를 통해 nex(X)를 다시 정의할 수 있음</li>
</ul>
<div id="a5ab3962-b156-45e0-9b50-7022271fab73" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> func(x):</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">"메롱"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="addfef7a-ebb2-4e2e-ba58-636cf2d88ef0" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>func(<span class="dv">33</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>'메롱'</code></pre>
</div>
</div>
<div id="52577e90-c738-4823-9e71-e90a08b86110" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>func(<span class="st">'sss'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>'메롱'</code></pre>
</div>
</div>
<div id="d2b905c2-5945-490c-b9c2-5c05d9f83a23" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>net.forward <span class="op">=</span> func</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="251c4329-29be-47f5-be68-57a68fb1c1e6" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>net.forward(X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>'메롱'</code></pre>
</div>
</div>
<div id="795880b5-6c45-4f30-8ae7-77f2629f233a" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>net(X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>'메롱'</code></pre>
</div>
</div>
<p>)🗣️</p>
<div id="fe4c05c3-2a39-4ed4-bb07-170a110cfec0" class="cell" data-execution_count="339">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(<span class="dv">1</span>,<span class="dv">1</span>),</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.Sigmoid()</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.randn(<span class="dv">5</span>,<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="000b4add-5303-4b44-9fa7-b443d5c08748" class="cell" data-execution_count="341">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>net(X)</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a><span class="co">#net.forward(X)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="341">
<pre><code>tensor([[0.3340],
        [0.4480],
        [0.3143],
        [0.2375],
        [0.2066]], grad_fn=&lt;SigmoidBackward0&gt;)</code></pre>
</div>
</div>
<p>그래서 <code>net.forward</code>를 재정의하면 <code>net(X)</code>의 기능을 재정의 할 수 있다.</p>
<div id="898715a9-bcd8-454f-9379-983bd192af8d" class="cell" data-execution_count="342">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> func(x):</span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">"메롱"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="1cbd8991-8321-4b37-836d-e77af9d4253c" class="cell" data-execution_count="348">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>net.forward <span class="op">=</span> func </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="7d5d17c6-3760-4314-8770-92f4dae04cca" class="cell" data-execution_count="349">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>net.forward(X) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="349">
<pre><code>'메롱'</code></pre>
</div>
</div>
<div id="695294dc-3eb6-4e7f-a8c7-1476b2e8059d" class="cell" data-execution_count="350">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>net(X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="350">
<pre><code>'메롱'</code></pre>
</div>
</div>
<p><code>#</code></p>
<p><code># 예비학습2</code>: <code>torch.nn.Module</code>을 상속받아서 네트워크를 만들면 (= “<code>class XXX(torch.nn.Module):</code>” 와 같은 방식으로 클래스를 선언하면) 약속된 아키텍처를 가진 네트워크를 찍어내는 함수를 만들 수 있다.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>클래스의 기초가 부족한 분들은 아래의 링크에서</p>
<ul>
<li><a href="https://guebin.github.io/PP2024/" class="uri">https://guebin.github.io/PP2024/</a></li>
</ul>
<p><code>11wk-2</code>, <code>12wk-2</code>, <code>13wk-2</code>, <code>14wk-2</code> 에 대한내용을 학습하시길 바랍니다.</p>
</div>
</div>
<ul>
<li>🗣️ 이전에 만든 사용자 정의 레이어와 방식 비슷</li>
</ul>
<p>(예제1) – <code>torch.nn.Module</code>의 상속을 이용하여 아래와 동일한 아키텍처를 가지는 네트워크를 설계하라.</p>
<div id="6d644969-b24a-4a02-9d4e-6fea2a6d80a8" class="cell" data-execution_count="377">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(in_features<span class="op">=</span><span class="dv">1</span>,out_features<span class="op">=</span><span class="dv">1</span>,bias<span class="op">=</span><span class="va">True</span>), <span class="co"># linr1</span></span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.Sigmoid(),<span class="co">#sig</span></span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(in_features<span class="op">=</span><span class="dv">1</span>,out_features<span class="op">=</span><span class="dv">1</span>,bias<span class="op">=</span><span class="va">False</span>) <span class="co"># linr2 </span></span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="925857ba-3116-48f4-8c1a-0aec96703146" class="cell" data-execution_count="378">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([[<span class="fl">1.0</span>]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="6a2949fd-b6aa-4fca-a3a4-c54c3f938e3e" class="cell" data-execution_count="379">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>net(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="379">
<pre><code>tensor([[-0.5737]], grad_fn=&lt;MmBackward0&gt;)</code></pre>
</div>
</div>
<p>(풀이)</p>
<p>🗣️(</p>
<div id="c12f0df2-884d-4544-817c-a7dcdaec1fa9" class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(in_features<span class="op">=</span><span class="dv">1</span>,out_features<span class="op">=</span><span class="dv">1</span>,bias<span class="op">=</span><span class="va">True</span>), <span class="co"># linr1</span></span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.Sigmoid(),<span class="co">#sig</span></span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(in_features<span class="op">=</span><span class="dv">1</span>,out_features<span class="op">=</span><span class="dv">1</span>,bias<span class="op">=</span><span class="va">False</span>) <span class="co"># linr2 </span></span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="acf7640b-b4a3-4941-86b4-0eef8929b3ae" class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([[<span class="fl">1.0</span>]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="f6c5cc7d-699d-4b94-95d0-898cda12dc58" class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>net(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="48">
<pre><code>tensor([[-0.3695]], grad_fn=&lt;MmBackward0&gt;)</code></pre>
</div>
</div>
<div id="ad3c85fc-1298-4dff-a562-1366207810a4" class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MyNet1(torch.nn.Module):</span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linr1 <span class="op">=</span> torch.nn.Linear(in_features<span class="op">=</span><span class="dv">1</span>,out_features<span class="op">=</span><span class="dv">1</span>,bias<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb77-5"><a href="#cb77-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sig <span class="op">=</span> torch.nn.Sigmoid()</span>
<span id="cb77-6"><a href="#cb77-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linr2 <span class="op">=</span> torch.nn.Linear(in_features<span class="op">=</span><span class="dv">1</span>,out_features<span class="op">=</span><span class="dv">1</span>,bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb77-7"><a href="#cb77-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>,x):</span>
<span id="cb77-8"><a href="#cb77-8" aria-hidden="true" tabindex="-1"></a>        <span class="co">#net(x): x --&gt; linr --&gt; sig --&gt; linr</span></span>
<span id="cb77-9"><a href="#cb77-9" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.linr2(<span class="va">self</span>.sig(<span class="va">self</span>.linr1(x))) <span class="co"># 구분을 위해 linr1 linr2</span></span>
<span id="cb77-10"><a href="#cb77-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="0dbd7195-8be5-432b-bbfc-733b75d7db54" class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> MyNet1()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="83fc155e-8319-4026-970b-b0be644b7156" class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>net(x) <span class="co"># 값은 달라지지만 동일한 기능을 수행</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="50">
<pre><code>tensor([[-0.0929]], grad_fn=&lt;MmBackward0&gt;)</code></pre>
</div>
</div>
<p>)🗣️</p>
<div id="fa23db0b-8afa-4364-812b-d0e43f40adfe" class="cell" data-execution_count="386">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MyNet1(torch.nn.Module):</span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linr1 <span class="op">=</span> torch.nn.Linear(in_features<span class="op">=</span><span class="dv">1</span>,out_features<span class="op">=</span><span class="dv">1</span>,bias<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb81-5"><a href="#cb81-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sig <span class="op">=</span> torch.nn.Sigmoid()</span>
<span id="cb81-6"><a href="#cb81-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linr2 <span class="op">=</span> torch.nn.Linear(in_features<span class="op">=</span><span class="dv">1</span>,out_features<span class="op">=</span><span class="dv">1</span>,bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb81-7"><a href="#cb81-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>,x):</span>
<span id="cb81-8"><a href="#cb81-8" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.linr2(<span class="va">self</span>.sig(<span class="va">self</span>.linr1(x)))</span>
<span id="cb81-9"><a href="#cb81-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>(예시2) – <code>torch.nn.Module</code>의 상속을 이용하여 아래와 동일한 동작을 하는 네트워크를 설계하라.</p>
<div id="1ba5a600-33d6-44d2-88cd-cbb2fa857880" class="cell" data-execution_count="389">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(in_features<span class="op">=</span><span class="dv">1</span>,out_features<span class="op">=</span><span class="dv">1</span>,bias<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a>    torch.nn.ReLU(),</span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(in_features<span class="op">=</span><span class="dv">1</span>,out_features<span class="op">=</span><span class="dv">1</span>,bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>(풀이)</p>
<div id="3973069e-5194-44eb-9516-c0e4ab5ba682" class="cell" data-execution_count="390">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MyNet2(torch.nn.Module):</span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linr1 <span class="op">=</span> torch.nn.Linear(in_features<span class="op">=</span><span class="dv">1</span>,out_features<span class="op">=</span><span class="dv">1</span>,bias<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb83-5"><a href="#cb83-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.relu <span class="op">=</span> torch.nn.ReLU()</span>
<span id="cb83-6"><a href="#cb83-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linr2 <span class="op">=</span> torch.nn.Linear(in_features<span class="op">=</span><span class="dv">1</span>,out_features<span class="op">=</span><span class="dv">1</span>,bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb83-7"><a href="#cb83-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>,X):</span>
<span id="cb83-8"><a href="#cb83-8" aria-hidden="true" tabindex="-1"></a>        netout <span class="op">=</span> <span class="va">self</span>.linr2(<span class="va">self</span>.relu(<span class="va">self</span>.linr1(x)))</span>
<span id="cb83-9"><a href="#cb83-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> netout</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong><em>사용자 정의 네트워크를 만드는 방법</em></strong></p>
<p><strong>step1:</strong> 아래와 코드를 복사하여 틀을 만든다. (이건 무조건 고정임, XXXX 자리는 원하는 이름을 넣는다)</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> XXXX(torch.nn.Module):</span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a>        <span class="co">## 우리가 netout을 구할때 사용할 레이어를 정의 </span></span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a>        <span class="co">## 정의 끝</span></span>
<span id="cb84-7"><a href="#cb84-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>,X):</span>
<span id="cb84-8"><a href="#cb84-8" aria-hidden="true" tabindex="-1"></a>        <span class="co">## netout을 어떻게 구할것인지 정의 </span></span>
<span id="cb84-9"><a href="#cb84-9" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb84-10"><a href="#cb84-10" aria-hidden="true" tabindex="-1"></a>        <span class="co">## 정의 끝</span></span>
<span id="cb84-11"><a href="#cb84-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> netout</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li><code>forward</code>의 입력: <code>X</code>는 <code>net(X)</code>에 사용하는 <code>X</code>임</li>
<li><code>forward</code>의 출력: <code>netout</code>은 <code>net.forward(X)</code> 함수의 리턴값임</li>
<li>당연히 <code>X</code>/<code>netout</code>은 다른 변수로 써도 무방 (예를들면 <code>input</code>/<code>output</code> 이라든지)</li>
</ul>
<p><strong>step2:</strong> <code>def __init__(self):</code>에 yhat을 구하기 위해 필요한 재료를 레이어를 정의하고 이름을 붙인다. 이름은 항상 <code>self.xxx</code> 와 같은 식으로 정의한다.</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> XXXX(torch.nn.Module):</span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a>        <span class="co">## 우리가 netout을 구할때 사용할 레이어를 정의 </span></span>
<span id="cb85-5"><a href="#cb85-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.xxx1 <span class="op">=</span> torch.nn.Linear(in_features<span class="op">=</span><span class="dv">1</span>,out_features<span class="op">=</span><span class="dv">1</span>,bias<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb85-6"><a href="#cb85-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.xxx2 <span class="op">=</span> torch.nn.Sigmoid()</span>
<span id="cb85-7"><a href="#cb85-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.xxx3 <span class="op">=</span> torch.nn.Linear(in_features<span class="op">=</span><span class="dv">1</span>,out_features<span class="op">=</span><span class="dv">1</span>,bias<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb85-8"><a href="#cb85-8" aria-hidden="true" tabindex="-1"></a>        <span class="co">## 정의 끝</span></span>
<span id="cb85-9"><a href="#cb85-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>,X):</span>
<span id="cb85-10"><a href="#cb85-10" aria-hidden="true" tabindex="-1"></a>        <span class="co">## netout을 어떻게 구할것인지 정의 </span></span>
<span id="cb85-11"><a href="#cb85-11" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb85-12"><a href="#cb85-12" aria-hidden="true" tabindex="-1"></a>        <span class="co">## 정의 끝</span></span>
<span id="cb85-13"><a href="#cb85-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> netout</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>step3:</strong> <code>def forward:</code>에 “X –&gt; netout” 으로 가는 과정을 묘사한 코드를 작성하고 netout을 리턴하도록 한다.</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> XXXX(torch.nn.Module):</span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>        <span class="co">## 우리가 netout 구할때 사용할 레이어를 정의 </span></span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.xxx1 <span class="op">=</span> torch.nn.Linear(in_features<span class="op">=</span><span class="dv">1</span>,out_features<span class="op">=</span><span class="dv">1</span>,bias<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.xxx2 <span class="op">=</span> torch.nn.Sigmoid()</span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.xxx3 <span class="op">=</span> torch.nn.Linear(in_features<span class="op">=</span><span class="dv">1</span>,out_features<span class="op">=</span><span class="dv">1</span>,bias<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb86-8"><a href="#cb86-8" aria-hidden="true" tabindex="-1"></a>        <span class="co">## 정의 끝</span></span>
<span id="cb86-9"><a href="#cb86-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>,X):</span>
<span id="cb86-10"><a href="#cb86-10" aria-hidden="true" tabindex="-1"></a>        <span class="co">## netout을 어떻게 구할것인지 정의 </span></span>
<span id="cb86-11"><a href="#cb86-11" aria-hidden="true" tabindex="-1"></a>        u <span class="op">=</span> <span class="va">self</span>.xxx1(X) </span>
<span id="cb86-12"><a href="#cb86-12" aria-hidden="true" tabindex="-1"></a>        v <span class="op">=</span> <span class="va">self</span>.xxx2(u)</span>
<span id="cb86-13"><a href="#cb86-13" aria-hidden="true" tabindex="-1"></a>        netout <span class="op">=</span> <span class="va">self</span>.xxx3(v) </span>
<span id="cb86-14"><a href="#cb86-14" aria-hidden="true" tabindex="-1"></a>        <span class="co">## 정의 끝</span></span>
<span id="cb86-15"><a href="#cb86-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> netout</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><code>#</code></p>
<p><code># 실습(2025-중간고사 4번)</code>: 자유 낙하 운동이란 어떤 물체가 일정한 높이에서 떨어져 지면에 도달하기 까지 걸리는 시간을 다루는 물리학 개념이다. 다음은 물리학의 자유 낙하 운동에서 착안하여 생성한 데이터이다.</p>
<div id="5bc7c052-39e7-426b-9c0e-00ded7fe5bd2" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="51">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> torch.rand(<span class="dv">100</span>)<span class="op">*</span><span class="dv">100</span></span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a>h,_ <span class="op">=</span> h.sort()</span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> h.reshape(<span class="dv">100</span>,<span class="dv">1</span>)</span>
<span id="cb87-5"><a href="#cb87-5" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> torch.sqrt(<span class="dv">2</span><span class="op">*</span>h<span class="op">/</span><span class="fl">9.8</span>) <span class="op">+</span> torch.randn([<span class="dv">100</span>,<span class="dv">1</span>])<span class="op">*</span><span class="fl">0.1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>여기에서 <span class="math inline">\(h\)</span>는 낙하전의 높이(단위: m), <span class="math inline">\(t\)</span>는 해당높이에서 물치가 지면에 도달하기 까지 걸리는 시간(단위:초)을 의미한다. 예를 들어 아래의 자료는 <span class="math inline">\(h=99.3920, t=4.4583\)</span>를 의미하는데</p>
<div id="b97f7a93-1291-4d58-823c-b0379c51b54b" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="52">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>h[<span class="op">-</span><span class="dv">1</span>], t[<span class="op">-</span><span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="52">
<pre><code>(tensor([99.3920]), tensor([4.4583]))</code></pre>
</div>
</div>
<p>이것은 높이 <span class="math inline">\(99.3920\)</span>m에서 낙하한 물체가 약 <span class="math inline">\(4.4583\)</span>초만에 지면에 도달했음을 의미한다. 아래의 그림은 <span class="math inline">\(x\)</span>축에 <span class="math inline">\(h\)</span>, <span class="math inline">\(y\)</span>축에 <span class="math inline">\(t\)</span>를 두고 해당 데이터를 산점도로 시각화 한 것이다.</p>
<div id="205c0230-9f05-4703-8940-0a47be6f7772" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="53">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>plt.plot(h,t,<span class="st">'o'</span>,alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Height (m)'</span>)</span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Time to fall (sec)'</span>)</span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Free Fall Time vs Height'</span>)</span>
<span id="cb90-5"><a href="#cb90-5" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb90-6"><a href="#cb90-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11wk-1_files/figure-html/cell-54-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>그래프를 보면 높이가 높을 수록 낙하시간도 길어지는 경향이 관찰된다. 다만 동일한 높이라 하더라도 낙하시간이 조금씩 차이나는 경우가 있는데, 이는 사람이 시간측정을 수동으로 하며 발생하는 실험오차 때문이다. 이러한 오차에도 불구하고 <span class="math inline">\(h\)</span>와 <span class="math inline">\(t\)</span>사이에는 일정한 규칙이 존재하는듯 하다. 물리학과 교수님께 자문을 요청한 결과 자유낙하에 걸리는 시간은 <span class="math inline">\(\sqrt{h}\)</span>에 비례함을 알 수 있었고 이를 근거로 아래와 같은 모형을 설계하였다.</p>
<p><span class="math display">\[t_i = \beta_0 + \beta_1 \sqrt{h_i}+\epsilon_i, \quad \epsilon_i \sim {\cal N}(0,\sigma^2)\]</span></p>
<p>위의 모형을 활용하여 높이 <span class="math inline">\(h\)</span>로부터 낙하시간 <span class="math inline">\(t\)</span>를 예측하는 신경망 모델을 설계하고 학습하라. 학습한 신경망 모델을 활용하여 높이 40m,60m,80m 에서 물체를 자유낙하 시켰을때 지면에 도달하기까지 걸리는 시간을 각각 예측하라.</p>
<p>(풀이)</p>
<p>🗣️(</p>
<ul>
<li>h –&gt; sqrt –&gt; linr –&gt; t_hat</li>
</ul>
<div id="2021b9cb-571a-43c3-86aa-64cc49c591bd" class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> FreeFallNet(torch.nn.Module):</span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linr <span class="op">=</span> torch.nn.Linear(<span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>,h):</span>
<span id="cb91-6"><a href="#cb91-6" aria-hidden="true" tabindex="-1"></a>        netout <span class="op">=</span> <span class="va">self</span>.linr(torch.sqrt(h))</span>
<span id="cb91-7"><a href="#cb91-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> netout</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="a0214940-9fd6-4b06-b583-ae78c4594ba2" class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> FreeFallNet()</span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss()</span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters())</span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a><span class="co">#---#</span></span>
<span id="cb92-5"><a href="#cb92-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2000</span>):</span>
<span id="cb92-6"><a href="#cb92-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">#1</span></span>
<span id="cb92-7"><a href="#cb92-7" aria-hidden="true" tabindex="-1"></a>    netout <span class="op">=</span> net(h)</span>
<span id="cb92-8"><a href="#cb92-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">#2</span></span>
<span id="cb92-9"><a href="#cb92-9" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(netout,t)</span>
<span id="cb92-10"><a href="#cb92-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#3</span></span>
<span id="cb92-11"><a href="#cb92-11" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb92-12"><a href="#cb92-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">#4</span></span>
<span id="cb92-13"><a href="#cb92-13" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb92-14"><a href="#cb92-14" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="16abdcc1-d845-46ec-90d0-e0f6841269cc" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="56">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a>plt.plot(h,t,<span class="st">'o'</span>,alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Height (m)'</span>)</span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Time to fall (sec)'</span>)</span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Free Fall Time vs Height'</span>)</span>
<span id="cb93-5"><a href="#cb93-5" aria-hidden="true" tabindex="-1"></a>plt.plot(h,net(h).data,<span class="st">'--'</span>)</span>
<span id="cb93-6"><a href="#cb93-6" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb93-7"><a href="#cb93-7" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11wk-1_files/figure-html/cell-57-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="955bd429-df52-4dd6-9597-e26b31603c89" class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> FreeFallNet()</span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss()</span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters())</span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a><span class="co">#---#</span></span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10000</span>):</span>
<span id="cb94-6"><a href="#cb94-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">#1</span></span>
<span id="cb94-7"><a href="#cb94-7" aria-hidden="true" tabindex="-1"></a>    netout <span class="op">=</span> net(h)</span>
<span id="cb94-8"><a href="#cb94-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">#2</span></span>
<span id="cb94-9"><a href="#cb94-9" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(netout,t)</span>
<span id="cb94-10"><a href="#cb94-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#3</span></span>
<span id="cb94-11"><a href="#cb94-11" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb94-12"><a href="#cb94-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">#4</span></span>
<span id="cb94-13"><a href="#cb94-13" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb94-14"><a href="#cb94-14" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="a326805a-a617-40d8-88dd-0d1572a396d4" class="cell" data-vscode="{&quot;languageId&quot;:&quot;python&quot;}" data-execution_count="58">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a>plt.plot(h,t,<span class="st">'o'</span>,alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Height (m)'</span>)</span>
<span id="cb95-3"><a href="#cb95-3" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Time to fall (sec)'</span>)</span>
<span id="cb95-4"><a href="#cb95-4" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Free Fall Time vs Height'</span>)</span>
<span id="cb95-5"><a href="#cb95-5" aria-hidden="true" tabindex="-1"></a>plt.plot(h,net(h).data,<span class="st">'--'</span>)</span>
<span id="cb95-6"><a href="#cb95-6" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb95-7"><a href="#cb95-7" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11wk-1_files/figure-html/cell-59-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>코드가 깔끔함</li>
</ul>
<div id="3b663f66-31f0-4eeb-b297-5fcc8a8456f7" class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>hh <span class="op">=</span> torch.tensor([<span class="dv">20</span>,<span class="dv">30</span>,<span class="dv">40</span>,<span class="dv">50</span>,<span class="dv">60</span>,<span class="dv">70</span>]).reshape(<span class="dv">6</span>,<span class="dv">1</span>)</span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a>net(hh)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="59">
<pre><code>tensor([[2.0253],
        [2.4746],
        [2.8534],
        [3.1872],
        [3.4889],
        [3.7664]], grad_fn=&lt;AddmmBackward0&gt;)</code></pre>
</div>
</div>
<div class="sourceCode" id="cb98"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 지난 시간 코드 (xx 추가됨)</span></span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>hh <span class="op">=</span> torch.tensor([<span class="dv">40</span>,<span class="dv">60</span>,<span class="dv">80</span>]).<span class="bu">float</span>().reshape(<span class="dv">3</span>,<span class="dv">1</span>)</span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a>xx <span class="op">=</span> torch.sqrt(hh)</span>
<span id="cb98-4"><a href="#cb98-4" aria-hidden="true" tabindex="-1"></a>net(xx)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>)🗣️</p>
<div id="e92eac45-e4bd-4ea9-b8ea-d4a3b0cbbc3a" class="cell" data-execution_count="405">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> FreeFallNet(torch.nn.Module):</span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb99-3"><a href="#cb99-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb99-4"><a href="#cb99-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linr <span class="op">=</span> torch.nn.Linear(<span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb99-5"><a href="#cb99-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>,h):</span>
<span id="cb99-6"><a href="#cb99-6" aria-hidden="true" tabindex="-1"></a>        netout <span class="op">=</span> <span class="va">self</span>.linr(torch.sqrt(h))</span>
<span id="cb99-7"><a href="#cb99-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> netout    </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="1137b676-b286-4a81-931d-408a476c3962" class="cell" data-execution_count="406">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> FreeFallNet()</span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss()</span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters())</span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a><span class="co">#---#</span></span>
<span id="cb100-5"><a href="#cb100-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10000</span>):</span>
<span id="cb100-6"><a href="#cb100-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">#1</span></span>
<span id="cb100-7"><a href="#cb100-7" aria-hidden="true" tabindex="-1"></a>    netout <span class="op">=</span> net(h)</span>
<span id="cb100-8"><a href="#cb100-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">#2</span></span>
<span id="cb100-9"><a href="#cb100-9" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(netout,t)</span>
<span id="cb100-10"><a href="#cb100-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#3</span></span>
<span id="cb100-11"><a href="#cb100-11" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb100-12"><a href="#cb100-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">#4 </span></span>
<span id="cb100-13"><a href="#cb100-13" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb100-14"><a href="#cb100-14" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="999c8426-4ed7-4384-a3ee-8f7825518888" class="cell" data-execution_count="407">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a>plt.plot(h,t,<span class="st">'o'</span>,alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Height (m)'</span>)</span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Time to fall (sec)'</span>)</span>
<span id="cb101-4"><a href="#cb101-4" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Free Fall Time vs Height'</span>)</span>
<span id="cb101-5"><a href="#cb101-5" aria-hidden="true" tabindex="-1"></a>plt.plot(h,net(h).data,<span class="st">'--'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11wk-1_files/figure-html/cell-63-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="377615cc-91a5-4e46-9a01-ac913f6b0535" class="cell" data-execution_count="410">
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a>hh <span class="op">=</span> torch.tensor([<span class="dv">20</span>,<span class="dv">30</span>,<span class="dv">40</span>,<span class="dv">50</span>,<span class="dv">60</span>,<span class="dv">70</span>]).reshape(<span class="dv">6</span>,<span class="dv">1</span>)</span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a>net(hh)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="410">
<pre><code>tensor([[2.0253],
        [2.4746],
        [2.8534],
        [3.1872],
        [3.4889],
        [3.7664]], grad_fn=&lt;AddmmBackward0&gt;)</code></pre>
</div>
</div>
<p><code>#</code></p>
</section>
<section id="b.-mf-based-추천시스템-재설계-1" class="level2">
<h2 class="anchored" data-anchor-id="b.-mf-based-추천시스템-재설계-1">B. MF-based 추천시스템 재설계</h2>
<p>아래의 자료를 활용하여 추천시스템을 설계하고자한다.</p>
<div id="4c78e3d6-0dff-428d-9823-31476a2eaf55" class="cell" data-tags="[]" data-execution_count="60">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a>df_view <span class="op">=</span> pd.read_csv(<span class="st">'https://raw.githubusercontent.com/guebin/DL2024/main/posts/solo.csv'</span>,index_col<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a>df_view</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="60">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">영식(IN)</th>
<th data-quarto-table-cell-role="th">영철(IN)</th>
<th data-quarto-table-cell-role="th">영호(IS)</th>
<th data-quarto-table-cell-role="th">광수(IS)</th>
<th data-quarto-table-cell-role="th">상철(EN)</th>
<th data-quarto-table-cell-role="th">영수(EN)</th>
<th data-quarto-table-cell-role="th">규빈(ES)</th>
<th data-quarto-table-cell-role="th">다호(ES)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">옥순(IN)</td>
<td>NaN</td>
<td>4.02</td>
<td>3.45</td>
<td>3.42</td>
<td>0.84</td>
<td>1.12</td>
<td>0.43</td>
<td>0.49</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">영자(IN)</td>
<td>3.93</td>
<td>3.99</td>
<td>3.63</td>
<td>3.43</td>
<td>0.98</td>
<td>0.96</td>
<td>0.52</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">정숙(IS)</td>
<td>3.52</td>
<td>3.42</td>
<td>4.05</td>
<td>4.06</td>
<td>0.39</td>
<td>NaN</td>
<td>0.93</td>
<td>0.99</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">영숙(IS)</td>
<td>3.43</td>
<td>3.57</td>
<td>NaN</td>
<td>3.95</td>
<td>0.56</td>
<td>0.52</td>
<td>0.89</td>
<td>0.89</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">순자(EN)</td>
<td>1.12</td>
<td>NaN</td>
<td>0.59</td>
<td>0.43</td>
<td>4.01</td>
<td>4.16</td>
<td>3.52</td>
<td>3.38</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">현숙(EN)</td>
<td>0.94</td>
<td>1.05</td>
<td>0.32</td>
<td>0.45</td>
<td>4.02</td>
<td>3.78</td>
<td>NaN</td>
<td>3.54</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">서연(ES)</td>
<td>0.51</td>
<td>0.56</td>
<td>0.88</td>
<td>0.89</td>
<td>3.50</td>
<td>3.64</td>
<td>4.04</td>
<td>4.10</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">보람(ES)</td>
<td>0.48</td>
<td>0.51</td>
<td>1.03</td>
<td>NaN</td>
<td>3.52</td>
<td>4.00</td>
<td>3.82</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">하니(I)</td>
<td>4.85</td>
<td>4.82</td>
<td>NaN</td>
<td>4.98</td>
<td>4.53</td>
<td>4.39</td>
<td>4.45</td>
<td>4.52</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>사용자정의 네트워크를 이용하여 MF-based 추천시스템을 설계하라.</p>
<p>(풀이1) – <code>net(x1,x2)</code></p>
<p>🗣️(</p>
<ul>
<li>이전 풀이가 너무 복잡하여 yhat을 다음과 같이 바꾸고 싶음</li>
</ul>
<div class="sourceCode" id="cb105"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="co">#df_view</span></span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span>
<span id="cb105-3"><a href="#cb105-3" aria-hidden="true" tabindex="-1"></a>ebdd1 <span class="op">=</span> torch.nn.Embedding(<span class="dv">9</span>,<span class="dv">2</span>)</span>
<span id="cb105-4"><a href="#cb105-4" aria-hidden="true" tabindex="-1"></a>ebdd2 <span class="op">=</span> torch.nn.Embedding(<span class="dv">8</span>,<span class="dv">2</span>)</span>
<span id="cb105-5"><a href="#cb105-5" aria-hidden="true" tabindex="-1"></a>b1 <span class="op">=</span> torch.nn.Embedding(<span class="dv">9</span>,<span class="dv">1</span>)</span>
<span id="cb105-6"><a href="#cb105-6" aria-hidden="true" tabindex="-1"></a>b2 <span class="op">=</span> torch.nn.Embedding(<span class="dv">8</span>,<span class="dv">1</span>)</span>
<span id="cb105-7"><a href="#cb105-7" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> <span class="bu">list</span>(ebdd1.parameters()) <span class="op">+</span> <span class="bu">list</span>(ebdd2.parameters())  <span class="op">+</span> <span class="bu">list</span>(b1.parameters()) <span class="op">+</span> <span class="bu">list</span>(b2.parameters())</span>
<span id="cb105-8"><a href="#cb105-8" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(params)</span>
<span id="cb105-9"><a href="#cb105-9" aria-hidden="true" tabindex="-1"></a>sig <span class="op">=</span> torch.nn.Sigmoid()</span>
<span id="cb105-10"><a href="#cb105-10" aria-hidden="true" tabindex="-1"></a><span class="co">#----#</span></span>
<span id="cb105-11"><a href="#cb105-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5000</span>):</span>
<span id="cb105-12"><a href="#cb105-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step1</span></span>
<span id="cb105-13"><a href="#cb105-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># W_features = ebdd1(x1) </span></span>
<span id="cb105-14"><a href="#cb105-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># M_features = ebdd2(x2) </span></span>
<span id="cb105-15"><a href="#cb105-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># W_bias = b1(x1)</span></span>
<span id="cb105-16"><a href="#cb105-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># M_bais = b2(x2)</span></span>
<span id="cb105-17"><a href="#cb105-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># yhat = sig((W_features * M_features).sum(axis=1).reshape(-1,1) + W_bias + M_bais)*5</span></span>
<span id="cb105-18"><a href="#cb105-18" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> net(x1,x2)</span>
<span id="cb105-19"><a href="#cb105-19" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step2</span></span>
<span id="cb105-20"><a href="#cb105-20" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y)</span>
<span id="cb105-21"><a href="#cb105-21" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step3</span></span>
<span id="cb105-22"><a href="#cb105-22" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb105-23"><a href="#cb105-23" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step4</span></span>
<span id="cb105-24"><a href="#cb105-24" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb105-25"><a href="#cb105-25" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>이에 맞춰 network를 설계하면</li>
</ul>
<div id="dc7824cc-34ff-43f8-b5b4-eba993d8d9c7" class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="co">#df_view</span></span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MFbased1(torch.nn.Module):</span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb106-4"><a href="#cb106-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb106-5"><a href="#cb106-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ebdd1 <span class="op">=</span> torch.nn.Embedding(<span class="dv">9</span>,<span class="dv">2</span>)</span>
<span id="cb106-6"><a href="#cb106-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ebdd2 <span class="op">=</span> torch.nn.Embedding(<span class="dv">8</span>,<span class="dv">2</span>)</span>
<span id="cb106-7"><a href="#cb106-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b1 <span class="op">=</span> torch.nn.Embedding(<span class="dv">9</span>,<span class="dv">1</span>)</span>
<span id="cb106-8"><a href="#cb106-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b2 <span class="op">=</span> torch.nn.Embedding(<span class="dv">8</span>,<span class="dv">1</span>)</span>
<span id="cb106-9"><a href="#cb106-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sig <span class="op">=</span> torch.nn.Sigmoid()</span>
<span id="cb106-10"><a href="#cb106-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>,x1,x2):</span>
<span id="cb106-11"><a href="#cb106-11" aria-hidden="true" tabindex="-1"></a>        W_features <span class="op">=</span> <span class="va">self</span>.ebdd1(x1) </span>
<span id="cb106-12"><a href="#cb106-12" aria-hidden="true" tabindex="-1"></a>        M_features <span class="op">=</span> <span class="va">self</span>.ebdd2(x2) </span>
<span id="cb106-13"><a href="#cb106-13" aria-hidden="true" tabindex="-1"></a>        W_bias <span class="op">=</span> <span class="va">self</span>.b1(x1)</span>
<span id="cb106-14"><a href="#cb106-14" aria-hidden="true" tabindex="-1"></a>        M_bais <span class="op">=</span> <span class="va">self</span>.b2(x2)</span>
<span id="cb106-15"><a href="#cb106-15" aria-hidden="true" tabindex="-1"></a>        yhat <span class="op">=</span> <span class="va">self</span>.sig((W_features <span class="op">*</span> M_features).<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>) <span class="op">+</span> W_bias <span class="op">+</span> M_bais)<span class="op">*</span><span class="dv">5</span></span>
<span id="cb106-16"><a href="#cb106-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> yhat</span>
<span id="cb106-17"><a href="#cb106-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-18"><a href="#cb106-18" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> MFbased1()</span>
<span id="cb106-19"><a href="#cb106-19" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span>
<span id="cb106-20"><a href="#cb106-20" aria-hidden="true" tabindex="-1"></a><span class="co"># params = list(ebdd1.parameters()) + list(ebdd2.parameters())  + list(b1.parameters()) + list(b2.parameters())</span></span>
<span id="cb106-21"><a href="#cb106-21" aria-hidden="true" tabindex="-1"></a><span class="co"># 이렇게 net을 선언하면 net.parameters()와 동일</span></span>
<span id="cb106-22"><a href="#cb106-22" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters())</span>
<span id="cb106-23"><a href="#cb106-23" aria-hidden="true" tabindex="-1"></a><span class="co">#----#</span></span>
<span id="cb106-24"><a href="#cb106-24" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10000</span>):</span>
<span id="cb106-25"><a href="#cb106-25" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step1</span></span>
<span id="cb106-26"><a href="#cb106-26" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> net(x1,x2)</span>
<span id="cb106-27"><a href="#cb106-27" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step2</span></span>
<span id="cb106-28"><a href="#cb106-28" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y)</span>
<span id="cb106-29"><a href="#cb106-29" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step3</span></span>
<span id="cb106-30"><a href="#cb106-30" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb106-31"><a href="#cb106-31" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step4</span></span>
<span id="cb106-32"><a href="#cb106-32" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb106-33"><a href="#cb106-33" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="3ccd65ed-13c9-4a6e-a89f-5b2e13188638" class="cell" data-execution_count="67">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>y[:<span class="dv">5</span>], yhat[:<span class="dv">5</span>] <span class="co"># 잘 적합됨</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="67">
<pre><code>(tensor([[4.0200],
         [3.4500],
         [3.4200],
         [0.8400],
         [1.1200]]),
 tensor([[4.0793],
         [3.4667],
         [3.3657],
         [0.9102],
         [0.9532]], grad_fn=&lt;SliceBackward0&gt;))</code></pre>
</div>
</div>
<div id="1ce9977b-630e-4483-89d6-cbf4490bb11c" class="cell" data-execution_count="69">
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a><span class="co"># list(net.parameters()) # parameter == 이전 params 확인 코드</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>)🗣️</p>
<div id="e652b2a8-e9b7-42a8-a507-617bae9fef77" class="cell" data-execution_count="420">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a><span class="co">#df_view</span></span>
<span id="cb110-2"><a href="#cb110-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MFbased1(torch.nn.Module):</span>
<span id="cb110-3"><a href="#cb110-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb110-4"><a href="#cb110-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb110-5"><a href="#cb110-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ebdd1 <span class="op">=</span> torch.nn.Embedding(<span class="dv">9</span>,<span class="dv">2</span>)</span>
<span id="cb110-6"><a href="#cb110-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ebdd2 <span class="op">=</span> torch.nn.Embedding(<span class="dv">8</span>,<span class="dv">2</span>)</span>
<span id="cb110-7"><a href="#cb110-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b1 <span class="op">=</span> torch.nn.Embedding(<span class="dv">9</span>,<span class="dv">1</span>)</span>
<span id="cb110-8"><a href="#cb110-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b2 <span class="op">=</span> torch.nn.Embedding(<span class="dv">8</span>,<span class="dv">1</span>)        </span>
<span id="cb110-9"><a href="#cb110-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sig <span class="op">=</span> torch.nn.Sigmoid()</span>
<span id="cb110-10"><a href="#cb110-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>,x1,x2):</span>
<span id="cb110-11"><a href="#cb110-11" aria-hidden="true" tabindex="-1"></a>        W_features <span class="op">=</span> <span class="va">self</span>.ebdd1(x1) </span>
<span id="cb110-12"><a href="#cb110-12" aria-hidden="true" tabindex="-1"></a>        M_features <span class="op">=</span> <span class="va">self</span>.ebdd2(x2) </span>
<span id="cb110-13"><a href="#cb110-13" aria-hidden="true" tabindex="-1"></a>        W_bias <span class="op">=</span> <span class="va">self</span>.b1(x1)</span>
<span id="cb110-14"><a href="#cb110-14" aria-hidden="true" tabindex="-1"></a>        M_bais <span class="op">=</span> <span class="va">self</span>.b2(x2)</span>
<span id="cb110-15"><a href="#cb110-15" aria-hidden="true" tabindex="-1"></a>        yhat <span class="op">=</span> <span class="va">self</span>.sig((W_features <span class="op">*</span> M_features).<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>) <span class="op">+</span> W_bias <span class="op">+</span> M_bais)<span class="op">*</span><span class="dv">5</span>        </span>
<span id="cb110-16"><a href="#cb110-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> yhat</span>
<span id="cb110-17"><a href="#cb110-17" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> MFbased1()</span>
<span id="cb110-18"><a href="#cb110-18" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span>
<span id="cb110-19"><a href="#cb110-19" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters())</span>
<span id="cb110-20"><a href="#cb110-20" aria-hidden="true" tabindex="-1"></a><span class="co">#----#</span></span>
<span id="cb110-21"><a href="#cb110-21" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10000</span>):</span>
<span id="cb110-22"><a href="#cb110-22" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step1</span></span>
<span id="cb110-23"><a href="#cb110-23" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> net(x1,x2)</span>
<span id="cb110-24"><a href="#cb110-24" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step2</span></span>
<span id="cb110-25"><a href="#cb110-25" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y)</span>
<span id="cb110-26"><a href="#cb110-26" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step3</span></span>
<span id="cb110-27"><a href="#cb110-27" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb110-28"><a href="#cb110-28" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step4</span></span>
<span id="cb110-29"><a href="#cb110-29" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb110-30"><a href="#cb110-30" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="6eb0ef27-501c-4ecb-97f4-793210ee992f" class="cell" data-execution_count="421">
<div class="sourceCode cell-code" id="cb111"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a>y[:<span class="dv">5</span>], yhat[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="421">
<pre><code>(tensor([[4.0200],
         [3.4500],
         [3.4200],
         [0.8400],
         [1.1200]]),
 tensor([[4.0800],
         [3.4664],
         [3.3650],
         [0.9111],
         [0.9538]], grad_fn=&lt;SliceBackward0&gt;))</code></pre>
</div>
</div>
<p>(풀이2) – <code>net(X)</code></p>
<p>🗣️(</p>
<div id="53b6dc72-dc45-43ef-82c6-959bd3e0afe2" class="cell" data-execution_count="70">
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a>x1, x2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="70">
<pre><code>(tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3,
         3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6,
         6, 6, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8]),
 tensor([1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 6, 7, 0, 1, 3,
         4, 5, 6, 7, 0, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 7, 0, 1, 2, 3, 4, 5,
         6, 7, 0, 1, 2, 4, 5, 6, 0, 1, 3, 4, 5, 6, 7]))</code></pre>
</div>
</div>
<div id="eec8a2fc-f04d-4170-852f-a5c510313801" class="cell" data-execution_count="71">
<div class="sourceCode cell-code" id="cb115"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.stack([x1,x2],axis<span class="op">=</span><span class="dv">1</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="8875d88c-0cca-4241-9fb0-7b17cbe04d41" class="cell" data-execution_count="73">
<div class="sourceCode cell-code" id="cb116"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MFbased2(torch.nn.Module):</span>
<span id="cb116-2"><a href="#cb116-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb116-3"><a href="#cb116-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb116-4"><a href="#cb116-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ebdd1 <span class="op">=</span> torch.nn.Embedding(<span class="dv">9</span>,<span class="dv">2</span>)</span>
<span id="cb116-5"><a href="#cb116-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ebdd2 <span class="op">=</span> torch.nn.Embedding(<span class="dv">8</span>,<span class="dv">2</span>)</span>
<span id="cb116-6"><a href="#cb116-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b1 <span class="op">=</span> torch.nn.Embedding(<span class="dv">9</span>,<span class="dv">1</span>)</span>
<span id="cb116-7"><a href="#cb116-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b2 <span class="op">=</span> torch.nn.Embedding(<span class="dv">8</span>,<span class="dv">1</span>)        </span>
<span id="cb116-8"><a href="#cb116-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sig <span class="op">=</span> torch.nn.Sigmoid()</span>
<span id="cb116-9"><a href="#cb116-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>,X):</span>
<span id="cb116-10"><a href="#cb116-10" aria-hidden="true" tabindex="-1"></a>        x1 <span class="op">=</span> X[:,<span class="dv">0</span>] <span class="co"># 분리</span></span>
<span id="cb116-11"><a href="#cb116-11" aria-hidden="true" tabindex="-1"></a>        x2 <span class="op">=</span> X[:,<span class="dv">1</span>]</span>
<span id="cb116-12"><a href="#cb116-12" aria-hidden="true" tabindex="-1"></a>        W_features <span class="op">=</span> <span class="va">self</span>.ebdd1(x1) </span>
<span id="cb116-13"><a href="#cb116-13" aria-hidden="true" tabindex="-1"></a>        M_features <span class="op">=</span> <span class="va">self</span>.ebdd2(x2) </span>
<span id="cb116-14"><a href="#cb116-14" aria-hidden="true" tabindex="-1"></a>        W_bias <span class="op">=</span> <span class="va">self</span>.b1(x1)</span>
<span id="cb116-15"><a href="#cb116-15" aria-hidden="true" tabindex="-1"></a>        M_bais <span class="op">=</span> <span class="va">self</span>.b2(x2)</span>
<span id="cb116-16"><a href="#cb116-16" aria-hidden="true" tabindex="-1"></a>        yhat <span class="op">=</span> <span class="va">self</span>.sig((W_features <span class="op">*</span> M_features).<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>) <span class="op">+</span> W_bias <span class="op">+</span> M_bais)<span class="op">*</span><span class="dv">5</span>        </span>
<span id="cb116-17"><a href="#cb116-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> yhat</span>
<span id="cb116-18"><a href="#cb116-18" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> MFbased2()</span>
<span id="cb116-19"><a href="#cb116-19" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span>
<span id="cb116-20"><a href="#cb116-20" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters())</span>
<span id="cb116-21"><a href="#cb116-21" aria-hidden="true" tabindex="-1"></a><span class="co">#----#</span></span>
<span id="cb116-22"><a href="#cb116-22" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10000</span>):</span>
<span id="cb116-23"><a href="#cb116-23" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step1</span></span>
<span id="cb116-24"><a href="#cb116-24" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> net(X)</span>
<span id="cb116-25"><a href="#cb116-25" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step2</span></span>
<span id="cb116-26"><a href="#cb116-26" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y)</span>
<span id="cb116-27"><a href="#cb116-27" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step3</span></span>
<span id="cb116-28"><a href="#cb116-28" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb116-29"><a href="#cb116-29" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step4</span></span>
<span id="cb116-30"><a href="#cb116-30" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb116-31"><a href="#cb116-31" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="3a5abaf6-e62a-4b8b-93e9-abda06f5c90b" class="cell" data-execution_count="74">
<div class="sourceCode cell-code" id="cb117"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a>y[:<span class="dv">5</span>], yhat[:<span class="dv">5</span>] <span class="co"># 잘 적합됨</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="74">
<pre><code>(tensor([[4.0200],
         [3.4500],
         [3.4200],
         [0.8400],
         [1.1200]]),
 tensor([[4.0800],
         [3.4664],
         [3.3651],
         [0.9111],
         [0.9538]], grad_fn=&lt;SliceBackward0&gt;))</code></pre>
</div>
</div>
<ul>
<li>사용자 정의 네트워크를 이용하면 지저분한 부분을 위에(class) 몰아넣고 아래는 깔끔하게 정리할 수 있음</li>
</ul>
<p>)🗣️</p>
<div id="c771bba2-15b7-430a-92ee-ddbd9b0d2cfc" class="cell" data-execution_count="439">
<div class="sourceCode cell-code" id="cb119"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.stack([x1,x2],axis<span class="op">=</span><span class="dv">1</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="04b20c18-4a85-48ed-989e-e25ddb74f9d9" class="cell" data-execution_count="440">
<div class="sourceCode cell-code" id="cb120"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MFbased2(torch.nn.Module):</span>
<span id="cb120-2"><a href="#cb120-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb120-3"><a href="#cb120-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb120-4"><a href="#cb120-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ebdd1 <span class="op">=</span> torch.nn.Embedding(<span class="dv">9</span>,<span class="dv">2</span>)</span>
<span id="cb120-5"><a href="#cb120-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ebdd2 <span class="op">=</span> torch.nn.Embedding(<span class="dv">8</span>,<span class="dv">2</span>)</span>
<span id="cb120-6"><a href="#cb120-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b1 <span class="op">=</span> torch.nn.Embedding(<span class="dv">9</span>,<span class="dv">1</span>)</span>
<span id="cb120-7"><a href="#cb120-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b2 <span class="op">=</span> torch.nn.Embedding(<span class="dv">8</span>,<span class="dv">1</span>)        </span>
<span id="cb120-8"><a href="#cb120-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sig <span class="op">=</span> torch.nn.Sigmoid()</span>
<span id="cb120-9"><a href="#cb120-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>,X):</span>
<span id="cb120-10"><a href="#cb120-10" aria-hidden="true" tabindex="-1"></a>        x1 <span class="op">=</span> X[:,<span class="dv">0</span>]</span>
<span id="cb120-11"><a href="#cb120-11" aria-hidden="true" tabindex="-1"></a>        x2 <span class="op">=</span> X[:,<span class="dv">1</span>]</span>
<span id="cb120-12"><a href="#cb120-12" aria-hidden="true" tabindex="-1"></a>        W_features <span class="op">=</span> <span class="va">self</span>.ebdd1(x1) </span>
<span id="cb120-13"><a href="#cb120-13" aria-hidden="true" tabindex="-1"></a>        M_features <span class="op">=</span> <span class="va">self</span>.ebdd2(x2) </span>
<span id="cb120-14"><a href="#cb120-14" aria-hidden="true" tabindex="-1"></a>        W_bias <span class="op">=</span> <span class="va">self</span>.b1(x1)</span>
<span id="cb120-15"><a href="#cb120-15" aria-hidden="true" tabindex="-1"></a>        M_bais <span class="op">=</span> <span class="va">self</span>.b2(x2)</span>
<span id="cb120-16"><a href="#cb120-16" aria-hidden="true" tabindex="-1"></a>        yhat <span class="op">=</span> <span class="va">self</span>.sig((W_features <span class="op">*</span> M_features).<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>) <span class="op">+</span> W_bias <span class="op">+</span> M_bais)<span class="op">*</span><span class="dv">5</span>        </span>
<span id="cb120-17"><a href="#cb120-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> yhat</span>
<span id="cb120-18"><a href="#cb120-18" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> MFbased2()</span>
<span id="cb120-19"><a href="#cb120-19" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span>
<span id="cb120-20"><a href="#cb120-20" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters())</span>
<span id="cb120-21"><a href="#cb120-21" aria-hidden="true" tabindex="-1"></a><span class="co">#----#</span></span>
<span id="cb120-22"><a href="#cb120-22" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10000</span>):</span>
<span id="cb120-23"><a href="#cb120-23" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step1</span></span>
<span id="cb120-24"><a href="#cb120-24" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> net(X)</span>
<span id="cb120-25"><a href="#cb120-25" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step2</span></span>
<span id="cb120-26"><a href="#cb120-26" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y)</span>
<span id="cb120-27"><a href="#cb120-27" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step3</span></span>
<span id="cb120-28"><a href="#cb120-28" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb120-29"><a href="#cb120-29" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step4</span></span>
<span id="cb120-30"><a href="#cb120-30" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb120-31"><a href="#cb120-31" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="88fcb072-1091-4084-9732-04250b7c15cc" class="cell" data-execution_count="441">
<div class="sourceCode cell-code" id="cb121"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a>y[:<span class="dv">5</span>], yhat[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="441">
<pre><code>(tensor([[4.0200],
         [3.4500],
         [3.4200],
         [0.8400],
         [1.1200]]),
 tensor([[4.0800],
         [3.4664],
         [3.3651],
         [0.9111],
         [0.9538]], grad_fn=&lt;SliceBackward0&gt;))</code></pre>
</div>
</div>
</section>
</section>
<section id="mf-based-추천시스템을-넘어서" class="level1">
<h1>5. MF-based 추천시스템을 넘어서 📝</h1>
<p>🗣️(</p>
<pre><code>MF = Matrix Factorization = 행렬분해(SVD)
W_feature
M_feature
W_bias
M_bias

yhat = (W_feature*M_feature).sum(axis=1).reshape(-1,1) + 바이어스
이러한 아키텍쳐를 생각하는게 되게 특이한 방식임
#---#
[W_feature, M_feature, W_bias, M_bias]
(n,2) (n,2) (n,1) (n,1) ---&gt; (n,6) ---&gt;&gt; yhat : Neural Network</code></pre>
<p>)🗣️</p>
<section id="a.-nn-based-방식" class="level2">
<h2 class="anchored" data-anchor-id="a.-nn-based-방식">A. NN-based 방식</h2>
<p>아래의 자료를 활용하여 추천시스템을 설계하고자한다.</p>
<div id="dac9b60e-bb8e-4a2c-a967-f04c1398fce6" class="cell" data-tags="[]" data-execution_count="75">
<div class="sourceCode cell-code" id="cb124"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a>df_view <span class="op">=</span> pd.read_csv(<span class="st">'https://raw.githubusercontent.com/guebin/DL2025/main/posts/iamsolo.csv'</span>,index_col<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb124-2"><a href="#cb124-2" aria-hidden="true" tabindex="-1"></a>df_view</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="75">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">영식(IN)</th>
<th data-quarto-table-cell-role="th">영철(IN)</th>
<th data-quarto-table-cell-role="th">영호(IS)</th>
<th data-quarto-table-cell-role="th">광수(IS)</th>
<th data-quarto-table-cell-role="th">상철(EN)</th>
<th data-quarto-table-cell-role="th">영수(EN)</th>
<th data-quarto-table-cell-role="th">규빈(ES)</th>
<th data-quarto-table-cell-role="th">다호(ES)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">옥순(IN)</td>
<td>NaN</td>
<td>4.02</td>
<td>3.45</td>
<td>3.42</td>
<td>0.84</td>
<td>1.12</td>
<td>0.43</td>
<td>0.49</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">영자(IN)</td>
<td>3.93</td>
<td>3.99</td>
<td>3.63</td>
<td>3.43</td>
<td>0.98</td>
<td>0.96</td>
<td>0.52</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">정숙(IS)</td>
<td>3.52</td>
<td>3.42</td>
<td>4.05</td>
<td>4.06</td>
<td>0.39</td>
<td>NaN</td>
<td>0.93</td>
<td>0.99</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">영숙(IS)</td>
<td>3.43</td>
<td>3.57</td>
<td>NaN</td>
<td>3.95</td>
<td>0.56</td>
<td>0.52</td>
<td>0.89</td>
<td>0.89</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">순자(EN)</td>
<td>1.12</td>
<td>NaN</td>
<td>0.59</td>
<td>0.43</td>
<td>4.01</td>
<td>4.16</td>
<td>3.52</td>
<td>3.38</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">현숙(EN)</td>
<td>0.94</td>
<td>1.05</td>
<td>0.32</td>
<td>0.45</td>
<td>4.02</td>
<td>3.78</td>
<td>NaN</td>
<td>3.54</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">서연(ES)</td>
<td>0.51</td>
<td>0.56</td>
<td>0.88</td>
<td>0.89</td>
<td>3.50</td>
<td>3.64</td>
<td>4.04</td>
<td>4.10</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">보람(ES)</td>
<td>0.48</td>
<td>0.51</td>
<td>1.03</td>
<td>NaN</td>
<td>3.52</td>
<td>4.00</td>
<td>3.82</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">하니(I)</td>
<td>4.85</td>
<td>4.82</td>
<td>NaN</td>
<td>4.98</td>
<td>4.53</td>
<td>4.39</td>
<td>4.45</td>
<td>4.52</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="aad283e7-74cf-4d48-a0c3-1caa92266ae8" class="cell" data-tags="[]" data-execution_count="76">
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a><span class="co">#df_view</span></span>
<span id="cb125-2"><a href="#cb125-2" aria-hidden="true" tabindex="-1"></a>df_train <span class="op">=</span> df_view.stack().reset_index().set_axis([<span class="st">'여성출연자'</span>,<span class="st">'남성출연자'</span>,<span class="st">'궁합점수'</span>],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb125-3"><a href="#cb125-3" aria-hidden="true" tabindex="-1"></a>여성인덱스 <span class="op">=</span> {<span class="st">'옥순(IN)'</span>:<span class="dv">0</span>, <span class="st">'영자(IN)'</span>:<span class="dv">1</span>, <span class="st">'정숙(IS)'</span>:<span class="dv">2</span>, <span class="st">'영숙(IS)'</span>:<span class="dv">3</span>, <span class="st">'순자(EN)'</span>:<span class="dv">4</span>, <span class="st">'현숙(EN)'</span>:<span class="dv">5</span>, <span class="st">'서연(ES)'</span>:<span class="dv">6</span>, <span class="st">'보람(ES)'</span>:<span class="dv">7</span>, <span class="st">'하니(I)'</span>:<span class="dv">8</span>}</span>
<span id="cb125-4"><a href="#cb125-4" aria-hidden="true" tabindex="-1"></a>남성인덱스 <span class="op">=</span> {<span class="st">'영식(IN)'</span>:<span class="dv">0</span>, <span class="st">'영철(IN)'</span>:<span class="dv">1</span>, <span class="st">'영호(IS)'</span>:<span class="dv">2</span>, <span class="st">'광수(IS)'</span>:<span class="dv">3</span>, <span class="st">'상철(EN)'</span>:<span class="dv">4</span>, <span class="st">'영수(EN)'</span>:<span class="dv">5</span>, <span class="st">'규빈(ES)'</span>:<span class="dv">6</span>, <span class="st">'다호(ES)'</span>:<span class="dv">7</span>}</span>
<span id="cb125-5"><a href="#cb125-5" aria-hidden="true" tabindex="-1"></a>x1 <span class="op">=</span> torch.tensor(df_train.여성출연자.<span class="bu">map</span>(여성인덱스))</span>
<span id="cb125-6"><a href="#cb125-6" aria-hidden="true" tabindex="-1"></a>x2 <span class="op">=</span> torch.tensor(df_train.남성출연자.<span class="bu">map</span>(남성인덱스))</span>
<span id="cb125-7"><a href="#cb125-7" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.tensor(df_train.궁합점수).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>).<span class="bu">float</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>NN-based 추천시스템을 설계하라.</p>
<p>(풀이1) – 실패</p>
<p>🗣️(</p>
<div id="6efc2828-236c-449d-b4da-ebe023f95193" class="cell" data-execution_count="82">
<div class="sourceCode cell-code" id="cb126"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NNbased1(torch.nn.Module):</span>
<span id="cb126-2"><a href="#cb126-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb126-3"><a href="#cb126-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb126-4"><a href="#cb126-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ebdd1 <span class="op">=</span> torch.nn.Embedding(<span class="dv">9</span>,<span class="dv">2</span>)</span>
<span id="cb126-5"><a href="#cb126-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ebdd2 <span class="op">=</span> torch.nn.Embedding(<span class="dv">8</span>,<span class="dv">2</span>)</span>
<span id="cb126-6"><a href="#cb126-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b1 <span class="op">=</span> torch.nn.Embedding(<span class="dv">9</span>,<span class="dv">1</span>)</span>
<span id="cb126-7"><a href="#cb126-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b2 <span class="op">=</span> torch.nn.Embedding(<span class="dv">8</span>,<span class="dv">1</span>)</span>
<span id="cb126-8"><a href="#cb126-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sig <span class="op">=</span> torch.nn.Sigmoid()</span>
<span id="cb126-9"><a href="#cb126-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mlp <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb126-10"><a href="#cb126-10" aria-hidden="true" tabindex="-1"></a>            torch.nn.Linear(<span class="dv">6</span>,<span class="dv">1</span>),</span>
<span id="cb126-11"><a href="#cb126-11" aria-hidden="true" tabindex="-1"></a>            torch.nn.Sigmoid()</span>
<span id="cb126-12"><a href="#cb126-12" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb126-13"><a href="#cb126-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>,x1,x2):</span>
<span id="cb126-14"><a href="#cb126-14" aria-hidden="true" tabindex="-1"></a>        W_features <span class="op">=</span> <span class="va">self</span>.ebdd1(x1) </span>
<span id="cb126-15"><a href="#cb126-15" aria-hidden="true" tabindex="-1"></a>        M_features <span class="op">=</span> <span class="va">self</span>.ebdd2(x2) </span>
<span id="cb126-16"><a href="#cb126-16" aria-hidden="true" tabindex="-1"></a>        W_bias <span class="op">=</span> <span class="va">self</span>.b1(x1)</span>
<span id="cb126-17"><a href="#cb126-17" aria-hidden="true" tabindex="-1"></a>        M_bias <span class="op">=</span> <span class="va">self</span>.b2(x2)</span>
<span id="cb126-18"><a href="#cb126-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># yhat = self.sig((W_features * M_features).sum(axis=1).reshape(-1,1) + W_bias + M_bais)*5</span></span>
<span id="cb126-19"><a href="#cb126-19" aria-hidden="true" tabindex="-1"></a>        Z <span class="op">=</span> torch.concat([W_features, M_features, W_bias, M_bias], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb126-20"><a href="#cb126-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Z ---&gt; yhat (n,6) -&gt; (n,1)</span></span>
<span id="cb126-21"><a href="#cb126-21" aria-hidden="true" tabindex="-1"></a>        yhat <span class="op">=</span> <span class="va">self</span>.mlp(Z) <span class="op">*</span> <span class="dv">5</span></span>
<span id="cb126-22"><a href="#cb126-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> yhat</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="22884bb7-c02e-4aec-ad39-a5c955e533ef" class="cell" data-execution_count="84">
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> NNbased1()</span>
<span id="cb127-2"><a href="#cb127-2" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span>
<span id="cb127-3"><a href="#cb127-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters())</span>
<span id="cb127-4"><a href="#cb127-4" aria-hidden="true" tabindex="-1"></a><span class="co">#----#</span></span>
<span id="cb127-5"><a href="#cb127-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5000</span>):</span>
<span id="cb127-6"><a href="#cb127-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step1</span></span>
<span id="cb127-7"><a href="#cb127-7" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> net(x1,x2)</span>
<span id="cb127-8"><a href="#cb127-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step2</span></span>
<span id="cb127-9"><a href="#cb127-9" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y)</span>
<span id="cb127-10"><a href="#cb127-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step3</span></span>
<span id="cb127-11"><a href="#cb127-11" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb127-12"><a href="#cb127-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step4</span></span>
<span id="cb127-13"><a href="#cb127-13" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb127-14"><a href="#cb127-14" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="5cd79609-40cf-40e2-8358-d468fb87c19e" class="cell" data-execution_count="86">
<div class="sourceCode cell-code" id="cb128"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a>yhat[:<span class="dv">5</span>], y[:<span class="dv">5</span>] <span class="co"># 전혀 맞지 않음</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="86">
<pre><code>(tensor([[2.1566],
         [1.6486],
         [2.0613],
         [1.9107],
         [2.3132]], grad_fn=&lt;SliceBackward0&gt;),
 tensor([[4.0200],
         [3.4500],
         [3.4200],
         [0.8400],
         [1.1200]]))</code></pre>
</div>
</div>
<ul>
<li>모델이 너무 단순해서?</li>
</ul>
<p>)🗣️</p>
<div id="96398d04-aacb-41a1-8cfe-a34ce1f5697b" class="cell" data-tags="[]" data-execution_count="368">
<div class="sourceCode cell-code" id="cb130"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NNbased1(torch.nn.Module):</span>
<span id="cb130-2"><a href="#cb130-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb130-3"><a href="#cb130-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb130-4"><a href="#cb130-4" aria-hidden="true" tabindex="-1"></a>        <span class="co">#--#</span></span>
<span id="cb130-5"><a href="#cb130-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ebdd1 <span class="op">=</span> torch.nn.Embedding(<span class="dv">9</span>,<span class="dv">2</span>)</span>
<span id="cb130-6"><a href="#cb130-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ebdd2 <span class="op">=</span> torch.nn.Embedding(<span class="dv">8</span>,<span class="dv">2</span>)</span>
<span id="cb130-7"><a href="#cb130-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b1 <span class="op">=</span> torch.nn.Embedding(<span class="dv">9</span>,<span class="dv">1</span>)</span>
<span id="cb130-8"><a href="#cb130-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b2 <span class="op">=</span> torch.nn.Embedding(<span class="dv">8</span>,<span class="dv">1</span>)</span>
<span id="cb130-9"><a href="#cb130-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sig <span class="op">=</span> torch.nn.Sigmoid()</span>
<span id="cb130-10"><a href="#cb130-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mlp <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb130-11"><a href="#cb130-11" aria-hidden="true" tabindex="-1"></a>            torch.nn.Linear(<span class="dv">6</span>,<span class="dv">1</span>),</span>
<span id="cb130-12"><a href="#cb130-12" aria-hidden="true" tabindex="-1"></a>            torch.nn.Sigmoid()</span>
<span id="cb130-13"><a href="#cb130-13" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb130-14"><a href="#cb130-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>,x1,x2):</span>
<span id="cb130-15"><a href="#cb130-15" aria-hidden="true" tabindex="-1"></a>        W_feature <span class="op">=</span> <span class="va">self</span>.ebdd1(x1)</span>
<span id="cb130-16"><a href="#cb130-16" aria-hidden="true" tabindex="-1"></a>        W_bias <span class="op">=</span> <span class="va">self</span>.b1(x1)</span>
<span id="cb130-17"><a href="#cb130-17" aria-hidden="true" tabindex="-1"></a>        M_feature <span class="op">=</span> <span class="va">self</span>.ebdd2(x2)</span>
<span id="cb130-18"><a href="#cb130-18" aria-hidden="true" tabindex="-1"></a>        M_bias <span class="op">=</span> <span class="va">self</span>.b2(x2)</span>
<span id="cb130-19"><a href="#cb130-19" aria-hidden="true" tabindex="-1"></a>        <span class="co">#yhat = sig((W_feature * M_feature).sum(axis=1).reshape(-1,1) + W_bias + M_bias ) * 5 </span></span>
<span id="cb130-20"><a href="#cb130-20" aria-hidden="true" tabindex="-1"></a>        Z <span class="op">=</span> torch.concat([W_feature, M_feature, W_bias, M_bias],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb130-21"><a href="#cb130-21" aria-hidden="true" tabindex="-1"></a>        yhat <span class="op">=</span> <span class="va">self</span>.mlp(Z) <span class="op">*</span> <span class="dv">5</span> </span>
<span id="cb130-22"><a href="#cb130-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> yhat</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="95297222-0e0b-4414-93f4-b4e2dca7fd0b" class="cell" data-tags="[]" data-execution_count="369">
<div class="sourceCode cell-code" id="cb131"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> NNbased1()</span>
<span id="cb131-2"><a href="#cb131-2" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss()</span>
<span id="cb131-3"><a href="#cb131-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters(),lr<span class="op">=</span><span class="fl">0.1</span>) <span class="co"># 이게 편해요!!</span></span>
<span id="cb131-4"><a href="#cb131-4" aria-hidden="true" tabindex="-1"></a><span class="co">#--# </span></span>
<span id="cb131-5"><a href="#cb131-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5000</span>):</span>
<span id="cb131-6"><a href="#cb131-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1</span></span>
<span id="cb131-7"><a href="#cb131-7" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> net(x1,x2) </span>
<span id="cb131-8"><a href="#cb131-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2</span></span>
<span id="cb131-9"><a href="#cb131-9" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y)</span>
<span id="cb131-10"><a href="#cb131-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3 </span></span>
<span id="cb131-11"><a href="#cb131-11" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb131-12"><a href="#cb131-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 4 </span></span>
<span id="cb131-13"><a href="#cb131-13" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb131-14"><a href="#cb131-14" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="d083f56a-1e46-4c7d-a1d6-a2f805b6e716" class="cell" data-execution_count="370">
<div class="sourceCode cell-code" id="cb132"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true" tabindex="-1"></a>yhat[:<span class="dv">5</span>], y[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="370">
<pre><code>(tensor([[2.1563],
         [1.6488],
         [2.0608],
         [1.9119],
         [2.3126]], grad_fn=&lt;SliceBackward0&gt;),
 tensor([[4.0200],
         [3.4500],
         [3.4200],
         [0.8400],
         [1.1200]]))</code></pre>
</div>
</div>
<p>(풀이2) – 에라 모르겠다 깊은신경망..</p>
<p>🗣️(</p>
<div id="805c81f8-6181-41da-b7c5-3047b41c10d9" class="cell" data-execution_count="87">
<div class="sourceCode cell-code" id="cb134"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NNbased2(torch.nn.Module):</span>
<span id="cb134-2"><a href="#cb134-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb134-3"><a href="#cb134-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb134-4"><a href="#cb134-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ebdd1 <span class="op">=</span> torch.nn.Embedding(<span class="dv">9</span>,<span class="dv">2</span>)</span>
<span id="cb134-5"><a href="#cb134-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ebdd2 <span class="op">=</span> torch.nn.Embedding(<span class="dv">8</span>,<span class="dv">2</span>)</span>
<span id="cb134-6"><a href="#cb134-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b1 <span class="op">=</span> torch.nn.Embedding(<span class="dv">9</span>,<span class="dv">1</span>)</span>
<span id="cb134-7"><a href="#cb134-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b2 <span class="op">=</span> torch.nn.Embedding(<span class="dv">8</span>,<span class="dv">1</span>)</span>
<span id="cb134-8"><a href="#cb134-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sig <span class="op">=</span> torch.nn.Sigmoid()</span>
<span id="cb134-9"><a href="#cb134-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mlp <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb134-10"><a href="#cb134-10" aria-hidden="true" tabindex="-1"></a>            torch.nn.Linear(<span class="dv">6</span>,<span class="dv">15</span>),</span>
<span id="cb134-11"><a href="#cb134-11" aria-hidden="true" tabindex="-1"></a>            torch.nn.ReLU(),</span>
<span id="cb134-12"><a href="#cb134-12" aria-hidden="true" tabindex="-1"></a>            torch.nn.Linear(<span class="dv">15</span>,<span class="dv">15</span>),</span>
<span id="cb134-13"><a href="#cb134-13" aria-hidden="true" tabindex="-1"></a>            torch.nn.ReLU(),</span>
<span id="cb134-14"><a href="#cb134-14" aria-hidden="true" tabindex="-1"></a>            torch.nn.Linear(<span class="dv">15</span>,<span class="dv">1</span>),</span>
<span id="cb134-15"><a href="#cb134-15" aria-hidden="true" tabindex="-1"></a>            torch.nn.Sigmoid()</span>
<span id="cb134-16"><a href="#cb134-16" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb134-17"><a href="#cb134-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>,x1,x2):</span>
<span id="cb134-18"><a href="#cb134-18" aria-hidden="true" tabindex="-1"></a>        W_features <span class="op">=</span> <span class="va">self</span>.ebdd1(x1) </span>
<span id="cb134-19"><a href="#cb134-19" aria-hidden="true" tabindex="-1"></a>        M_features <span class="op">=</span> <span class="va">self</span>.ebdd2(x2) </span>
<span id="cb134-20"><a href="#cb134-20" aria-hidden="true" tabindex="-1"></a>        W_bias <span class="op">=</span> <span class="va">self</span>.b1(x1)</span>
<span id="cb134-21"><a href="#cb134-21" aria-hidden="true" tabindex="-1"></a>        M_bias <span class="op">=</span> <span class="va">self</span>.b2(x2)</span>
<span id="cb134-22"><a href="#cb134-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># yhat = self.sig((W_features * M_features).sum(axis=1).reshape(-1,1) + W_bias + M_bais)*5</span></span>
<span id="cb134-23"><a href="#cb134-23" aria-hidden="true" tabindex="-1"></a>        Z <span class="op">=</span> torch.concat([W_features, M_features, W_bias, M_bias], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb134-24"><a href="#cb134-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Z ---&gt; yhat (n,6) -&gt; (n,1)</span></span>
<span id="cb134-25"><a href="#cb134-25" aria-hidden="true" tabindex="-1"></a>        yhat <span class="op">=</span> <span class="va">self</span>.mlp(Z) <span class="op">*</span> <span class="dv">5</span></span>
<span id="cb134-26"><a href="#cb134-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> yhat</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="774f2451-3a56-48aa-989a-2265d8d6edfe" class="cell" data-execution_count="88">
<div class="sourceCode cell-code" id="cb135"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> NNbased2()</span>
<span id="cb135-2"><a href="#cb135-2" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span>
<span id="cb135-3"><a href="#cb135-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters())</span>
<span id="cb135-4"><a href="#cb135-4" aria-hidden="true" tabindex="-1"></a><span class="co">#----#</span></span>
<span id="cb135-5"><a href="#cb135-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5000</span>):</span>
<span id="cb135-6"><a href="#cb135-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step1</span></span>
<span id="cb135-7"><a href="#cb135-7" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> net(x1,x2)</span>
<span id="cb135-8"><a href="#cb135-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step2</span></span>
<span id="cb135-9"><a href="#cb135-9" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y)</span>
<span id="cb135-10"><a href="#cb135-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step3</span></span>
<span id="cb135-11"><a href="#cb135-11" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb135-12"><a href="#cb135-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step4</span></span>
<span id="cb135-13"><a href="#cb135-13" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb135-14"><a href="#cb135-14" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="0a347421-339f-41e2-aec1-bddae0ab9db6" class="cell" data-execution_count="89">
<div class="sourceCode cell-code" id="cb136"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a>yhat[:<span class="dv">5</span>], y[:<span class="dv">5</span>] <span class="co"># 너무 잘 맞는 느낌 (overfitting 의심)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="89">
<pre><code>(tensor([[4.0179],
         [3.4466],
         [3.4170],
         [0.8365],
         [1.1180]], grad_fn=&lt;SliceBackward0&gt;),
 tensor([[4.0200],
         [3.4500],
         [3.4200],
         [0.8400],
         [1.1200]]))</code></pre>
</div>
</div>
<p><em>(옥순-영식), (영자-다호), (하니-영호) 를 예측해보자.</em></p>
<div id="cbb8b7f3-24ab-466c-947c-ed960ef27b01" class="cell" data-execution_count="90">
<div class="sourceCode cell-code" id="cb138"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb138-1"><a href="#cb138-1" aria-hidden="true" tabindex="-1"></a>df_view</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="90">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">영식(IN)</th>
<th data-quarto-table-cell-role="th">영철(IN)</th>
<th data-quarto-table-cell-role="th">영호(IS)</th>
<th data-quarto-table-cell-role="th">광수(IS)</th>
<th data-quarto-table-cell-role="th">상철(EN)</th>
<th data-quarto-table-cell-role="th">영수(EN)</th>
<th data-quarto-table-cell-role="th">규빈(ES)</th>
<th data-quarto-table-cell-role="th">다호(ES)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">옥순(IN)</td>
<td>NaN</td>
<td>4.02</td>
<td>3.45</td>
<td>3.42</td>
<td>0.84</td>
<td>1.12</td>
<td>0.43</td>
<td>0.49</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">영자(IN)</td>
<td>3.93</td>
<td>3.99</td>
<td>3.63</td>
<td>3.43</td>
<td>0.98</td>
<td>0.96</td>
<td>0.52</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">정숙(IS)</td>
<td>3.52</td>
<td>3.42</td>
<td>4.05</td>
<td>4.06</td>
<td>0.39</td>
<td>NaN</td>
<td>0.93</td>
<td>0.99</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">영숙(IS)</td>
<td>3.43</td>
<td>3.57</td>
<td>NaN</td>
<td>3.95</td>
<td>0.56</td>
<td>0.52</td>
<td>0.89</td>
<td>0.89</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">순자(EN)</td>
<td>1.12</td>
<td>NaN</td>
<td>0.59</td>
<td>0.43</td>
<td>4.01</td>
<td>4.16</td>
<td>3.52</td>
<td>3.38</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">현숙(EN)</td>
<td>0.94</td>
<td>1.05</td>
<td>0.32</td>
<td>0.45</td>
<td>4.02</td>
<td>3.78</td>
<td>NaN</td>
<td>3.54</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">서연(ES)</td>
<td>0.51</td>
<td>0.56</td>
<td>0.88</td>
<td>0.89</td>
<td>3.50</td>
<td>3.64</td>
<td>4.04</td>
<td>4.10</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">보람(ES)</td>
<td>0.48</td>
<td>0.51</td>
<td>1.03</td>
<td>NaN</td>
<td>3.52</td>
<td>4.00</td>
<td>3.82</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">하니(I)</td>
<td>4.85</td>
<td>4.82</td>
<td>NaN</td>
<td>4.98</td>
<td>4.53</td>
<td>4.39</td>
<td>4.45</td>
<td>4.52</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<pre><code>{'옥순(IN)': 0, '영자(IN)': 1, '정숙(IS)': 2, '영숙(IS)': 3, '순자(EN)': 4,
 '현숙(EN)': 5, '서연(ES)': 6, '보람(ES)': 7, '하니(I)': 8}

{'영식(IN)': 0, '영철(IN)': 1, '영호(IS)': 2, '광수(IS)': 3, '상철(EN)': 4,
 '영수(EN)': 5, '규빈(ES)': 6, '다호(ES)': 7}</code></pre>
<div id="0c90523f-e264-4555-b8bf-5b47043f48ec" class="cell" data-execution_count="94">
<div class="sourceCode cell-code" id="cb140"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a>xx1 <span class="op">=</span> torch.tensor([<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">8</span>])</span>
<span id="cb140-2"><a href="#cb140-2" aria-hidden="true" tabindex="-1"></a>xx2 <span class="op">=</span> torch.tensor([<span class="dv">0</span>,<span class="dv">7</span>,<span class="dv">2</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="f4541281-4d77-4768-b6b8-fb4af01702dd" class="cell" data-execution_count="95">
<div class="sourceCode cell-code" id="cb141"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb141-1"><a href="#cb141-1" aria-hidden="true" tabindex="-1"></a>net(xx1,xx2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="95">
<pre><code>tensor([[3.3455],
        [1.3572],
        [4.9131]], grad_fn=&lt;MulBackward0&gt;)</code></pre>
</div>
</div>
<ul>
<li>4, 0.5, 5근처 정도가 맞는 것 같음 (overfitting)</li>
<li>epoch을 2,000으로 줄이면</li>
</ul>
<div id="efa05d7a-f6da-4359-aa00-03c32967f768" class="cell" data-execution_count="96">
<div class="sourceCode cell-code" id="cb143"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb143-1"><a href="#cb143-1" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> NNbased2()</span>
<span id="cb143-2"><a href="#cb143-2" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span>
<span id="cb143-3"><a href="#cb143-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters())</span>
<span id="cb143-4"><a href="#cb143-4" aria-hidden="true" tabindex="-1"></a><span class="co">#----#</span></span>
<span id="cb143-5"><a href="#cb143-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2000</span>):</span>
<span id="cb143-6"><a href="#cb143-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step1</span></span>
<span id="cb143-7"><a href="#cb143-7" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> net(x1,x2)</span>
<span id="cb143-8"><a href="#cb143-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step2</span></span>
<span id="cb143-9"><a href="#cb143-9" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y)</span>
<span id="cb143-10"><a href="#cb143-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step3</span></span>
<span id="cb143-11"><a href="#cb143-11" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb143-12"><a href="#cb143-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step4</span></span>
<span id="cb143-13"><a href="#cb143-13" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb143-14"><a href="#cb143-14" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="59b4b537-ad2a-4099-9cbd-02c43f27fc6f" class="cell" data-execution_count="98">
<div class="sourceCode cell-code" id="cb144"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb144-1"><a href="#cb144-1" aria-hidden="true" tabindex="-1"></a>yhat[:<span class="dv">5</span>], y[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="98">
<pre><code>(tensor([[4.0040],
         [3.4680],
         [3.4130],
         [0.8093],
         [1.1156]], grad_fn=&lt;SliceBackward0&gt;),
 tensor([[4.0200],
         [3.4500],
         [3.4200],
         [0.8400],
         [1.1200]]))</code></pre>
</div>
</div>
<div id="687777c3-af98-4567-ab55-83e0ad95d0f6" class="cell" data-execution_count="99">
<div class="sourceCode cell-code" id="cb146"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb146-1"><a href="#cb146-1" aria-hidden="true" tabindex="-1"></a>net(xx1,xx2) <span class="co"># 비슷함</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="99">
<pre><code>tensor([[3.8184],
        [0.5261],
        [4.9015]], grad_fn=&lt;MulBackward0&gt;)</code></pre>
</div>
</div>
<ul>
<li>✍️ 강의 영상(overfitting)과 다르게 잘 되긴 하였음</li>
<li>강의 영상처럼 모형 단순화</li>
</ul>
<div id="2a448712-8085-4898-ac14-c0e7f3b8a844" class="cell" data-execution_count="100">
<div class="sourceCode cell-code" id="cb148"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb148-1"><a href="#cb148-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NNbased2(torch.nn.Module):</span>
<span id="cb148-2"><a href="#cb148-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb148-3"><a href="#cb148-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb148-4"><a href="#cb148-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ebdd1 <span class="op">=</span> torch.nn.Embedding(<span class="dv">9</span>,<span class="dv">2</span>)</span>
<span id="cb148-5"><a href="#cb148-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ebdd2 <span class="op">=</span> torch.nn.Embedding(<span class="dv">8</span>,<span class="dv">2</span>)</span>
<span id="cb148-6"><a href="#cb148-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b1 <span class="op">=</span> torch.nn.Embedding(<span class="dv">9</span>,<span class="dv">1</span>)</span>
<span id="cb148-7"><a href="#cb148-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b2 <span class="op">=</span> torch.nn.Embedding(<span class="dv">8</span>,<span class="dv">1</span>)</span>
<span id="cb148-8"><a href="#cb148-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sig <span class="op">=</span> torch.nn.Sigmoid()</span>
<span id="cb148-9"><a href="#cb148-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mlp <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb148-10"><a href="#cb148-10" aria-hidden="true" tabindex="-1"></a>            torch.nn.Linear(<span class="dv">6</span>,<span class="dv">15</span>),</span>
<span id="cb148-11"><a href="#cb148-11" aria-hidden="true" tabindex="-1"></a>            torch.nn.ReLU(),</span>
<span id="cb148-12"><a href="#cb148-12" aria-hidden="true" tabindex="-1"></a>            torch.nn.Linear(<span class="dv">15</span>,<span class="dv">1</span>),</span>
<span id="cb148-13"><a href="#cb148-13" aria-hidden="true" tabindex="-1"></a>            torch.nn.Sigmoid()</span>
<span id="cb148-14"><a href="#cb148-14" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb148-15"><a href="#cb148-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>,x1,x2):</span>
<span id="cb148-16"><a href="#cb148-16" aria-hidden="true" tabindex="-1"></a>        W_features <span class="op">=</span> <span class="va">self</span>.ebdd1(x1) </span>
<span id="cb148-17"><a href="#cb148-17" aria-hidden="true" tabindex="-1"></a>        M_features <span class="op">=</span> <span class="va">self</span>.ebdd2(x2) </span>
<span id="cb148-18"><a href="#cb148-18" aria-hidden="true" tabindex="-1"></a>        W_bias <span class="op">=</span> <span class="va">self</span>.b1(x1)</span>
<span id="cb148-19"><a href="#cb148-19" aria-hidden="true" tabindex="-1"></a>        M_bias <span class="op">=</span> <span class="va">self</span>.b2(x2)</span>
<span id="cb148-20"><a href="#cb148-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># yhat = self.sig((W_features * M_features).sum(axis=1).reshape(-1,1) + W_bias + M_bais)*5</span></span>
<span id="cb148-21"><a href="#cb148-21" aria-hidden="true" tabindex="-1"></a>        Z <span class="op">=</span> torch.concat([W_features, M_features, W_bias, M_bias], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb148-22"><a href="#cb148-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Z ---&gt; yhat (n,6) -&gt; (n,1)</span></span>
<span id="cb148-23"><a href="#cb148-23" aria-hidden="true" tabindex="-1"></a>        yhat <span class="op">=</span> <span class="va">self</span>.mlp(Z) <span class="op">*</span> <span class="dv">5</span></span>
<span id="cb148-24"><a href="#cb148-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> yhat</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="1c48c30e-9cb5-40a2-b0f1-277adfcacf68" class="cell" data-execution_count="101">
<div class="sourceCode cell-code" id="cb149"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb149-1"><a href="#cb149-1" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> NNbased2()</span>
<span id="cb149-2"><a href="#cb149-2" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss() </span>
<span id="cb149-3"><a href="#cb149-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters())</span>
<span id="cb149-4"><a href="#cb149-4" aria-hidden="true" tabindex="-1"></a><span class="co">#----#</span></span>
<span id="cb149-5"><a href="#cb149-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2000</span>):</span>
<span id="cb149-6"><a href="#cb149-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step1</span></span>
<span id="cb149-7"><a href="#cb149-7" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> net(x1,x2)</span>
<span id="cb149-8"><a href="#cb149-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step2</span></span>
<span id="cb149-9"><a href="#cb149-9" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y)</span>
<span id="cb149-10"><a href="#cb149-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step3</span></span>
<span id="cb149-11"><a href="#cb149-11" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb149-12"><a href="#cb149-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">#step4</span></span>
<span id="cb149-13"><a href="#cb149-13" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb149-14"><a href="#cb149-14" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="c9caaea6-8047-4bb6-a770-a8261660ea8a" class="cell" data-execution_count="102">
<div class="sourceCode cell-code" id="cb150"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb150-1"><a href="#cb150-1" aria-hidden="true" tabindex="-1"></a>yhat[:<span class="dv">5</span>], y[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="102">
<pre><code>(tensor([[3.6244],
         [3.5508],
         [3.5255],
         [0.7445],
         [1.0485]], grad_fn=&lt;SliceBackward0&gt;),
 tensor([[4.0200],
         [3.4500],
         [3.4200],
         [0.8400],
         [1.1200]]))</code></pre>
</div>
</div>
<div id="b19bb97c-a3e5-4bbf-a2d9-41b8576b57ad" class="cell" data-execution_count="103">
<div class="sourceCode cell-code" id="cb152"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb152-1"><a href="#cb152-1" aria-hidden="true" tabindex="-1"></a>net(xx1,xx2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="103">
<pre><code>tensor([[3.5422],
        [0.9444],
        [4.9080]], grad_fn=&lt;MulBackward0&gt;)</code></pre>
</div>
</div>
<ul>
<li><p>✍️ 이번에는 강의 영상과 다르게 잘 안됨</p></li>
<li><p>밑의 강의 노트 코드: 랜덤으로 해도 안정적으로 결과가 잘 나옴</p></li>
<li><p>epoch을 줄이기만 하여도 overfitting 방지 효과가 있음 (early stopping)</p></li>
</ul>
<p>)🗣️</p>
<div id="94d19cbd-df19-49e2-bfce-9df1fd67ce74" class="cell" data-tags="[]" data-execution_count="371">
<div class="sourceCode cell-code" id="cb154"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb154-1"><a href="#cb154-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NNbased2(torch.nn.Module):</span>
<span id="cb154-2"><a href="#cb154-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb154-3"><a href="#cb154-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb154-4"><a href="#cb154-4" aria-hidden="true" tabindex="-1"></a>        <span class="co">#--#</span></span>
<span id="cb154-5"><a href="#cb154-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ebdd1 <span class="op">=</span> torch.nn.Embedding(<span class="dv">9</span>,<span class="dv">2</span>)</span>
<span id="cb154-6"><a href="#cb154-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ebdd2 <span class="op">=</span> torch.nn.Embedding(<span class="dv">8</span>,<span class="dv">2</span>)</span>
<span id="cb154-7"><a href="#cb154-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b1 <span class="op">=</span> torch.nn.Embedding(<span class="dv">9</span>,<span class="dv">1</span>)</span>
<span id="cb154-8"><a href="#cb154-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b2 <span class="op">=</span> torch.nn.Embedding(<span class="dv">8</span>,<span class="dv">1</span>)</span>
<span id="cb154-9"><a href="#cb154-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sig <span class="op">=</span> torch.nn.Sigmoid()</span>
<span id="cb154-10"><a href="#cb154-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mlp <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb154-11"><a href="#cb154-11" aria-hidden="true" tabindex="-1"></a>            torch.nn.Linear(<span class="dv">6</span>,<span class="dv">15</span>),</span>
<span id="cb154-12"><a href="#cb154-12" aria-hidden="true" tabindex="-1"></a>            torch.nn.ReLU(),</span>
<span id="cb154-13"><a href="#cb154-13" aria-hidden="true" tabindex="-1"></a>            torch.nn.Linear(<span class="dv">15</span>,<span class="dv">1</span>),</span>
<span id="cb154-14"><a href="#cb154-14" aria-hidden="true" tabindex="-1"></a>            torch.nn.Sigmoid()</span>
<span id="cb154-15"><a href="#cb154-15" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb154-16"><a href="#cb154-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>,x1,x2):</span>
<span id="cb154-17"><a href="#cb154-17" aria-hidden="true" tabindex="-1"></a>        W_feature <span class="op">=</span> <span class="va">self</span>.ebdd1(x1)</span>
<span id="cb154-18"><a href="#cb154-18" aria-hidden="true" tabindex="-1"></a>        W_bias <span class="op">=</span> <span class="va">self</span>.b1(x1)</span>
<span id="cb154-19"><a href="#cb154-19" aria-hidden="true" tabindex="-1"></a>        M_feature <span class="op">=</span> <span class="va">self</span>.ebdd2(x2)</span>
<span id="cb154-20"><a href="#cb154-20" aria-hidden="true" tabindex="-1"></a>        M_bias <span class="op">=</span> <span class="va">self</span>.b2(x2)</span>
<span id="cb154-21"><a href="#cb154-21" aria-hidden="true" tabindex="-1"></a>        <span class="co">#yhat = sig((W_feature * M_feature).sum(axis=1).reshape(-1,1) + W_bias + M_bias ) * 5 </span></span>
<span id="cb154-22"><a href="#cb154-22" aria-hidden="true" tabindex="-1"></a>        Z <span class="op">=</span> torch.concat([W_feature, M_feature, W_bias, M_bias],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb154-23"><a href="#cb154-23" aria-hidden="true" tabindex="-1"></a>        yhat <span class="op">=</span> <span class="va">self</span>.mlp(Z) <span class="op">*</span> <span class="dv">5</span> </span>
<span id="cb154-24"><a href="#cb154-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> yhat</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="f4f8f527-064d-4bee-8584-13f3a12b8a6d" class="cell" data-tags="[]" data-execution_count="402">
<div class="sourceCode cell-code" id="cb155"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb155-1"><a href="#cb155-1" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> NNbased2()</span>
<span id="cb155-2"><a href="#cb155-2" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.MSELoss()</span>
<span id="cb155-3"><a href="#cb155-3" aria-hidden="true" tabindex="-1"></a>optimizr <span class="op">=</span> torch.optim.Adam(net.parameters(),lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb155-4"><a href="#cb155-4" aria-hidden="true" tabindex="-1"></a><span class="co">#--# </span></span>
<span id="cb155-5"><a href="#cb155-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoc <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3000</span>):</span>
<span id="cb155-6"><a href="#cb155-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1</span></span>
<span id="cb155-7"><a href="#cb155-7" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> net(x1,x2) </span>
<span id="cb155-8"><a href="#cb155-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2</span></span>
<span id="cb155-9"><a href="#cb155-9" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(yhat,y)</span>
<span id="cb155-10"><a href="#cb155-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3 </span></span>
<span id="cb155-11"><a href="#cb155-11" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb155-12"><a href="#cb155-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 4 </span></span>
<span id="cb155-13"><a href="#cb155-13" aria-hidden="true" tabindex="-1"></a>    optimizr.step()</span>
<span id="cb155-14"><a href="#cb155-14" aria-hidden="true" tabindex="-1"></a>    optimizr.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="28892064-a85f-4b2d-b355-6b85bca58c49" class="cell" data-execution_count="403">
<div class="sourceCode cell-code" id="cb156"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb156-1"><a href="#cb156-1" aria-hidden="true" tabindex="-1"></a>yhat[:<span class="dv">10</span>], y[:<span class="dv">10</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="403">
<pre><code>(tensor([[4.0395],
         [3.4880],
         [3.4527],
         [0.8548],
         [1.1290],
         [0.4416],
         [0.5041],
         [3.9470],
         [4.0075],
         [3.6544]], grad_fn=&lt;SliceBackward0&gt;),
 tensor([[4.0200],
         [3.4500],
         [3.4200],
         [0.8400],
         [1.1200],
         [0.4300],
         [0.4900],
         [3.9300],
         [3.9900],
         [3.6300]]))</code></pre>
</div>
</div>
<p><em>(옥순-영식), (영자-다호), (하니-영호) 를 예측해보자.</em></p>
<div id="f68f60a2-7185-4f09-aa0b-7f3c228e8c87" class="cell" data-execution_count="404">
<div class="sourceCode cell-code" id="cb158"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb158-1"><a href="#cb158-1" aria-hidden="true" tabindex="-1"></a>df_view</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="404">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">영식(IN)</th>
<th data-quarto-table-cell-role="th">영철(IN)</th>
<th data-quarto-table-cell-role="th">영호(IS)</th>
<th data-quarto-table-cell-role="th">광수(IS)</th>
<th data-quarto-table-cell-role="th">상철(EN)</th>
<th data-quarto-table-cell-role="th">영수(EN)</th>
<th data-quarto-table-cell-role="th">규빈(ES)</th>
<th data-quarto-table-cell-role="th">다호(ES)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">옥순(IN)</td>
<td>NaN</td>
<td>4.02</td>
<td>3.45</td>
<td>3.42</td>
<td>0.84</td>
<td>1.12</td>
<td>0.43</td>
<td>0.49</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">영자(IN)</td>
<td>3.93</td>
<td>3.99</td>
<td>3.63</td>
<td>3.43</td>
<td>0.98</td>
<td>0.96</td>
<td>0.52</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">정숙(IS)</td>
<td>3.52</td>
<td>3.42</td>
<td>4.05</td>
<td>4.06</td>
<td>0.39</td>
<td>NaN</td>
<td>0.93</td>
<td>0.99</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">영숙(IS)</td>
<td>3.43</td>
<td>3.57</td>
<td>NaN</td>
<td>3.95</td>
<td>0.56</td>
<td>0.52</td>
<td>0.89</td>
<td>0.89</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">순자(EN)</td>
<td>1.12</td>
<td>NaN</td>
<td>0.59</td>
<td>0.43</td>
<td>4.01</td>
<td>4.16</td>
<td>3.52</td>
<td>3.38</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">현숙(EN)</td>
<td>0.94</td>
<td>1.05</td>
<td>0.32</td>
<td>0.45</td>
<td>4.02</td>
<td>3.78</td>
<td>NaN</td>
<td>3.54</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">서연(ES)</td>
<td>0.51</td>
<td>0.56</td>
<td>0.88</td>
<td>0.89</td>
<td>3.50</td>
<td>3.64</td>
<td>4.04</td>
<td>4.10</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">보람(ES)</td>
<td>0.48</td>
<td>0.51</td>
<td>1.03</td>
<td>NaN</td>
<td>3.52</td>
<td>4.00</td>
<td>3.82</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">하니(I)</td>
<td>4.85</td>
<td>4.82</td>
<td>NaN</td>
<td>4.98</td>
<td>4.53</td>
<td>4.39</td>
<td>4.45</td>
<td>4.52</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="a65ebe4f-1bd9-476d-a354-97550723edc9" class="cell" data-execution_count="405">
<div class="sourceCode cell-code" id="cb159"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb159-1"><a href="#cb159-1" aria-hidden="true" tabindex="-1"></a>xx1 <span class="op">=</span> torch.tensor([<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">8</span>])</span>
<span id="cb159-2"><a href="#cb159-2" aria-hidden="true" tabindex="-1"></a>xx2 <span class="op">=</span> torch.tensor([<span class="dv">0</span>,<span class="dv">7</span>,<span class="dv">2</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="1d27595f-398d-4bd2-8420-9cca647f1764" class="cell" data-execution_count="406">
<div class="sourceCode cell-code" id="cb160"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb160-1"><a href="#cb160-1" aria-hidden="true" tabindex="-1"></a>net(xx1,xx2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="406">
<pre><code>tensor([[3.9317],
        [0.6682],
        [4.9322]], grad_fn=&lt;MulBackward0&gt;)</code></pre>
</div>
</div>
</section>
<section id="b.-ncf-he2017neural" class="level2">
<h2 class="anchored" data-anchor-id="b.-ncf-he2017neural">B. NCF <span class="citation" data-cites="he2017neural">[@he2017neural]</span></h2>
<p><code>-</code> MF-based와 NN-base를 합친것</p>
<p>🗣️(</p>
<pre><code>MF-based    특징1*특징2
NN-based    [특징1, 특징2] --&gt; nn

# 그림 설명
User: 남성 출연자, Item: 여성 출연자로 생각

MF User Vector: 남성 출연자의 특징, MF Item Vector: 여성 출연자의 특징
(위의 두 특징 벡터 만드는 방식은 embedding layer: one hot encoding + linear)
MF User Vector MF Item Vector --Element-wise Product--&gt; GMF Layer
GMF Layer에서 Score로 바로 가면 MF-based

MLP User Vector: 남성 출연자의 특징, MLP Item Vector: 여성 출연자의 특징
MLP User Vector MLP Item Vector ---concat---&gt;
    ---ReLU ... Linear Transform ... ReLu---&gt; MLP Layer X
MLP Layer X에서 바로 Score로 가면 NN-based

요즘 많이 쓰이는 혼합 방식:
GMF Layer와 MLP Layer X로 적당히 조합하여 하나의 Layer를 만들고
Linear, Sigmoid 등을 이용하여 마무리</code></pre>
<p>)🗣️</p>
<p><img src="https://github.com/guebin/DL2024/blob/main/posts/NCF.png?raw=true" class="img-fluid"></p>
</section>
</section>
<section id="appendix-선택학습" class="level1">
<h1>Appendix – 선택학습 📝</h1>
<p>🗣️(</p>
<ul>
<li>11wk-2 강의 영상 참고 (9:10)
<ul>
<li>x가 숫자로 되어 있을 때 one hot encoding을 하지 않고</li>
<li>바로 linear transform 을 해도 비슷하다고 생각이 든다면 읽어보기</li>
</ul></li>
</ul>
<p>)🗣️</p>
<p><code># 의문</code>: 그냥 원핫인코딩없이 바로 선형변환하면 안되나? (= 꼭 임베딩레이어를 써야하나?)</p>
<div id="eec0e176-d5a4-40b2-bf78-3e2cc657d118" class="cell" data-tags="[]" data-execution_count="23">
<div class="sourceCode cell-code" id="cb163"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb163-1"><a href="#cb163-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">0</span>,<span class="dv">1</span>])</span>
<span id="cb163-2"><a href="#cb163-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> x.reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>).<span class="bu">float</span>()</span>
<span id="cb163-3"><a href="#cb163-3" aria-hidden="true" tabindex="-1"></a>x,X</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>(tensor([0, 1, 2, 0, 1]),
 tensor([[0.],
         [1.],
         [2.],
         [0.],
         [1.]]))</code></pre>
</div>
</div>
<div id="b1602e87-c137-41b2-b996-81af992e6d6e" class="cell" data-tags="[]" data-execution_count="25">
<div class="sourceCode cell-code" id="cb165"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb165-1"><a href="#cb165-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb165-2"><a href="#cb165-2" aria-hidden="true" tabindex="-1"></a>l1 <span class="op">=</span> torch.nn.Linear(<span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb165-3"><a href="#cb165-3" aria-hidden="true" tabindex="-1"></a>l1(X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>tensor([[-0.8470],
        [-1.1937],
        [-1.5404],
        [-0.8470],
        [-1.1937]], grad_fn=&lt;AddmmBackward0&gt;)</code></pre>
</div>
</div>
<div id="9da021eb-8440-4fd5-af7a-0c5af0aed330" class="cell" data-tags="[]" data-execution_count="26">
<div class="sourceCode cell-code" id="cb167"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb167-1"><a href="#cb167-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">43052</span>)</span>
<span id="cb167-2"><a href="#cb167-2" aria-hidden="true" tabindex="-1"></a>ebdd <span class="op">=</span> torch.nn.Embedding(<span class="dv">3</span>,<span class="dv">1</span>) </span>
<span id="cb167-3"><a href="#cb167-3" aria-hidden="true" tabindex="-1"></a>ebdd(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>tensor([[-0.8178],
        [-0.7052],
        [-0.5843],
        [-0.8178],
        [-0.7052]], grad_fn=&lt;EmbeddingBackward0&gt;)</code></pre>
</div>
</div>
<p>결과적으로 0,1,2 를 다른숫자들로 맵핑한건 비슷해보이는데?</p>
<p><code>-</code> 수식의 차이: 비슷해보이지만 계산방식이 조금 다름</p>
<div id="da2fa122-cb91-479f-8438-8cd1431bf33e" class="cell" data-tags="[]" data-execution_count="27">
<div class="sourceCode cell-code" id="cb169"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb169-1"><a href="#cb169-1" aria-hidden="true" tabindex="-1"></a>l1.weight, l1.bias</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>(Parameter containing:
 tensor([[-0.3467]], requires_grad=True),
 Parameter containing:
 tensor([-0.8470], requires_grad=True))</code></pre>
</div>
</div>
<ul>
<li><p><span class="math inline">\(l_1({\bf X}) = \begin{bmatrix} 0 \\ 1 \\ 2 \\ 0 \\ 1 \end{bmatrix} \times (-0.3467) + (-0.8470)=\begin{bmatrix} -0.8470 \\ -1.1937 \\ -1.5404 \\ -0.8470 \\ -1.1937 \end{bmatrix}\)</span></p></li>
<li><p><span class="math inline">\(\text{ebdd}({\boldsymbol x})= \text{linr}\big(\text{onehot}({\boldsymbol x})\big) = \begin{bmatrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1 \\ 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \end{bmatrix}\begin{bmatrix} -0.8178 \\ -0.7052 \\ -0.5843 \end{bmatrix} = \begin{bmatrix} -0.8178 \\ -0.7052 \\ -0.5843 \\ -0.8178 \\ -0.7052 \end{bmatrix}\)</span></p></li>
</ul>
<p><code>-</code> 데이터를 읽으며 해석: 사실상 0,1,2에 대한 의미는 “옥순”,“영숙”,“하니” 같은 자료였고, 임베딩의 결과는 “옥순”,“영숙”,“하니”가 가지는 어떠한 특징이었음 (예를들면 매력같은). 데이터를 상상하며 위의 결과를 다시 해석해보자.</p>
<p><strong>옥순이 가지는 어떠한 특징 (-0.8470 혹은 -0.8178) 을 바꾸고 싶다면?</strong></p>
<ul>
<li><code>ebdd</code>의 경우: <code>ebdd.weigth</code>에 있는 -0.8178 이라는 숫자를 조정하면 된다. 이 조정은 옥순의 특징만 바꾸며 영숙과 하니의 특징은 바꾸지 않는다. (개별조정이 쉬움)</li>
<li><code>linr</code>의 경우: <code>linr.weight</code>에 있는 -0.3467 혹은 <code>linr.bias</code>에 있는 -0.8470 을 조정하면 되는데, 이를 조정하면 옥순의 특징을 바꿈과 동시에 영숙/하니의 특징까지 같이 바뀌게 된다. (개별조정이 어려움)</li>
</ul>
<p><strong>만약에 출연자가 1000명이라면??</strong></p>
<ul>
<li><code>linr</code>의 경우: 1000명의 특징을 단 2개의 파라메터로 조정해야한다. (그리고 한명의 특징을 바꾸면 999명의 특징이 같이 바뀐다, 개별조정은 애초에 가능하지 않음.)</li>
<li><code>ebdd</code>의 경우: 1000개의 특징을 조정할 수 있는 1000개의 파라메터를 확보할 수 있게 된다.</li>
</ul>
<p><code>-</code> 결론: ebdd가 더 파라메터 미세조정을 통하여 특징을 학습하기 용이하다. (독립적으로 특징값을 줄 수 있으니까!)</p>
<blockquote class="blockquote">
<p>만약에 문자열이 “최우수(A)”, “우수(B)”, “보통(C)”, “미흡(D)”, “매우미흡(F)” 이었다면 특징을 뽑아낼때 linr 가 더 적절했겠죠?</p>
</blockquote>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>