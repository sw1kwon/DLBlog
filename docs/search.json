[
  {
    "objectID": "posts/01wk-1.html",
    "href": "posts/01wk-1.html",
    "title": "01wk-1: (토치) – 강의소개, 파이토치 기본",
    "section": "",
    "text": "📘 Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\n📝 🗣️ ✍️ 🔬 ❓"
  },
  {
    "objectID": "posts/01wk-1.html#a.-torch",
    "href": "posts/01wk-1.html#a.-torch",
    "title": "01wk-1: (토치) – 강의소개, 파이토치 기본",
    "section": "A. torch",
    "text": "A. torch\n🗣️ torch는 numpy와 비슷 (벡터 만들기 등)\n- 벡터\n\ntorch.tensor([1,2,3])\n\ntensor([1, 2, 3])\n\n\n- 벡터의 덧셈\n\ntorch.tensor([1,2,3]) + torch.tensor([2,2,2])\n\ntensor([3, 4, 5])\n\n\n- 브로드캐스팅\n\ntorch.tensor([1,2,3]) + 2\n\ntensor([3, 4, 5])"
  },
  {
    "objectID": "posts/01wk-1.html#b.-벡터와-매트릭스",
    "href": "posts/01wk-1.html#b.-벡터와-매트릭스",
    "title": "01wk-1: (토치) – 강의소개, 파이토치 기본",
    "section": "B. 벡터와 매트릭스",
    "text": "B. 벡터와 매트릭스\n🗣️ torch.tensor는 np.array와 비슷\n- \\(3 \\times 2\\) matrix\n\ntorch.tensor([[1,2],[3,4],[5,6]]) \n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n- \\(3 \\times 1\\) matrix = \\(3 \\times 1\\) column vector\n\ntorch.tensor([[1],[3],[5]]) \n\ntensor([[1],\n        [3],\n        [5]])\n\n\n- \\(1 \\times 2\\) matrix = \\(1 \\times 2\\) row vector\n\ntorch.tensor([[1,2]]) \n\ntensor([[1, 2]])\n\n\n🗣️ torch.tensor([[1,2],[3,4],[5,6]])에서 [3,4],[5,6] 삭제라고 생각\n🗣️ column vector와 row vector는 구분되고 선언 방법이 다름\n- 더하기\n브로드캐스팅(편한거)\n\ntorch.tensor([[1,2],[3,4],[5,6]]) - 1\n\ntensor([[0, 1],\n        [2, 3],\n        [4, 5]])\n\n\n🗣️ “matrix - scalar”는 불가능하지만 알아서 원소별로 전부 뺌\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1],[-3],[-5]])\n\ntensor([[0, 1],\n        [0, 1],\n        [0, 1]])\n\n\n🗣️ (3, 2) - (3, 1)을 알아서 뺌\n✍️ torch.tensor([[-1,-1],[-3, 3],[-5,-5]])\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1,-2]])\n\ntensor([[0, 0],\n        [2, 2],\n        [4, 4]])\n\n\n🗣️ (3, 2) - (1, 2)을 알아서 뺌\n✍️ torch.tensor([[-1,-2],[-1,-2],[-1,-2]])\n잘못된 브로드캐스팅\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1,-3,-5]])\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[11], line 1\n----&gt; 1 torch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1,-3,-5]])\n\nRuntimeError: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1\n\n\n\n🗣️ 세로로 쓰거나 가로로 두 개의 원소만 썼으면 가능\n✍️ torch.tensor([[-1],[-3],[-5]]) 또는 torch.tensor([[-1,-3],[-1,-3],[-1,-3]]) 등\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1],[-2]])\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[12], line 1\n----&gt; 1 torch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1],[-2]])\n\nRuntimeError: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 0\n\n\n\n🗣️ (3, 2) - (2, 1) 는 알아서 채우기 어려우므로 error\n이상한 것\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([-1,-2])\n\ntensor([[0, 0],\n        [2, 2],\n        [4, 4]])\n\n\n🗣️ (3, 2) matrix - 길이가 2인 vector(2x1, 1x2 둘 다 아님)\n🗣️ “matrix - vector”를 row vector로 해석하고 늘려서 계산한 듯\n✍️ torch.tensor([[-1,-2],[-1,-2],[-1,-2]])\n🔬(\n\n차원 수만 알고 싶을 때 → tensor.dim() 또는 tensor.ndim\n각 차원의 크기까지 알고 싶을 때 → tensor.shape 또는 tensor.size()\n\n\nprint(torch.tensor([[1,2],[3,4],[5,6]]).dim())\nprint(torch.tensor([[1,2],[3,4],[5,6]]).shape)\nprint(torch.tensor([-1,-2]).dim())\nprint(torch.tensor([-1,-2]).shape)\nprint(torch.tensor([[1,2],[3,4],[5,6]]).ndim)\nprint(torch.tensor([[1,2],[3,4],[5,6]]).size())\nprint(torch.tensor([-1,-2]).ndim)\nprint(torch.tensor([-1,-2]).size())\n\n2\ntorch.Size([3, 2])\n1\ntorch.Size([2])\n2\ntorch.Size([3, 2])\n1\ntorch.Size([2])\n\n\n\n참고 (Chat GPT4o)\n\n\nNumPy와 PyTorch 차이 정리\n\n\n\n\n기능\nPyTorch\nNumPy\n\n\n\n\n차원 수\n.dim() 또는 .ndim\n.ndim\n\n\nshape 확인\n.shape 또는 .size()\n.shape\n\n\n크기 변경\n.view(), .reshape()\n.reshape()\n\n\n타입\ntorch.Tensor\nnp.ndarray\n\n\n\n\n실전 팁:\n\nPyTorch의 .dim()만 NumPy에서 안 먹힌다는 것만 기억하면 둘 다 거의 비슷하게 다룰 수 있음\n다차원 배열을 다룰 때 .ndim, .shape는 양쪽 모두 안전하게 쓸 수 있는 핵심 도구\ndim()은 PyTorch 고유 메서드\n\n\n)🔬\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([-1,-3,-5])\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[15], line 1\n----&gt; 1 torch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([-1,-3,-5])\n\nRuntimeError: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1\n\n\n\n🗣️ 길이가 3인 vector를 column vector로 해석하고 (3,2)로 채워서 계산할 것 같지만 X (이번에 발견)\n- 행렬곱\n정상적인 행렬곱\n\ntorch.tensor([[1,2],[3,4],[5,6]]) @ torch.tensor([[1],[2]])\n\ntensor([[ 5],\n        [11],\n        [17]])\n\n\n🗣️ (3,2) matirx @ (2,1) vector = (3,1) matrix\n\ntorch.tensor([[1,2,3]]) @ torch.tensor([[1,2],[3,4],[5,6]]) \n\ntensor([[22, 28]])\n\n\n🗣️ (1,3) @ (3,2) = (1,2)\n잘못된 행렬곱\n\ntorch.tensor([[1,2],[3,4],[5,6]]) @ torch.tensor([[1,2]])\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[18], line 1\n----&gt; 1 torch.tensor([[1,2],[3,4],[5,6]]) @ torch.tensor([[1,2]])\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (3x2 and 1x2)\n\n\n\n🗣️ (3,2) @ (1,2) 불가\n\ntorch.tensor([[1],[2],[3]]) @ torch.tensor([[1,2],[3,4],[5,6]]) \n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[19], line 1\n----&gt; 1 torch.tensor([[1],[2],[3]]) @ torch.tensor([[1,2],[3,4],[5,6]]) \n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (3x1 and 3x2)\n\n\n\n🗣️ (3,1) @ (3,2) 불가\n이상한 것\n\ntorch.tensor([[1,2],[3,4],[5,6]]) @ torch.tensor([1,2]) # 이게 왜 가능..\n\ntensor([ 5, 11, 17])\n\n\n🗣️ (3,2) @ (2) 길이가 2인 vector / 사람마다 해석 애매 (2,1)? (1,2)? / 곱하기를 위해 (2,1) column vector로 해석\n🗣️ (3,2) @ (2,1)로 해석 후 계산하여 (3) 길이가 3인 vector가 나옴\n\ntorch.tensor([1,2,3]) @ torch.tensor([[1,2],[3,4],[5,6]]) # 이건 왜 가능?\n\ntensor([22, 28])\n\n\n🗣️ (3) @ (3,2)에서 (3)을 (1,3) row vector로 해석\n🗣️( 엄밀하게 하려면\n\ntorch.tensor([[1,2,3]]) @ torch.tensor([[1,2],[3,4],[5,6]])\n\ntensor([[22, 28]])\n\n\n✍️ 당연히 결과의 차원도 다름\n)🗣️"
  },
  {
    "objectID": "posts/01wk-1.html#c.-transpose-reshape",
    "href": "posts/01wk-1.html#c.-transpose-reshape",
    "title": "01wk-1: (토치) – 강의소개, 파이토치 기본",
    "section": "C. transpose, reshape",
    "text": "C. transpose, reshape\n- transpose\n\ntorch.tensor([[1,2],[3,4]]).T \n\ntensor([[1, 3],\n        [2, 4]])\n\n\n\ntorch.tensor([[1],[3]]).T \n\ntensor([[1, 3]])\n\n\n🗣️ column vector -&gt; row vector\n\ntorch.tensor([[1,2]]).T \n\ntensor([[1],\n        [2]])\n\n\n🗣️ row vector -&gt; column vector\n🗣️ 차원을 바꾸는 효과 (1,2) -&gt; (2,1)\n- reshape\n🗣️( 차원 보기\n\ntorch.tensor([[1,2]]).shape\n\ntorch.Size([1, 2])\n\n\n을 column vector로 바꾸고 싶으면\n\ntorch.tensor([[1,2]]).reshape(2,1)\n\ntensor([[1],\n        [2]])\n\n\ntranspose와 동일\n)🗣️\n일반적인 사용\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(2,3)\n\ntensor([[1, 2, 3],\n        [4, 5, 6]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]])\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(1,6)\n\ntensor([[1, 2, 3, 4, 5, 6]])\n\n\n🗣️ (3,2) -&gt; (1,6)\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(6)\n\ntensor([1, 2, 3, 4, 5, 6])\n\n\n🗣️ (3,2)를 그냥 6으로 : 길이가 6인 vector로 바꿈\n편한 것\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(2,-1)\n\ntensor([[1, 2, 3],\n        [4, 5, 6]])\n\n\n🗣️ torch.tensor([[1,2],[3,4],[5,6]]).reshape(2,??)를 원할 때 ??를 알아서 맞춤 (불가능하면 error)\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(6,-1)\n\ntensor([[1],\n        [2],\n        [3],\n        [4],\n        [5],\n        [6]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(-1,6)\n\ntensor([[1, 2, 3, 4, 5, 6]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(-1)\n\ntensor([1, 2, 3, 4, 5, 6])\n\n\n🗣️ 전체를 vector로 바꾸고 싶을 때 (1차원)"
  },
  {
    "objectID": "posts/01wk-1.html#d.-concat-stack-starstarstar",
    "href": "posts/01wk-1.html#d.-concat-stack-starstarstar",
    "title": "01wk-1: (토치) – 강의소개, 파이토치 기본",
    "section": "D. concat, stack \\((\\star\\star\\star)\\)",
    "text": "D. concat, stack \\((\\star\\star\\star)\\)\n- concat\n\na = torch.tensor([[1],[3],[5]])\nb = torch.tensor([[2],[4],[6]])\ntorch.concat([a,b],axis=1)\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n🗣️(\n\na\n\ntensor([[1],\n        [3],\n        [5]])\n\n\n\nb\n\ntensor([[2],\n        [4],\n        [6]])\n\n\na와 b를 모두 vector로 갖고 있는데 [a b]처럼 놓고 싶을 때 사용\n\na, b\n\n(tensor([[1],\n         [3],\n         [5]]),\n tensor([[2],\n         [4],\n         [6]]))\n\n\n\ntorch.concat([a,b]) # 이렇게 하면 좌우가 아니라 위 아래로 합쳐짐\n\ntensor([[1],\n        [3],\n        [5],\n        [2],\n        [4],\n        [6]])\n\n\n(3,1)과 (3,1)을 (3,2)로 만들고 싶었는데 (6,1)이 됨 -&gt; axis=1 옵션 사용하면 (3,2) 가능 (모르겠으면 밑의 링크 참조)\n)🗣️\n\ntorch.concat([a,b],axis=1)\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n- stack\n\na = torch.tensor([1,3,5])\nb = torch.tensor([2,4,6])\ntorch.stack([a,b],axis=1)\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n🗣️(\n\na\n\ntensor([1, 3, 5])\n\n\n\nb\n\ntensor([2, 4, 6])\n\n\n\na.reshape(3,1) # 참고) concat 설명 예시와 동일\n\ntensor([[1],\n        [3],\n        [5]])\n\n\n\ntorch.concat([a.reshape(3,1), b.reshape(3,1)], axis=1) # 리스트로 만든 후 이렇게 하면 되긴하나 너무 힘듦\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n\ntorch.stack([a,b], axis=1) # 같은 결과\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n차이: concat은 바꾸려는 대상의 dimension을 바꾸지는 X (matrix는 matrix로, vector는 vector로) / stack은 dimension을 하나 늘려서 바꿔줌\nconcat과 stack 둘 다 알면 좋음\n)🗣️\n\ntorch.concat([a.reshape(3,1),b.reshape(3,1)],axis=1)\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n\n\n\n\n\n\nWarning\n\n\n\nconcat과 stack을 지금 처음본다면 아래를 복습하시는게 좋습니다.\nhttps://guebin.github.io/PP2024/posts/06wk-2.html#numpy와-축axis"
  },
  {
    "objectID": "posts/02wk-2.html",
    "href": "posts/02wk-2.html",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "",
    "text": "📘 Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\n📝 🗣️ ✍️ 🔬 ❓"
  },
  {
    "objectID": "posts/02wk-2.html#a.-print",
    "href": "posts/02wk-2.html#a.-print",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "A. print",
    "text": "A. print\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nalpha = 0.001\nprint(f\"시작값 = {What.data.reshape(-1)}\")\nfor epoc in range(30):\n    yhat = X @ What\n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - alpha * What.grad\n    print(f'loss = {loss:.2f} \\t 업데이트폭 = {-alpha * What.grad.reshape(-1)} \\t 업데이트결과: {What.data.reshape(-1)}')\n    What.grad = None\n\n시작값 = tensor([-5., 10.])\nloss = 8587.69   업데이트폭 = tensor([ 1.3423, -1.1889])      업데이트결과: tensor([-3.6577,  8.8111])\nloss = 5675.21   업데이트폭 = tensor([ 1.1029, -0.9499])      업데이트결과: tensor([-2.5548,  7.8612])\nloss = 3755.64   업데이트폭 = tensor([ 0.9056, -0.7596])      업데이트결과: tensor([-1.6492,  7.1016])\nloss = 2489.58   업데이트폭 = tensor([ 0.7431, -0.6081])      업데이트결과: tensor([-0.9061,  6.4935])\nloss = 1654.04   업데이트폭 = tensor([ 0.6094, -0.4872])      업데이트결과: tensor([-0.2967,  6.0063])\nloss = 1102.32   업데이트폭 = tensor([ 0.4995, -0.3907])      업데이트결과: tensor([0.2028, 5.6156])\nloss = 737.84    업데이트폭 = tensor([ 0.4091, -0.3136])      업데이트결과: tensor([0.6119, 5.3020])\nloss = 496.97    업데이트폭 = tensor([ 0.3350, -0.2519])      업데이트결과: tensor([0.9469, 5.0501])\nloss = 337.71    업데이트폭 = tensor([ 0.2742, -0.2025])      업데이트결과: tensor([1.2211, 4.8477])\nloss = 232.40    업데이트폭 = tensor([ 0.2243, -0.1629])      업데이트결과: tensor([1.4454, 4.6848])\nloss = 162.73    업데이트폭 = tensor([ 0.1834, -0.1311])      업데이트결과: tensor([1.6288, 4.5537])\nloss = 116.63    업데이트폭 = tensor([ 0.1500, -0.1056])      업데이트결과: tensor([1.7787, 4.4480])\nloss = 86.13     업데이트폭 = tensor([ 0.1226, -0.0851])      업데이트결과: tensor([1.9013, 4.3629])\nloss = 65.93     업데이트폭 = tensor([ 0.1001, -0.0687])      업데이트결과: tensor([2.0014, 4.2942])\nloss = 52.57     업데이트폭 = tensor([ 0.0818, -0.0554])      업데이트결과: tensor([2.0832, 4.2388])\nloss = 43.72     업데이트폭 = tensor([ 0.0668, -0.0447])      업데이트결과: tensor([2.1500, 4.1941])\nloss = 37.86     업데이트폭 = tensor([ 0.0545, -0.0361])      업데이트결과: tensor([2.2045, 4.1579])\nloss = 33.97     업데이트폭 = tensor([ 0.0445, -0.0292])      업데이트결과: tensor([2.2490, 4.1287])\nloss = 31.40     업데이트폭 = tensor([ 0.0363, -0.0236])      업데이트결과: tensor([2.2853, 4.1051])\nloss = 29.70     업데이트폭 = tensor([ 0.0296, -0.0191])      업데이트결과: tensor([2.3150, 4.0860])\nloss = 28.57     업데이트폭 = tensor([ 0.0242, -0.0155])      업데이트결과: tensor([2.3392, 4.0705])\nloss = 27.83     업데이트폭 = tensor([ 0.0197, -0.0125])      업데이트결과: tensor([2.3589, 4.0580])\nloss = 27.33     업데이트폭 = tensor([ 0.0161, -0.0101])      업데이트결과: tensor([2.3750, 4.0479])\nloss = 27.00     업데이트폭 = tensor([ 0.0131, -0.0082])      업데이트결과: tensor([2.3881, 4.0396])\nloss = 26.79     업데이트폭 = tensor([ 0.0107, -0.0067])      업데이트결과: tensor([2.3988, 4.0330])\nloss = 26.64     업데이트폭 = tensor([ 0.0087, -0.0054])      업데이트결과: tensor([2.4075, 4.0276])\nloss = 26.55     업데이트폭 = tensor([ 0.0071, -0.0044])      업데이트결과: tensor([2.4146, 4.0232])\nloss = 26.48     업데이트폭 = tensor([ 0.0058, -0.0035])      업데이트결과: tensor([2.4204, 4.0197])\nloss = 26.44     업데이트폭 = tensor([ 0.0047, -0.0029])      업데이트결과: tensor([2.4251, 4.0168])\nloss = 26.41     업데이트폭 = tensor([ 0.0038, -0.0023])      업데이트결과: tensor([2.4290, 4.0144])\n\n\n\n🗣️\n\nloss만 보면 점점 감소함, 갈수록 감소하는 폭도 작아지며 26 근처로 수렴\n업데이트 폭도 처음에는 컸다가 감소\n이에 따라 업데이트 결과도 갈수록 잘 안 바뀜"
  },
  {
    "objectID": "posts/02wk-2.html#b.-시각화-yhat의-관점에서",
    "href": "posts/02wk-2.html#b.-시각화-yhat의-관점에서",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "B. 시각화 – yhat의 관점에서!",
    "text": "B. 시각화 – yhat의 관점에서!\n🗣️(\n\nWhat = torch.tensor([[-5.0], [10.0]], requires_grad=True)\n\n\nyhat = X@What\nloss = torch.sum((yhat-y)**2)\nloss.backward()\nWhat.data = What.data - 0.001*What.grad\nWhat.grad = None\n\n\nplt.plot(x,y,'o')\nplt.plot(x, (X@What).data, '--', color=\"C1\") # 선 색깔 주황색 고정\n\n\n\n\n\n\n\n\n\n아래 코드를 반복하며 지켜보면 선이 변화하는 것을 볼 수 있음 (밑의 그래프는 여러번 반복한 최종 결과)\n\n\nyhat = X@What\nloss = torch.sum((yhat-y)**2)\nloss.backward()\nWhat.data = What.data - 0.001*What.grad\nWhat.grad = None\nplt.plot(x,y,'o')\nplt.plot(x, (X@What).data, '--', color=\"C1\")\n\n\n\n\n\n\n\n\n\n한 가지 아쉬운 점: 중간 과정의 그래프가 사라짐\n\n\nWhat = torch.tensor([[-5.0], [10.0]], requires_grad=True)\n\n\nplt.plot(x,y,'o')\nfig = plt.gcf() # 중간 그림을 저장 (호출 가능) get current figure\n\n\n\n\n\n\n\n\n\nax = fig.gca() # get current axes (axes: axis의 복수형, 여기서는 x축,y축 모두를 지칭)\nyhat = X@What\nloss = torch.sum((yhat-y)**2)\nloss.backward()\nWhat.data = What.data - 0.001*What.grad\nWhat.grad = None\nax.plot(x, (X@What).data, '--', color=\"C1\") # plt를 ax로 수정\n\n\nfig # 1번 실행\n\n\n\n\n\n\n\n\n\n1번 더 실행하면 겹쳐짐\n\n\nax = fig.gca() # get current axes (axes: axis의 복수형, 여기서는 x축,y축 모두를 지칭)\nyhat = X@What\nloss = torch.sum((yhat-y)**2)\nloss.backward()\nWhat.data = What.data - 0.001*What.grad\nWhat.grad = None\nax.plot(x, (X@What).data, '--', color=\"C1\") # plt를 ax로 수정\n\n\nfig # 1번 더 실행 (겹쳐짐)\n\n\n\n\n\n\n\n\n\n초기화 후 반복하면 업데이트된 폭을 볼 수 있음 (점점 줄어드는 것 같음)\n\n\nWhat = torch.tensor([[-5.0], [10.0]], requires_grad=True)\n\n\nplt.plot(x,y,'o')\nfig = plt.gcf()\n\n\n\n\n\n\n\n\n\nax = fig.gca()\nyhat = X@What\nloss = torch.sum((yhat-y)**2)\nloss.backward()\nWhat.data = What.data - 0.001*What.grad\nWhat.grad = None\nax.plot(x, (X@What).data, '--', color=\"C1\")\nfig\n\n\n\n\n\n\n\n\n\n제목을 넣을 수도 있음 (set_title, 단순 문자열 아니여도 가능)\n\n\nWhat = torch.tensor([[-5.0], [10.0]], requires_grad=True)\n\nplt.plot(x,y,'o')\nfig = plt.gcf()\n\n\n\n\n\n\n\n\n\nfor epoc in range(20):\n    ax = fig.gca()\n    yhat = X@What\n    loss = torch.sum((yhat-y)**2)\n    loss.backward()\n    What.data = What.data - 0.001*What.grad\n    What.grad = None\n    ax.plot(x, (X@What).data, '--', color=\"C1\")\n    ax.set_title(What.data.reshape(-1))\n    fig\n\n\nfig\n\n\n\n\n\n\n\n\n)🗣️\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nalpha = 0.001\nplt.plot(x,y,'o',label = \"observed\")\nfig = plt.gcf()\nax = fig.gca()\nax.plot(x,X@What.data,'--',color=\"C1\")\nfor epoc in range(30):\n    yhat = X @ What\n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - alpha * What.grad\n    ax.plot(x,X@What.data,'--',color=\"C1\",alpha=0.1)\n    What.grad = None\n\n\n\n\n\n\n\n\n🗣️ alpha: 겹쳐지면 진해짐"
  },
  {
    "objectID": "posts/02wk-2.html#c.-시각화-loss의-관점에서",
    "href": "posts/02wk-2.html#c.-시각화-loss의-관점에서",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "C. 시각화 – loss의 관점에서!!",
    "text": "C. 시각화 – loss의 관점에서!!\n🗣️(\n\ndef plot_loss():\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='3d')\n    w0 = np.arange(-6, 11, 0.5) \n    w1 = np.arange(-6, 11, 0.5)\n    W1,W0 = np.meshgrid(w1,w0)\n    LOSS=W0*0\n    for i in range(len(w0)):\n        for j in range(len(w1)):\n            LOSS[i,j]=torch.sum((y-w0[i]-w1[j]*x)**2)\n    ax.plot_surface(W0, W1, LOSS, rstride=1, cstride=1, color='b',alpha=0.1)\n    ax.azim = 30  ## 3d plot의 view 조절 \n    ax.dist = 8   ## 3d plot의 view 조절 \n    ax.elev = 5   ## 3d plot의 view 조절 \n    ax.set_xlabel(r'$w_0$')  # x축 레이블 설정\n    ax.set_ylabel(r'$w_1$')  # y축 레이블 설정\n    ax.set_xticks([-5,0,5,10])  # x축 틱 간격 설정\n    ax.set_yticks([-5,0,5,10])  # y축 틱 간격 설정\n    plt.close(fig)  # 자동 출력 방지\n    return fig\n\n\nfig = plot_loss()\nfig # loss_fn(w0hat, w1hat)을 z에 찍음\n\n\n\n\n\n\n\n\n\n# 손실 8587.6875 를 계산하는 또 다른 방식\ndef l(w0hat,w1hat):\n    yhat = w0hat + w1hat*x\n    return torch.sum((y-yhat)**2)\n\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nWhat\n\ntensor([[-5.],\n        [10.]], requires_grad=True)\n\n\n\nl(-5,10) # 손실 계산\n\ntensor(8587.6875)\n\n\n\ntorch.sum((y-X@What)**2) # 다른 방법\n\ntensor(8587.6875, grad_fn=&lt;SumBackward0&gt;)\n\n\n\nyhat = -5 + 10*x\ntorch.sum((y-yhat)**2) # 다른 방법 2\n\ntensor(8587.6875)\n\n\n\nfig\nax = fig.gca()\nax.scatter(-5, 10, l(-5,10)) # 점 찍기\n\n&lt;mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7fc9261c2bb0&gt;\n\n\n\nfig\n\n\n\n\n\n\n\n\n\nfig\nax = fig.gca()\nax.scatter(-1, 3, l(-1,3)) # 다른 점 찍기\n\n&lt;mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7fc925df1eb0&gt;\n\n\n\nfig\n\n\n\n\n\n\n\n\n\n위 과정을 반복하면 곡면을 그릴 수 있음\n밑은 True 값 찍기\n\n\nfig\nax = fig.gca()\nax.scatter(2.5, 4.0, l(2.5,4.0)) # True 값\n\n&lt;mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7fc925f14670&gt;\n\n\n\nfig\n\n\n\n\n\n\n\n\n\n밑에 정리된 코드 과정\n\n\nfig = plot_loss()\nfig # loss_fn(w0hat,w1hat)\nax = fig.gca()\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nw0hat, w1hat = What.data.reshape(-1) # 언패킹\nax.scatter(w0hat, w1hat, l(w0hat, w1hat)) # x, y, z\nfig # 최초의 직선에 대응하는 What 값\n\n\n\n\n\n\n\n\n\nyhat = X@What\nloss = torch.sum((y-yhat)**2)\nloss.backward()\nWhat.data = What.data - 0.001*What.grad\nWhat.grad = None\nw0hat, w1hat = What.data.reshape(-1)\nax.scatter(w0hat, w1hat, l(w0hat, w1hat))\nfig # 반복 실행할수록 update됨\n\n\n\n\n\n\n\n\n\nyhat = X@What\nloss = torch.sum((y-yhat)**2)\nloss.backward()\nWhat.data = What.data - 0.001*What.grad\nWhat.grad = None\nw0hat, w1hat = What.data.reshape(-1)\nax.scatter(w0hat, w1hat, l(w0hat, w1hat), color=\"C1\") # 앞으로는 주황색으로 색깔 고정\nfig # 반복 실행할수록 점점 최소가 되는 쪽으로 진행됨\n\n\n\n\n\n\n\n\n)🗣️\n\ndef plot_loss():\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='3d')\n    w0 = np.arange(-6, 11, 0.5) \n    w1 = np.arange(-6, 11, 0.5)\n    W1,W0 = np.meshgrid(w1,w0)\n    LOSS=W0*0\n    for i in range(len(w0)):\n        for j in range(len(w1)):\n            LOSS[i,j]=torch.sum((y-w0[i]-w1[j]*x)**2)\n    ax.plot_surface(W0, W1, LOSS, rstride=1, cstride=1, color='b',alpha=0.1)\n    ax.azim = 30  ## 3d plot의 view 조절 \n    ax.dist = 8   ## 3d plot의 view 조절 \n    ax.elev = 5   ## 3d plot의 view 조절 \n    ax.set_xlabel(r'$w_0$')  # x축 레이블 설정\n    ax.set_ylabel(r'$w_1$')  # y축 레이블 설정\n    ax.set_xticks([-5,0,5,10])  # x축 틱 간격 설정\n    ax.set_yticks([-5,0,5,10])  # y축 틱 간격 설정\n    plt.close(fig)  # 자동 출력 방지\n    return fig\n\n\n# 손실 8587.6875 를 계산하는 또 다른 방식\ndef l(w0hat,w1hat):\n    yhat = w0hat + w1hat*x\n    return torch.sum((y-yhat)**2)\n\n\nfig = plot_loss()\nax = fig.gca()\nax.scatter(2.5, 4, l(2.5,4), s=200, marker='*', color='red', label=r\"${\\bf W}=[2.5, 4]'$\")\nax.scatter(-5, 10, l(-5,10), s=200, marker='*', color='blue', label=r\"initial $\\hat{\\bf W}=[-5, 10]'$\")\nax.legend()\nfig\n\n\n\n\n\n\n\n\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nalpha = 0.001\nfor epoc in range(30):\n    yhat = X @ What\n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - 0.001 * What.grad\n    w0,w1 = What.data.reshape(-1) \n    ax.scatter(w0,w1,l(w0,w1),s=5,marker='o',color='blue')\n    What.grad = None\n\n\nfig\n\n\n\n\n\n\n\n\n\n🗣️\n\nB의 시각화에서 최초의 직선에 대응하는 점이 파란색 점\n점들이 빨간색 점으로 이동하는 과정은 직선이 올라가는 과정에 대응"
  },
  {
    "objectID": "posts/02wk-2.html#d.-애니메이션",
    "href": "posts/02wk-2.html#d.-애니메이션",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "D. 애니메이션",
    "text": "D. 애니메이션\n\nfrom matplotlib import animation\n\n\nplt.rcParams['figure.figsize'] = (7.5,2.5)\nplt.rcParams[\"animation.html\"] = \"jshtml\" \n\n\ndef show_animation(alpha=0.001):\n    ## 1. 히스토리 기록을 위한 list 초기화\n    loss_history = [] \n    yhat_history = [] \n    What_history = [] \n\n    ## 2. 학습 + 학습과정기록\n    What= torch.tensor([[-5.0],[10.0]],requires_grad=True)\n    What_history.append(What.data.tolist())\n    for epoc in range(30): \n        yhat=X@What ; yhat_history.append(yhat.data.tolist())\n        loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n        loss.backward() \n        What.data = What.data - alpha * What.grad; What_history.append(What.data.tolist())\n        What.grad = None    \n\n    ## 3. 시각화 \n    fig = plt.figure()\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n\n    #### ax1: yhat의 관점에서.. \n    ax1.plot(x,y,'o',label=r\"$(x_i,y_i)$\")\n    line, = ax1.plot(x,yhat_history[0],label=r\"$(x_i,\\hat{y}_i)$\") \n    ax1.legend()\n    #### ax2: loss의 관점에서.. \n    w0 = np.arange(-6, 11, 0.5) \n    w1 = np.arange(-6, 11, 0.5)\n    W1,W0 = np.meshgrid(w1,w0)\n    LOSS=W0*0\n    for i in range(len(w0)):\n        for j in range(len(w1)):\n            LOSS[i,j]=torch.sum((y-w0[i]-w1[j]*x)**2)\n    ax2.plot_surface(W0, W1, LOSS, rstride=1, cstride=1, color='b',alpha=0.1)\n    ax2.azim = 30  ## 3d plot의 view 조절 \n    ax2.dist = 8   ## 3d plot의 view 조절 \n    ax2.elev = 5   ## 3d plot의 view 조절 \n    ax2.set_xlabel(r'$w_0$')  # x축 레이블 설정\n    ax2.set_ylabel(r'$w_1$')  # y축 레이블 설정\n    ax2.set_xticks([-5,0,5,10])  # x축 틱 간격 설정\n    ax2.set_yticks([-5,0,5,10])  # y축 틱 간격 설정\n    ax2.scatter(2.5, 4, l(2.5,4), s=200, marker='*', color='red', label=r\"${\\bf W}=[2.5, 4]'$\")\n    ax2.scatter(-5, 10, l(-5,10), s=200, marker='*', color='blue')\n    ax2.legend()\n    def animate(epoc):\n        line.set_ydata(yhat_history[epoc])\n        ax2.scatter(np.array(What_history)[epoc,0],np.array(What_history)[epoc,1],loss_history[epoc],color='grey')\n        fig.suptitle(f\"alpha = {alpha} / epoch = {epoc}\")\n        return line\n\n    ani = animation.FuncAnimation(fig, animate, frames=30)\n    plt.close()\n    return ani\n\n\n🗣️ alpha:\n\n학습률: update되는 폭 (ML 관점)\nstep size: 오른쪽 그림 함수 관점 (산업 공학 관점)\n\n\n\nani = show_animation(alpha=0.001)\nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/02wk-2.html#e.-학습률에-따른-시각화",
    "href": "posts/02wk-2.html#e.-학습률에-따른-시각화",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "E. 학습률에 따른 시각화",
    "text": "E. 학습률에 따른 시각화\n- \\(\\alpha\\)가 너무 작다면 비효율적임\n\nshow_animation(alpha=0.0001)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n🗣️ 0.001 -&gt; 0.0001\n\n아까보다 가는 둥 마는 둥 함\n\n\n- \\(\\alpha\\)가 크다고 무조건 좋은건 또 아님\n\nshow_animation(alpha=0.0083)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n🗣️ 0.001 -&gt; 0.0083 (직접 찾은 숫자)\n\n처음부터 최소점을 지나버림 (직선이 점들 위로 바로 올라감) -&gt; 바람직하지 않음\n이후 직선이 다시 점들 아래로 내려옴\n왔다갔다하면서 내려오는 것 같기는 하나 효율적인 느낌은 아님\n\n\n- 수틀리면 수렴안할수도??\n\nshow_animation(alpha=0.0085)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n🗣️ 0.001 -&gt; 0.0085\n\n직전의 0.0083과 얼마 차이가 나지도 않는데\n이번에는 왔다갔다하면서 수렴하지도 않음\n오히려 갈수록 포물선 모양으로 점점 올라감\n\n\n- 그냥 망할수도??\n\nshow_animation(alpha=0.01)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n🗣️ 0.001 -&gt; 0.01\n\n기울기가 무한대가 됨\n교훈: alpha를 잘 선택해야 수렴함\n\n\n\n\nplt.rcdefaults()\nplt.rcParams['figure.figsize'] = 4.5,3.0"
  },
  {
    "objectID": "posts/02wk-2.html#a.-기본패턴",
    "href": "posts/02wk-2.html#a.-기본패턴",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "A. 기본패턴",
    "text": "A. 기본패턴\n🗣️ SSE 말고 MSE로\n\n## -- 외우세요!!! -- ##\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = X@What \n    # step2: loss\n    loss = torch.sum((y-yhat)**2)/100\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    What.data = What.data - 0.1 * What.grad\n    What.grad = None\n\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What.data,'--')\nplt.title(f'What={What.data.reshape(-1)}');"
  },
  {
    "objectID": "posts/02wk-2.html#b.-step2의-수정-loss_fn-이용",
    "href": "posts/02wk-2.html#b.-step2의-수정-loss_fn-이용",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "B. Step2의 수정 – loss_fn 이용",
    "text": "B. Step2의 수정 – loss_fn 이용\n🗣️(\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\n\n\nyhat=X@What\n\n\ntorch.sum((y-yhat)**2)/100 # MSE\n\ntensor(85.8769, grad_fn=&lt;DivBackward0&gt;)\n\n\n\ntorch.mean((y-yhat)**2) # MSE\n\ntensor(85.8769, grad_fn=&lt;MeanBackward0&gt;)\n\n\n\ndef loss_fn(yhat, y):\n    return torch.mean((y-yhat)**2)\n\n\nloss_fn(yhat,y)\n\ntensor(85.8769, grad_fn=&lt;MeanBackward0&gt;)\n\n\n\nloss_fn 원리를 잘 모른다면 pytorch 함수 이용\n\n\nloss_fn = torch.nn.MSELoss()\nloss_fn(yhat,y) # 결과는 동일\n\ntensor(85.8769, grad_fn=&lt;MseLossBackward0&gt;)\n\n\n\n틀린 설명\n\ntorch.nn.MSELoss는 함수인데, “None -&gt; MSE를 계산해주는 함수”인 함수\n\n맞는 설명\n\ntorch.nn.MSELoss는 callable object를 생성하는 클래스\n\n\n)🗣️\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\nloss_fn = torch.nn.MSELoss()\nfor epoc in range(30):\n    # step1: yhat \n    yhat = X@What \n    # step2: loss\n    #loss = torch.sum((y-yhat)**2)/100\n    loss = loss_fn(yhat,y) # 여기서는 큰 상관없지만 습관적으로 yhat을 먼저넣는 연습을 하자!!\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    What.data = What.data - 0.1 * What.grad\n    What.grad = None\n\n🗣️ loss_fn은 무조건 yhat 먼저\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What.data,'--')\nplt.title(f'What={What.data.reshape(-1)}');"
  },
  {
    "objectID": "posts/02wk-2.html#c.-step1의-수정-net-이용",
    "href": "posts/02wk-2.html#c.-step1의-수정-net-이용",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "C. Step1의 수정 – net 이용",
    "text": "C. Step1의 수정 – net 이용\n🗣️ yhat = X@What도 알고 싶지 않다면 (네트워크 이용)\n# net – net 오브젝트란?\n원래 yhat을 이런식으로 구했는데 ~\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\nyhat= X@What\nyhat[:5]\n\ntensor([[-29.8211],\n        [-28.6215],\n        [-24.9730],\n        [-21.2394],\n        [-19.7919]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n아래와 같은 방식으로 코드를 짜고 싶음..\nyhat = net(X) # \n🗣️ X를 입력으로 받아 yhat을 출력하고 싶음\n위와 같은 코드를 가능하게 하는 net은 torch에서 지원하고 아래와 같이 사용할 수 있음.\n🗣️(\n\n# torch.nn.Linear?\n\nnet = torch.nn.Linear(\n    in_features= ??,\n    out_features= ??,\n    bias= False # default는 True\n)\n\nin_features: 입력(X)에 대한 차원 (features를 dimension으로 생각)\n\n\nX.shape # 100은 관측값 개수에 따라 바뀔 수 있고, 2는 모형이 정해지면 안 바뀜\n\ntorch.Size([100, 2])\n\n\n\nout_features: 출력(y)에 대한 차원\n\n\ny.shape # 마찬가지로 1\n\ntorch.Size([100, 1])\n\n\n\nnet = torch.nn.Linear(\n    in_features= 2,\n    out_features= 1,\n    bias= False\n)\n\n\nyhat = net(X)\nyhat[:5]\n\ntensor([[-0.1600],\n        [-0.1362],\n        [-0.0639],\n        [ 0.0101],\n        [ 0.0388]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\n원래 구한 yhat과 비교하면 What을 설정하지 않았으므로 당연히 다름\n\n\nnet.weight # What과 같다고 생각하면 됨\n\nParameter containing:\ntensor([[0.3320, 0.1982]], requires_grad=True)\n\n\n\n엄밀히 말하면 net.weight는 2x1 matrix가 아니라 1x2 martix\n\n컴퓨터 공학적 이유로 이렇게 되어 있음 (column vector보다 row vector 연산이 쉽다고 함)\n\n\n\nnet.weight.T # 이게 진짜 What과 동일\n\ntensor([[0.3320],\n        [0.1982]], grad_fn=&lt;PermuteBackward0&gt;)\n\n\n\nnet.weight.data = torch.tensor([[-5.0],[10.0]]).T\nnet.weight.data\n\ntensor([[-5., 10.]])\n\n\n\nyhat= net(X)\nyhat[:5]\n\ntensor([[-29.8211],\n        [-28.6215],\n        [-24.9730],\n        [-21.2394],\n        [-19.7919]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\n원래 구한 yhat과 동일\n\n)🗣️\n\n# yhat = net(X) \nnet = torch.nn.Linear(\n    in_features=2, # X:(n,2) --&gt; 2 \n    out_features=1, # yhat:(n,1) --&gt; 1 \n    bias=False \n)\n\n\nnet.weight.data = torch.tensor([[-5.0], [10.0]]).T # .T 를 해야함. 외우세요 \nnet.weight\n\nParameter containing:\ntensor([[-5., 10.]], requires_grad=True)\n\n\n\nnet(X)[:5]\n\ntensor([[-29.8211],\n        [-28.6215],\n        [-24.9730],\n        [-21.2394],\n        [-19.7919]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\n(X@What)[:5]\n\ntensor([[-29.8211],\n        [-28.6215],\n        [-24.9730],\n        [-21.2394],\n        [-19.7919]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\n(X@net.weight.T)[:5]\n\ntensor([[-29.8211],\n        [-28.6215],\n        [-24.9730],\n        [-21.2394],\n        [-19.7919]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n#\n- 수정된코드\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\nfor epoc in range(30):\n    # step1: yhat\n    # yhat = X@What \n    yhat = net(X)\n    # step2: loss\n    loss = loss_fn(yhat,y)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    net.weight.data = net.weight.data - 0.1 * net.weight.grad\n    net.weight.grad = None\n\n🗣️ What.data -&gt; net.weight.data, What.grad -&gt; net.weight.grad\n\nplt.plot(x,y,'o')\nplt.plot(x,net(X).data,'--')\nplt.title(f'net.weight={net.weight.data.reshape(-1)}');"
  },
  {
    "objectID": "posts/02wk-2.html#d.-step4의-수정-optimizer의-이용",
    "href": "posts/02wk-2.html#d.-step4의-수정-optimizer의-이용",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "D. Step4의 수정 – optimizer의 이용",
    "text": "D. Step4의 수정 – optimizer의 이용\n- 소망: 아래의 과정을 좀 더 편하게 했으면..\nnet.weight.data = net.weight.data - 0.1 * net.weight.grad\nnet.weight.data = None \n# optimizer – 이걸 이용하면 update 과정을 손쉽게 할 수 있음\n기존코드\n\n## -- 준비과정 -- ## \n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n\n\n## -- 1에폭진행 -- ## \n# step1: \nyhat = net(X)\n# step2: loss\nloss = loss_fn(yhat,y)\n# step3: 미분\nloss.backward()\n# step4: update\nprint(net.weight.data)\nnet.weight.data = net.weight.data - 0.1 * net.weight.grad\nprint(net.weight.data)\nnet.weight.grad = None\n\ntensor([[-5., 10.]])\ntensor([[-3.6577,  8.8111]])\n\n\n\n## -- 2에폭진행 -- ## \n# step1: 2에폭진행\nyhat = net(X)\n# step2: loss\nloss = loss_fn(yhat,y)\n# step3: 미분\nloss.backward()\n# step4: update\nprint(net.weight.data)\nnet.weight.data = net.weight.data - 0.1 * net.weight.grad\nprint(net.weight.data)\nnet.weight.grad = None\n\ntensor([[-3.6577,  8.8111]])\ntensor([[-2.5548,  7.8612]])\n\n\n새로운코드 – optimizer 이용\n🗣️(\n\ntorch.optim.SGD : optimizer를 만들어줌\ntorch.optim.SGD는 net.weight를 갖고 있어야 함(What)\n\nnet.weight는 net.parameters()로 볼 수 있음\nnet.parameters()는 generator: iterable object -&gt; list화 가능\n\ntorch.optim.SGD는 학습률 lr도 갖고 있어야 함\n\n\nnet.weight\n\nParameter containing:\ntensor([[-2.5548,  7.8612]], requires_grad=True)\n\n\n\nnet.parameters()\n\n&lt;generator object Module.parameters at 0x7fc922ade820&gt;\n\n\n\nlist(net.parameters()) # 값을 보려면\n\n[Parameter containing:\n tensor([[-2.5548,  7.8612]], requires_grad=True)]\n\n\n\n# optimizr = torch.optim.SGD(net.parameters(), lr=0.1) # net.parameters(): generator\n\n\nnet.weight.data = net.weight.data - 0.1 * net.weight.grad\n\n=&gt; optimizr.step()\n\nnet.weight.grad = None\n\n=&gt; optimizr.zero_grad()\n\n\n)🗣️\n\n## -- 준비과정 -- ## \n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n# step4를 위한 사전준비\noptimizr = torch.optim.SGD(net.parameters(),lr=0.1)\n\n\n## -- 1에폭진행 -- ## \nyhat = net(X)\n# step2: loss\nloss = loss_fn(yhat,y)\n# step3: 미분\nloss.backward()\n# step4: update\nprint(net.weight.data)\n#net.weight.data = net.weight.data - 0.1 * net.weight.grad\noptimizr.step()\nprint(net.weight.data)\n#net.weight.grad = None\noptimizr.zero_grad()\n\ntensor([[-5., 10.]])\ntensor([[-3.6577,  8.8111]])\n\n\n\n## -- 2에폭진행 -- ## \nyhat = net(X)\n# step2: loss\nloss = loss_fn(yhat,y)\n# step3: 미분\nloss.backward()\n# step4: update\nprint(net.weight.data)\n#net.weight.data = net.weight.data - 0.1 * net.weight.grad\noptimizr.step()\nprint(net.weight.data)\n#net.weight.grad = None\noptimizr.zero_grad()\n\ntensor([[-3.6577,  8.8111]])\ntensor([[-2.5548,  7.8612]])\n\n\n#\n- 수정된코드\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n# step4를 위한 사전준비 \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = net(X)\n    # step2: loss\n    loss = loss_fn(yhat,y)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.data,'--')\nplt.title(f'net.weight={net.weight.data.reshape(-1)}');"
  },
  {
    "objectID": "posts/14wk-2.html",
    "href": "posts/14wk-2.html",
    "title": "14wk-2: (강화학습) – 4x4 Grid World q_table, Appedix B",
    "section": "",
    "text": "📘 Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\n📝 🗣️ ✍️ 🔬 ❓"
  },
  {
    "objectID": "posts/14wk-2.html#a.-미래보상",
    "href": "posts/14wk-2.html#a.-미래보상",
    "title": "14wk-2: (강화학습) – 4x4 Grid World q_table, Appedix B",
    "section": "A. 미래보상",
    "text": "A. 미래보상\n\n🗣️\n\n밴딧 게임은 미래보상이 없음 (다음 State가 없음)\n\n\n- 언뜻생각하면 4x4 문제에서 q_table은 아래와 같이 생각하는게 합리적인듯 보인다.\n\nq[s1,s2,a] = 상태 (s1,s2)에서 행동 a를 했을 경우 얻게되는 보상의 평균\n\\(q(s,a) = r(s,a) = \\mathbb{E}[\\text{Reward} | \\text{State}=s, \\text{Action}=a]\\)\n\n그렇지만 아래와 같이 생각하는게 더 합리적이다.\n\nq[s1,s2,a] = 상태 (s1,s2)에서 행동 a를 했을 경우 얻게되는 보상의 평균 + 미래에 얻게되리라 기대하는 보상\n\\(q(s,a) = r(s,a) + r_{\\text{future}}\\)\n\n\n단, 여기에서 미래에 얻게되리라 기대하는 보상은 최선의 선택을 한다는 전제하에 계산\n\n- 미래에 얻게되리라 기대하는 보상은 어떻게 정의할 수 있을까?\n\n# 예제1 – 상태 (2,2) 에서 “action=down” 을 했을때\n\n즉시 얻게되는 보상과\n미래에 얻게되리라 기대하는 보상\n\n은 무엇인가? 이것을 바탕으로 \\(s=(2,1)\\), \\(a=\\text{down}\\) 의 품질(Quality)는 어떻게 평가할 수 있는가?\n(풀이?)\n즉시 얻을 수 있다고 생각되는 보상은-1 이고 미래에 얻으리라 기대되는 보상은 100 점이다. 따라서 99점으로 평가하는게 합리적인듯하다. 수식으로 쓰면\n\\[q(s,a)=q(s_1,s_2,a)=q(2,2, \\text{down}) = -1 + 100 = r(2,2,\\text{down}) + \\max_{a'}q(3,2,a')\\]\n와 같이 쓸 수 있겠다.\n\n🗣️\n\n\\(\\max_{a'}q(3,2,a')\\)= (3,2)에서 할 수 있는 모든 액션들을 고려하였을 때 받게 되는 최대 품질\n\\(a'\\) = 0,1,2,3 = 왼쪽,오른쪽,아래,위\n\nq(3,2,왼)=?? &lt; 100\nq(3,2,오)=100\nq(3,2,아)=-10\nq(3,2,위)=?? &lt; 100\n\n\n\n#\n# 예제2 – 상태 (1,2) 에서 “action=down” 을 했을때\n\n즉시 얻게되는 보상과\n미래에 얻게되리라 기대하는 보상\n\n은 무엇인가? 이것을 바탕으로 \\(s=(1,2)\\), \\(a=\\text{down}\\) 의 품질(Quality)는 어떻게 평가할 수 있는가?\n(풀이?)\n즉시 얻을 수 있다고 생각되는 보상은-1 이고 미래에 얻으리라 기대되는 보상은 99점이다. 따라서 98점으로 평가하는게 합리적인듯하다. 수식으로 쓰면\n\\[q(s,a)=q(s_1,s_2,a)=q(1,2, \\text{down}) = -1 + 99 = r(1,2,\\text{down}) + \\max_{a'}q(2,2,a')\\]\n와 같이 쓸 수 있겠다.\n\n🗣️\n\n\\(\\max_{a'}q(2,2,a')\\)= (2,2)에서 할 수 있는 모든 액션들을 고려하였을 때 받게 되는 최대 품질\n\nq(3,2,up)=?? &lt; 99\nq(3,2,down)=99\nq(3,2,right)=99\nq(3,2,left)=?? &lt; 99\n\n\n\n#\n# 예제3 – 상태 (0,1) 에서 “action=right” 을 했을때\n\n즉시 얻게되는 보상과\n미래에 얻게되리라 기대하는 보상\n\n은 무엇인가? 이것을 바탕으로 \\(s=(0,1)\\), \\(a=\\text{right}\\) 의 품질(Quality)는 어떻게 평가할 수 있는가?\n(풀이?)\n앞의 예제들을 일반화하면 아래와 같은 수식을 쓸 수 있다.\n\\[q(0,1, \\text{right}) = r(0,1,\\text{right}) + \\max_{a'}q(0,2,a')\\]\n따라서 만약에 \\(\\max_{a}q(0,2,a)\\)의 값을 알고 있다면 이를 구할 수 있다.\n#\n- (아직 부족한) 깨달음: 모든 \\((s,a)\\)에 대하여 \\(q(s,a)\\)의 값은 아래와 같이 정의할 수 있겠다.\n\\[q(s,a) = r(s,a) + \\max_{a'}q(s',a')\\]"
  },
  {
    "objectID": "posts/14wk-2.html#b.-감가율",
    "href": "posts/14wk-2.html#b.-감가율",
    "title": "14wk-2: (강화학습) – 4x4 Grid World q_table, Appedix B",
    "section": "B. 감가율",
    "text": "B. 감가율\n# 예제1 – 당신은 지금 아무것도 쓰여 있지 않은 빈 종이 한 장을 가지고 있습니다. 이 종이에 쓸 수 있는 숫자는 오직 두 가지, 0 또는 1입니다. 어떤 숫자를 쓰느냐에 따라 보상이 달라지는데, 수많은 실험을 통해 0을 쓰면 아무 보상도 없고, 1을 쓰면 10만 원을 받을 수 있다는 사실이 확인되었습니다. 이 사실이 확인된 이후 이 빈 종이의 가치는 얼마일까요?\n(1) 0원이다.\n(2) 10만원이다.\n(3) 5만원이다.\n(4) 모르겠다.\n#\n# 예제2 – 당신 앞에는 빨간색 종이 한 장이 있습니다. 이 종이에는 0 또는 1 중 하나의 숫자를 쓸 수 있습니다. 만약 1을 쓰면 다음 단계인 주황색 종이 한 장을 받게 됩니다. 주황색 종이에도 똑같이 0 또는 1을 쓸 수 있고, 여기에 1을 쓰면 노란색 종이, 그다음은 초록색 종이, 그 다음은 파란색 종이, 그 다음은 남색 종이, 마지막으로는 보라색 종이를 순서대로 받습니다. 총 7단계(빨강 → 주황 → 노랑 → 초록 → 파랑 → 남색 → 보라색)를 거친 후, 보라색 종이에 1을 쓰면 비로소 10만 원의 현금 보상을 받을 수 있습니다. 단, 어느 단계에서든 0을 쓰면 아무 일도 일어나지 않고 그 즉시 게임이 종료됩니다. 즉, 그 이후로는 종이도 받을 수 없고 보상도 없습니다. 이 사실이 알려진 이후, 지금 당신이 들고 있는 ’빨간색 종이’의 가치는 얼마일까요?\n(1) 0원이다.\n(2) 10만 원이다.\n(3) \\(\\frac{1}{2^6}\\) x 10만원이다.\n(4) 모르겠다.\n🗣️(\n\n둘 다 답 (4)\n\n10만원을 받아도 굳이 숫자를 써야하는 종이를 10만원을 똑같이 주고 살 이유는 없음\n아무리 미래 보상이 확실해도 지금 당장 받는 것보다는 가격이 떨어짐\n\n예제 2에서 빨간색 종이와 보라색 종이를 선택하라고 하면 전부 보라색 종이를 선택함\n\n거래 당사자 간의 합의된 감가율에 따라 달라짐\n\n\n\n0.99 # 보라색 종이의 가치를 0.99라고 한다면\n\n0.99\n\n\n\n0.99**2 # 남색 종이의 가치\n\n0.9801\n\n\n)🗣️\n#\n- 직관: 아무리 보장된 보상이라고 해도, 미래에 주어지는 보상은 현재의 보상과 동급취급할 수 없다.\n- 진짜 깨달음: 모든 \\((s,a)\\)에 대하여 \\(q(s,a)\\)의 값은 아래와 같이 정의하는게 합리적이다.\n\\[q(s,a) = r(s,a) + \\gamma \\max_{a'}q(s',a')\\]\n여기에서 \\(\\gamma\\)는 0과 1사이의 값이며 감가율(discout factor)이라 부른다.\n\n🗣️\n\n즉시 받게 되는 보상 + 감가율 * 미래에 받게 되는 보상"
  },
  {
    "objectID": "posts/14wk-2.html#c.-q_table-update",
    "href": "posts/14wk-2.html#c.-q_table-update",
    "title": "14wk-2: (강화학습) – 4x4 Grid World q_table, Appedix B",
    "section": "C. q_table update",
    "text": "C. q_table update\n- 지난시간코드\n\nclass GridWorld:\n    def __init__(self):\n        self.a2d = {\n            0: np.array([0,1]), # →\n            1: np.array([0,-1]), # ←  \n            2: np.array([1,0]),  # ↓\n            3: np.array([-1,0])  # ↑\n        }\n        self.state_space = gym.spaces.MultiDiscrete([4,4])\n        self.state = np.array([0,0])\n        self.reward = None\n        self.terminated = False\n    def step(self,action):\n        self.state = self.state + self.a2d[action]\n        s1,s2 = self.state\n        if (s1==3) and (s2==3):\n            self.reward = 100 \n            self.terminated = True\n        elif self.state in self.state_space:\n            self.reward = -1 \n            self.terminated = False\n        else:\n            self.reward = -10\n            self.terminated = True\n        # print(\n        #     f\"action = {action}\\t\"\n        #     f\"state = {self.state - self.a2d[action]} -&gt; {self.state}\\t\"\n        #     f\"reward = {self.reward}\\t\"\n        #     f\"termiated = {self.terminated}\"\n        # )            \n        return self.state, self.reward, self.terminated\n    def reset(self):\n        self.state = np.array([0,0])\n        self.terminated = False\n        return self.state\nclass RandomAgent:\n    def __init__(self):\n        self.state = np.array([0,0]) \n        self.action = None \n        self.reward = None \n        self.next_state = None\n        self.terminated = None\n        #---#\n        self.states = collections.deque(maxlen=500000)\n        self.actions = collections.deque(maxlen=500000)\n        self.rewards = collections.deque(maxlen=500000)\n        self.next_states = collections.deque(maxlen=500000)\n        self.terminations = collections.deque(maxlen=500000)\n        #---#\n        self.action_space = gym.spaces.Discrete(4)\n        self.n_experience = 0\n    def act(self):\n        self.action = self.action_space.sample()\n    def save_experience(self):\n        self.states.append(self.state)\n        self.actions.append(self.action)\n        self.rewards.append(self.reward)\n        self.next_states.append(self.next_state)\n        self.terminations.append(self.terminated)\n        self.n_experience = self.n_experience + 1\n    def learn(self):\n        pass\n\n\nplayer = RandomAgent()\nenv = GridWorld()\nscores = [] \nscore = 0 \n#\nfor e in range(1,100000):\n    #---에피소드시작---#\n    while True:\n        # step1 -- 액션선택\n        player.act()\n        # step2 -- 환경반응 \n        player.next_state, player.reward, player.terminated = env.step(player.action)\n        # step3 -- 경험기록 & 학습 \n        player.save_experience()\n        player.learn()\n        # step4 --종료 조건 체크 & 후속 처리\n        if env.terminated:\n            score = score + player.reward\n            scores.append(score)\n            score = 0 \n            player.state = env.reset() \n            break\n        else: \n            score = score + player.reward         \n            player.state = player.next_state\n\n\n\n\n\n\n\nImportant\n\n\n\n강의노트 수정 2025-06-12\n노규호학생의 도움으로 예전강의의 오류를 발견하여 수정하였습니다.\n# 수정전\n...\n        if env.terminated:\n            ...\n        else: \n            score = score + player.reward\n            scores.append(score)            \n            player.state = player.next_state\n            \n# 수정후\n        if env.terminated:\n            ...\n        else: \n            score = score + player.reward\n#            scores.append(score)            ### &lt;--- 여기를 주석처리해야함!! \n            player.state = player.next_state\n\n\n- 상황: player가 경험은 있는데, q_table을 만들줄 모름 (데이터는 있음, 학습이 안된상태)\n\nplayer.n_experience\n\n326783\n\n\n- 저번시간에 배운 q_table\n\nq_table = np.zeros((4,4,4))\nmemory = zip(player.states, player.actions, player.rewards)\nfor (s1,s2), a, r in memory:\n    qhat = q_table[s1,s2,a] # 내가 생각했던갓\n    q = r # 실제값\n    diff = q-qhat # 차이\n    q_table[s1,s2,a] = q_table[s1,s2,a]  + 0.01*diff# update\n\n\nfor a in [0,1,2,3]: \n    print(f\"action = {a}\")\n    print(f\"q[...,{a}] = {q_table[...,a].round(3)}\")\n    print(\"---\")\n\naction = 0\nq[...,0] = [[ -1.     -1.     -1.    -10.   ]\n [ -1.     -1.     -1.    -10.   ]\n [ -1.     -1.     -1.     -9.999]\n [ -1.     -1.     99.991   0.   ]]\n---\naction = 1\nq[...,1] = [[-10.  -1.  -1.  -1.]\n [-10.  -1.  -1.  -1.]\n [-10.  -1.  -1.  -1.]\n [-10.  -1.  -1.   0.]]\n---\naction = 2\nq[...,2] = [[ -1.     -1.     -1.     -1.   ]\n [ -1.     -1.     -1.     -1.   ]\n [ -1.     -1.     -1.     99.993]\n [-10.    -10.     -9.999   0.   ]]\n---\naction = 3\nq[...,3] = [[-10. -10. -10. -10.]\n [ -1.  -1.  -1.  -1.]\n [ -1.  -1.  -1.  -1.]\n [ -1.  -1.  -1.   0.]]\n---\n\n\n\n🗣️\n\naction 0: 오른쪽\naction 1: 왼쪽\naction 2: 아래\naction 3: 위\n\n\n- 이번시간에 배운 q_table: 아래를 이용한다.\n\\[q(s,a) = r(s,a) + \\gamma \\max_{a'}q(s',a')\\]\n\n\n\n\n\n\nNote\n\n\n\n사실 좀 더 실용적으로는(=코딩친화적으로는) 아래의 수식을 쓰는게 좋다.\n\\[q(s,a) = \\begin{cases} r(s,a) & \\text{if terminated} \\\\ r(s,a) + \\gamma \\max_{a'}q(s',a') & \\text{else} \\end{cases}\\]\n\n\n🗣️(\nq_table = np.zeros((4,4,4))\nmemory = zip(player.states, player.actions, player.rewards)\nfor (s1,s2), a, r in memory:\n    qhat = q_table[s1,s2,a] # 내가 생각했던 값\n    if tmd:\n        q = r # 실제값\n    else:\n        future = q_table[ss1,ss2,:].max() # ss1,ss2 : 다음 상태\n        q = r + 0.95*future\n    diff = q-qhat # 차이\n    q_table[s1,s2,a] = q_table[s1,s2,a]  + 0.01*diff# update\n\n정의 되어 있지 않은 내용을 쓰면\n\n\n# player.next_states # 다음 상태가 저장되어 있음\n\n\n# player.terminations # True, False가 저장되어 있음\n\n\nq_table = np.zeros((4,4,4))\nmemory = zip(player.states, player.actions, player.rewards, player.next_states, player.terminations)\nfor (s1,s2), a, r, (ss1,ss2), tmd in memory:\n    qhat = q_table[s1,s2,a] # 내가 생각했던 값\n    if tmd:\n        q = r # 실제값\n    else:\n        future = q_table[ss1,ss2,:].max() # ss1,ss2 : 다음 상태\n        q = r + 0.95*future\n    diff = q-qhat # 차이\n    q_table[s1,s2,a] = q_table[s1,s2,a]  + 0.01*diff# update\n\n\nq_table[...,0] # action 0 을 했을 때 테이블\n\narray([[72.83952058, 77.72350932, 82.80344973, -9.99996536],\n       [77.72636791, 82.87118608, 88.27814712, -9.99999613],\n       [82.86957406, 88.28769271, 93.99071303, -9.9993985 ],\n       [88.24270099, 93.97700808, 99.99082608,  0.        ]])\n\n\n\n감가율을 5%가 아니라 1%만 깎으면 값이 조금 더 커짐 (미래에 대한 보상을 조금 더 높게 치므로)\n\n\nq_table = np.zeros((4,4,4))\nmemory = zip(player.states, player.actions, player.rewards, player.next_states, player.terminations)\nfor (s1,s2), a, r, (ss1,ss2), tmd in memory:\n    qhat = q_table[s1,s2,a] # 내가 생각했던 값\n    if tmd:\n        q = r # 실제값\n    else:\n        future = q_table[ss1,ss2,:].max() # ss1,ss2 : 다음 상태\n        q = r + 0.99*future\n    diff = q-qhat # 차이\n    q_table[s1,s2,a] = q_table[s1,s2,a]  + 0.01*diff# update\n\n\nq_table[...,0] # action 0 을 했을 때 테이블\n\narray([[90.18056786, 92.09886903, 93.96750757, -9.99996536],\n       [92.10224034, 94.04416666, 95.99626811, -9.99999613],\n       [94.04234232, 96.00663449, 97.990322  , -9.9993985 ],\n       [95.95777379, 97.97603998, 99.99082608,  0.        ]])\n\n\n\n학습하기에는 5%가 나을 것 같음 (값마다 차이가 크므로)\n\n\nq_table = np.zeros((4,4,4))\nmemory = zip(player.states, player.actions, player.rewards, player.next_states, player.terminations)\nfor (s1,s2), a, r, (ss1,ss2), tmd in memory:\n    qhat = q_table[s1,s2,a] # 내가 생각했던 값\n    if tmd:\n        q = r # 실제값\n    else:\n        future = q_table[ss1,ss2,:].max() # ss1,ss2 : 다음 상태\n        q = r + 0.95*future\n    diff = q-qhat # 차이\n    q_table[s1,s2,a] = q_table[s1,s2,a]  + 0.01*diff# update\n\n\nq_table[...,0] # action 0 을 했을 때 테이블\n\narray([[72.83952058, 77.72350932, 82.80344973, -9.99996536],\n       [77.72636791, 82.87118608, 88.27814712, -9.99999613],\n       [82.86957406, 88.28769271, 93.99071303, -9.9993985 ],\n       [88.24270099, 93.97700808, 99.99082608,  0.        ]])\n\n\n\nq_table[...,1] # 왼쪽으로 갔을 때 테이블\n\narray([[-10.        ,  68.19615723,  72.83448762,  77.68726629],\n       [-10.        ,  72.83795619,  77.72290021,  82.84620653],\n       [-10.        ,  77.72026164,  82.86332991,  88.19689967],\n       [ -9.99997682,  82.748506  ,  88.11876519,   0.        ]])\n\n\n\nq_table[...,2] # 아래로 갔을 때 테이블\n\narray([[72.83963932, 77.72633004, 82.86856325, 88.23479886],\n       [77.72428797, 82.8712446 , 88.28755321, 93.9835884 ],\n       [82.81365039, 88.27147768, 93.98527541, 99.99427983],\n       [-9.99998066, -9.99999722, -9.99915348,  0.        ]])\n\n\n\nq_table[...,3] # 위로 갔을 때 테이블\n\narray([[-10.        , -10.        , -10.        ,  -9.99997587],\n       [ 68.19612628,  72.8376872 ,  77.7195001 ,  82.71315412],\n       [ 72.83517558,  77.72302563,  82.86358289,  88.14411865],\n       [ 77.68021549,  82.84140857,  88.18561423,   0.        ]])\n\n\n\n액션에 따라 출력\n\n\nfor a in [0,1,2,3]: \n    print(f\"action = {a}\")\n    print(f\"q[...,{a}] = {q_table[...,a].round(3)}\")\n    print(\"---\")\n\naction = 0\nq[...,0] = [[ 72.84   77.724  82.803 -10.   ]\n [ 77.726  82.871  88.278 -10.   ]\n [ 82.87   88.288  93.991  -9.999]\n [ 88.243  93.977  99.991   0.   ]]\n---\naction = 1\nq[...,1] = [[-10.     68.196  72.834  77.687]\n [-10.     72.838  77.723  82.846]\n [-10.     77.72   82.863  88.197]\n [-10.     82.749  88.119   0.   ]]\n---\naction = 2\nq[...,2] = [[ 72.84   77.726  82.869  88.235]\n [ 77.724  82.871  88.288  93.984]\n [ 82.814  88.271  93.985  99.994]\n [-10.    -10.     -9.999   0.   ]]\n---\naction = 3\nq[...,3] = [[-10.    -10.    -10.    -10.   ]\n [ 68.196  72.838  77.72   82.713]\n [ 72.835  77.723  82.864  88.144]\n [ 77.68   82.841  88.186   0.   ]]\n---\n\n\n\n# player.q_table # 정의힌 적이 없으므로 error\n\n\nplayer.q_table = q_table # 방금 한 것을 덮어 씌우면\n\n\nplayer.q_table\n\narray([[[ 72.83952058, -10.        ,  72.83963932, -10.        ],\n        [ 77.72350932,  68.19615723,  77.72633004, -10.        ],\n        [ 82.80344973,  72.83448762,  82.86856325, -10.        ],\n        [ -9.99996536,  77.68726629,  88.23479886,  -9.99997587]],\n\n       [[ 77.72636791, -10.        ,  77.72428797,  68.19612628],\n        [ 82.87118608,  72.83795619,  82.8712446 ,  72.8376872 ],\n        [ 88.27814712,  77.72290021,  88.28755321,  77.7195001 ],\n        [ -9.99999613,  82.84620653,  93.9835884 ,  82.71315412]],\n\n       [[ 82.86957406, -10.        ,  82.81365039,  72.83517558],\n        [ 88.28769271,  77.72026164,  88.27147768,  77.72302563],\n        [ 93.99071303,  82.86332991,  93.98527541,  82.86358289],\n        [ -9.9993985 ,  88.19689967,  99.99427983,  88.14411865]],\n\n       [[ 88.24270099,  -9.99997682,  -9.99998066,  77.68021549],\n        [ 93.97700808,  82.748506  ,  -9.99999722,  82.84140857],\n        [ 99.99082608,  88.11876519,  -9.99915348,  88.18561423],\n        [  0.        ,   0.        ,   0.        ,   0.        ]]])\n\n\n)🗣️\n\nq_table = np.zeros((4,4,4))\nmemory = zip(player.states, player.actions, player.rewards, player.next_states, player.terminations)\nfor (s1,s2), a, r, (ss1,ss2), tmd  in memory:\n    qhat = q_table[s1,s2,a] # 내가 생각했던값\n    if tmd: \n        q = r # 실제값\n    else: \n        future = q_table[ss1,ss2,:].max()\n        q = r + 0.95 * future\n    diff = q-qhat # 차이\n    q_table[s1,s2,a] = q_table[s1,s2,a]  + 0.01*diff# update\n\n\nfor a in [0,1,2,3]: \n    print(f\"action = {a}\")\n    print(f\"q[...,{a}] = {q_table[...,a].round(3)}\")\n    print(\"---\")\n\naction = 0\nq[...,0] = [[ 72.838  77.721  82.807 -10.   ]\n [ 77.725  82.87   88.276 -10.   ]\n [ 82.867  88.285  93.989  -9.999]\n [ 88.229  93.978  99.991   0.   ]]\n---\naction = 1\nq[...,1] = [[-10.     68.195  72.833  77.683]\n [-10.     72.836  77.721  82.849]\n [-10.     77.717  82.862  88.186]\n [-10.     82.723  88.128   0.   ]]\n---\naction = 2\nq[...,2] = [[ 72.838  77.724  82.867  88.241]\n [ 77.721  82.869  88.286  93.982]\n [ 82.801  88.272  93.985  99.993]\n [-10.    -10.     -9.999   0.   ]]\n---\naction = 3\nq[...,3] = [[-10.    -10.    -10.    -10.   ]\n [ 68.195  72.835  77.718  82.734]\n [ 72.832  77.721  82.863  88.122]\n [ 77.678  82.845  88.216   0.   ]]\n---\n\n\naction 0: 오른쪽\naction 1: 왼쪽\naction 2: 아래쪽\naction 3: 위쪽\n\nplayer.q_table = q_table\n\n- 이제 플레이어의 행동은?\n🗣️(\n\ns1=0\ns2=0\n\n\nplayer.q_table[s1,s2,:]\n\narray([ 72.83952058, -10.        ,  72.83963932, -10.        ])\n\n\n\n숫자 4개 (각 액션을 했을 때의 결과), 0 또는 2의 행동을 하면 됨\n\n\nplayer.q_table[s1,s2,:].argmax() # 이것이 action이 되어야 함\n\nnp.int64(2)\n\n\n\ndef act(player,s1,s2):\n    action = player.q_table[s1,s2,:].argmax()\n    return action\n\n\nact(player,0,0) # player 오브젝트 안에는 q_table이 있음\n\nnp.int64(2)\n\n\naction 0: 오른쪽\naction 1: 왼쪽\naction 2: 아래쪽\naction 3: 위쪽\n✍️ 강의 영상과 세부 방향은 다름 (큰 틀은 동일)\n\nact(player,0,0) # 출발에서 아래쪽이므로 맞는 것 같음 (강의 영상은 오른쪽)\n\nnp.int64(2)\n\n\n\nact(player,1,0) # 오른쪽으로 이동 (1,0) =&gt; (1,1)\n\nnp.int64(0)\n\n\n\nact(player,1,1) # 아래쪽으로 이동 (1,1) =&gt; (2,1)\n\nnp.int64(2)\n\n\n\nact(player,2,1) # 오른쪽으로 이동 (2,1) =&gt; (2,2)\n\nnp.int64(0)\n\n\n\nact(player,2,2) # 오른쪽으로 이동 (2,2) =&gt; (2,3)\n\nnp.int64(0)\n\n\n\nact(player,2,3) # 아래쪽으로 이동 (2,3) =&gt; (3,3)\n\nnp.int64(2)\n\n\n)🗣️\n\nplayer.q_table\n\narray([[[ 72.83771663, -10.        ,  72.83771538, -10.        ],\n        [ 77.72139771,  68.19454652,  77.72442966, -10.        ],\n        [ 82.80747929,  72.83310558,  82.86672465, -10.        ],\n        [ -9.99998197,  77.6827334 ,  88.24107054,  -9.99998511]],\n\n       [[ 77.72454812, -10.        ,  77.72127368,  68.19457346],\n        [ 82.86950596,  72.83600446,  82.86912699,  72.83541752],\n        [ 88.27585546,  77.72068451,  88.28563001,  77.71797997],\n        [ -9.99999683,  82.84920596,  93.98163671,  82.73393175]],\n\n       [[ 82.8669733 , -10.        ,  82.8012108 ,  72.83236834],\n        [ 88.28521264,  77.71722413,  88.27171754,  77.72136508],\n        [ 93.9886205 ,  82.86197892,  93.98461924,  82.86278052],\n        [ -9.99904498,  88.18588483,  99.99321405,  88.12228859]],\n\n       [[ 88.22883855,  -9.9999832 ,  -9.99997635,  77.67756866],\n        [ 93.97813902,  82.72305248,  -9.99999792,  82.84474465],\n        [ 99.99082608,  88.12798376,  -9.99917862,  88.21551322],\n        [  0.        ,   0.        ,   0.        ,   0.        ]]])\n\n\n\ndef act(player,s1,s2):\n    action = player.q_table[s1,s2,:].argmax()\n    return action\n\n\nact(player,0,0)\n\n0\n\n\n\nplayer.q_table[0,0,:]\n\narray([ 72.83771663, -10.        ,  72.83771538, -10.        ])\n\n\n🗣️(\n\nQ (q_table) –&gt; DQN (Deep, Network)\n\n# SARSA\nQ learning 은 SARS 까지만 생각함 (next action은 최적의 값을 가정)\n#---#\nq_table ---&gt; 어떠한 행동을 할지 결정\n학습 이후에는 정해진 path로만 감\n\nact(player,0,0)\n\nnp.int64(2)\n\n\n\nplayer.q_table[0,0,:]\n\narray([ 72.83952058, -10.        ,  72.83963932, -10.        ])\n\n\n0과 2는 사실상 비등한 가치를 갖고 있음에도 매우 작은 차이 때문에 항상 2만 선택\n이게 맞는 건가 싶으면서 확률로 바꿔서 반반으로 선택하는 것도 생각해볼만 함\n(결정적 설계 vs 확률적 설계)\n\n하지만 밴딧게임에서 보상이 1, 10이 아니라 1, 2라면\n1을 1/(1+2)의 확률로 선택하는 것은 너무 큰 것 같음\nsoftmax 함수를 취해서 2에 많은 확률을 줄 수도 있음 (만들기 나름)\n\n항상 결정적으로 설계하는 것이 best가 아님을 알 수 있음\n\n많은 변형 가능\n100번 중 95번은 결정적, 5번은 확률적 등\n)🗣️"
  },
  {
    "objectID": "posts/06wk-2.html",
    "href": "posts/06wk-2.html",
    "title": "06wk-2: (신경망) – 다항분류, FashionMNIST",
    "section": "",
    "text": "📘 Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\n📝 🗣️ ✍️ 🔬 ❓"
  },
  {
    "objectID": "posts/06wk-2.html#a.-이항분류와-bcewithlogitsloss",
    "href": "posts/06wk-2.html#a.-이항분류와-bcewithlogitsloss",
    "title": "06wk-2: (신경망) – 다항분류, FashionMNIST",
    "section": "A. 이항분류와 BCEWithLogitsLoss",
    "text": "A. 이항분류와 BCEWithLogitsLoss\n- 데이터\n\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\nto_tensor = torchvision.transforms.ToTensor()\nX0_train = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==0])\nX1_train = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==1])\nX = torch.concat([X0_train,X1_train],axis=0).reshape(-1,784)\ny = torch.tensor([0.0]*len(X0_train) + [1.0]*len(X1_train)).reshape(-1,1)\n\n🗣️(\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\n\n\nnet(X)\n\ntensor([[0.4577],\n        [0.4624],\n        [0.4653],\n        ...,\n        [0.4700],\n        [0.4620],\n        [0.4738]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n)\nsig = torch.nn.Sigmoid()\n\n\nsig(net(X))\n\ntensor([[0.4577],\n        [0.4624],\n        [0.4653],\n        ...,\n        [0.4700],\n        [0.4620],\n        [0.4738]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\ntorch.exp(net(X))/(1+torch.exp(net(X)))\n\ntensor([[0.4577],\n        [0.4624],\n        [0.4653],\n        ...,\n        [0.4700],\n        [0.4620],\n        [0.4738]], grad_fn=&lt;DivBackward0&gt;)\n\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n)\nsig = torch.nn.Sigmoid()\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(1,31):\n    #1\n    netout = net(X)\n    yhat = sig(netout)\n    #2\n    loss = loss_fn(yhat,y)\n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nsig(net(X))\n\ntensor([[0.0179],\n        [0.0205],\n        [0.1106],\n        ...,\n        [0.8751],\n        [0.8740],\n        [0.8033]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\ntorch.manual_seed(43052)\nsig = torch.nn.Sigmoid()\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    sig\n)\n\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(1,31):\n    #1\n    #netout = net(X)\n    yhat = net(X)\n    #2\n    loss = loss_fn(yhat,y)\n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nnet(X)\n\ntensor([[0.0179],\n        [0.0205],\n        [0.1106],\n        ...,\n        [0.8751],\n        [0.8740],\n        [0.8033]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\n결과 동일\n\ntorch.nn.Linear(32,1)을 빼면 optimizer에 parameter가 전달이 되지 않아 update가 되지 않음\nsig에는 학습해야할 parameter가 없으므로 빼도(빼고 나온 결과에 sig) 되고 넣어도 됨\n\n\n\nsig(net(X)) # 확률\n\ntensor([[0.5045],\n        [0.5051],\n        [0.5276],\n        ...,\n        [0.7058],\n        [0.7056],\n        [0.6907]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n)\nsig = torch.nn.Sigmoid()\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(1,31):\n    #1\n    netout = net(X)\n    yhat = sig(netout)\n    #2\n    loss = loss_fn(yhat,y)\n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nlogits = netout = net(X) # 로짓\n\n\nsig(logits) # sig(net(X))과 동일\n\ntensor([[0.0179],\n        [0.0205],\n        [0.1106],\n        ...,\n        [0.8751],\n        [0.8740],\n        [0.8033]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\ntorch.exp(logits)/(1+torch.exp(logits))\n\ntensor([[0.0179],\n        [0.0205],\n        [0.1106],\n        ...,\n        [0.8751],\n        [0.8740],\n        [0.8033]], grad_fn=&lt;DivBackward0&gt;)\n\n\n\n만약 logit이 0이면 1/2\n\n\ntorch.exp(torch.tensor([0]))/(1+torch.exp(torch.tensor([0])))\n\ntensor([0.5000])\n\n\n\n만약 logit이 양수면 증가할수록 전체 값은 1에 가까워짐\n만약 logit이 음수면 증가할수록 전체 값은 0에 가까워짐\n위의 내용을 활용하여 accuracy 적용 가능\n\n\n((sig(netout) &gt; 0.5) == y).float().mean()\n\ntensor(0.9956)\n\n\n\nsig(netout)&gt;0.5\n\ntensor([[False],\n        [False],\n        [False],\n        ...,\n        [ True],\n        [ True],\n        [ True]])\n\n\n\nnetout&gt;0 # 위와 동일\n\ntensor([[False],\n        [False],\n        [False],\n        ...,\n        [ True],\n        [ True],\n        [ True]])\n\n\n\n((netout&gt;0) == y).float().mean() # 위와 동일\n\ntensor(0.9956)\n\n\n)🗣️\n- 예전에 적합했던 코드에서 sig를 분리한것\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n)\nsig = torch.nn.Sigmoid()\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(1,31):\n    #1\n    netout = net(X) # netout = logits\n    yhat = sig(netout) # yhat = probs\n    #2\n    loss = loss_fn(yhat,y)\n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n# netout(=logits) 의 특징\n\n\\(netout &gt;0 \\Leftrightarrow sig(netout) &gt; 0.5\\)\n\\(netout &lt;0 \\Leftrightarrow sig(netout) &lt; 0.5\\)\n\n\n((net(X)&gt;0) ==y).float().mean()\n\ntensor(0.9956)\n\n\n- 아래의 코드는 위의 코드와 같은 코드임\n\n🗣️\n\nloss에서 logits과 y를 바로 비교하고 싶음\nBCELoss 대신 BCEWithLogitsLoss 사용 (yhat과 y가 아닌 logits과 y를 비교하여 loss계산)\nloss에 yhat을 집어넣을 필요가 없기 때문에 yhat 구하는 코드 삭제\n이렇게 바꾸면 컴퓨터 공학적으로 나음 (연산 편리)\n\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n)\nloss_fn = torch.nn.BCEWithLogitsLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(1,31):\n    #1\n    netout = net(X) \n    #2\n    loss = loss_fn(netout,y)\n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n🗣️(\n\n각 코드 마지막에 다음을 실행하고 결과를 비교하면 같음을 알 수 있음\n\n##--에폭이후코드--#\nacc = ((net(X)&gt;0) ==u).float().mean()\nprint(epoc, acc)\n)🗣️"
  },
  {
    "objectID": "posts/06wk-2.html#b.-범주형자료의-변환",
    "href": "posts/06wk-2.html#b.-범주형자료의-변환",
    "title": "06wk-2: (신경망) – 다항분류, FashionMNIST",
    "section": "B. 범주형자료의 변환",
    "text": "B. 범주형자료의 변환\n- 범주형자료를 숫자로 어떻게 바꿀까?\n\n실패 / 성공 \\(\\to\\) 0 / 1\n숫자0그림 / 숫자1그림 \\(\\to\\) 0 / 1\n강아지그림 / 고양이그림 \\(\\to\\) 0 / 1\n강아지그림 / 고양이그림 / 토끼그림 \\(\\to\\) 0 / 1 / 2 ?????\n\n- 주입식교육: 강아지그림/고양이그림/토끼그림일 경우 숫자화시키는 방법\n\n잘못된방식: 강아지그림 = 0, 고양이그림 = 1, 토끼그림 = 2\n올바른방식: 강아지그림 = [1,0,0], 고양이그림 = [0,1,0], 토끼그림 = [0,0,1] ### &lt;– 이런방식을 원핫인코딩이라함\n\n🗣️(\n[1,0,0]\n[1,0,0]\n[0,1,0]\n[0,0,1]\ncolumn 별로 평균\n[0.5,0.25,0.25]\n강아지가 50% 있다고 생각 가능 (평균이 의미를 가짐)\n)🗣️\n- 왜?\n\n설명1: 강아지그림, 고양이그림, 토끼그림은 서열측도가 아니라 명목척도임. 그래서 범주를 0,1,2 로 숫자화하면 평균등의 의미가 없음 (사회조사분석사 2급 스타일)\n설명2: 범주형은 원핫인코딩으로 해야함 (“30일만에 끝내는 실전머신러닝” 이런 책에 나오는 스타일)\n설명3: 동전을 한번 던져서 나오는 결과는 \\(n=1\\)인 이항분포를 따름. 주사위 한번 던져서 나오는 눈금의 숫자는 \\(n=1\\)인 다항분포를 따름. \\(n=1\\)인 이항분포의 실현값은 0,1 이고, \\(n=1\\)인 다항분포의 실현값은 [1,0,0], [0,1,0], [0,0,1] 이므로 당연히 \\(y_i\\) 는 [1,0,0], [0,1,0], [0,0,1] 중 하나의 형태를 가진다고 가정하는게 바람직함 (이 설명이 이 중에서 가장 정확한 설명임)\n\n🗣️(\n모델링 = 스트럭처 + 오차\ny = 0,1,0,0,1\nprob = 0.2. 0.8 (스트럭처)\n오차항에 대한 모델: 이항 분포\ny = 앞면, 뒷면 ---&gt; 0,1 # n=1인 이항분포를 따름 = 베르누이를 따름\ny = 주사위 1,2,3,4,5,6 ---&gt; 다항분포를 따름 n=1\nn=1인 다항분포의 realization: [1,0,0,0,0,0] ...\n)🗣️"
  },
  {
    "objectID": "posts/06wk-2.html#c.-실습-3개의-클래스를-구분",
    "href": "posts/06wk-2.html#c.-실습-3개의-클래스를-구분",
    "title": "06wk-2: (신경망) – 다항분류, FashionMNIST",
    "section": "C. 실습: 3개의 클래스를 구분",
    "text": "C. 실습: 3개의 클래스를 구분\n- 데이터준비\n\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\nto_tensor = torchvision.transforms.ToTensor()\nX0 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==0])\nX1 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==1])\nX2 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==2])\nX = torch.concat([X0,X1,X2]).reshape(-1,1*28*28)\ny = torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2)).reshape(-1,1).float()\n\n🗣️(\n\nX.shape\n\ntorch.Size([18623, 784])\n\n\n\ny\n\ntensor([[0.],\n        [0.],\n        [0.],\n        ...,\n        [2.],\n        [2.],\n        [2.]])\n\n\n\ny.reshape(-1)\n\ntensor([0., 0., 0.,  ..., 2., 2., 2.])\n\n\n\nset(y.reshape(-1).tolist())\n\n{0.0, 1.0, 2.0}\n\n\n\nplt.imshow(X[0].reshape(28,28), cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nplt.imshow(X[10000].reshape(28,28), cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nplt.imshow(X[-1].reshape(28,28), cmap=\"gray\")\n\n\n\n\n\n\n\n\n\ny.shape\n\ntorch.Size([18623, 1])\n\n\n\ny\n\ntensor([[0.],\n        [0.],\n        [0.],\n        ...,\n        [2.],\n        [2.],\n        [2.]])\n\n\n\ny가 이렇게 정리되어 있으면 안 됨\n\n[[0],[0],[1],[2]] -&gt; [[1,0,0],[1,0,0],[0,1,0],[0,0,1]] 이런식으로 바꾸고 싶음\n\n# torch.nn.functional.one_hot([0,0,1,2]) # error\n\n\ntorch.nn.functional.one_hot(torch.tensor([0,0,1,2]))\n\ntensor([[1, 0, 0],\n        [1, 0, 0],\n        [0, 1, 0],\n        [0, 0, 1]])\n\n\n\n1차원의 tensor로 넣어주면 바꿔줌\n\n\ny.reshape(-1)\n\ntensor([0., 0., 0.,  ..., 2., 2., 2.])\n\n\n\n이대로 집어 넣으면 error (float으로 들어감)\n1차원의 tensor + int로 넣어주면 바꿔줌\n\n\ny.reshape(-1).long()\n\ntensor([0, 0, 0,  ..., 2, 2, 2])\n\n\n)🗣️\n\ny = torch.nn.functional.one_hot(y.reshape(-1).long()).float()\ny\n\ntensor([[1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        ...,\n        [0., 0., 1.],\n        [0., 0., 1.],\n        [0., 0., 1.]])\n\n\n🗣️ 다시 float으로 바꿔줌\n- 적합\n🗣️(\n\nX.shape, y.shape\n\n(torch.Size([18623, 784]), torch.Size([18623, 3]))\n\n\n\nSigmoid는 1차원일 때 적용되므로 1차원이 아닌 지금은 다른 것이 필요\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32), # 일단 32 정도\n    torch.nn.ReLU(), # 표현력 올리기\n    torch.nn.Linear(32,3)\n)\nloss_fn = torch.nn.CrossEntropyLoss() # 다차원일 때 사용 (logits과 y 비교)\n\n\nnet(X)\n\ntensor([[-0.0676,  0.0558,  0.0013],\n        [-0.0191,  0.0977, -0.0303],\n        [-0.0771,  0.0898,  0.0959],\n        ...,\n        [-0.0168,  0.0298,  0.0016],\n        [ 0.0077,  0.0703,  0.0517],\n        [ 0.0628,  0.0072,  0.0380]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\nloss_fn(net(X),y) # y가 float이 아니면 error\n\ntensor(1.0771, grad_fn=&lt;DivBackward1&gt;)\n\n\n\n참고) BCEWithLigitsLoss: Binary Cross Entropy\n\n)🗣️\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,3),\n)\nloss_fn = torch.nn.CrossEntropyLoss() # 의미상 CEWithLogitsLoss\noptimizr = torch.optim.Adam(net.parameters())\nfor epoc in range(1,31):\n    #1\n    netout = net(X) # netout: (n,3) \n    #2\n    loss = loss_fn(netout,y) \n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n🗣️(\n\naccuracy 계산\n\n\nnetout[::2] # logit 값 (클수록 1이 나올 확률이 높음)\n\ntensor([[ 2.7971, -1.7052, -1.4072],\n        [ 1.3707, -0.7746, -0.2272],\n        [ 4.1326, -2.8297, -1.6813],\n        ...,\n        [-0.5738, -2.3579,  1.8868],\n        [ 0.3950, -1.6556,  1.0137],\n        [-0.7091, -1.2342,  1.3557]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\ntorch.exp(netout) # 전부 양수가 됨\n\ntensor([[16.3971,  0.1817,  0.2448],\n        [19.7109,  0.2345,  0.2365],\n        [ 3.9381,  0.4609,  0.7968],\n        ...,\n        [ 1.4843,  0.1910,  2.7557],\n        [ 0.5556,  0.1023,  9.1077],\n        [ 0.4921,  0.2911,  3.8796]], grad_fn=&lt;ExpBackward0&gt;)\n\n\n\np1 = 16.3971 / (16.3971+0.1817+0.2448)\np2 = 0.1817 / (16.3971+0.1817+0.2448)\np3 = 0.2448 / (16.3971+0.1817+0.2448)\n\n\np1,p2,p3 # 0~1사이에 있음 # 무조건 양수 # p1+p2+p3 = 1\n# --&gt; 각각 카테고리에 속할 확률이라고 해석 가능 (softmax function)\n# 숫자가 크면 그 카테고리에 속한다고 네트워크가 강하게 확신\n\n(0.9746487077676597, 0.010800304334387409, 0.014550987897952877)\n\n\n\nnetout\n\ntensor([[ 2.7971, -1.7052, -1.4072],\n        [ 2.9812, -1.4505, -1.4417],\n        [ 1.3707, -0.7746, -0.2272],\n        ...,\n        [ 0.3950, -1.6556,  1.0137],\n        [-0.5878, -2.2794,  2.2091],\n        [-0.7091, -1.2342,  1.3557]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\nnetout.argmax(axis=1) # 예측값\n\ntensor([0, 0, 0,  ..., 2, 2, 2])\n\n\n\ny\n\ntensor([[1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        ...,\n        [0., 0., 1.],\n        [0., 0., 1.],\n        [0., 0., 1.]])\n\n\n\ny.argmax(axis=1)\n\ntensor([0, 0, 0,  ..., 2, 2, 2])\n\n\n)🗣️\n\n(netout.argmax(axis=1) == y.argmax(axis=1)).float().mean()\n\ntensor(0.9674)"
  },
  {
    "objectID": "posts/06wk-2.html#d.-결론-외우세여",
    "href": "posts/06wk-2.html#d.-결론-외우세여",
    "title": "06wk-2: (신경망) – 다항분류, FashionMNIST",
    "section": "D. 결론 – 외우세여",
    "text": "D. 결론 – 외우세여\n- 파이토치버전 // 코딩용\n\n\n\n분류\nnetout의 의미\n손실함수\n\n\n\n\n이항분류\nprob\nBCELoss\n\n\n이항분류\nlogit\nBCEWithLogitsLoss\n\n\n다항분류\nprobs\nNA\n\n\n다항분류\nlogits\nCrossEntropyLoss\n\n\n\n\n🗣️\n\nprob인데 BCEWithLogitsLoss: Sigmoid 2번\nlogit인데 BCELoss: Sigmoid 0번\n2번째와 4번째가 코딩적으로 나음, 개념적으로 이해하기는 1번째가 나음\n\n\n\nCrossEntropyLoss 이거 이름이 완전 마음에 안들어요.. CEWithLogitsLoss 라고 하는게 더 좋을 것 같습니다.\n\n- 일반적개념 // 이론용\n\n\n\n\n\n\n\n\n\n분류\n오차항의가정\n마지막활성화함수\n손실함수\n\n\n\n\n이항분류\n이항분포\nsigmoid1\nBinary Cross Entropy\n\n\n다항분류\n다항분포\nsoftmax2\nCross Entropy\n\n\n\n- 참고 (sigmoid, softmax 계산과정비교)\n\n\\(prob = \\text{sig}(logit) =\\frac{\\exp(logit)}{1+\\exp(logit)}\\)\n\\(probs= \\text{softmax}\\left(\\begin{bmatrix} logit_1 \\\\ logit_2 \\\\ logit_3\\end{bmatrix}\\right) =\\begin{bmatrix} \\frac{\\exp(logit_1)}{\\exp(logit_1)+\\exp(logit_2)+\\exp(logit_3)} \\\\\n\\frac{\\exp(logit_2)}{\\exp(logit_1)+\\exp(logit_2)+\\exp(logit_3)} \\\\\n\\frac{\\exp(logit_3)}{\\exp(logit_1)+\\exp(logit_2)+\\exp(logit_3)} \\end{bmatrix}\\)"
  },
  {
    "objectID": "posts/06wk-2.html#a.-데이터",
    "href": "posts/06wk-2.html#a.-데이터",
    "title": "06wk-2: (신경망) – 다항분류, FashionMNIST",
    "section": "A. 데이터",
    "text": "A. 데이터\nhttps://arxiv.org/abs/1708.07747 [@xiao2017fashion]\n\ntrain_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True)\ntest_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True)\nto_tensor = torchvision.transforms.ToTensor()\nX = torch.stack([to_tensor(img) for img, lbl in train_dataset])\ny = torch.tensor([lbl for img, lbl in train_dataset])\ny = torch.nn.functional.one_hot(y).float()\nXX = torch.stack([to_tensor(img) for img, lbl in test_dataset])\nyy = torch.tensor([lbl for img, lbl in test_dataset])\nyy = torch.nn.functional.one_hot(yy).float()\n\n100.0%\n100.0%\n100.0%\n100.0%\n\n\n🗣️(\n\nX.shape, y.shape, XX.shape, yy.shape\n\n(torch.Size([60000, 1, 28, 28]),\n torch.Size([60000, 10]),\n torch.Size([10000, 1, 28, 28]),\n torch.Size([10000, 10]))\n\n\n\nX[0,0,:,:].shape # 4차원\n\ntorch.Size([28, 28])\n\n\n\nplt.imshow(X[0,0,:,:], cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nplt.imshow(X[1,0,:,:], cmap=\"gray\") # 다음 그림\n\n\n\n\n\n\n\n\n\nplt.imshow(X[2,0,:,:], cmap=\"gray\") # 다음 그림\n\n\n\n\n\n\n\n\n\ny # 원핫인코딩 되어 있음\n\ntensor([[0., 0., 0.,  ..., 0., 0., 1.],\n        [1., 0., 0.,  ..., 0., 0., 0.],\n        [1., 0., 0.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [1., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]])\n\n\n\ntorchvision.datasets.FashionMNIST.classes\n\n['T-shirt/top',\n 'Trouser',\n 'Pullover',\n 'Dress',\n 'Coat',\n 'Sandal',\n 'Shirt',\n 'Sneaker',\n 'Bag',\n 'Ankle boot']\n\n\n\ntorchvision.datasets.FashionMNIST.classes[9] # label 9가 의미하는 것\n\n'Ankle boot'\n\n\n\nplt.imshow(X[2,0,:,:], cmap=\"gray\")\nprint(y[2,:])\n\ntensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n\n\n\n\n\n\n\n\n\n\nplt.imshow(X[2,0,:,:], cmap=\"gray\")\nprint(y[2,:].argmax())\n\ntensor(0)\n\n\n\n\n\n\n\n\n\n\nplt.imshow(X[2,0,:,:], cmap=\"gray\")\nprint(y[2,:].argmax().item())\n\n0\n\n\n\n\n\n\n\n\n\n\nplt.imshow(X[2,0,:,:], cmap=\"gray\")\nprint(torchvision.datasets.FashionMNIST.classes[y[2,:].argmax().item()])\n\nT-shirt/top\n\n\n\n\n\n\n\n\n\n)🗣️\n\nobs_idx = 301\nplt.imshow(X[obs_idx,0,:,:],cmap=\"gray\")\nplt.title(torchvision.datasets.FashionMNIST.classes[y[obs_idx,:].argmax().item()]);"
  },
  {
    "objectID": "posts/06wk-2.html#b.-간단한-신경망",
    "href": "posts/06wk-2.html#b.-간단한-신경망",
    "title": "06wk-2: (신경망) – 다항분류, FashionMNIST",
    "section": "B. 간단한 신경망",
    "text": "B. 간단한 신경망\n🗣️(\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32), # 28*28\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,10)\n)\nloss.fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\n\n\n# net(X) # error\n\n\nX.shape # 784가 아님\n\ntorch.Size([60000, 1, 28, 28])\n\n\n\nnet(X.reshape(-1,784))\n\ntensor([[-0.1190,  0.1954, -0.1191,  ...,  0.0729,  0.1721, -0.0408],\n        [-0.0379,  0.2657, -0.0238,  ..., -0.0695,  0.1528, -0.0089],\n        [-0.0768,  0.1645,  0.0813,  ...,  0.0280,  0.0686, -0.0330],\n        ...,\n        [-0.1537,  0.0787, -0.0260,  ..., -0.0972,  0.0474,  0.0150],\n        [-0.0558,  0.1724,  0.0855,  ...,  0.0176,  0.0808, -0.0563],\n        [-0.0231,  0.2125,  0.0721,  ...,  0.0299,  0.2542, -0.0449]],\n       grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\n매번 하기는 귀찮음 (다음과 같이 하고 싶음)\n\nnet = torch.nn.Sequential(\n    형태를 바꿔주는 변환,\n    torch.nn.Linear(784,32), # 28*28\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,10)\n)\nloss.fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\n\nclass Flatten(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self,inp):\n        out=inp.reshape(-1,784)\n        return out\n\n\nnet = torch.nn.Sequential(\n    Flatten(),\n    torch.nn.Linear(784,32), # 28*28\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,10)\n)\nloss.fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\n\n\nnet(X)\n\ntensor([[ 0.1065, -0.0595, -0.0168,  ...,  0.0957,  0.0512,  0.1637],\n        [-0.0600, -0.4660,  0.2520,  ...,  0.4221,  0.0290,  0.1224],\n        [ 0.0321, -0.2154,  0.0601,  ...,  0.2178, -0.0819,  0.0307],\n        ...,\n        [ 0.0069, -0.3970,  0.0333,  ...,  0.2753,  0.0132,  0.1855],\n        [ 0.0425, -0.2264,  0.0967,  ...,  0.2295, -0.0723,  0.0762],\n        [ 0.0436, -0.2097,  0.0193,  ...,  0.2153, -0.0889, -0.0272]],\n       grad_fn=&lt;AddmmBackward0&gt;)\n\n\nclass Flatten(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self,inp):\n        # out=inp.reshape(-1,784) # 여기 빼고 고정\n        return out\n\n사용자가 원하는 대로 할 수는 있지만 귀찮음 (torch에 같은 기능을 지원해줌)\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Flatten(),\n    torch.nn.Linear(784,32), # 28*28\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,10)\n)\nloss.fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\n\n\nnet(X)\n\ntensor([[-0.1967,  0.0710, -0.1439,  ..., -0.0351, -0.2101, -0.0983],\n        [-0.0537,  0.0729, -0.1805,  ...,  0.0139, -0.1520, -0.0359],\n        [-0.1419,  0.1204, -0.0488,  ..., -0.0232, -0.0582, -0.0687],\n        ...,\n        [-0.1134,  0.1152, -0.0716,  ...,  0.0311, -0.1294, -0.1053],\n        [-0.1655,  0.1211, -0.0752,  ..., -0.0604, -0.0637, -0.0946],\n        [-0.2413,  0.1072,  0.0042,  ..., -0.0254, -0.1170, -0.1348]],\n       grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\n진행\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Flatten(),\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,10)\n)\nloss.fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#--#\n\n\nfor epoc in range(1,301):\n    #---에폭시작---#\n    # 1\n    netout = net(X)\n    # 2\n    loss = loss_fn(netout,y)\n    # 3\n    loss.backward()\n    # 4\n    optimizr.step()\n    optimizr.zero_grad()\n    #---에폭끝---#\n    if epoc%50==0:\n        logits = net(X).data\n        acc = (logits.argmax(axis=1) == y.argmax(axis=1)).float().mean()       \n        print(f\"# of epochs={epoc}, train_acc={acc:.4f}\")  \n\n# of epochs=50, train_acc=0.7334\n# of epochs=100, train_acc=0.8052\n# of epochs=150, train_acc=0.8295\n# of epochs=200, train_acc=0.8398\n# of epochs=250, train_acc=0.8488\n# of epochs=300, train_acc=0.8556\n\n\n\nlogits = net(XX).data\nacc = (logits.argmax(axis=1) == yy.argmax(axis=1)).float().mean()       \nprint(f\"test_acc={acc:.4f}\")\n\ntest_acc=0.8383\n\n\n\n오버피팅도 있는 것 같고 훈련을 더 한다고해서 훈련 정확도가 높아질 것 같지도 않음 (표현력 자체가 안좋은 것 같음)\n이제 32도 늘려보고 여러가지 시도를 하고 싶은데 GPU를 사용해야할 것 같음\nX가 cuda에 전부 안 올라갈 수 있으므로 다음과 같은 준비과정 필요\n\n)🗣️\n- Step1: 데이터정리\n\nds_train = torch.utils.data.TensorDataset(X,y)\ndl_train = torch.utils.data.DataLoader(ds_train,batch_size=256,shuffle=True)\nds_test = torch.utils.data.TensorDataset(XX,yy)\ndl_test = torch.utils.data.DataLoader(ds_test,batch_size=256)\n\n\n🗣️\n\ntest data도 GPU 메모리가 걱정되면 따로 정리\nbatch_size는 GPU 메모리가 감당할 수 있는 정도 (일단 train과 같은 크기로 함)\ntest는 update 하지도 않고 accuracy만 계산하면 되므로 굳이 shuffle 필요 X\n\n\n- Step2: 학습에 필요한 준비 (모델링)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Flatten(),\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,10)\n).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\n\n- Step3: 적합\n\nfor epoc in range(1,31):\n    net.train() # 지금은 아니지만 dropout 사용 시\n    #---에폭시작---#\n    for Xm,ym in dl_train:        \n        Xm = Xm.to(\"cuda:0\")\n        ym = ym.to(\"cuda:0\")\n        # 1\n        netout = net(Xm)\n        # 2 \n        loss = loss_fn(netout,ym)\n        # 3 \n        loss.backward()\n        # 4 \n        optimizr.step()\n        optimizr.zero_grad()\n    #---에폭끝---#\n    if epoc % 5 == 0:\n        net.eval()\n        s =0\n        for Xm,ym in dl_train:        \n            Xm = Xm.to(\"cuda:0\")\n            ym = ym.to(\"cuda:0\")        \n            logits = net(Xm).data \n            s = s+ (logits.argmax(axis=1) == ym.argmax(axis=1)).float().sum()\n        acc = s / len(X)\n        print(f\"# of epochs = {epoc},train_acc = {acc:.4f}\") \n\n# of epochs = 5,train_acc = 0.8588\n# of epochs = 10,train_acc = 0.8659\n# of epochs = 15,train_acc = 0.8779\n# of epochs = 20,train_acc = 0.8831\n# of epochs = 25,train_acc = 0.8856\n# of epochs = 30,train_acc = 0.8876\n\n\n- Step4: 적합결과 시각화 및 분석\n\nnet.eval()\ns =0\nfor Xm,ym in dl_test:        \n    Xm = Xm.to(\"cuda:0\")\n    ym = ym.to(\"cuda:0\")        \n    logits = net(Xm).data \n    s = s+ (logits.argmax(axis=1) == ym.argmax(axis=1)).float().sum()\nacc = s / len(XX)\nprint(f\"test_acc = {acc:.4f}\") \n\ntest_acc = 0.8638\n\n\n🗣️ 개선이 필요해보임"
  },
  {
    "objectID": "posts/06wk-2.html#c.-약간-더-복잡한-신경망",
    "href": "posts/06wk-2.html#c.-약간-더-복잡한-신경망",
    "title": "06wk-2: (신경망) – 다항분류, FashionMNIST",
    "section": "C. 약간 더 복잡한 신경망",
    "text": "C. 약간 더 복잡한 신경망\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Flatten(),\n    torch.nn.Linear(784,256),\n    torch.nn.ReLU(),\n    torch.nn.Linear(256,10)\n).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\n\n\nfor epoc in range(1,31):\n    net.train()\n    #---에폭시작---#\n    for Xm,ym in dl_train:        \n        Xm = Xm.to(\"cuda:0\")\n        ym = ym.to(\"cuda:0\")\n        # 1\n        netout = net(Xm)\n        # 2 \n        loss = loss_fn(netout,ym)\n        # 3 \n        loss.backward()\n        # 4 \n        optimizr.step()\n        optimizr.zero_grad()\n    #---에폭끝---#\n    if epoc % 5 == 0:\n        net.eval()\n        s =0\n        for Xm,ym in dl_train:        \n            Xm = Xm.to(\"cuda:0\")\n            ym = ym.to(\"cuda:0\")        \n            logits = net(Xm).data \n            s = s+ (logits.argmax(axis=1) == ym.argmax(axis=1)).float().sum()\n        acc = s / len(X)\n        print(f\"# of epochs = {epoc},train_acc = {acc:.4f}\") \n\n# of epochs = 5,train_acc = 0.8843\n# of epochs = 10,train_acc = 0.9020\n# of epochs = 15,train_acc = 0.9176\n# of epochs = 20,train_acc = 0.9265\n# of epochs = 25,train_acc = 0.9345\n# of epochs = 30,train_acc = 0.9388\n\n\n\nnet.eval()\ns =0\nfor Xm,ym in dl_test:        \n    Xm = Xm.to(\"cuda:0\")\n    ym = ym.to(\"cuda:0\")        \n    logits = net(Xm).data \n    s = s+ (logits.argmax(axis=1) == ym.argmax(axis=1)).float().sum()\nacc = s / len(XX)\nprint(f\"test_acc = {acc:.4f}\") \n\ntest_acc = 0.8892\n\n\n🗣️ 오버피팅인 것 같고 만족스럽지도 않음"
  },
  {
    "objectID": "posts/06wk-2.html#d.-발악",
    "href": "posts/06wk-2.html#d.-발악",
    "title": "06wk-2: (신경망) – 다항분류, FashionMNIST",
    "section": "D. 발악",
    "text": "D. 발악\n- 노드를 많이..\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Flatten(),\n    torch.nn.Linear(784,4096),\n    torch.nn.Dropout(0.5),\n    torch.nn.ReLU(),\n    torch.nn.Linear(4096,10)\n).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\n\n\nfor epoc in range(1,31):\n    net.train()\n    #---에폭시작---#\n    for Xm,ym in dl_train:        \n        Xm = Xm.to(\"cuda:0\")\n        ym = ym.to(\"cuda:0\")\n        # 1\n        netout = net(Xm)\n        # 2 \n        loss = loss_fn(netout,ym)\n        # 3 \n        loss.backward()\n        # 4 \n        optimizr.step()\n        optimizr.zero_grad()\n    #---에폭끝---#\n    if epoc % 5 == 0:\n        net.eval()\n        s =0\n        for Xm,ym in dl_train:        \n            Xm = Xm.to(\"cuda:0\")\n            ym = ym.to(\"cuda:0\")        \n            logits = net(Xm).data \n            s = s+ (logits.argmax(axis=1) == ym.argmax(axis=1)).float().sum()\n        acc = s / len(X)\n        print(f\"# of epochs = {epoc},train_acc = {acc:.4f}\") \n\n# of epochs = 5,train_acc = 0.8870\n# of epochs = 10,train_acc = 0.9024\n# of epochs = 15,train_acc = 0.9116\n# of epochs = 20,train_acc = 0.9214\n# of epochs = 25,train_acc = 0.9302\n# of epochs = 30,train_acc = 0.9307\n\n\n\nnet.eval()\ns =0\nfor Xm,ym in dl_test:        \n    Xm = Xm.to(\"cuda:0\")\n    ym = ym.to(\"cuda:0\")        \n    logits = net(Xm).data \n    s = s+ (logits.argmax(axis=1) == ym.argmax(axis=1)).float().sum()\nacc = s / len(XX)\nprint(f\"test_acc = {acc:.4f}\") \n\ntest_acc = 0.8913\n\n\n🗣️ 크게 의미 없어 보임\n- 레이어를 많이..\n🗣️ 256이 괜찮은 것 같아서 많이 반복해봄\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Flatten(),\n    torch.nn.Linear(784,256),\n    torch.nn.ReLU(),\n    torch.nn.Linear(256,256),\n    torch.nn.ReLU(),\n    torch.nn.Linear(256,256),\n    torch.nn.ReLU(), \n    torch.nn.Linear(256,256),\n    torch.nn.ReLU(),    \n    torch.nn.Linear(256,10)\n).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\n\n\nfor epoc in range(1,31):\n    net.train()\n    #---에폭시작---#\n    for Xm,ym in dl_train:        \n        Xm = Xm.to(\"cuda:0\")\n        ym = ym.to(\"cuda:0\")\n        # 1\n        netout = net(Xm)\n        # 2 \n        loss = loss_fn(netout,ym)\n        # 3 \n        loss.backward()\n        # 4 \n        optimizr.step()\n        optimizr.zero_grad()\n    #---에폭끝---#\n    if epoc % 5 == 0:\n        net.eval()\n        s =0\n        for Xm,ym in dl_train:        \n            Xm = Xm.to(\"cuda:0\")\n            ym = ym.to(\"cuda:0\")        \n            logits = net(Xm).data \n            s = s+ (logits.argmax(axis=1) == ym.argmax(axis=1)).float().sum()\n        acc = s / len(X)\n        print(f\"# of epochs = {epoc},train_acc = {acc:.4f}\") \n\n# of epochs = 5,train_acc = 0.8881\n# of epochs = 10,train_acc = 0.9154\n# of epochs = 15,train_acc = 0.9240\n# of epochs = 20,train_acc = 0.9303\n# of epochs = 25,train_acc = 0.9511\n# of epochs = 30,train_acc = 0.9547\n\n\n\nnet.eval()\ns =0\nfor Xm,ym in dl_test:        \n    Xm = Xm.to(\"cuda:0\")\n    ym = ym.to(\"cuda:0\")        \n    logits = net(Xm).data \n    s = s+ (logits.argmax(axis=1) == ym.argmax(axis=1)).float().sum()\nacc = s / len(XX)\nprint(f\"test_acc = {acc:.4f}\") \n\ntest_acc = 0.8907\n\n\n\ntest_acc 90% 넘기는게 엄청 힘들다"
  },
  {
    "objectID": "posts/06wk-2.html#f.-합성곱신경망",
    "href": "posts/06wk-2.html#f.-합성곱신경망",
    "title": "06wk-2: (신경망) – 다항분류, FashionMNIST",
    "section": "F. 합성곱신경망",
    "text": "F. 합성곱신경망\n- https://brunch.co.kr/@hvnpoet/109\n🗣️(\n\n선형변환 + 비선형변환\nLinear transform 대신 Convolution2d (그냥 2d 버전의 선형변환이라고 일단 생각)\ninput channel: 흑백 1개, 컬러 3개\noutput channel: input을 몇개로 변환할지\n비선형변환은 ReLU로 진행\nkernel_size: 다음에 설명 (윈도우 크기)\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(in_channels=1, out_channels=64, kernel_size=5),\n    torch.nn.ReLU(),\n)\n\n\nX.shape\n\ntorch.Size([60000, 1, 28, 28])\n\n\n\nnet(X).shape\n\ntorch.Size([60000, 64, 24, 24])\n\n\n\n숫자가 이런 식으로 변함\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(in_channels=1, out_channels=64, kernel_size=5),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d(kernel_size=2)\n)\n\n\nX.shape\n\ntorch.Size([60000, 1, 28, 28])\n\n\n\nnet(X).shape\n\ntorch.Size([60000, 64, 12, 12])\n\n\n\n이 상태에서 Flatten()\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(in_channels=1, out_channels=64, kernel_size=5),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d(kernel_size=2),\n    torch.nn.Flatten()\n)\n\n\nX.shape\n\ntorch.Size([60000, 1, 28, 28])\n\n\n\nnet(X).shape\n\ntorch.Size([60000, 9216])\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(in_channels=1, out_channels=64, kernel_size=5),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d(kernel_size=2),\n    torch.nn.Flatten(),\n    torch.nn.Linear(9216,10) # 이 이후는 softmax function\n)\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(in_channels=1 ,out_channels=64,kernel_size=5),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d(kernel_size=2),    \n    torch.nn.Flatten(),\n    torch.nn.Linear(9216,10)\n).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\n\n층을 한 번 더 반복\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(in_channels=1 ,out_channels=64,kernel_size=5),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d(kernel_size=2),\n    torch.nn.Conv2d(in_channels=64 ,out_channels=64,kernel_size=5), # 64\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d(kernel_size=2),    \n    torch.nn.Flatten(),\n    torch.nn.Linear(9216,10)\n).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\n\n\n# net(X.to(\"cuda:0\")) # error\n\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (60000x1024 and 9216x10)\n\n)🗣️\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(in_channels=1 ,out_channels=64,kernel_size=5),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d(kernel_size=2),\n    torch.nn.Conv2d(in_channels=64 ,out_channels=64,kernel_size=5),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d(kernel_size=2),    \n    torch.nn.Flatten(),\n    torch.nn.Linear(1024,10)\n).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\n\n\n🗣️\n\n예전에는 Flatten을 하고 시작\n이번에는 Flatten 전에 이미지 자체를 처리하는 과정을 거쳤더니\n(Flatten 다음은 차원만 맞춤 - 선형변환)\n결과가 잘 나옴\n\n\n\nfor epoc in range(1,31):\n    net.train()\n    #---에폭시작---#\n    for Xm,ym in dl_train:        \n        Xm = Xm.to(\"cuda:0\")\n        ym = ym.to(\"cuda:0\")\n        # 1\n        netout = net(Xm)\n        # 2 \n        loss = loss_fn(netout,ym)\n        # 3 \n        loss.backward()\n        # 4 \n        optimizr.step()\n        optimizr.zero_grad()\n    #---에폭끝---#\n    if epoc % 5 == 0:\n        net.eval()\n        s =0\n        for Xm,ym in dl_train:        \n            Xm = Xm.to(\"cuda:0\")\n            ym = ym.to(\"cuda:0\")        \n            logits = net(Xm).data \n            s = s+ (logits.argmax(axis=1) == ym.argmax(axis=1)).float().sum()\n        acc = s / len(X)\n        print(f\"# of epochs = {epoc},train_acc = {acc:.4f}\") \n\n# of epochs = 5,train_acc = 0.9065\n# of epochs = 10,train_acc = 0.9326\n# of epochs = 15,train_acc = 0.9438\n# of epochs = 20,train_acc = 0.9552\n# of epochs = 25,train_acc = 0.9689\n# of epochs = 30,train_acc = 0.9756\n\n\n\n🗣️ 표현력 자체는 좋음\n🗣️ 오버피팅 감안하더라도 정확도가 올라감 (90% 넘음)\n\n\nnet.eval()\ns =0\nfor Xm,ym in dl_test:        \n    Xm = Xm.to(\"cuda:0\")\n    ym = ym.to(\"cuda:0\")        \n    logits = net(Xm).data \n    s = s+ (logits.argmax(axis=1) == ym.argmax(axis=1)).float().sum()\nacc = s / len(XX)\nprint(f\"test_acc = {acc:.4f}\") \n\ntest_acc = 0.9151\n\n\n\n\n\n\n\n\nNote\n\n\n\n네트워크를 아래와 같이 설정했더니\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(in_channels=1 ,out_channels=64,kernel_size=5),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d(kernel_size=2),\n    torch.nn.Conv2d(in_channels=64 ,out_channels=64,kernel_size=5),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d(kernel_size=2),    \n    torch.nn.Flatten(),\n    torch.nn.Linear(1024,10)\n)\n결과가 좋네? 정도만 알면됩니다."
  },
  {
    "objectID": "posts/06wk-2.html#footnotes",
    "href": "posts/06wk-2.html#footnotes",
    "title": "06wk-2: (신경망) – 다항분류, FashionMNIST",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nprob=sig(logit)↩︎\nprobs=soft(logits)↩︎"
  },
  {
    "objectID": "posts/01wk-2.html",
    "href": "posts/01wk-2.html",
    "title": "01wk-2, 02wk-1: (회귀) – 회귀모형, 손실함수, 파이토치를 이용한 추정",
    "section": "",
    "text": "📘 Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\n📝 🗣️ ✍️ 🔬 ❓"
  },
  {
    "objectID": "posts/01wk-2.html#a.-아이스-아메리카노-가짜자료",
    "href": "posts/01wk-2.html#a.-아이스-아메리카노-가짜자료",
    "title": "01wk-2, 02wk-1: (회귀) – 회귀모형, 손실함수, 파이토치를 이용한 추정",
    "section": "A. 아이스 아메리카노 (가짜자료)",
    "text": "A. 아이스 아메리카노 (가짜자료)\n- 카페주인인 박혜원씨는 온도와 아이스아메리카노 판매량이 관계가 있다는 것을 알았다. 구체적으로는\n\n“온도가 높아질 수록 (=날씨가 더울수록) 아이스아메리카노의 판매량이 증가”\n\n한다는 사실을 알게 되었다. 이를 확인하기 위해서 아래와 같이 100개의 데이터를 모았다.\n\ntemp = [-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n        -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n        -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n        -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n        -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n        -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n        -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n         0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n         0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n         0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n         1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n         1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n         2.3935,  2.6056,  2.6057,  2.6632]\n\n\nsales= [-8.5420, -6.5767, -5.9496, -4.4794, -4.2516, -3.1326, -4.0239, -4.1862,\n        -3.3403, -2.2027, -2.0262, -2.5619, -1.3353, -2.0466, -0.4664, -1.3513,\n        -1.6472, -0.1089, -0.3071, -0.6299, -0.0438,  0.4163,  0.4166, -0.0943,\n         0.2662,  0.4591,  0.8905,  0.8998,  0.6314,  1.3845,  0.8085,  1.2594,\n         1.1211,  1.9232,  1.0619,  1.3552,  2.1161,  1.1437,  1.6245,  1.7639,\n         1.6022,  1.7465,  0.9830,  1.7824,  2.1116,  2.8621,  2.1165,  1.5226,\n         2.5572,  2.8361,  3.3956,  2.0679,  2.8140,  3.4852,  3.6059,  2.5966,\n         2.8854,  3.9173,  3.6527,  4.1029,  4.3125,  3.4026,  3.2180,  4.5686,\n         4.3772,  4.3075,  4.4895,  4.4827,  5.3170,  5.4987,  5.4632,  6.0328,\n         5.2842,  5.0539,  5.4538,  6.0337,  5.7250,  5.7587,  6.2020,  6.5992,\n         6.4621,  6.5140,  6.6846,  7.3497,  8.0909,  7.0794,  6.8667,  7.4229,\n         7.2544,  7.1967,  9.5006,  9.0339,  7.4887,  9.0759, 11.0946, 10.3260,\n        12.2665, 13.0983, 12.5468, 13.8340]\n\n🗣️ 음수 판매량은 일단 무시\n여기에서 temp는 평균기온이고, sales는 아이스아메리카노 판매량이다. 평균기온과 판매량의 그래프를 그려보면 아래와 같다.\n\nplt.plot(temp,sales,'o')\n\n\n\n\n\n\n\n\n🗣️ 약간의 오차는 있지만 선으로 보임\n오늘 바깥의 온도는 0.5도 이다. 아이스 아메라카노를 몇잔정도 만들어 두면 좋을까?\n🗣️ 이 그래프를 보고 4.5잔 정도로 짐작 가능"
  },
  {
    "objectID": "posts/01wk-2.html#b.-가짜자료를-만든-방법",
    "href": "posts/01wk-2.html#b.-가짜자료를-만든-방법",
    "title": "01wk-2, 02wk-1: (회귀) – 회귀모형, 손실함수, 파이토치를 이용한 추정",
    "section": "B. 가짜자료를 만든 방법",
    "text": "B. 가짜자료를 만든 방법\n- 방법1: \\(y_i= w_0+w_1 x_i +\\epsilon_i = 2.5 + 4x_i +\\epsilon_i, \\quad i=1,2,\\dots,n\\)\n🗣️(\nxi = 온도 = temp\nyi = 판매량 = sales\n판매량 = 2.5 + 4*온도 + 오차\n\ntorch.randn(10) # 표준정규분포에서 10개 값 추출, 길이가 10인 vector (column vector인지 row vector인지는 모름)\n\ntensor([-0.4351, -0.4066,  1.2577, -1.1443,  0.3941, -0.2229, -0.4337,  0.8736,\n         0.6216,  1.0963])\n\n\n\ntorch.randn(100).sort() # 100개 값을 정렬 / 앞은 정렬된 값, 뒤는 인덱스\n\ntorch.return_types.sort(\nvalues=tensor([-3.3450e+00, -2.3363e+00, -1.7533e+00, -1.6534e+00, -1.4996e+00,\n        -1.4218e+00, -1.3757e+00, -1.3314e+00, -1.1898e+00, -1.1594e+00,\n        -1.1386e+00, -1.0975e+00, -1.0961e+00, -1.0899e+00, -1.0250e+00,\n        -9.7851e-01, -9.1254e-01, -8.8307e-01, -8.7845e-01, -8.4915e-01,\n        -7.4344e-01, -7.0972e-01, -7.0845e-01, -6.8746e-01, -6.7488e-01,\n        -6.6512e-01, -6.0503e-01, -5.8921e-01, -5.4838e-01, -5.1363e-01,\n        -5.0996e-01, -4.7537e-01, -4.3955e-01, -3.5707e-01, -3.4237e-01,\n        -3.4013e-01, -3.2890e-01, -3.2078e-01, -3.0216e-01, -2.9112e-01,\n        -2.8083e-01, -2.4387e-01, -2.4171e-01, -2.0109e-01, -1.9779e-01,\n        -1.9549e-01, -5.8397e-02, -2.5842e-02, -2.2056e-02,  2.0055e-03,\n         1.0348e-02,  2.2201e-02,  2.5445e-02,  2.6868e-02,  6.2116e-02,\n         1.3408e-01,  1.5172e-01,  2.0091e-01,  2.3218e-01,  2.5000e-01,\n         2.7442e-01,  2.8144e-01,  3.4857e-01,  3.7494e-01,  4.4520e-01,\n         4.8013e-01,  4.9466e-01,  5.0311e-01,  5.7595e-01,  6.2995e-01,\n         6.3221e-01,  6.5666e-01,  6.5788e-01,  6.6027e-01,  6.7909e-01,\n         7.1635e-01,  7.1752e-01,  7.2141e-01,  8.0059e-01,  8.0419e-01,\n         8.0801e-01,  8.1830e-01,  8.9444e-01,  9.6222e-01,  9.9973e-01,\n         1.1303e+00,  1.1527e+00,  1.2046e+00,  1.2086e+00,  1.2469e+00,\n         1.2752e+00,  1.2872e+00,  1.3125e+00,  1.4296e+00,  1.4390e+00,\n         1.5448e+00,  1.6129e+00,  1.6454e+00,  1.6769e+00,  1.7580e+00]),\nindices=tensor([81, 19, 56, 18, 89, 54, 27, 31, 65, 85, 94, 47,  0,  7,  8, 57, 14, 92,\n         3, 12, 86, 48,  9, 82, 62, 78,  1, 28, 32, 67, 21, 53, 10, 30, 23,  5,\n        88, 24, 63, 40, 20, 77, 34, 87, 99, 80, 41,  4, 69, 90, 35, 72, 58, 11,\n        22, 42, 76, 95, 74, 38, 46, 59, 91, 68, 43, 44, 50, 96, 51,  6, 29, 13,\n        66, 49, 73,  2, 70, 93, 97, 16, 15, 98, 55, 33, 39, 84, 25, 61, 17, 64,\n        45, 26, 75, 71, 79, 37, 60, 83, 36, 52]))\n\n\n\na = torch.randn(100).sort()\ntype(a)\n\ntorch.return_types.sort\n\n\n\na[0]\n\ntensor([-2.8188e+00, -2.7746e+00, -2.5355e+00, -2.4374e+00, -2.2716e+00,\n        -2.1492e+00, -1.8555e+00, -1.8281e+00, -1.6228e+00, -1.6164e+00,\n        -1.5151e+00, -1.5046e+00, -1.4989e+00, -1.4708e+00, -1.4605e+00,\n        -1.3748e+00, -1.3521e+00, -1.3183e+00, -1.2710e+00, -1.2416e+00,\n        -1.1459e+00, -1.0949e+00, -1.0907e+00, -1.0903e+00, -1.0481e+00,\n        -1.0313e+00, -1.0079e+00, -1.0003e+00, -9.9874e-01, -9.9081e-01,\n        -9.8943e-01, -9.7448e-01, -9.4772e-01, -9.4282e-01, -9.1282e-01,\n        -8.8605e-01, -8.6893e-01, -8.5283e-01, -7.8566e-01, -7.7867e-01,\n        -7.6961e-01, -7.4827e-01, -6.6928e-01, -6.3990e-01, -5.9842e-01,\n        -5.8057e-01, -5.5388e-01, -5.1941e-01, -5.1005e-01, -4.9040e-01,\n        -4.7796e-01, -3.9862e-01, -3.9854e-01, -3.8835e-01, -3.7719e-01,\n        -3.6587e-01, -3.0923e-01, -3.0278e-01, -2.5337e-01, -2.1358e-01,\n        -1.7441e-01, -1.4875e-01, -5.6163e-02, -3.3250e-02, -2.6646e-02,\n         2.1082e-03,  1.3442e-02,  9.5665e-02,  1.0434e-01,  1.2852e-01,\n         1.8255e-01,  2.2326e-01,  2.3160e-01,  2.5853e-01,  2.6803e-01,\n         3.3640e-01,  3.6288e-01,  3.7120e-01,  3.8451e-01,  4.0117e-01,\n         4.3763e-01,  4.5193e-01,  5.2404e-01,  6.1333e-01,  6.7461e-01,\n         6.8081e-01,  8.0477e-01,  9.1538e-01,  9.5395e-01,  1.0907e+00,\n         1.1139e+00,  1.1281e+00,  1.2559e+00,  1.2686e+00,  1.3258e+00,\n         1.3563e+00,  1.3864e+00,  1.5558e+00,  1.6258e+00,  2.1654e+00])\n\n\n\nx,_ = torch.randn(100).sort() # 언패킹\nx\n\ntensor([-2.8984, -2.6607, -2.2449, -2.2072, -2.1918, -2.1538, -1.9428, -1.9416,\n        -1.8612, -1.6956, -1.6357, -1.4785, -1.4322, -1.2127, -1.1737, -0.9456,\n        -0.9244, -0.8456, -0.8190, -0.7925, -0.7609, -0.7305, -0.7011, -0.6806,\n        -0.6442, -0.6117, -0.6059, -0.5994, -0.4920, -0.4066, -0.3879, -0.3867,\n        -0.3612, -0.3604, -0.3142, -0.3112, -0.2940, -0.2812, -0.2753, -0.2665,\n        -0.2145, -0.2106, -0.1864, -0.1633, -0.1470, -0.1331, -0.1316, -0.0994,\n        -0.0954, -0.0717, -0.0586, -0.0329,  0.0095,  0.0182,  0.0214,  0.0915,\n         0.0952,  0.1077,  0.1124,  0.1612,  0.1614,  0.1969,  0.2003,  0.3242,\n         0.3424,  0.3925,  0.4078,  0.4468,  0.4536,  0.5199,  0.5238,  0.5563,\n         0.5595,  0.6236,  0.6372,  0.6451,  0.6630,  0.7122,  0.7335,  0.7569,\n         0.7589,  0.8969,  0.9318,  0.9552,  1.0023,  1.0198,  1.1083,  1.1978,\n         1.2752,  1.2928,  1.3265,  1.3825,  1.4325,  1.5292,  1.6095,  1.6239,\n         1.7316,  2.0886,  2.3070,  3.2682])\n\n\n\ntorch.manual_seed(43052) # 값 고정\nx,_ = torch.randn(100).sort()\nx\n\ntensor([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n        -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n        -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n        -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n        -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n        -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n        -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n         0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n         0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n         0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n         1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n         1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n         2.3935,  2.6056,  2.6057,  2.6632])\n\n\n\n# temp # 위의 temp와 x는 동일\n\n\nsales[0] # -2.4821 * 4 + 2.5 + 오차\n\n-8.542\n\n\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\neps = torch.randn(100)*0.5 # 오차 만들기 (분산 작게하려고 0.5를 곱함)\n\n\n-2.4821 * 4 + 2.5 + eps[0] # sales[0]과 동일\n\ntensor(-8.5420)\n\n\n\nx[1] * 4 + 2.5 + eps[1] # 두 번째 값\n\ntensor(-6.5767)\n\n\n\nsales[1]\n\n-6.5767\n\n\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\neps = torch.randn(100)*0.5\ny = x * 4 + 2.5 + eps # 브로드캐스팅 이용\n\n\ntemp[:5],sales[:5]\n\n([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792],\n [-8.542, -6.5767, -5.9496, -4.4794, -4.2516])\n\n\n\nx[:5], y[:5] # 위와 동일\n\n(tensor([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792]),\n tensor([-8.5420, -6.5767, -5.9496, -4.4794, -4.2516]))\n\n\n)🗣️\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\neps = torch.randn(100)*0.5\ny = x * 4 + 2.5 + eps\n\n\nx[:5], y[:5]\n\n(tensor([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792]),\n tensor([-8.5420, -6.5767, -5.9496, -4.4794, -4.2516]))\n\n\n- 방법2: \\({\\bf y}={\\bf X}{\\bf W} +\\boldsymbol{\\epsilon}\\)\n\n\\({\\bf y}=\\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\dots \\\\ y_n\\end{bmatrix}, \\quad {\\bf X}=\\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\dots \\\\ 1 & x_n\\end{bmatrix}, \\quad {\\bf W}=\\begin{bmatrix} 2.5 \\\\ 4 \\end{bmatrix}, \\quad \\boldsymbol{\\epsilon}= \\begin{bmatrix} \\epsilon_1 \\\\ \\dots \\\\ \\epsilon_n\\end{bmatrix}\\)\n\n🗣️(\n\\(y_1 = 2.5 + 4x_1 + \\epsilon_1\\)\n\\(y_2 = 2.5 + 4x_2 + \\epsilon_2\\)\n\\(y_3 = 2.5 + 4x_3 + \\epsilon_3\\) … 을 위와 같이 표현할 수 있음\n방법1은 scalar로 표현, 방법2는 matrix로 표현\n\ny # 길이가 100인 vector (방법1) / 방법2는 (100,1) matrix로 표현되어야 함\n\ntensor([-8.5420, -6.5767, -5.9496, -4.4794, -4.2516, -3.1326, -4.0239, -4.1862,\n        -3.3403, -2.2027, -2.0262, -2.5619, -1.3353, -2.0466, -0.4664, -1.3513,\n        -1.6472, -0.1089, -0.3071, -0.6299, -0.0438,  0.4163,  0.4166, -0.0943,\n         0.2662,  0.4591,  0.8905,  0.8998,  0.6314,  1.3845,  0.8085,  1.2594,\n         1.1211,  1.9232,  1.0619,  1.3552,  2.1161,  1.1437,  1.6245,  1.7639,\n         1.6022,  1.7465,  0.9830,  1.7824,  2.1116,  2.8621,  2.1165,  1.5226,\n         2.5572,  2.8361,  3.3956,  2.0679,  2.8140,  3.4852,  3.6059,  2.5966,\n         2.8854,  3.9173,  3.6527,  4.1029,  4.3125,  3.4026,  3.2180,  4.5686,\n         4.3772,  4.3075,  4.4895,  4.4827,  5.3170,  5.4987,  5.4632,  6.0328,\n         5.2842,  5.0539,  5.4538,  6.0337,  5.7250,  5.7587,  6.2020,  6.5992,\n         6.4621,  6.5140,  6.6846,  7.3497,  8.0909,  7.0794,  6.8667,  7.4229,\n         7.2544,  7.1967,  9.5006,  9.0339,  7.4887,  9.0759, 11.0946, 10.3260,\n        12.2665, 13.0983, 12.5468, 13.8340])\n\n\n\nx # 길이가 100인 vector (방법1) / 방법2는 [1 x] 이런식으로 표현되어야 함\n\ntensor([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n        -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n        -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n        -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n        -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n        -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n        -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n         0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n         0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n         0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n         1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n         1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n         2.3935,  2.6056,  2.6057,  2.6632])\n\n\n[1 x] 만들기\n\ntorch.ones(100) , x # 길이가 100인 vector\n\n(tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n tensor([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n         -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n         -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n         -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n         -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n         -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n         -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n          0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n          0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n          0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n          1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n          1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n          2.3935,  2.6056,  2.6057,  2.6632]))\n\n\n\n# torch.stack([torch.ones(100) , x]) # 좌우로 합치기 위해 stack 사용\nprint(torch.stack([torch.ones(100) , x]).shape)\n# torch.stack([torch.ones(100) , x], axis=1) # 원했던 결과\nprint(torch.stack([torch.ones(100) , x], axis=1).shape)\n\n# torch.stack([torch.ones(100) , x]).T # 다른 방법\nprint(torch.stack([torch.ones(100) , x]).T.shape)\n\ntorch.Size([2, 100])\ntorch.Size([100, 2])\ntorch.Size([100, 2])\n\n\n\nX = torch.stack([torch.ones(100) , x], axis=1)\nW = torch.tensor([[2.5],[4.0]])\ny = X@W + eps.reshape(100,1)\ny.shape\n\ntorch.Size([100, 1])\n\n\n\nsales[:5]\n\n[-8.542, -6.5767, -5.9496, -4.4794, -4.2516]\n\n\n\ny[:5,0]\n\ntensor([-8.5420, -6.5767, -5.9496, -4.4794, -4.2516])\n\n\nsales와 y 동일\n🔬🗣️(\n\n(참고) 인덱싱 관련 설명\n\n\ny[:5]\n\ntensor([[-8.5420],\n        [-6.5767],\n        [-5.9496],\n        [-4.4794],\n        [-4.2516]])\n\n\ny는 matrix 이므로\n\ny[:5,[0]] # column vector처럼 됨\n\ntensor([[-8.5420],\n        [-6.5767],\n        [-5.9496],\n        [-4.4794],\n        [-4.2516]])\n\n\n\n# y[:,:] # y가 그대로 나옴\n\n\ny[:5,:] # 그 중 5개만\n\ntensor([[-8.5420],\n        [-6.5767],\n        [-5.9496],\n        [-4.4794],\n        [-4.2516]])\n\n\n나열 방식만 다르고 값은 sales와 똑같음\n)🔬🗣️\n\nX = torch.stack([torch.ones(100) , x], axis=1) # (100, 2)\nW = torch.tensor([[2.5],[4.0]]) # (2, 1)\ny = X@W + eps.reshape(100,1) # (100, 1)\nx # 아마도 (100,) \n\ntensor([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n        -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n        -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n        -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n        -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n        -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n        -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n         0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n         0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n         0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n         1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n         1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n         2.3935,  2.6056,  2.6057,  2.6632])\n\n\n(100,)을 (100,1)로 바꾸고 싶음\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\neps = torch.randn(100)*0.5\ny = x * 4 + 2.5 + eps\n\nX = torch.stack([torch.ones(100) , x], axis=1) # (100, 2)\nW = torch.tensor([[2.5],[4.0]]) # (2, 1)\ny = X@W + eps.reshape(100,1) # (100, 1)\nx = X[:,[1]]\n\n\nx[:5], y[:5]\n\n(tensor([[-2.4821],\n         [-2.3621],\n         [-1.9973],\n         [-1.6239],\n         [-1.4792]]),\n tensor([[-8.5420],\n         [-6.5767],\n         [-5.9496],\n         [-4.4794],\n         [-4.2516]]))\n\n\n\ntemp[:5], sales[:5]\n\n([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792],\n [-8.542, -6.5767, -5.9496, -4.4794, -4.2516])\n\n\n방법 2처럼 matrix로도 가능하다는 것을 확인\n)🗣️\n📝(\nX = torch.stack([torch.ones(100),x],axis=1)\nW = torch.tensor([[2.5],[4.0]])\ny = X@W + eps.reshape(100,1)\nx = X[:,[1]]\n✍️ 편의상 위의 코드는 실행시키지 않음\n\nX[:5,:], y[:5,:]\n\n(tensor([[ 1.0000, -2.4821],\n         [ 1.0000, -2.3621],\n         [ 1.0000, -1.9973],\n         [ 1.0000, -1.6239],\n         [ 1.0000, -1.4792]]),\n tensor([[-8.5420],\n         [-6.5767],\n         [-5.9496],\n         [-4.4794],\n         [-4.2516]]))\n\n\n)📝\n- ture와 observed data를 동시에 시각화\n🗣️(\n\nplt.plot(temp, sales) # 이러한 데이터를 관측했다고 생각\n\n\n\n\n\n\n\n\n\nplt.plot(temp, sales, 'o') # scatter plot\n\n\n\n\n\n\n\n\n\nplt.plot(x, y, 'o') # 위와 동일\n\n\n\n\n\n\n\n\nx에서 y로 가는 패턴을 찾고 싶음\n\nplt.plot(x, y, 'o', label=\"observed data\") # 관측한 값\nplt.legend()\n\n\n\n\n\n\n\n\n\nplt.plot(x, y, 'o', label=\"observed data\") # 점선 + epsilon(통계적으로 설명할 수 없는 현상, random)\nplt.plot(x, 2.5 + 4*x, '--', label=\"true\") # 원래 관측되어야 했던 값\nplt.legend()\n\n\n\n\n\n\n\n\n\n하고 싶은 것\n\n카페 주인: 온도가 0.5일 때 얼마나 팔릴지 알고 싶음\n가장 간단: 0.5를 점선 위에 올린 후 y 값을 예측 (0.5 * 4 + 2.5 = 4.5)\n하지만 실제로는 파란색만 알고 있으므로 위의 방법은 cheating\n\n\n\nplt.plot(x,y,'o',label=r\"observed data: $(x_i,y_i)$\")\n#plt.plot(x,2.5+4*x,'--',label=r\"true: $(x_i, 4x_i+2.5)$ // $y=4x+2.5$ \")\nplt.legend()\n\n\n\n\n\n\n\n\n\n하고 싶은 것\n\n위의 상태에서 적당한 추세선을 그려서 추정\n\n\n)🗣️\n\nplt.plot(x,y,'o',label=r\"observed data: $(x_i,y_i)$\")\n#plt.plot(x,2.5+4*x,'--',label=r\"true: $(x_i, 4x_i+2.5)$ // $y=4x+2.5$ \")\nplt.legend()"
  },
  {
    "objectID": "posts/01wk-2.html#c.-회귀분석이란",
    "href": "posts/01wk-2.html#c.-회귀분석이란",
    "title": "01wk-2, 02wk-1: (회귀) – 회귀모형, 손실함수, 파이토치를 이용한 추정",
    "section": "C. 회귀분석이란?",
    "text": "C. 회귀분석이란?\n- 클리셰: 관측한 자료 \\((x_i,y_i)\\) 가 있음 \\(\\to\\) 우리는 \\((x_i,y_i)\\)의 관계를 파악하여 새로운 \\(x\\)가 왔을때 그것에 대한 예측값(predicted value) \\(\\hat{y}\\)을 알아내는 법칙을 알고 싶음 \\(\\to\\) 관계를 파악하기 위해서 \\((x_i, y_i)\\)의 산점도를 그려보니 \\(x_i\\)와 \\(y_i\\)는 선형성을 가지고 있다는 것이 파악됨 \\(\\to\\) 오차항이 등분산성을 가지고 어쩌고 저쩌고… \\(\\to\\) 하여튼 \\((x_i,y_i)\\) 를 “적당히 잘 관통하는” 어떠한 하나의 추세선을 잘 추정하면 된다.\n- 회귀분석이란 산점도를 보고 적당한 추세선을 찾는 것이다. 좀 더 정확하게 말하면 \\((x_1,y_1) \\dots (x_n,y_n)\\) 으로 \\(\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\) 를 최대한 \\(\\begin{bmatrix} 2.5 \\\\ 4 \\end{bmatrix}\\)와 비슷하게 찾는 것.\n\ngiven data : \\(\\big\\{(x_i,y_i) \\big\\}_{i=1}^{n}\\)\nparameter: \\({\\bf W}=\\begin{bmatrix} w_0 \\\\ w_1 \\end{bmatrix}\\)\nestimated parameter: \\({\\bf \\hat{W}}=\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\)\n\n🗣️ y = ax + b 꼴에서 a, b를 정함\n- 더 쉽게 말하면 아래의 그림을 보고 “적당한” 추세선을 찾는 것이다.\n\nplt.plot(x,y,'o',label=r\"observed data: $(x_i,y_i)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n- 추세선을 그리는 행위 = \\((w_0,w_1)\\)을 선택하는일"
  },
  {
    "objectID": "posts/01wk-2.html#a.-1단계-최초의-점선",
    "href": "posts/01wk-2.html#a.-1단계-최초의-점선",
    "title": "01wk-2, 02wk-1: (회귀) – 회귀모형, 손실함수, 파이토치를 이용한 추정",
    "section": "A. 1단계 – 최초의 점선",
    "text": "A. 1단계 – 최초의 점선\n🗣️(\n\nWhat = torch.tensor([[-5.0],[10.0]], requires_grad=True)\nWhat\n\ntensor([[-5.],\n        [10.]], requires_grad=True)\n\n\n\nyhat = X@What\n\n\n# plt.plot(x, y, 'o')\n# plt.plot(x, yhat, '--')\n\n\n실행시키면 error\nrequires_grad=True를 없애면 error 발생 X\nrequires_grad=True\n\n미분이 필요함을 나타내는 옵션\n지금은 의미를 정확하게 알 수 없지만 편의상 이름을 미분꼬리표라고 부르겠음\n\n\n\nWhat+1\n\ntensor([[-4.],\n        [11.]], grad_fn=&lt;AddBackward0&gt;)\n\n\n\n꼬리표가 바뀌긴 하나 큰 지장은 없음\n\n\n# yhat\n\n\nyhat을 실행시켜도 계산을 잘 되나 꼬리표가 있음\n꼬리표 때문에 그래프를 그리면 error가 발생\n해결책 (꼬리표를 제거한다고 생각, 꼬리표가 있으면 계산은 가능하나 그래프 그리기 불가능)\n\nRuntimeError: Can’t call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n.data\n\n\n\n# yhat.detach()\n\n\n# yhat.data\n\n\nplt.plot(x, y, 'o')\nplt.plot(x, yhat.detach(), '--') # 그림을 그리기 위해서 yhat의 미분꼬리표를 제거\n\n\n\n\n\n\n\n\n)🗣️\n🗣️ 그냥 아무 직선을 그음 (2단계만 잘 되면 상관 X)\n\nWhat = torch.tensor([[-5.0],[10.0]])\nWhat\n\ntensor([[-5.],\n        [10.]])\n\n\n\nyhat = X@What \n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.data,'--')"
  },
  {
    "objectID": "posts/01wk-2.html#b.-2단계-update",
    "href": "posts/01wk-2.html#b.-2단계-update",
    "title": "01wk-2, 02wk-1: (회귀) – 회귀모형, 손실함수, 파이토치를 이용한 추정",
    "section": "B. 2단계 – update",
    "text": "B. 2단계 – update\n- ’적당한 정도’를 판단하기 위한 장치: loss function 도입!\n\\[loss=\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2=\\sum_{i=1}^{n}(y_i-(\\hat{w}_0+\\hat{w}_1x_i))^2=({\\bf y}-{\\bf\\hat{y}})^\\top({\\bf y}-{\\bf\\hat{y}})=({\\bf y}-{\\bf X}{\\bf \\hat{W}})^\\top({\\bf y}-{\\bf X}{\\bf \\hat{W}})\\]\n🗣️ loss는 \\((\\hat{w}_0, \\hat{w}_1)\\)을 입력으로 받음. loss 값을 최소로 만드는 \\((\\hat{w}_0, \\hat{w}_1)\\)을 찾으면 됨.\n- loss 함수의 특징: 위 그림의 주황색 점선이 ‘적당할 수록’ loss값이 작다.\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat)\n\n\n\n\n\n\n\n\n\nloss = torch.sum((y-yhat)**2)\nloss\n\ntensor(8587.6875)\n\n\n- 우리의 목표: 이 loss(=8587.6275)을 더 줄이자.\n\n궁극적으로는 아예 모든 조합 \\((\\hat{w}_0,\\hat{w}_1)\\)에 대하여 가장 작은 loss를 찾으면 좋겠다.\n\n- 문제의 치환: 생각해보니까 우리의 문제는 아래와 같이 수학적으로 단순화 되었다.\n\n가장 적당한 주황색 선을 찾자 \\(\\to\\) \\(loss(\\hat{w}_0,\\hat{w}_1)\\)를 최소로하는 \\((\\hat{w}_0,\\hat{w}_1)\\)의 값을 찾자.\n\n- 수정된 목표: \\(loss(\\hat{w}_0,\\hat{w}_1)\\)를 최소로 하는 \\((\\hat{w}_0,\\hat{w}_1)\\)을 구하라.\n\n단순한 수학문제가 되었다. 이것은 마치 \\(f(x,y)\\)를 최소화하는 \\((x,y)\\)를 찾으라는 것임.\n함수의 최대값 혹은 최소값을 컴퓨터를 이용하여 찾는것을 “최적화”라고 하며 이는 산공교수님들이 가장 잘하는 분야임. (산공교수님들에게 부탁하면 잘해줌, 산공교수님들은 보통 최적화해서 어디에 쓸지보다 최적화 자체에 더 관심을 가지고 연구하심)\n최적화를 하는 방법? 경사하강법\n\n# 경사하강법 아이디어 (1차원)\n\n임의의 점을 찍는다.\n그 점에서 순간기울기를 구한다. (접선) &lt;– 미분\n순간기울기(=미분계수)의 부호를 살펴보고 부호와 반대방향으로 움직인다.\n\n\n팁: 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 조절한다. \\(\\to\\) \\(\\alpha\\)를 도입\n\n\n최종수식: \\(\\hat{w} \\leftarrow \\hat{w} - \\alpha \\times \\frac{\\partial}{\\partial w}loss(w)\\)\n\n#\n🗣️(\n\n보폭: step size\n함수를 최고차항이 양수인 2차 함수로 생각하면 이해하기 쉬움\n\nx에서 a만큼 오른쪽으로 이동: x + a\nx에서 a만큼 왼쪽으로 이동: x - a\n미분계수가 0인쪽으로 움직일 때\n\nx가 오른쪽에 있으면 미분계수 &gt; 0\nx가 왼쪽에 있으면 미분계수 &lt; 0\n\n미분계수가 0인쪽과 가까울수록 접선 기울기의 절대값이 작아짐 -&gt; \\(\\alpha\\)로 조절\n\n\\(\\alpha\\)가 너무 작으면 수렴 속도가 느릴 수 있고, 너무 크면 수렴을 안할 수 있음\n\n예시) \\(f(x) = x^2\\) 에서 \\(x=2\\)일 때 \\(\\alpha = 1\\)이면 \\(x\\)는 \\(-2\\)와 \\(2\\)만 왔다갔다 함\n\n\n)🗣️\n# 경사하강법 아이디어 (2차원)\n\n\n임의의 점을 찍는다.\n그 점에서 순간기울기를 구한다. (접평면) &lt;– 편미분\n순간기울기(=미분계수)의 부호를 살펴보고 부호와 반대방향으로 각각 움직인다.\n\n\n팁: 여기서도 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 각각 조절한다. \\(\\to\\) \\(\\alpha\\)를 도입.\n\n#\n🗣️(\n\n여기서 임의의 점은 2차원\n편미분: 하나만 변수로 보고 나머지 고정\n\n이후 1차원 방식과 동일\n어떤 방향(왼쪽, 오른쪽)으로 얼마나 갈 지(\\(\\alpha\\))\n\n\n)🗣️\n- 경사하강법 = loss를 줄이도록 \\({\\bf \\hat{W}}\\)를 개선하는 방법\n\n업데이트 공식: 수정값 = 원래값 - \\(\\alpha\\) \\(\\times\\) 기울어진크기(=미분계수)\n여기에서 \\(\\alpha\\)는 전체적인 보폭의 크기를 결정한다. 즉 \\(\\alpha\\)값이 클수록 한번의 update에 움직이는 양이 크다.\n\n🗣️ \\(\\alpha\\)를 ML에서는 학습률이라고 함\n- loss는 \\(\\hat{\\bf W} =\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\) 에 따라서 값이 바뀌는 함수로 해석가능하고 구체적인 형태는 아래와 같음.\n\\[ loss(\\hat{w}_0,\\hat{w}_1) := loss(\\hat{\\bf W})=\\sum_{i=1}^{n}(y_i-(\\hat{w}_0+\\hat{w}_1x_i))^2=({\\bf y}-{\\bf X}{\\bf \\hat{W}})^\\top({\\bf y}-{\\bf X}{\\bf \\hat{W}})\\]\n따라서 구하고 싶은것은 아래와 같음\n\\[\\hat{\\bf W}^{LSE} = \\underset{\\bf \\hat{W}}{\\operatorname{argmin}} ~ loss(\\hat{\\bf W})\\]\n\n\n\n\n\n\nWarning\n\n\n\n아래의 수식\n\\[\\hat{\\bf W}^{LSE} = \\underset{\\bf \\hat{W}}{\\operatorname{argmin}} ~ loss(\\hat{\\bf W})\\]\n은 아래와 같이 표현해도 무방합니다.\n\\[\\hat{\\bf W} = \\underset{\\bf W}{\\operatorname{argmin}} ~ loss({\\bf W})\\]\n마치 함수 \\(f(\\hat{x})=({\\hat x}-1)^2\\) 을 \\(f(x)=(x-1)^2\\) 이라고 표현할 수 있는 것 처럼요..\n\n\n여기까지 01wk-2에서 수업했습니다~\n\n여기부터는 02wk-1에서..\n# 지난시간 복습\n\n# x,X,W,y // X = [1 x], W = [w0, w1]' # 회귀분석에서는 W=β\n# 회귀모형: y=X@W+ϵ = X@β+ϵ\n# true: E(y)=X@W\n# observed: (x,y)\n# estimated W = What = [w0hat, w1hat]' &lt;-- 아무값이나넣었음.. \n# estimated y = yhat = X@What = X@β̂ \n# loss = yhat이랑 y랑 얼마나 비슷한지 = sum((y-yhat)^2)\n# (x,y) 보고 최적의 선분을 그리는것 = loss를 가장 작게 만드는 What = [w0hat, w1hat] 를 찾는것\n# 전략: (1) 아무 What나 찍는다 (2) 그거보다 더 나은 What을 찾는다. (3) 1-2를 반복한다. \n# 전략2가 어려운데, 이를 수행하는 방법이 경사하강법 \n# 경사하강법 알고리즘: 더나은What = 원래What - 0.1*미분값\n\n\nWhat = torch.tensor([[-5.0],[10.0]])\nWhat\n\ntensor([[-5.],\n        [10.]])\n\n\n\nyhat = X@What \nplt.plot(x,y,'o')\nplt.plot(x,yhat,'--')\n\n\n\n\n\n\n\n\n\nloss = torch.sum((y-yhat)**2)\nloss\n\ntensor(8587.6875)\n\n\n복습끝~\n#\n- 더 나은 선으로 업데이트하기 위해서는 공식 “더나은What = 원래What - 0.1*미분값” 를 적용해야하고 이를 위해서는 미분값을 계산할 수 있어야 함.\n\n\n\n\n\n\nImportant\n\n\n\n경사하강법을 좀 더 엄밀하게 써보자. 경사하강법은 \\(loss(\\hat{\\bf W})\\)를 최소로 만드는 \\(\\hat{\\bf W}\\)를 컴퓨터로 구하는 방법인데, 구체적으로는 아래와 같다.\n1. 임의의 점 \\(\\hat{\\bf W}\\)를 찍는다.\n2. 그 점에서 순간기울기를 구한다. 즉 \\(\\left.\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})\\right|_{{\\bf W}=\\hat{\\bf W}}\\) 를 계산한다.\n3. \\(\\hat{\\bf W}\\)에서의 순간기울기의 부호를 살펴보고 부호와 반대방향으로 움직인다. 이때 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 각각 조절한다. 즉 아래의 수식에 따라 업데이트 한다.\n\\[\\hat{\\bf W} \\leftarrow \\hat{\\bf W} - \\alpha \\times \\left.\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})\\right|_{{\\bf W}=\\hat{\\bf W}}\\]\n여기에서 맨 마지막 수식을 간단하게 쓴 것이 더나은What = 원래What - 0.1*미분값 이다.\n\n\n- 미분값을 계산하는 방법1\n\n# 손실 8587.6875 를 계산하는 또 다른 방식\ndef l(w0,w1):\n    yhat = w0 + w1*x\n    return torch.sum((y-yhat)**2)\n\n\nl(-5,10)\n\ntensor(8587.6875)\n\n\n🗣️(\n\n굳이 함수를 만든 이유: 미분하려고\n편미분 구현\n\nl(-5,10)\n(l(w0+h,w1) - l(w0,w1))/h: 도함수\n\n\n)🗣️\n\nh=0.001\nprint((l(-5+h,10) - l(-5,10))/h)\nprint((l(-5,10+h) - l(-5,10))/h)\n\ntensor(-1341.7968)\ntensor(1190.4297)\n\n\n일단 이거로 업데이트해볼까?\n\n# 더나은What = 원래What - 0.1*미분값\n# [-5,10] - 0.001 * [-1341.7968,1190.4297]\n\n\nsssss = What - 0.001 * torch.tensor([[-1341.7968],[1190.4297]])\nsssss\n\ntensor([[-3.6582],\n        [ 8.8096]])\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What,'-') # 원래What: 주황색\nplt.plot(x,X@sssss,'-') # 더나은What: 초록색\n\n\n\n\n\n\n\n\n\n잘 된 것 같긴한데..\n미분구하는게 너무 어려워..\n다른 방법 없을까?\n\n\n\n\n\n\n\nImportant\n\n\n\n사실 이 방법은\n\n\\(\\frac{\\partial}{\\partial w_0}loss(w_0,w_1) \\approx \\frac{loss(w_0+h,w_1)-loss(w_0,w_1)}{h}\\)\n\\(\\frac{\\partial}{\\partial w_1}loss(w_0,w_1) \\approx \\frac{loss(w_0,w_1+h)-loss(w_0,w_1)}{h}\\)\n\n이 계산을 이용하여\n\\[\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W}):= \\begin{bmatrix} \\frac{\\partial}{\\partial w_0} \\\\ \\frac{\\partial}{\\partial w_1}\\end{bmatrix}loss({\\bf W}) =  \\begin{bmatrix} \\frac{\\partial}{\\partial w_0}loss({\\bf W}) \\\\ \\frac{\\partial}{\\partial w_1}loss({\\bf W})\\end{bmatrix}  =  \\begin{bmatrix} \\frac{\\partial}{\\partial w_0}loss(w_0,w_1) \\\\ \\frac{\\partial}{\\partial w_1}loss(w_0,w_1)\\end{bmatrix}\\]\n를 계산한 것이라 볼 수 있죠\n\n\n- 미분값을 계산하는 방법2\n\n## 약간의 지식이 필요함. \n# loss = (y-XWhat)'(y-XWhat)\n# = (y'-What'X')(y-XWhat)\n# = y'y-y'XWhat -What'X'y + What'X'XWhat \n# loss를 What으로 미분\n# loss' = -X'y - X'y + 2X'XWhat\n\n❓ 행렬 미분 복습 필요\n\n-2*X.T@y + 2*X.T@X@What\n\ntensor([[-1342.2524],\n        [ 1188.9302]])\n\n\n🗣️ 약간의 오차는 있지만 위와 비슷 (그러나 방법1, 방법2 말고 다른 방법을 쓰고 싶음)\n\n\n\n\n\n\nImportant\n\n\n\n이 방법은 \\(loss({\\bf W})\\)의 미분을 구할수 있어야 사용가능합니다. 즉\n\\[\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})= -2{\\bf X}^\\top {\\bf y} + 2{\\bf X}^\\top {\\bf X}{\\bf W}\\]\n를 계산할 수 있어야 합니다.\n\n\n- 미분값을 계산하는 방법3 – 이 패턴을 외우세여\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nWhat\n\ntensor([[-5.],\n        [10.]], requires_grad=True)\n\n\n\nyhat = X@What\nloss = torch.sum((y-yhat)**2)\nloss\n\ntensor(8587.6875, grad_fn=&lt;SumBackward0&gt;)\n\n\n🗣️ 꼬리표가 있긴하지만 결과는 위와 동일\n\nloss.backward() # loss를 미분하라.. 꼬리표가 있게 한 What으로.. \n\n🗣️(\n\nloss를 What으로 미분\n일반적으로 미분을 하면 도함수가 나오지만, 이 경우는 도함수에서 현재 What값을 대입한 결과가 나옴\n정확히 말하면 What에 해당하는 접선의 기울기\n실행해도 실행결과는 나오지 않음. 결과는 What.grad에 저장되어 있음\n\n)🗣️\n\nWhat.grad\n\ntensor([[-1342.2524],\n        [ 1188.9305]])\n\n\n- 위의 코드를 다시 복습해보자.\n– loss.backward()실행전 –\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nyhat = X@What\nloss = torch.sum((y-yhat)**2)\n\n\nWhat.data, What.grad\n\n(tensor([[-5.],\n         [10.]]),\n None)\n\n\n🗣️ .backward()를 실행하지 않아서 .grad에 아무 값도 없음(None으로 초기화 됨)\n– loss.backward()실행후 –\n\nloss.backward()\n\n\nWhat.data, What.grad\n\n(tensor([[-5.],\n         [10.]]),\n tensor([[-1342.2524],\n         [ 1188.9305]]))\n\n\n🗣️(\n\n.backward()를 실행하니 .grad에 기울기 값이 계산되어 업데이트 됨\nloss.backward(): What.grad &lt;- What에서 미분값 인줄 알았으나 사실은\nloss.backward(): What.grad &lt;- What.grad + What에서 미분값 (즉, 누적을 시켜서 더함)\n\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\n\n\nyhat = X@What\nloss = torch.sum((y-yhat)**2)\nloss.backward()\n\n\nWhat.data, What.grad\n\n(tensor([[-5.],\n         [10.]]),\n tensor([[-1342.2524],\n         [ 1188.9305]]))\n\n\n\nyhat = X@What\nloss = torch.sum((y-yhat)**2)\nloss.backward()\n\n\nWhat.data, What.grad\n\n(tensor([[-5.],\n         [10.]]),\n tensor([[-2684.5049],\n         [ 2377.8611]]))\n\n\n\n두 배가 됨\n왜?\n\n산공: 알고리즘 상에서는 What.grad의 값은 loss.backward()를 할때마다 초기화가 맞음 (이론적으로는 이게 맞음)\n컴공: 그러면 나중에 계산 효율이 안 좋아짐 (웬만하면 계산한 미분값을 갖고 있고 싶음, 필요 없으면 따로 초기화하면 됨)\n통계: 최적화와 미분 빨리하는 것에 관심 X\n\n\n)🗣️\n✍️ 이후 원활한 코드 실행을 위한 코드 (의미X)\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nyhat = X@What\nloss = torch.sum((y-yhat)**2)\n\nWhat.data, What.grad\n\nloss.backward()\n\nWhat.data, What.grad\n\n(tensor([[-5.],\n         [10.]]),\n tensor([[-1342.2524],\n         [ 1188.9305]]))\n\n\n# 1회 업데이트 과정을 차근차근 시각화하며 정리해보자.\n\nalpha = 0.001 \nprint(f\"{What.data} -- 수정전\")\nprint(f\"{-alpha*What.grad} -- 수정하는폭\")\nprint(f\"{What.data-alpha*What.grad} -- 수정후\")\nprint(f\"{torch.tensor([[2.5],[4]])} -- 참값(이건 비밀~~)\")\n\ntensor([[-5.],\n        [10.]]) -- 수정전\ntensor([[ 1.3423],\n        [-1.1889]]) -- 수정하는폭\ntensor([[-3.6577],\n        [ 8.8111]]) -- 수정후\ntensor([[2.5000],\n        [4.0000]]) -- 참값(이건 비밀~~)\n\n\n🗣️(\n\n\\(\\alpha\\)를 0.001로 잡은 이유: 미분값이 1000 단위로 나와서 그대로 넣으면 원하는 결과가 안 나올 것 같음\n\n잘 수렴될때까지 시행착오를 겪으며 해봐야 함\n\n수정하는 폭: 위 그래프에서 주황색 선\n수정 후: 위 그래프에서 초록색 선\n수정 전보다 수정 후가 참값에 가까우므로 올바른 방향을 진행되고 있음을 알 수 있음\n\n)🗣️\n\nWbefore = What.data\nWafter = What.data - alpha * What.grad \nWbefore, Wafter\n\n(tensor([[-5.],\n         [10.]]),\n tensor([[-3.6577],\n         [ 8.8111]]))\n\n\n\nplt.plot(x,y,'o',label=r'observed data')\nplt.plot(x,X@Wbefore,'--', label=r\"$\\hat{\\bf y}_{before}={\\bf X}@\\hat{\\bf W}_{before}$\")\nplt.plot(x,X@Wafter,'--', label=r\"$\\hat{\\bf y}_{after}={\\bf X}@\\hat{\\bf W}_{after}$\")\nplt.legend()\n\n\n\n\n\n\n\n\n#"
  },
  {
    "objectID": "posts/01wk-2.html#c.-3단계-iteration-learn-estimate-bfhat-w",
    "href": "posts/01wk-2.html#c.-3단계-iteration-learn-estimate-bfhat-w",
    "title": "01wk-2, 02wk-1: (회귀) – 회귀모형, 손실함수, 파이토치를 이용한 추정",
    "section": "C. 3단계 – iteration (=learn = estimate \\(\\bf{\\hat W}\\))",
    "text": "C. 3단계 – iteration (=learn = estimate \\(\\bf{\\hat W}\\))\n- 이제 1단계와 2단계를 반복만하면된다. 그래서 아래와 같은 코드를 작성하면 될 것 같은데…\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True) # 최초의 직선을 만드는 값\nfor epoc in range(30):\n    yhat = X@What \n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - 0.001 * What.grad\n돌려보면 잘 안된다.\n🗣️ 원래 철자는 epoch이지만 편의상 epoc으로 작성, 잘 되기 위해서는 마지막에 초기화를 해줘야 함\n- 아래와 같이 해야한다.\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True) # 최초의 직선을 만드는 값\nfor epoc in range(30):\n    yhat = X@What \n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - 0.001 * What.grad\n    What.grad = None \n\n\nplt.plot(x,y,'o',label=r\"observed: $(x_i,y_i)$\")\nplt.plot(x,X@What.data,'--o', label=r\"estimated: $(x_i,\\hat{y}_i)$ -- after 30 iterations (=epochs)\", alpha=0.4 )\nplt.legend()\n\n\n\n\n\n\n\n\n- 왜? loss.backward() 는 아래의 역할을 하는것 처럼 이해되었지만\n\nWhat.grad \\(\\leftarrow\\) What에서미분값\n\n실제로는 아래의 역할을 수행하기 때문이다. (컴퓨터공학적인 이유로..)\n\nWhat.grad \\(\\leftarrow\\) What.grad + What에서미분값\n\n\n\n\n\n\n\nNote\n\n\n\nWhat.grad \\(\\leftarrow\\) What.grad + What에서미분값 임을 확인하기 위해서.. 약간의 테스트를 했습니다.\n먼저\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True) # 최초의 직선을 만드는 값\nprint(What.data)\nprint(What.grad)\n를 확인한뒤 아래를 반복실행해봤을때\nyhat = X@What \nloss = torch.sum((y-yhat)**2)\nloss.backward() # \nprint(What.data)\nprint(What.grad)\nWhat.data와 What.grad 값이 계속 일정하게 나온다면\n\nWhat.grad \\(\\leftarrow\\) What에서미분값\n\n이와 같은 계산이 진행되는 것이겠고, What.grad의 값이 자꾸 커진다면\n\nWhat.grad \\(\\leftarrow\\) What.grad + What에서미분값\n\n이와 같은 계산이 진행되는 것이겠죠?"
  },
  {
    "objectID": "posts/04wk-2.html",
    "href": "posts/04wk-2.html",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "",
    "text": "📘 Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\n📝 🗣️ ✍️ 🔬 ❓"
  },
  {
    "objectID": "posts/04wk-2.html#a.-step은-표현-불가능하지-않나",
    "href": "posts/04wk-2.html#a.-step은-표현-불가능하지-않나",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "A. Step은 표현 불가능하지 않나?",
    "text": "A. Step은 표현 불가능하지 않나?\n# 예제1 – 일부러 이상하게 만든 취업합격률 곡선\n\ntorch.manual_seed(43052)\nx = torch.linspace(-1,1,2000).reshape(-1,1)\nu = 0*x-3\nu[x&lt;-0.2] = (15*x+6)[x&lt;-0.2]\nu[(-0.2&lt;x)&(x&lt;0.4)] = (0*x-1)[(-0.2&lt;x)&(x&lt;0.4)]\nsig = torch.nn.Sigmoid()\nv = π = sig(u)\ny = torch.bernoulli(v)\n\n\nplt.plot(x,y,'.',alpha=0.03, label=\"observed\")\nplt.plot(x,v,'--', label=\"unobserved\")\nplt.legend()\n\n\n\n\n\n\n\n\n🗣️ 뚝 떨어지는 부분은 어떻게 해야하지? 기울기를 급하게 근사하는 식으로 접근\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(512,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n🗣️ bias 여부가 직선의 개수에 영향을 주지는 X, (1,2)가 아니라 (1,512)로 하면 여러 번 꺾일 것임\n\nplt.plot(x,y,'.',alpha=0.03, label=\"observed\")\nplt.plot(x,v, label=\"true\")\nplt.plot(x,net(x).data,'--', label=\"estimated\")\nplt.legend()\n\n\n\n\n\n\n\n\n🗣️ true는 관측할 수 없음, estimated는 true와 차이가 있어도 쓸만 함\n🗣️(\n\n과정 살펴보기\n\n\nnet\n\nSequential(\n  (0): Linear(in_features=1, out_features=512, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=512, out_features=1, bias=True)\n  (3): Sigmoid()\n)\n\n\n\nnet[:1]\n\nSequential(\n  (0): Linear(in_features=1, out_features=512, bias=True)\n)\n\n\n\nnet[:3]\n\nSequential(\n  (0): Linear(in_features=1, out_features=512, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=512, out_features=1, bias=True)\n)\n\n\n\nplt.plot(net[:3](x).data) # 꺾인 선\n\n\n\n\n\n\n\n\n\n정답은 아니지만 적당히 근사적으로 쓸 수 있을 것 같음\n\n\nplt.plot(net[:4](x).data) # sigmoid 결과\n\n\n\n\n\n\n\n\n)🗣️\n#"
  },
  {
    "objectID": "posts/04wk-2.html#b.-곡선은-표현-불가능하지-않나",
    "href": "posts/04wk-2.html#b.-곡선은-표현-불가능하지-않나",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "B. 곡선은 표현 불가능하지 않나?",
    "text": "B. 곡선은 표현 불가능하지 않나?\n# 예제2 – 2024년 수능 미적30번 문제에 나온 곡선\n\\[y_i = e^{-x_i} \\times  |\\cos(5x_i)| \\times \\sin(5x) + \\epsilon_i, \\quad \\epsilon_i \\sim N(0,\\sigma^2)\\]\n\ntorch.manual_seed(43052)\nx = torch.linspace(0,2,2000).reshape(-1,1)\neps = torch.randn(2000).reshape(-1,1)*0.05\nfx = torch.exp(-1*x)* torch.abs(torch.cos(3*x))*(torch.sin(3*x))\ny = fx + eps\n\n\nplt.plot(x,y,label=\"observed\",alpha=0.5)\nplt.plot(x,fx,label=\"true\")\n\n\n\n\n\n\n\n\n🗣️ 되게 세밀하게 많이 꺾으면 곡선은 아니지만 곡선처럼 보일 수 있을 것 같음 (이 상황에서 bias 여부는 의미 X)\n🗣️(\n\n굳이 0과 1 사이로 누를 필요도 없고 - 값도 갖고 있으므로 sigmoid 취할 필요는 없을듯\ny가 0 또는 1이 아니고 연속적인 어떤 값을 계속 가질 수 있음\n\n회귀랑 비슷하므로 MSELoss 사용\nBCELoss를 여기서 사용한다면 이 경우 log에 음수가 들어갈 수도 있으므로 X\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1024), # 꺽이지않은 1024개의 직선\n    torch.nn.ReLU(), # 꺽인(렐루된) 1024개의 직선 \n    torch.nn.Linear(1024,1), # 합쳐진 하나의 꺽인 직선 \n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n## \nfor epoc in range(1000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,label=\"observed\",alpha=0.5)\nplt.plot(x,fx,label=\"true\")\nplt.plot(x,net(x).data,'--',label=\"estimated\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n잘 보면 직선 느낌이 있기는 하나 이 정도면 그럭저럭 괜찮음\n\n)🗣️\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2048), # 꺽이지않은 1024개의 직선\n    torch.nn.ReLU(), # 꺽인(렐루된) 1024개의 직선 \n    torch.nn.Linear(2048,1), # 합쳐진 하나의 꺽인 직선 \n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n## \nfor epoc in range(1000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,label=\"observed\",alpha=0.5)\nplt.plot(x,fx,label=\"true\")\nplt.plot(x,net(x).data,'--',label=\"estimated\")\nplt.legend()\n\n\n\n\n\n\n\n\n#"
  },
  {
    "objectID": "posts/04wk-2.html#a.-시벤코정리-소개",
    "href": "posts/04wk-2.html#a.-시벤코정리-소개",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "A. 시벤코정리 소개",
    "text": "A. 시벤코정리 소개\n\n\n\n\n\n\nUniversal Approximation Thm [@cybenko1989approximation]\n\n\n\n하나의 은닉층을 가지는 아래와 같은 꼴의 네트워크 \\(net: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\)는\nnet = torch.nn.Sequential(\n    torch.nn.Linear(p,???),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(???,q)\n)\n모든 보렐 가측함수 (Borel measurable function)\n\\[f: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\]\n를 원하는 정확도로 “근사”시킬 수 있다. 쉽게 말하면 \\({\\bf X} \\to {\\bf y}\\) 인 어떠한 복잡한 규칙라도 하나의 은닉층을 가진 신경망이 원하는 정확도로 근사시킨다는 의미이다. 예를들면 아래와 같은 문제를 해결할 수 있다.\n\n\\({\\bf X}_{n\\times 2}\\)는 토익점수, GPA 이고 \\({\\bf y}_{n\\times 1}\\)는 취업여부일 경우 \\({\\bf X} \\to {\\bf y}\\)인 규칙을 신경망은 항상 찾을 수 있다.\n\\({\\bf X}_{n \\times p}\\)는 주택이미지, 지역정보, 주택면적, 주택에 대한 설명 이고 \\({\\bf y}_{n\\times 1}\\)는 주택가격일 경우 \\({\\bf X} \\to {\\bf y}\\)인 규칙을 신경망은 항상 찾을 수 있다.\n\n즉 하나의 은닉층을 가진 신경망의 표현력은 거의 무한대라 볼 수 있다.\n\n\n\n🗣️\n\n시벤코가 Sigmoid로 증명했으나 ReLU를 넣어도 상관 X\nx는 p의 차원을 갖고 y는 q의 차원을 가져도 됨 (같을 필요 X)\n???: 아무 숫자를 넣어도 상관없으나 2^n 으로 쓰는게 메모리에 효율적이라고 알려져 있음\n보렐가측함수: 일반인들이 상상할 수 있는 거의 모든 함수\n이미지와 텍스트도 숫자로 바꿀 수 있음 =&gt; X를 nxp로 정리 가능\n\n\n\n보렐가측함수에 대한 정의는 측도론에 대한 이해가 있어야 가능함. 측도론에 대한 내용이 궁금하다면 https://guebin.github.io/SS2024/ 을 공부해보세요"
  },
  {
    "objectID": "posts/04wk-2.html#b.-왜-가능한가",
    "href": "posts/04wk-2.html#b.-왜-가능한가",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "B. 왜 가능한가??",
    "text": "B. 왜 가능한가??\n- 준비\n\nx = torch.linspace(-10,10,200).reshape(-1,1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=2),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(in_features=2,out_features=1)\n)\nl1,a1,l2 = net\n\n🗣️ 2개의 직선 -&gt; 2개의 곡선(Sigmoid) -&gt; 1개로 합침\n\nnet\n\nSequential(\n  (0): Linear(in_features=1, out_features=2, bias=True)\n  (1): Sigmoid()\n  (2): Linear(in_features=2, out_features=1, bias=True)\n)\n\n\n🗣️(\n\nplt.plot(x, net[0](x).data)\n\n\n\n\n\n\n\n\n\nplt.plot(x, net[:2](x).data) # Sigmoid 까지\n\n\n\n\n\n\n\n\n\nplt.plot(x, net[:3](x).data) # 합쳐서 하나의 Sigmoid\n\n\n\n\n\n\n\n\n)🗣️\n# 생각1 – 2개의 시그모이드를 우연히 잘 조합하면 하나의 계단함수를 만들 수 있다.\n🗣️ 숫자를 잘 때려맞추다보면..\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+10.00,+10.00])\n\n\nl2.weight.data = torch.tensor([[1.00,1.00]])\nl2.bias.data = torch.tensor([-1.00])\n\n\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x)[:,[0]].data,label=r\"$-5x+10$\")\nax[0].plot(x,l1(x)[:,[1]].data,label=r\"$5x+10$\")\nax[0].set_title('$l_1(x)$')\nax[0].legend()\nax[1].plot(x,a1(l1(x))[:,[0]].data,label=r\"$v_1=sig(-5x+10)$\")\nax[1].plot(x,a1(l1(x))[:,[1]].data,label=r\"$v_2=sig(5x+10)$\")\nax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[1].legend()\nax[2].plot(x,l2(a1(l1(x))).data,color='C2',label=r\"$v_1+v_2-1$\")\nax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$')\nax[2].legend()\n\n\n\n\n\n\n\n\n#\n# 생각2 – 계단함수의 모양이 꼭 생각1과 같을 필요는 없다. 중심은 이동가능하고, 높이도 조절가능하다.\n가능한 예시1\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+0.00,+20.00])\nl2.weight.data = torch.tensor([[1.00,1.00]])\nl2.bias.data = torch.tensor([-1.00])\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x).data.numpy(),'--',color='C0'); ax[0].set_title('$l_1(x)$')\nax[1].plot(x,a1(l1(x)).data.numpy(),'--',color='C0'); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[2].plot(x,l2(a1(l1(x))).data,'--',color='C0'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$');\nax[2].set_ylim(-0.1,2.6)\n\n\n\n\n\n\n\n\n가능한 예시2\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+20.00,+00.00])\nl2.weight.data = torch.tensor([[2.50,2.50]])\nl2.bias.data = torch.tensor([-2.50])\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x).data.numpy(),'--',color='C1'); ax[0].set_title('$l_1(x)$')\nax[1].plot(x,a1(l1(x)).data.numpy(),'--',color='C1'); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[2].plot(x,l2(a1(l1(x))).data,'--',color='C1'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$');\nax[2].set_ylim(-0.1,2.6)\n\n\n\n\n\n\n\n\n#\n# 생각3: 첫번째 선형변환(=\\(l_1\\))에서 out_features=4로 하고 적당한 가중치를 조정하면 \\((l_2\\circ a_1 \\circ l_1)(x)\\)의 결과로 생각2의 예시1,2를 조합한 형태도 가능할 것 같다. 즉 4개의 시그모이드를 잘 조합하면 2단계 계단함수를 만들 수 있다.\n\nl1 = torch.nn.Linear(in_features=1,out_features=4)\na1 = torch.nn.Sigmoid()\nl2 = torch.nn.Linear(in_features=4,out_features=1)\n\n\nl1.weight.data = torch.tensor([[-5.00],[5.00],[-5.00],[5.00]])\nl1.bias.data = torch.tensor([0.00, 20.00, 20.00, 0])\nl2.weight.data = torch.tensor([[1.00,  1.00, 2.50,  2.50]])\nl2.bias.data = torch.tensor([-1.0-2.5])\n\n🗣️ 숫자를 바꾸면 모양이 달라짐\n\nplt.plot(l2(a1(l1(x))).data,'--')\nplt.title(r\"$(l_2 \\circ a_1 \\circ l_1)(x)$\")\n\nText(0.5, 1.0, '$(l_2 \\\\circ a_1 \\\\circ l_1)(x)$')\n\n\n\n\n\n\n\n\n\n\n이러한 함수는 계단모양이며, 0을 제외한 서로다른 계단의 높이는 2개가 된다. 이를 간단히 “2단계-계단함수”라고 칭하자.\n\n#\n# 생각4 – \\(2m\\)개의 시그모이드를 우연히 잘 조합하면 \\(m\\)단계 계단함수를 만들 수 있다.\n- 정리1: 2개의 시그모이드를 우연히 잘 결합하면 아래와 같은 “1단계-계단함수” 함수 \\(h\\)를 만들 수 있다.\n🗣️(\n\nsig = torch.nn.Sigmoid()\n\n\n곱하는 숫자가 커질수록 급하게 올라감\n\n\nplt.plot(x, sig(0.5*(x-0.5)))\n\n\n\n\n\n\n\n\n\nplt.plot(x, sig(3*(x-0.5)))\n\n\n\n\n\n\n\n\n\nplt.plot(x, sig(200*(x-0.5)))\n\n\n\n\n\n\n\n\n\nplt.plot(x, sig(200*(x-0.5)))\nplt.plot(x, -sig(200*(x+0.5)))\n\n\n\n\n\n\n\n\n\nv1 = sig(200*(x-0.5))\nv2 = -sig(200*(x+0.5))\nplt.plot(x,v1+v2)\n\n\n\n\n\n\n\n\n\nplt.plot(x, -sig(200*(x-0.5)))\nplt.plot(x, sig(200*(x+0.5)))\n\n\n\n\n\n\n\n\n)🗣️\n\ndef h(x):\n    sig = torch.nn.Sigmoid()\n    v1 = -sig(200*(x-0.5))\n    v2 = sig(200*(x+0.5))\n    return v1+v2 \n\n\nplt.plot(x,h(x))\nplt.title(\"$h(x)$\")\n\nText(0.5, 1.0, '$h(x)$')\n\n\n\n\n\n\n\n\n\n- 정리2: 위와 같은 함수 \\(h\\)를 이용한 아래의 네트워크를 고려하자. 이는 “m단계-계단함수”를 만든다.\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{h}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n그리고 위의 네트워크와 동일한 효과를 주는 아래의 네트워크가 항상 존재함.\n🗣️ 2개의 Sigmoid를 각각 취함\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2m)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,2m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n#\n# 생각5 – 그런데 어지간한 함수형태는 구불구불한 “m단계-계단함수”로 다 근사할 수 있지 않나?\n그렇다면 아래의 네트워크에서 (1) ?? 를 충분히 키우고 (2) 적절하게 학습만 잘 된다면\nnet = torch.nn.Sequential(\n    torch.nn.Linear(p,???),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(???,q)\n)\n위의 네트워크는 거의 무한한 표현력을 가진다. –&gt; 이런식으로 증명하면 됩니당\n#"
  },
  {
    "objectID": "posts/04wk-2.html#c.-h의-위력",
    "href": "posts/04wk-2.html#c.-h의-위력",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "C. \\(h\\)의 위력",
    "text": "C. \\(h\\)의 위력\n🗣️ Sigmoid 대신 h를 하고 싶음\n- 소망: 아래와 같이 net을 설계해서, 그 위력을 체감해보고 싶은데..\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,??),\n    torch.nn.H(),\n    torch.nn.Linear(??,1)\n)\n- \\(h(x)\\)를 생성하는 클래스를 만들어보자.\n🗣️ Module: 상속 / 잘 모르겠으면 다음을 templete으로 생각하고 외우기\nclass H(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self,x):\n        # out = h(x)\n        return out\n🗣️(\n\nclass H(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self,x):\n        def h(x):\n            sig = torch.nn.Sigmoid()\n            v1 = -sig(200*(x-0.5))\n            v2 = sig(200*(x+0.5))\n            return v1+v2 \n        out = h(x)\n        return out \n\n\nmy_h = H()\n\n\nplt.plot(x, my_h(x))\n\n\n\n\n\n\n\n\n)🗣️\n\nclass H(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self,x):\n        def h(x):\n            sig = torch.nn.Sigmoid()\n            v1 = -sig(200*(x-0.5))\n            v2 = sig(200*(x+0.5))\n            return v1+v2 \n        out = h(x)\n        return out \n\n\nh = H()\n\n- \\(h\\)의 위력을 체감해보자.\n# 예제1 – 스펙의 역설\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2025/main/posts/ironyofspec.csv\")\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\n\n🗣️(\n\n다음을 적합시키려고 함\n\n\nplt.plot(x,prob)\n\n\n\n\n\n\n\n\n\nnetwork 만든 이전 방식\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2,bias=False),\n    torch.nn.ReLu(),\n    torch.nn.Linear(2,1),\n    torch.Sigmoid()\n)\n\n이제 이렇게 하지 않고 다음과 같이 하려고 함\n\n)🗣️\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2048),\n    H(),\n    torch.nn.Linear(2048,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(200):\n    ## 1 \n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,prob)\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n\n\n🗣️ 적합된 것을 보면 안 맞기는 하나 따라가고는 있음\n#\n# 예제2 – 수능곡선\n\ntorch.manual_seed(43052)\nx = torch.linspace(0,2,2000).reshape(-1,1)\neps = torch.randn(2000).reshape(-1,1)*0.05\nfx = torch.exp(-1*x)* torch.abs(torch.cos(3*x))*(torch.sin(3*x))\ny = fx + eps\n\n\nplt.plot(x,y,alpha=0.5)\nplt.plot(x,fx)\n\n\n\n\n\n\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2048),\n    H(),\n    torch.nn.Linear(2048,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(200):\n    ## 1 \n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n🗣️ Sigmoid를 할 필요는 X\n\nplt.plot(x,y,alpha=0.5)\nplt.plot(x,fx)\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n\n\n#"
  },
  {
    "objectID": "posts/04wk-2.html#d.-의문점",
    "href": "posts/04wk-2.html#d.-의문점",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "D. 의문점",
    "text": "D. 의문점\n🗣️ 반박은 다음 시간\n- 이 수업을 잘 이해한 사람: 그냥 활성화함수를 \\(h\\)로 쓰면 끝 아니야? 뭐하러 relu 를 쓰는거지?\n- 딥러닝을 좀 공부해본사람1: 왜 딥러닝이 2010년이 지나서야 떳지? 1989년에 세상의 모든 문제가 풀려야 하는것 아닌가?\n- 딥러닝을 좀 공부해본사람2: 하나의 은닉층을 가진 네크워크는 잘 안쓰지 않나? 은닉층이 깊을수록 좋다고 들었는데?\n- 약간의 의구심이 있지만 아무튼 우리는 아래의 무기를 가진 꼴이 되었다.\n\n\n\n\n\n\n우리의 무기\n\n\n\n하나의 은닉층을 가지는 아래와 같은 꼴의 네트워크로,\nnet = torch.nn.Sequential(\n    torch.nn.Linear(p,???),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(???,q)\n)\n\\(f: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\) 인 모든 보렐 가측 함수 \\(f\\) 을 원하는 정확도로 “근사”시킬 수 있다."
  },
  {
    "objectID": "posts/04wk-2.html#a.-예비학습-plt.imshow",
    "href": "posts/04wk-2.html#a.-예비학습-plt.imshow",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "A. 예비학습 – plt.imshow()",
    "text": "A. 예비학습 – plt.imshow()\n- plt.imshow(..., cmap=\"gray\") 에서 ...이 shape이 (??,??)이면 흑백이미지를 출력\n🗣️(\n\nimg = torch.tensor([[255,100],\n                    [255,0]])\nplt.imshow(img)\n\n\n\n\n\n\n\n\n\nimg.shape # 2x2 픽셀\n\ntorch.Size([2, 2])\n\n\n)🗣️\n\nimg = torch.tensor([[255,100],\n                    [255,0]])\nplt.imshow(img,cmap=\"gray\")\n\n\n\n\n\n\n\n\n🗣️ 숫자가 클수록 흰색, 작을수록 검정색\n- plt.imshow(...) 에서 ...의 shape이 (??,??,3)이면 칼라이미지를 출력\n🗣️(\n\nr = torch.tensor([[255,0],\n                  [255,0]])\ng = r*0\nb = r*0\ng\n\ntensor([[0, 0],\n        [0, 0]])\n\n\n\nr.shape\n\ntorch.Size([2, 2])\n\n\n\ntorch.stack([r,g,b],axis=-1)\n\ntensor([[[255,   0,   0],\n         [  0,   0,   0]],\n\n        [[255,   0,   0],\n         [  0,   0,   0]]])\n\n\n\ntorch.stack([r,g,b],axis=-1).shape\n\ntorch.Size([2, 2, 3])\n\n\n)🗣️\n\nr = torch.tensor([[255,0],\n                  [255,0]])\ng = torch.tensor([[0,255],\n                  [0,0]])\nb = torch.tensor([[0,0],\n                  [0,255]])\nimg = torch.stack([r,g,b],axis=-1)\nplt.imshow(img)\n\n\n\n\n\n\n\n\n🔬\n\nimg\n\ntensor([[[255,   0,   0],\n         [  0, 255,   0]],\n\n        [[255,   0,   0],\n         [  0,   0, 255]]])\n\n\n- plt.imshow(...) 에서 ...의 자료형이 int인지 float인지에 따라서 인식이 다름\n🗣️ int: max를 255로 그림, float: max를 1로 그림\n\nr = torch.tensor([[1,0],\n                  [1,0]])\ng = torch.tensor([[0,1],\n                  [0,0]])\nb = torch.tensor([[0,0],\n                  [0,1]])\nimg = torch.stack([r,g,b],axis=-1)\nplt.imshow(img)\n\n\n\n\n\n\n\n\n\nimg[0]\n\ntensor([[1, 0, 0],\n        [0, 1, 0]])\n\n\n\nr = torch.tensor([[255,0],\n                  [255,0]])/255\ng = torch.tensor([[0,255],\n                  [0,0]])/255\nb = torch.tensor([[0,0],\n                  [0,255]])/255\nimg = torch.stack([r,g,b],axis=-1)\nplt.imshow(img)\n\n\n\n\n\n\n\n\n\nimg[0]\n\ntensor([[1., 0., 0.],\n        [0., 1., 0.]])"
  },
  {
    "objectID": "posts/04wk-2.html#b.-데이터",
    "href": "posts/04wk-2.html#b.-데이터",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "B. 데이터",
    "text": "B. 데이터\n- 데이터 정리코드\n\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\nto_tensor = torchvision.transforms.ToTensor()\nX3 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==3])\nX7 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==7])\nX = torch.concat([X3,X7],axis=0)\ny = torch.tensor([0.0]*len(X3) + [1.0]*len(X7))\n\n100.0%\n100.0%\n100.0%\n100.0%\n\n\n🗣️(\n\nX.shape # 4차원\n\ntorch.Size([12396, 1, 28, 28])\n\n\n\nX[0].shape\n\ntorch.Size([1, 28, 28])\n\n\n\nX[0][0].shape\n\ntorch.Size([28, 28])\n\n\n\nplt.imshow(X[0][0],cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nplt.imshow(X[0].reshape(28,28),cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nplt.imshow(X[1].reshape(28,28),cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nplt.imshow(X[-1].reshape(28,28),cmap=\"gray\") # 끝에 있는 관측치\n\n\n\n\n\n\n\n\n\nplt.imshow(X[-2].reshape(28,28),cmap=\"gray\") # 끝에 있는 관측치\n\n\n\n\n\n\n\n\n\ny\n\ntensor([0., 0., 0.,  ..., 1., 1., 1.])\n\n\n\n0은 3의 이미지, 1은 7의 이미지\n\n\nlen(y)\n\n12396\n\n\n)🗣️\n\nplt.plot(y,'.')\n\n\n\n\n\n\n\n\n- 우리는 \\({\\bf X}: (n,1,28,28)\\) 에서 \\({\\bf y}: (n,1)\\)으로 가는 맵핑을 배우고 싶음. \\(\\to\\) 이런건 배운적이 없는데?.. \\(\\to\\) 그렇다면 \\({\\bf X}:(n,784) \\to {\\bf y}:(n,1)\\) 으로 가는 맵핑을 학습하자.\n)🗣️\n\n28*28\n\n784\n\n\n[img for img in X] = [X[0], X[1], ..., X[-1]]\n\nX[0].shape\n\ntorch.Size([1, 28, 28])\n\n\n\ntorch.stack([img.reshape(-1) for img in X])\n\ntensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]])\n\n\n\ntorch.stack([img.reshape(-1) for img in X]).shape\n\ntorch.Size([12396, 784])\n\n\n\ny.shape # vector\n\ntorch.Size([12396])\n\n\n)🗣️\n\nX = torch.stack([img.reshape(-1) for img in X])\ny = y.reshape(-1,1)\n\n\nX.shape,y.shape\n\n(torch.Size([12396, 784]), torch.Size([12396, 1]))"
  },
  {
    "objectID": "posts/04wk-2.html#c.-학습",
    "href": "posts/04wk-2.html#c.-학습",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "C. 학습",
    "text": "C. 학습\n🗣️ H가 더 좋은 것을 알고 있지만 사람들이 많이 쓰는 ReLU로\n🗣️(\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\n\n\nnet(X)\n\ntensor([[0.5066],\n        [0.5152],\n        [0.4821],\n        ...,\n        [0.5168],\n        [0.5087],\n        [0.5066]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\ny와 비슷한 형태로 출력되는 것이 중요\n\n)🗣️\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(200):\n    ## 1 \n    yhat = net(X) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y,'.')\nplt.plot(net(X).data,'.',alpha=0.2)\n\n\n\n\n\n\n\n\n🗣️ 틀린 것도 있지만 맞은 것이 더 많음 (2,000번하면 더 많이 맞춤)\n🗣️(Accuracy\n\nRule 정하기\n\n\nnet(X).data &gt; 0.5\n\ntensor([[False],\n        [False],\n        [False],\n        ...,\n        [ True],\n        [ True],\n        [ True]])\n\n\n\n(net(X).data &gt; 0.5)*1.0\n\ntensor([[0.],\n        [0.],\n        [0.],\n        ...,\n        [1.],\n        [1.],\n        [1.]])\n\n\n\ny\n\ntensor([[0.],\n        [0.],\n        [0.],\n        ...,\n        [1.],\n        [1.],\n        [1.]])\n\n\n\n(y == (net(X).data &gt; 0.5)*1.0)\n\ntensor([[True],\n        [True],\n        [True],\n        ...,\n        [True],\n        [True],\n        [True]])\n\n\n\n(y == (net(X).data &gt; 0.5)*1.0).sum()\n\ntensor(12264)\n\n\n\nlen(y)\n\n12396\n\n\n\n12264/12396\n\n0.989351403678606\n\n\n\n((y == (net(X).data &gt; 0.5))*1.0).mean()\n\ntensor(0.9894)\n\n\n)🗣️\n\n((y == (net(X).data &gt; 0.5))*1.0).mean()\n\ntensor(0.9894)\n\n\n\n\n\n\n\n\nNote\n\n\n\n이미지자료의 차원\n\n칼라이미지데이터 \\({\\bf X}\\)는 (n,3,h,w) 의 차원을 가지거나 (n,h,w,3)의 차원을 가진다.\n흑백이미지데이터 \\({\\bf X}\\)는 (n,h,w) 의 차원을 가지거나 (n,1,h,w)의 차원을 가지거나 (n,h,w,1)의 차원을 가진다."
  },
  {
    "objectID": "posts/04wk-1.html",
    "href": "posts/04wk-1.html",
    "title": "04wk-1: (신경망) – 로지스틱의 한계 극복",
    "section": "",
    "text": "📘 Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\n\n\n\n\n\n\n\n\nType\nWhat It Means\nWhen I Use It\n\n\n\n\n📝 Lecture\nOriginal material from the professor’s notes\nWhen I’m referencing core concepts or provided code\n\n\n🗣️ In-Class Note\nVerbal explanations shared during the lecture\nWhen I want to record something the professor said in class but didn’t include in the official notes\n\n\n✍️ My Note\nMy thoughts, interpretations, or additional explanations\nWhen I reflect on or explain something in my own words\n\n\n🔬 Experiment\nCode I tried out or changed to explore further\nWhen I test variations or go beyond the original example\n\n\n❓ Question\nQuestions I had while studying\nWhen I want to revisit or research something more deeply\n\n\n\n📝 🗣️ ✍️ 🔬 ❓\n\n1. 강의노트 원본 및 영상 링크\nhttps://guebin.github.io/DL2025/posts/04wk-1.html\n\n\n2. Imports 📝\n\nimport torch\nimport matplotlib.pyplot as plt \nimport pandas as pd\n\n\nplt.rcParams['figure.figsize'] = (4.5, 3.0)\n\n\n\n3. 꺽인직선을 만드는 방법 📝\n지난시간복습\n\n# 오늘의 잔소리.. \n## 회귀(카페예제): yhat=직선=linr(x), 정규분포, MSEloss\n## 로지스틱(스펙과취업): yhat=곡선=sig(직선)=sig(linr(x)), 베르누이, BCELoss\n## 이름없음(스펙의역설): yhat=꺽인곡선=sig(꺽인직선)=sig(??), 베르누이, BCELOss\n\n- 로지스틱의 한계를 극복하기 위해서는 시그모이드를 취하기 전에 꺽인 그래프 모양을 만드는 기술이 있어야겠음.\n- 아래와 같은 벡터 \\({\\bf x}\\)를 가정하자.\n\nx = torch.linspace(-1,1,1001).reshape(-1,1)\nx\n\ntensor([[-1.0000],\n        [-0.9980],\n        [-0.9960],\n        ...,\n        [ 0.9960],\n        [ 0.9980],\n        [ 1.0000]])\n\n\n- 목표: 아래와 같은 벡터 \\({\\bf y}\\)를 만들어보자.\n\\[{\\bf y} = [y_1,y_2,\\dots,y_{n}]^\\top, \\quad y_i = \\begin{cases} 9x_i +4.5& x_i &lt;0 \\\\ -4.5x_i + 4.5& x_i &gt;0 \\end{cases}\\]\n\n\n\n\n\n\nCaution\n\n\n\n일반적으로 제 강의노트에서\n\n독립변수 = 설명변수 = \\({\\bf x}\\), \\({\\bf X}\\)\n종속변수 = 반응변수 = \\({\\bf y}\\)\n\n를 의미하는데요, 여기에서 \\(({\\bf x},{\\bf y})\\) 는 (독립변수,종속변수) 혹은 (설명변수,반응변수) 를 의미하는게 아닙니다.\n\n\n# 방법1 – 수식 그대로 구현\n🗣️(\n\nplt.plot(x,x,color=\"red\")\nplt.plot(x,9*x+4.5,color=\"blue\")\nplt.plot(x,-4.5*x+4.5,color=\"orange\")\n\n\n\n\n\n\n\n\n\n# (9*x+4.5)[x&lt;0]\n\n\nlen(9*x+4.5)\n\n1001\n\n\n\nlen((9*x+4.5)[x&lt;0])\n\n501\n\n\n)🗣️\n\nplt.plot(x,9*x+4.5,color=\"blue\",alpha=0.1)\nplt.plot(x[x&lt;0], (9*x+4.5)[x&lt;0],color=\"blue\")\nplt.plot(x,-4.5*x+4.5,color=\"orange\",alpha=0.1)\nplt.plot(x[x&gt;0], (-4.5*x+4.5)[x&gt;0],color=\"orange\")\n\n\n\n\n\n\n\n\n\ny = x*0\ny[x&lt;0] = (9*x+4.5)[x&lt;0]\ny[x&gt;0] = (-4.5*x+4.5)[x&gt;0]\nplt.plot(x,y)\n\n\n\n\n\n\n\n\n#\n# 방법2 – 렐루이용\n🗣️(\n\nrelu = torch.nn.ReLU()\nplt.plot(x,x,color=\"red\")\nplt.plot(x,relu(x),color=\"blue\")\n\n\n\n\n\n\n\n\n\nx가 0보다 작으면 y를 0으로 만듦\n\n\nrelu = torch.nn.ReLU()\nplt.plot(x,x,color=\"red\")\nplt.plot(x,relu(-x),color=\"blue\")\n\n\n\n\n\n\n\n\n\ny축 대칭\n\n\nrelu = torch.nn.ReLU()\nplt.plot(x,relu(x),color=\"red\")\nplt.plot(x,relu(-x),color=\"blue\")\n\n\n\n\n\n\n\n\n\nrelu = torch.nn.ReLU()\nplt.plot(x,-relu(x),color=\"red\")\nplt.plot(x,relu(-x),color=\"blue\")\n\n\n\n\n\n\n\n\n\nrelu = torch.nn.ReLU()\nplt.plot(x,-relu(x),color=\"red\")\nplt.plot(x,-relu(-x),color=\"blue\")\n\n\n\n\n\n\n\n\n\n파란색의 기울기를 9, 빨간색의 기울기를 4.5로 만들면\n\n\nrelu = torch.nn.ReLU()\nplt.plot(x,-4.5*relu(x),color=\"red\")\nplt.plot(x,-9*relu(-x),color=\"blue\")\n\n\n\n\n\n\n\n\n\ny절편이 4.5이므로\n\n\nrelu = torch.nn.ReLU()\n# plt.plot(x,-4.5*relu(x),color=\"red\")\n# plt.plot(x,-9*relu(-x),color=\"blue\")\ny = -4.5*relu(x) + -9*relu(-x)\nplt.plot(x,y)\n\n\n\n\n\n\n\n\n\nrelu = torch.nn.ReLU()\n# plt.plot(x,-4.5*relu(x),color=\"red\")\n# plt.plot(x,-9*relu(-x),color=\"blue\")\ny = -4.5*relu(x) + -9*relu(-x) + 4.5\nplt.plot(x,y)\n\n\n\n\n\n\n\n\n)🗣️\n\nrelu = torch.nn.ReLU()\n#plt.plot(x,-4.5*relu(x),color=\"red\")\n#plt.plot(x,-9*relu(-x),color=\"blue\")\ny = -4.5*relu(x) + -9*relu(-x) + 4.5\nplt.plot(x,y)\n\n\n\n\n\n\n\n\n- 좀 더 중간과정을 시각화 – (강의때 설명안했음)\n\nfig = plt.figure(figsize=(6, 4))\nspec = fig.add_gridspec(4, 3)\nax1 = fig.add_subplot(spec[:2,0]); ax1.set_title(r'$x$'); ax1.set_ylim(-1,1)\nax2 = fig.add_subplot(spec[2:,0]); ax2.set_title(r'$-x$'); ax2.set_ylim(-1,1)\nax3 = fig.add_subplot(spec[:2,1]); ax3.set_title(r'$relu(x)$'); ax3.set_ylim(-1,1)\nax4 = fig.add_subplot(spec[2:,1]); ax4.set_title(r'$relu(-x)$'); ax4.set_ylim(-1,1)\nax5 = fig.add_subplot(spec[1:3,2]); ax5.set_title(r'$-4.5 relu(x)-9 relu(-x)+4.5$')\n#---#\nax1.plot(x,'--',color='C0')\nax2.plot(-x,'--',color='C1')\nax3.plot(relu(x),'--',color='C0')\nax4.plot(relu(-x),'--',color='C1')\nax5.plot(-4.5*relu(x)-9*relu(-x)+4.5,'--',color='C2')\nfig.tight_layout()\n\n\n\n\n\n\n\n\n#\n# 방법3 – relu의 브로드캐스팅 활용\n🗣️(\n\ntorch.tensor([[1,2],[2,3],[4,-4]]) \n\ntensor([[ 1,  2],\n        [ 2,  3],\n        [ 4, -4]])\n\n\n\nplt.plot(torch.tensor([[1,2],[2,3],[4,-4]]), '--o') \n\n\n\n\n\n\n\n\n\ncolumn별로 plot이 됨\n\n\ntorch.concat([x,-x], axis=1)\n\ntensor([[-1.0000,  1.0000],\n        [-0.9980,  0.9980],\n        [-0.9960,  0.9960],\n        ...,\n        [ 0.9960, -0.9960],\n        [ 0.9980, -0.9980],\n        [ 1.0000, -1.0000]])\n\n\n\nplt.plot(torch.concat([x,-x], axis=1))\n\n\n\n\n\n\n\n\n\n여기서 relu를 하면? relu는 column wise하게 브로드캐스팅 됨\n\n\nplt.plot(relu(torch.concat([x,-x], axis=1)))\n\n\n\n\n\n\n\n\n\nu = torch.concat([x,-x], axis=1)\nv = relu(u)\nplt.plot(v)\n\n\n\n\n\n\n\n\n\nu = torch.concat([x,-x], axis=1)\nv = relu(u)\nv[:,[0]] # 첫번째 열\n\ntensor([[0.0000],\n        [0.0000],\n        [0.0000],\n        ...,\n        [0.9960],\n        [0.9980],\n        [1.0000]])\n\n\n)🗣️\n- 우리가 하고 싶은 것\n\n# y = -4.5*relu(x) + -9*relu(-x) + 4.5\n\n- 아래와 같은 아이디어로 y를 계산해도 된다.\n\nx, relu 준비\nu = [x -x]\nv = relu(u) = [relu(x), relu(-x)] = [v1 v2]\ny = -4.5*v1 + -9*v2 + 4.5\n\n\nu = torch.concat([x,-x],axis=1)\nv = relu(u)\nv1 = v[:,[0]]\nv2 = v[:,[1]]\ny = -4.5*v1 -9*v2 + 4.5 \nplt.plot(x,y)\n\n\n\n\n\n\n\n\n🗣️(\n\nBonus\n\n\nv # nx2\n\ntensor([[0.0000, 1.0000],\n        [0.0000, 0.9980],\n        [0.0000, 0.9960],\n        ...,\n        [0.9960, 0.0000],\n        [0.9980, 0.0000],\n        [1.0000, 0.0000]])\n\n\n\nv.T # 2xn, 중첩 리스트로 해석 가능\n\ntensor([[0.0000, 0.0000, 0.0000,  ..., 0.9960, 0.9980, 1.0000],\n        [1.0000, 0.9980, 0.9960,  ..., 0.0000, 0.0000, 0.0000]])\n\n\n\nv1, v2 = v.T # 언패킹, v1과 v2는 length n인 vector\ny = -4.5*v1 -9*v2 + 4.5 \ny # y 역시 vector\n\ntensor([-4.5000, -4.4820, -4.4640,  ...,  0.0180,  0.0090,  0.0000])\n\n\n\ny가 nx1이 되어야하므로\n\n\nv1, v2 = v.T\ny = -4.5*v1 -9*v2 + 4.5 \ny = y.reshape(-1,1)\nplt.plot(x,y)\n\n\n\n\n\n\n\n\n)🗣️\n#\n# 방법4 – y = linr(v)\n🗣️(\n\nv\n\ntensor([[0.0000, 1.0000],\n        [0.0000, 0.9980],\n        [0.0000, 0.9960],\n        ...,\n        [0.9960, 0.0000],\n        [0.9980, 0.0000],\n        [1.0000, 0.0000]])\n\n\n\nv @ torch.tensor([[-4.5],[-9]])\n\ntensor([[-9.0000],\n        [-8.9820],\n        [-8.9640],\n        ...,\n        [-4.4820],\n        [-4.4910],\n        [-4.5000]])\n\n\n\ny = v @ torch.tensor([[-4.5],[-9]]) + 4.5\nplt.plot(x,y)\n\n\n\n\n\n\n\n\n)🗣️\n\n# 4. y = -4.5*v1 + -9*v2 + 4.5 = [v1 v2] @ [[-4.5],[-9]] + 4.5 \n# y = -4 + 3*x = [1 x] @ [[-4],[3]]\n\n\nx \nu = torch.concat([x,-x],axis=1)\nv = relu(u) \ny = v @ torch.tensor([[-4.5],[-9]]) + 4.5 \n\n\nplt.plot(x,y)\n\n\n\n\n\n\n\n\n#\n# 방법5 – u = linr(x)\n🗣️(\n\n#u = [x -x] = x @ [[1 -1]]\n\n)🗣️\n\n# x \n# u = torch.concat([x,-x],axis=1)\n# v = relu(u) \n# y = v @ torch.tensor([[-4.5],[-9]]) + 4.5 \n\n\nx \nu = x @ torch.tensor([[1.0, -1.0]])\nv = relu(u) \ny = v @ torch.tensor([[-4.5],[-9]]) + 4.5 \n\n\nplt.plot(x,y)\n\n\n\n\n\n\n\n\n#\n# 방법6 – torch.nn.Linear()를 이용\n🗣️(\n\n# x \n# u = x @ torch.tensor([[1.0, -1.0]]) = linr(x) =&gt; l1(x) \n# v = relu(u) = a1(u)\n# y = v @ torch.tensor([[-4.5],[-9]]) + 4.5 = linr(x) =&gt; l2(v) \n\n\nl은 linear의 약자, a는 activation function의 약자\n\n\n# u = l1(x) # l1은 x-&gt;u인 선형변환: (n,1) -&gt; (n,2) 인 선형변환\nl1 = torch.nn.Linear(1,2,bias=False)\nl1.weight.data = torch.tensor([[1.0, -1.0]]).T \nl1(x)\n\ntensor([[-1.0000,  1.0000],\n        [-0.9980,  0.9980],\n        [-0.9960,  0.9960],\n        ...,\n        [ 0.9960, -0.9960],\n        [ 0.9980, -0.9980],\n        [ 1.0000, -1.0000]], grad_fn=&lt;MmBackward0&gt;)\n\n\n\nu\n\ntensor([[-1.0000,  1.0000],\n        [-0.9980,  0.9980],\n        [-0.9960,  0.9960],\n        ...,\n        [ 0.9960, -0.9960],\n        [ 0.9980, -0.9980],\n        [ 1.0000, -1.0000]])\n\n\n\n# u = l1(x) # l1은 x-&gt;u인 선형변환: (n,1) -&gt; (n,2) 인 선형변환\nl1 = torch.nn.Linear(1,2,bias=False)\nl1.weight.data = torch.tensor([[1.0, -1.0]]).T \na1 = relu \nl2 = torch.nn.Linear(2,1,bias=True) # + 4.5 =&gt; bias\nl2.weight.data = torch.tensor([[-4.5],[-9]]).T \nl2.bias.data = torch.tensor([4.5])\nu = l1(x)\nv = a1(u) \ny = l2(v) \n\n\ny\n\ntensor([[-4.5000],\n        [-4.4820],\n        [-4.4640],\n        ...,\n        [ 0.0180],\n        [ 0.0090],\n        [ 0.0000]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\nplt.plot(x,y.data)\n\n\n\n\n\n\n\n\n\npiecewise linear function 정의 (x -&gt; l1 -&gt; a1 -&gt; l2) =&gt; 한 번에 그래프 그리기 가능\n\n\npwlinr = torch.nn.Sequential(l1,a1,l2)\nplt.plot(x,pwlinr(x).data)\n\n\n\n\n\n\n\n\n)🗣️\n\n# x \n# u = x @ torch.tensor([[1.0, -1.0]]) = l1(x) \n# v = relu(u) = a1(u)\n# y = v @ torch.tensor([[-4.5],[-9]]) + 4.5 = l2(v) \n\n\n# u = l1(x) # l1은 x-&gt;u인 선형변환: (n,1) -&gt; (n,2) 인 선형변환\nl1 = torch.nn.Linear(1,2,bias=False)\nl1.weight.data = torch.tensor([[1.0, -1.0]]).T \na1 = relu \nl2 = torch.nn.Linear(2,1,bias=True)\nl2.weight.data = torch.tensor([[-4.5],[-9]]).T \nl2.bias.data = torch.tensor([4.5])\n#---#\nx\nu = l1(x)\nv = a1(u) \ny = l2(v) \n\n\nplt.plot(x,y.data)\n\n\n\n\n\n\n\n\n\npwlinr = torch.nn.Sequential(l1,a1,l2)\nplt.plot(x,pwlinr(x).data)\n\n\n\n\n\n\n\n\n#\n\n\n\n\n\n\nNote\n\n\n\n수식표현\n(1) \\({\\bf X}=\\begin{bmatrix} x_1 \\\\ \\dots \\\\ x_n \\end{bmatrix}\\)\n(2) \\(l_1({\\bf X})={\\bf X}{\\bf W}^{(1)}\\overset{bc}{+} {\\boldsymbol b}^{(1)}=\\begin{bmatrix} x_1 & -x_1 \\\\ x_2 & -x_2 \\\\ \\dots & \\dots \\\\ x_n & -x_n\\end{bmatrix}\\)\n\n\\({\\bf W}^{(1)}=\\begin{bmatrix} 1 & -1 \\end{bmatrix}\\)\n\\({\\boldsymbol b}^{(1)}=\\begin{bmatrix} 0 & 0 \\end{bmatrix}\\)\n\n(3) \\((a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big)=\\begin{bmatrix} \\text{relu}(x_1) & \\text{relu}(-x_1) \\\\ \\text{relu}(x_2) & \\text{relu}(-x_2) \\\\ \\dots & \\dots \\\\ \\text{relu}(x_n) & \\text{relu}(-x_n)\\end{bmatrix}\\)\n(4) \\((l_2 \\circ a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big){\\bf W}^{(2)}\\overset{bc}{+}b^{(2)}\\)\n\\(\\quad=\\begin{bmatrix} -4.5\\times\\text{relu}(x_1) -9.0 \\times \\text{relu}(-x_1) +4.5 \\\\ -4.5\\times\\text{relu}(x_2) -9.0 \\times\\text{relu}(-x_2) + 4.5 \\\\ \\dots \\\\ -4.5\\times \\text{relu}(x_n) -9.0 \\times\\text{relu}(-x_n)+4.5 \\end{bmatrix}\\)\n\n\\({\\bf W}^{(2)}=\\begin{bmatrix} -4.5 \\\\ -9 \\end{bmatrix}\\)\n\\(b^{(2)}=4.5\\)\n\n(5) \\(\\textup{pwlinr}({\\bf X})=(l_2 \\circ a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big){\\bf W}^{(2)}\\overset{bc}{+}b^{(2)}\\)\n\\(\\quad =\\begin{bmatrix} -4.5\\times\\text{relu}(x_1) -9.0 \\times \\text{relu}(-x_1) +4.5 \\\\ -4.5\\times\\text{relu}(x_2) -9.0 \\times\\text{relu}(-x_2) + 4.5 \\\\ \\dots \\\\ -4.5\\times \\text{relu}(x_n) -9.0 \\times\\text{relu}(-x_n)+4.5 \\end{bmatrix}\\)\n\n\n\n\n4. 스펙의역설 적합 📝\n- 다시한번 데이터 정리\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2025/main/posts/ironyofspec.csv\")\n\n🗣️(\n\ntorch.tensor(df.x)\n\ntensor([-1.0000, -0.9990, -0.9980,  ...,  0.9980,  0.9990,  1.0000],\n       dtype=torch.float64)\n\n\n\ndtype=torch.float64을 보기 싫으면 다음과 같이 하면 됨 (pytorch는 기본적으로 32형으로 저장되는 것을 원함)\n\n\ntorch.tensor(df.x).float() # vector\n\ntensor([-1.0000, -0.9990, -0.9980,  ...,  0.9980,  0.9990,  1.0000])\n\n\n\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\n\n\nplt.plot(x,y,'.',alpha=0.03)\n\n\n\n\n\n\n\n\n\nprob: 참값, 관측 불가\n\n)🗣️\n\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x,prob,'--')\n\n\n\n\n\n\n\n\n- Step1에 대한 생각: 네트워크를 어떻게 만들까? = 아키텍처를 어떻게 만들까? = 모델링\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n\n\\(l_1\\): torch.nn.Linear(1,2,bias=False)\n\\(a_1\\): torch.nn.ReLU()\n\\(l_2\\): torch.nn.Linear(2,1,bias=True)\n\\(a_2\\): torch.nn.Sigmoid()\n\n🗣️ l2까지는 꺾인 선\n- Step1-4\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2,bias=False),\n    torch.nn.ReLU(),\n    torch.nn.Linear(2,1,bias=True),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss() \noptimizr = torch.optim.Adam(net.parameters())\n\n🗣️ lr 따로 설정 안하면 default로 들어감\n\nfor epoc in range(5000):\n    ## step1\n    yhat = net(x)\n    ## step2\n    loss = loss_fn(yhat,y)\n    ## step3\n    loss.backward()\n    ## step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x,prob,'--')\nplt.plot(x,yhat.data,'--')\n\n\n\n\n\n\n\n\n한번더~\n\nfor epoc in range(5000):\n    ## step1\n    yhat = net(x)\n    ## step2\n    loss = loss_fn(yhat,y)\n    ## step3\n    loss.backward()\n    ## step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x,prob,'--')\nplt.plot(x,yhat.data,'--')\n\n\n\n\n\n\n\n\n🗣️(\n\n???\n\n\nnet\n\nSequential(\n  (0): Linear(in_features=1, out_features=2, bias=False)\n  (1): ReLU()\n  (2): Linear(in_features=2, out_features=1, bias=True)\n  (3): Sigmoid()\n)\n\n\n\nnet[0](x) # 처음 linear transform 통과\n\ntensor([[-2.8167,  3.9404],\n        [-2.8139,  3.9364],\n        [-2.8111,  3.9325],\n        ...,\n        [ 2.8111, -3.9325],\n        [ 2.8139, -3.9364],\n        [ 2.8167, -3.9404]], grad_fn=&lt;MmBackward0&gt;)\n\n\n\nplt.plot(x,net[0](x).data)\n\n\n\n\n\n\n\n\n\n기울기 튜닝이 이미 되어 있음 (생각대로라면 나중에 되어야 함)\n\n\nplt.plot(x,net[1](net[0](x)).data) # 랠루\n\n\n\n\n\n\n\n\n\nplt.plot(x,net[2](net[1](net[0](x))).data) # 2번째 linear transform\n\n\n\n\n\n\n\n\n\nplt.plot(x,net[3](net[2](net[1](net[0](x)))).data) # sigmoid\n\n\n\n\n\n\n\n\n\n원래라면 u = x @ [1 -1] 처럼 그래프 틀을 맞춰놓고 기울기를 미세조정하였지만\n기울기를 처음부터 미세조정하면서 해도 잘 맞을 수 있음\n\n이 말은 global min을 하나만 갖는 것이 아님 (여러 개의 최저값이 있을 수 있음)\n\n\n)🗣️"
  },
  {
    "objectID": "posts/07wk-1.html",
    "href": "posts/07wk-1.html",
    "title": "07wk-1: (합성곱신경망) – CNN 자랑, CNN 핵심레이어",
    "section": "",
    "text": "📘 Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\n📝 🗣️ ✍️ 🔬 ❓"
  },
  {
    "objectID": "posts/07wk-1.html#a.-성능좋음",
    "href": "posts/07wk-1.html#a.-성능좋음",
    "title": "07wk-1: (합성곱신경망) – CNN 자랑, CNN 핵심레이어",
    "section": "A. 성능좋음",
    "text": "A. 성능좋음\nFashion MNIST\n\ntrain_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True)\ntest_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True)\ntrain_dataset = torch.utils.data.Subset(train_dataset, range(5000))\ntest_dataset = torch.utils.data.Subset(test_dataset, range(1000))\nto_tensor = torchvision.transforms.ToTensor()\nX = torch.stack([to_tensor(img) for img, lbl in train_dataset]).to(\"cuda:0\")\ny = torch.tensor([lbl for img, lbl in train_dataset])\ny = torch.nn.functional.one_hot(y).float().to(\"cuda:0\")\nXX = torch.stack([to_tensor(img) for img, lbl in test_dataset]).to(\"cuda:0\")\nyy = torch.tensor([lbl for img, lbl in test_dataset])\nyy = torch.nn.functional.one_hot(yy).float().to(\"cuda:0\")\n\n🗣️(\n\nX.shape # 시간이 오래 걸려서 줄임\n\ntorch.Size([5000, 1, 28, 28])\n\n\n\ny.shape, XX.shape\n\n(torch.Size([5000, 10]), torch.Size([1000, 1, 28, 28]))\n\n\n)🗣️\n발악수준으로 설계한 신경망\n\ntorch.manual_seed(0)\nnet = torch.nn.Sequential(\n    torch.nn.Flatten(),\n    torch.nn.Linear(784,2048),\n    torch.nn.ReLU(),\n    torch.nn.Linear(2048,10)\n).to(\"cuda\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(1,500):\n    #1\n    logits = net(X)\n    #2\n    loss = loss_fn(logits, y) \n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\n(net(X).argmax(axis=1) == y.argmax(axis=1)).float().mean()\n\ntensor(1., device='cuda:0')\n\n\n\n🗣️ 학습으로는 개선될 것이 없음 (오버피팅의 끝)\n\n\n(net(XX).argmax(axis=1) == yy.argmax(axis=1)).float().mean()\n\ntensor(0.8530, device='cuda:0')\n\n\n대충대충 설계한 합성곱신경망\n\ntorch.manual_seed(0)\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,2),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d(2),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2704,10),\n).to(\"cuda\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(1,500):\n    #1\n    logits = net(X)\n    #2\n    loss = loss_fn(logits, y) \n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\n(net(X).argmax(axis=1) == y.argmax(axis=1)).float().mean()\n\ntensor(0.9666, device='cuda:0')\n\n\n\n(net(XX).argmax(axis=1) == yy.argmax(axis=1)).float().mean()\n\ntensor(0.8710, device='cuda:0')\n\n\n\n🗣️ 오버피팅도 전보다 덜 함, test acc도 개선\n\n🗣️(\n\n2704\n\n\nnet\n\nSequential(\n  (0): Conv2d(1, 16, kernel_size=(2, 2), stride=(1, 1))\n  (1): ReLU()\n  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (3): Flatten(start_dim=1, end_dim=-1)\n  (4): Linear(in_features=2704, out_features=10, bias=True)\n)\n\n\n\nnet[:-1]\n\nSequential(\n  (0): Conv2d(1, 16, kernel_size=(2, 2), stride=(1, 1))\n  (1): ReLU()\n  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (3): Flatten(start_dim=1, end_dim=-1)\n)\n\n\n\nnet[:-1](X)\n\ntensor([[0.4116, 0.4116, 0.4116,  ..., 0.6122, 0.5657, 0.2136],\n        [0.4116, 0.4128, 0.4128,  ..., 0.7154, 0.0000, 0.0000],\n        [0.4116, 0.4116, 0.4116,  ..., 0.0000, 0.0000, 0.0000],\n        ...,\n        [0.4116, 0.4116, 0.4116,  ..., 0.0000, 0.0000, 0.0000],\n        [0.4116, 0.4116, 0.4116,  ..., 0.0000, 0.0000, 0.0000],\n        [0.4116, 0.4116, 0.4116,  ..., 0.0000, 0.0000, 0.0000]],\n       device='cuda:0', grad_fn=&lt;ViewBackward0&gt;)\n\n\n\nnet[:-1](X).shape\n\ntorch.Size([5000, 2704])\n\n\n\n아무거나 써놓고 error 보고 고쳐도 됨\n참고) GPU error 나면 Kernel 재시작\n\n)🗣️"
  },
  {
    "objectID": "posts/07wk-1.html#b.-파라메터적음",
    "href": "posts/07wk-1.html#b.-파라메터적음",
    "title": "07wk-1: (합성곱신경망) – CNN 자랑, CNN 핵심레이어",
    "section": "B. 파라메터적음",
    "text": "B. 파라메터적음\n\nnet1 = torch.nn.Sequential(\n    torch.nn.Flatten(),\n    torch.nn.Linear(784,2048),\n    torch.nn.ReLU(),\n    torch.nn.Linear(2048,10)\n)\nnet2 = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,2),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d(2),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2704,10),\n)\n\n\nnet1\n\nSequential(\n  (0): Flatten(start_dim=1, end_dim=-1)\n  (1): Linear(in_features=784, out_features=2048, bias=True)\n  (2): ReLU()\n  (3): Linear(in_features=2048, out_features=10, bias=True)\n)\n\n\n\nnet1_params = list(net1.parameters())\nprint(net1_params[0].shape)\nprint(net1_params[1].shape)\nprint(net1_params[2].shape)\nprint(net1_params[3].shape)\n\ntorch.Size([2048, 784])\ntorch.Size([2048])\ntorch.Size([10, 2048])\ntorch.Size([10])\n\n\n\n2048*784 + 2048 + 10*2048 + 10 \n\n1628170\n\n\n🗣️(\n\nnet1.parameters()\n\n&lt;generator object Module.parameters at 0x7f542f6dbcf0&gt;\n\n\n\ngenerator: next가 됨 / for문을 돌리기 편한 list 비슷한 형태\n\n\nnext(net1.parameters())\n\nParameter containing:\ntensor([[-0.0290,  0.0095, -0.0319,  ..., -0.0157, -0.0290, -0.0092],\n        [-0.0115, -0.0210, -0.0033,  ..., -0.0106, -0.0276, -0.0034],\n        [-0.0270, -0.0204,  0.0075,  ..., -0.0183, -0.0071,  0.0063],\n        ...,\n        [ 0.0150, -0.0349,  0.0023,  ...,  0.0235,  0.0061,  0.0350],\n        [-0.0234, -0.0295, -0.0202,  ..., -0.0353, -0.0169, -0.0149],\n        [-0.0315,  0.0171, -0.0010,  ..., -0.0192, -0.0257,  0.0305]],\n       requires_grad=True)\n\n\n\nlist(net1.parameters())\n\n[Parameter containing:\n tensor([[-0.0290,  0.0095, -0.0319,  ..., -0.0157, -0.0290, -0.0092],\n         [-0.0115, -0.0210, -0.0033,  ..., -0.0106, -0.0276, -0.0034],\n         [-0.0270, -0.0204,  0.0075,  ..., -0.0183, -0.0071,  0.0063],\n         ...,\n         [ 0.0150, -0.0349,  0.0023,  ...,  0.0235,  0.0061,  0.0350],\n         [-0.0234, -0.0295, -0.0202,  ..., -0.0353, -0.0169, -0.0149],\n         [-0.0315,  0.0171, -0.0010,  ..., -0.0192, -0.0257,  0.0305]],\n        requires_grad=True),\n Parameter containing:\n tensor([ 0.0101, -0.0294,  0.0133,  ...,  0.0234,  0.0283, -0.0351],\n        requires_grad=True),\n Parameter containing:\n tensor([[-1.2926e-02, -9.9654e-03, -1.9394e-02,  ..., -4.1905e-05,\n          -1.8466e-02, -1.9714e-02],\n         [-5.3193e-03,  1.1461e-02,  4.5922e-03,  ..., -2.1761e-02,\n           2.1826e-02,  1.1969e-02],\n         [-4.7551e-03, -2.1131e-02, -6.7052e-03,  ...,  2.1758e-02,\n           9.4742e-03, -6.0024e-04],\n         ...,\n         [ 8.4402e-03,  3.9834e-03, -2.1895e-02,  ...,  3.9969e-03,\n           1.6158e-02, -1.3650e-02],\n         [-2.0990e-02,  5.0413e-05,  2.1427e-02,  ..., -1.6232e-02,\n          -5.4801e-03,  9.2220e-04],\n         [ 4.4055e-03,  3.9634e-03,  1.7039e-03,  ...,  1.1729e-02,\n           5.9133e-03, -1.3802e-02]], requires_grad=True),\n Parameter containing:\n tensor([ 0.0117,  0.0112, -0.0121, -0.0206, -0.0110, -0.0080,  0.0154,  0.0140,\n          0.0115,  0.0209], requires_grad=True)]\n\n\n\nnet1_params = list(net1.parameters())\nprint(net1_params[0].shape)\nprint(net1_params[1].shape) # bias\nprint(net1_params[2].shape) # what\nprint(net1_params[3].shape) # bias\n\ntorch.Size([2048, 784])\ntorch.Size([2048])\ntorch.Size([10, 2048])\ntorch.Size([10])\n\n\n)🗣️\n\n🗣️ net에 parameter가 많다: 비싸다 (net은 GPU에 다 올릴 수 밖에 없음)\n\n\nnet2\n\nSequential(\n  (0): Conv2d(1, 16, kernel_size=(2, 2), stride=(1, 1))\n  (1): ReLU()\n  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (3): Flatten(start_dim=1, end_dim=-1)\n  (4): Linear(in_features=2704, out_features=10, bias=True)\n)\n\n\n\nnet2_params = list(net2.parameters())\nprint(net2_params[0].shape)\nprint(net2_params[1].shape)\nprint(net2_params[2].shape) # what\nprint(net2_params[3].shape) # bias\n\ntorch.Size([16, 1, 2, 2])\ntorch.Size([16])\ntorch.Size([10, 2704])\ntorch.Size([10])\n\n\n\n16*1*2*2 + 16 + 10*2704 + 10 \n\n27130\n\n\n\n27130/1628170\n\n0.01666287918337766\n\n\n\n🗣️ 대충 만들었는데 성능도 좋음\n\n🗣️(\n\nnet2_params = list(net2.parameters())\nprint(net2_params[0].shape)\n\ntorch.Size([16, 1, 2, 2])\n\n\n\n차원이 많음\n\n)🗣️"
  },
  {
    "objectID": "posts/07wk-1.html#c.-유명함",
    "href": "posts/07wk-1.html#c.-유명함",
    "title": "07wk-1: (합성곱신경망) – CNN 자랑, CNN 핵심레이어",
    "section": "C. 유명함",
    "text": "C. 유명함\n- https://brunch.co.kr/@hvnpoet/109\n🗣️(\n\n딥러닝슈퍼스타 – 힌튼, 르쿤, 벤지오, 응\n\n힌튼 – DBN(사이언스) —&gt; 깊은신경망을 만들어도 학습할 수 있다.\n\n관심X\n\n힌튼 대학원생: 알렉스 –&gt; CIFAR10(이미지 데이터)\n\n다른 대학원생: 공모전 제안 -&gt; 나갔음\n\n\n내 컴퓨터가 너무 느림 –&gt; GPU\n오버피팅 –&gt; 드랍아웃\nlocal min, 기울기소멸, … (Adam 개발 전) –&gt; 렐루(벤지오 연구실 개발) 사용\n\n1등 &lt;– 1%만 올려도 대단한데 10%를 올림 (2012년)\n2014 &lt;– Adam\n\n요즘은 더 좋은 트랜스포머가 나오긴 함\n\n)🗣️"
  },
  {
    "objectID": "posts/07wk-1.html#a.-torch.nn.relu",
    "href": "posts/07wk-1.html#a.-torch.nn.relu",
    "title": "07wk-1: (합성곱신경망) – CNN 자랑, CNN 핵심레이어",
    "section": "A. torch.nn.ReLU",
    "text": "A. torch.nn.ReLU\n(예시1) 연산방법\n\nimg = torch.randn(1,1,4,4) # (4,4) 흑백이미지 한장\nrelu = torch.nn.ReLU()\n\n🗣️ (obs, channel, (img size))\n\nimg\n\ntensor([[[[ 1.4381,  0.2449, -0.6420,  2.6874],\n          [ 0.7790,  1.0558,  0.7939,  0.1099],\n          [ 0.3492,  1.7610,  1.6032,  2.4212],\n          [ 0.5416, -0.2153, -1.2772,  0.6885]]]])\n\n\n\nrelu(img)\n\ntensor([[[[1.4381, 0.2449, 0.0000, 2.6874],\n          [0.7790, 1.0558, 0.7939, 0.1099],\n          [0.3492, 1.7610, 1.6032, 2.4212],\n          [0.5416, 0.0000, 0.0000, 0.6885]]]])"
  },
  {
    "objectID": "posts/07wk-1.html#b.-torch.nn.maxpool2d",
    "href": "posts/07wk-1.html#b.-torch.nn.maxpool2d",
    "title": "07wk-1: (합성곱신경망) – CNN 자랑, CNN 핵심레이어",
    "section": "B. torch.nn.MaxPool2d",
    "text": "B. torch.nn.MaxPool2d\n(예시1) 연산방법, kernel_size 의 의미\n\nimg = torch.rand(1,1,4,4)\nmp = torch.nn.MaxPool2d(kernel_size=2)\n\n\nimg\n\ntensor([[[[0.8921, 0.4222, 0.5778, 0.2707],\n          [0.6921, 0.5627, 0.5356, 0.1048],\n          [0.5356, 0.7699, 0.9047, 0.5911],\n          [0.3617, 0.5345, 0.1218, 0.4772]]]])\n\n\n\nmp(img)\n\ntensor([[[[0.8921, 0.5778],\n          [0.7699, 0.9047]]]])\n\n\n🗣️ 2*2 window를 만든 뒤 max 값을 적음\n(예시2) 이미지크기와 딱 맞지않는 커널일경우?\n\nimg = torch.rand(1,1,5,5)\nmp = torch.nn.MaxPool2d(kernel_size=3)\n\n\nimg\n\ntensor([[[[0.9560, 0.4947, 0.1591, 0.2606, 0.9130],\n          [0.0603, 0.1255, 0.6520, 0.2504, 0.8759],\n          [0.7544, 0.5927, 0.5319, 0.2390, 0.2883],\n          [0.9470, 0.8519, 0.3501, 0.0725, 0.3881],\n          [0.7203, 0.0753, 0.8360, 0.1287, 0.9515]]]])\n\n\n\nmp(img)\n\ntensor([[[[0.9560]]]])\n\n\n\n🗣️ version마다 다름\n\npytorch는 나머지를 그냥 버림\n나머지 중 max를 적기도 함\n\n\n(예시3) 정사각형이 아닌 커널\n\nimg = torch.rand(1,1,4,4)\nmp = torch.nn.MaxPool2d(kernel_size=(4,2))\n\n\nimg\n\ntensor([[[[0.4283, 0.9998, 0.3532, 0.3085],\n          [0.3278, 0.8575, 0.3331, 0.9769],\n          [0.0239, 0.2457, 0.8468, 0.8224],\n          [0.9593, 0.1292, 0.5930, 0.3652]]]])\n\n\n\nmp(img)\n\ntensor([[[[0.9998, 0.9769]]]])"
  },
  {
    "objectID": "posts/07wk-1.html#c.-torch.nn.conv2d",
    "href": "posts/07wk-1.html#c.-torch.nn.conv2d",
    "title": "07wk-1: (합성곱신경망) – CNN 자랑, CNN 핵심레이어",
    "section": "C. torch.nn.Conv2d",
    "text": "C. torch.nn.Conv2d\n(예시1) 연산방법, stride=2\n\nimg = torch.rand(1,1,4,4) # (?, in_channels, ?, ?) \nconv = torch.nn.Conv2d(in_channels=1,out_channels=1,kernel_size=2,stride=2) # stride=2: window를 2칸 움직이라는 뜻 (바로 위의 예시와 비슷)\n\n\nimg\n\ntensor([[[[0.7679, 0.3459, 0.6509, 0.7905],\n          [0.1166, 0.8762, 0.9373, 0.8573],\n          [0.5778, 0.8702, 0.9686, 0.5854],\n          [0.1373, 0.3530, 0.0529, 0.0139]]]])\n\n\n\nconv(img)\n\ntensor([[[[ 0.1106, -0.1898],\n          [ 0.0529, -0.0976]]]], grad_fn=&lt;ConvolutionBackward0&gt;)\n\n\n??\n🗣️ 바로 유추하기 어려움\n🗣️(\n\nimg[:, :, :2, :2], img\n\n(tensor([[[[0.7679, 0.3459],\n           [0.1166, 0.8762]]]]),\n tensor([[[[0.7679, 0.3459, 0.6509, 0.7905],\n           [0.1166, 0.8762, 0.9373, 0.8573],\n           [0.5778, 0.8702, 0.9686, 0.5854],\n           [0.1373, 0.3530, 0.0529, 0.0139]]]]))\n\n\n\nimg[:, :, :2, 2:], img\n\n(tensor([[[[0.6509, 0.7905],\n           [0.9373, 0.8573]]]]),\n tensor([[[[0.7679, 0.3459, 0.6509, 0.7905],\n           [0.1166, 0.8762, 0.9373, 0.8573],\n           [0.5778, 0.8702, 0.9686, 0.5854],\n           [0.1373, 0.3530, 0.0529, 0.0139]]]]))\n\n\n\nimg[:, :, 2:, :2], img\n\n(tensor([[[[0.5778, 0.8702],\n           [0.1373, 0.3530]]]]),\n tensor([[[[0.7679, 0.3459, 0.6509, 0.7905],\n           [0.1166, 0.8762, 0.9373, 0.8573],\n           [0.5778, 0.8702, 0.9686, 0.5854],\n           [0.1373, 0.3530, 0.0529, 0.0139]]]]))\n\n\n\nimg[:, :, 2:, 2:], img\n\n(tensor([[[[0.9686, 0.5854],\n           [0.0529, 0.0139]]]]),\n tensor([[[[0.7679, 0.3459, 0.6509, 0.7905],\n           [0.1166, 0.8762, 0.9373, 0.8573],\n           [0.5778, 0.8702, 0.9686, 0.5854],\n           [0.1373, 0.3530, 0.0529, 0.0139]]]]))\n\n\n\nconv(img) # 미분꼬리표 -&gt; parameter\n\ntensor([[[[ 0.1106, -0.1898],\n          [ 0.0529, -0.0976]]]], grad_fn=&lt;ConvolutionBackward0&gt;)\n\n\n\nconv.weight.data, conv.bias.data\n\n(tensor([[[[-0.0218,  0.2400],\n           [-0.4914,  0.3394]]]]),\n tensor([-0.1958]))\n\n\n\nimg[:, :, :2, :2], img\n\n(tensor([[[[0.7679, 0.3459],\n           [0.1166, 0.8762]]]]),\n tensor([[[[0.7679, 0.3459, 0.6509, 0.7905],\n           [0.1166, 0.8762, 0.9373, 0.8573],\n           [0.5778, 0.8702, 0.9686, 0.5854],\n           [0.1373, 0.3530, 0.0529, 0.0139]]]]))\n\n\n\n-0.0218 * 0.7679\n\n-0.01674022\n\n\n\nimg[:, :, :2, :2]*conv.weight.data, img # 행렬 곱이 아니라 원소 별로 곱함 \n\n(tensor([[[[-0.0167,  0.0830],\n           [-0.0573,  0.2974]]]]),\n tensor([[[[0.7679, 0.3459, 0.6509, 0.7905],\n           [0.1166, 0.8762, 0.9373, 0.8573],\n           [0.5778, 0.8702, 0.9686, 0.5854],\n           [0.1373, 0.3530, 0.0529, 0.0139]]]]))\n\n\n\n(img[:, :, :2, :2]*conv.weight.data).sum()+conv.bias.data, conv(img)\n\n(tensor([0.1106]),\n tensor([[[[ 0.1106, -0.1898],\n           [ 0.0529, -0.0976]]]], grad_fn=&lt;ConvolutionBackward0&gt;))\n\n\n\n(img[:, :, :2, 2:]*conv.weight.data).sum()+conv.bias.data, conv(img) # 두번째 값\n\n(tensor([-0.1898]),\n tensor([[[[ 0.1106, -0.1898],\n           [ 0.0529, -0.0976]]]], grad_fn=&lt;ConvolutionBackward0&gt;))\n\n\n\n(img[:, :, 2:, :2]*conv.weight.data).sum()+conv.bias.data, conv(img) # 세번째 값\n\n(tensor([0.0529]),\n tensor([[[[ 0.1106, -0.1898],\n           [ 0.0529, -0.0976]]]], grad_fn=&lt;ConvolutionBackward0&gt;))\n\n\n\n(img[:, :, 2:, 2:]*conv.weight.data).sum()+conv.bias.data, conv(img) # 네번째 값\n\n(tensor([-0.0976]),\n tensor([[[[ 0.1106, -0.1898],\n           [ 0.0529, -0.0976]]]], grad_fn=&lt;ConvolutionBackward0&gt;))\n\n\n)🗣️\n\nconv.weight.data, conv.bias.data\n\n(tensor([[[[ 0.3095,  0.0207],\n           [-0.3130,  0.2836]]]]),\n tensor([-0.2675]))\n\n\n\n(img[:,  :,  :2,  :2] * conv.weight.data).sum()+conv.bias.data, conv(img)\n\n(tensor([-0.3077]),\n tensor([[[[-0.3077, -0.4760],\n           [ 0.0550, -0.0650]]]], grad_fn=&lt;ConvolutionBackward0&gt;))\n\n\n\n(img[:,  :,  :2,  2:] * conv.weight.data).sum()+conv.bias.data, conv(img)\n\n(tensor([-0.4760]),\n tensor([[[[-0.3077, -0.4760],\n           [ 0.0550, -0.0650]]]], grad_fn=&lt;ConvolutionBackward0&gt;))\n\n\n\n(img[:,  :,  2:,  :2] * conv.weight.data).sum()+conv.bias.data, conv(img)\n\n(tensor([0.0550]),\n tensor([[[[-0.3077, -0.4760],\n           [ 0.0550, -0.0650]]]], grad_fn=&lt;ConvolutionBackward0&gt;))\n\n\n\n(img[:,  :,  2:,  2:] * conv.weight.data).sum()+conv.bias.data, conv(img)\n\n(tensor([-0.0650]),\n tensor([[[[-0.3077, -0.4760],\n           [ 0.0550, -0.0650]]]], grad_fn=&lt;ConvolutionBackward0&gt;))"
  },
  {
    "objectID": "posts/06wk-1.html",
    "href": "posts/06wk-1.html",
    "title": "06wk-1: (신경망) – 데이터분석 코딩패턴",
    "section": "",
    "text": "📘 Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\n📝 🗣️ ✍️ 🔬 ❓"
  },
  {
    "objectID": "posts/06wk-1.html#a.-일반적인-traintest-셋팅",
    "href": "posts/06wk-1.html#a.-일반적인-traintest-셋팅",
    "title": "06wk-1: (신경망) – 데이터분석 코딩패턴",
    "section": "A. 일반적인 train/test 셋팅",
    "text": "A. 일반적인 train/test 셋팅\n- Step1: 데이터정리\n\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\ntest_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True)\nto_tensor = torchvision.transforms.ToTensor()\nX0 = torch.stack([to_tensor(img) for img, lbl in train_dataset if lbl==0])\nX1 = torch.stack([to_tensor(img) for img, lbl in train_dataset if lbl==1])\nX = torch.concat([X0,X1],axis=0).reshape(-1,784)\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\nXX0 = torch.stack([to_tensor(img) for img, lbl in test_dataset if lbl==0])\nXX1 = torch.stack([to_tensor(img) for img, lbl in test_dataset if lbl==1])\nXX = torch.concat([XX0,XX1],axis=0).reshape(-1,784)\nyy = torch.tensor([0.0]*len(XX0) + [1.0]*len(XX1)).reshape(-1,1)\n\n🗣️(\n\nX[0].shape\n\ntorch.Size([784])\n\n\n\nplt.imshow(X[0].reshape(28,28), cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nprint(y[0]) # label이 tensor 형태로 저장되어 있음\n\ntensor([0.])\n\n\n\nX만 가지고 학습을 한 뒤 XX를 가지고 확인\n\n\nX.shape, y.shape\n\n(torch.Size([12665, 784]), torch.Size([12665, 1]))\n\n\n\nXX.shape, yy.shape\n\n(torch.Size([2115, 784]), torch.Size([2115, 1]))\n\n\n)🗣️\n- Step2: 학습가능한 오브젝트들의 설정 (모델링과정 포함)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(), # (n,32)\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid() # y는 0 또는 1\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters()) # Adam은 너무 잘 맞춰서 SGD\n\n- Step3: 학습 (=적합)\n\nfor epoc in range(1,501):\n    #---에폭시작---# \n    # 1 \n    yhat = net(X) \n    # 2 \n    loss = loss_fn(yhat,y) \n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\n    #---에폭끝---# \n    #에폭마다 내가 보고싶은것들을 보여주는 코드\n    if (epoc % 50) ==0: # 50으로 나눈 나머지 = 0 =&gt; 50의 배수\n        acc = ((net(X).data &gt; 0.5) == y).float().mean().item() # item: tensor -&gt; float\n        print(f\"# of epochs={epoc}   \\t train_acc = {acc:.4f}\")\n\n# of epochs=50       train_acc = 0.4677\n# of epochs=100      train_acc = 0.4677\n# of epochs=150      train_acc = 0.4757\n# of epochs=200      train_acc = 0.5295\n# of epochs=250      train_acc = 0.6632\n# of epochs=300      train_acc = 0.7929\n# of epochs=350      train_acc = 0.8731\n# of epochs=400      train_acc = 0.9206\n# of epochs=450      train_acc = 0.9465\n# of epochs=500      train_acc = 0.9634\n\n\n🗣️ 오버피팅 비판 가능성 존재\n- Step4: 예측 & 결과분석\ntrain acc\n\n((net(X).data &gt; 0.5) == y).float().mean()\n\ntensor(0.9634)\n\n\ntest acc\n\n((net(XX).data&gt;0.5) == yy).float().mean()\n\ntensor(0.9749)\n\n\n🗣️ 실전에서 더 괜찮음\n🗣️ Step4: acc, recall, F1 score, 시각화 등\n#에폭마다 내가 보고싶은것들을 보여주는 코드\n    if (epoc % 50) ==0: # 50으로 나눈 나머지 = 0 =&gt; 50의 배수\n        acc = ((net(X).data &gt; 0.5) == y).float().mean().item() # item: tensor -&gt; float\n        Xval --&gt; # train data 자체에서 test 데이터를 나누고 정확도를 비교하며 early stopping 할 수도 있음 (오버피팅 방지)\n        print(f\"# of epochs={epoc}   \\t train_acc = {acc:.4f}\")"
  },
  {
    "objectID": "posts/06wk-1.html#b.-dropout-사용",
    "href": "posts/06wk-1.html#b.-dropout-사용",
    "title": "06wk-1: (신경망) – 데이터분석 코딩패턴",
    "section": "B. Dropout 사용",
    "text": "B. Dropout 사용\n- Step1: 데이터정리\n\npass\n\n- Step2: 학습가능한 오브젝트들의 설정 (모델링과정 포함)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.Dropout(0.9),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters())\n\n🗣️ 원래는 활성화 함수 다음이지만 ReLU 한정 전에도 사용 가능\n- Step3: 학습 (=적합)\n\nfor epoc in range(1,501):\n    net.train()\n    #---에폭시작---# \n    # 1 \n    yhat = net(X) \n    # 2 \n    loss = loss_fn(yhat,y) \n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\n    #---에폭끝---# \n    net.eval()\n    #에폭마다 내가 보고싶은것들을 보여주는 코드\n    if (epoc % 50) ==0:\n        acc = ((net(X).data &gt; 0.5) == y).float().mean().item()\n        print(f\"# of epochs={epoc}   \\t train_acc = {acc:.4f}\")\n\n# of epochs=50       train_acc = 0.4677\n# of epochs=100      train_acc = 0.4677\n# of epochs=150      train_acc = 0.4744\n# of epochs=200      train_acc = 0.5215\n# of epochs=250      train_acc = 0.6435\n# of epochs=300      train_acc = 0.7675\n# of epochs=350      train_acc = 0.8468\n# of epochs=400      train_acc = 0.8978\n# of epochs=450      train_acc = 0.9301\n# of epochs=500      train_acc = 0.9492\n\n\n\n# of epochs=50       train_acc = 0.4677\n# of epochs=100      train_acc = 0.4677\n# of epochs=150      train_acc = 0.4757 # 위의 결과와 살짝 다름\n# of epochs=200      train_acc = 0.5295\n# of epochs=250      train_acc = 0.6632\n# of epochs=300      train_acc = 0.7929\n# of epochs=350      train_acc = 0.8731\n# of epochs=400      train_acc = 0.9206\n# of epochs=450      train_acc = 0.9465\n# of epochs=500      train_acc = 0.9634\n\n- Step4: 예측 & 결과분석\ntrain acc\n\n((net(X).data &gt; 0.5) == y).float().mean()\n\ntensor(0.9492)\n\n\ntest acc\n\n((net(XX).data&gt;0.5) == yy).float().mean()\n\ntensor(0.9626)\n\n\n🗣️ 실전에서 더 괜찮음"
  },
  {
    "objectID": "posts/06wk-1.html#c.-gpu도-사용",
    "href": "posts/06wk-1.html#c.-gpu도-사용",
    "title": "06wk-1: (신경망) – 데이터분석 코딩패턴",
    "section": "C. GPU도 사용",
    "text": "C. GPU도 사용\n- Step1: 데이터정리\n\npass\n\n- Step2: 학습가능한 오브젝트들의 설정 (모델링과정 포함)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.Dropout(0.9),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters())\n\n- Step3: 학습 (=적합)\n\nfor epoc in range(1,501):\n    net.train()\n    #---에폭시작---# \n    X = X.to(\"cuda:0\")\n    y = y.to(\"cuda:0\")\n    # 1 \n    yhat = net(X) \n    # 2 \n    loss = loss_fn(yhat,y) \n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\n    #---에폭끝---# \n    net.eval()\n    #에폭마다 내가 보고싶은것들을 보여주는 코드\n    if (epoc % 50) ==0:\n        acc = ((net(X).data &gt; 0.5) == y).float().mean().item()\n        print(f\"# of epochs={epoc}   \\t train_acc = {acc:.4f}\")\n\n# of epochs=50       train_acc = 0.4677\n# of epochs=100      train_acc = 0.4677\n# of epochs=150      train_acc = 0.4745\n# of epochs=200      train_acc = 0.5223\n# of epochs=250      train_acc = 0.6441\n# of epochs=300      train_acc = 0.7686\n# of epochs=350      train_acc = 0.8469\n# of epochs=400      train_acc = 0.8979\n# of epochs=450      train_acc = 0.9302\n# of epochs=500      train_acc = 0.9492\n\n\n🗣️ 빠름\n- Step4: 예측 & 결과분석\ntrain acc\n\n((net(X).data &gt; 0.5) == y).float().mean()\n\ntensor(0.9492, device='cuda:0')\n\n\ntest acc\n\n# ((net(XX).data&gt;0.5) == yy).float().mean() # net(XX)가 문제\n\n🗣️ XX를 GPU에 올리든가, net를 CPU에 내리든가\n\nXX = XX.to(\"cuda:0\")\nyy = yy.to(\"cuda:0\") \n\n\n((net(XX).data&gt;0.5) == yy).float().mean()\n\ntensor(0.9626, device='cuda:0')"
  },
  {
    "objectID": "posts/06wk-1.html#d.-미니배치도-사용",
    "href": "posts/06wk-1.html#d.-미니배치도-사용",
    "title": "06wk-1: (신경망) – 데이터분석 코딩패턴",
    "section": "D. 미니배치도 사용",
    "text": "D. 미니배치도 사용\n- Step1: 데이터정리\n🗣️ 다시 CPU로 내림\n\nX = X.to(\"cpu\")\ny = y.to(\"cpu\")\nXX = XX.to(\"cpu\")\nyy = yy.to(\"cpu\")\n\n🗣️(\n\nX.shape\n\ntorch.Size([12665, 784])\n\n\n\nds  = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size = 16) \n\n\n# for Xm, ym in dl: # m: 미니 배치\n#     print(Xm) # 하나하나가 미니배치\n\n\n# for Xm, ym in dl: # m: 미니 배치\n#     print(Xm.shape) # 결과: torch.Size([16, 784])\n\n\nds  = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size = 16, shuffle=True) \n\n\n# for Xm, ym in dl: # m: 미니 배치\n#     print(ym) # 섞여 있음\n\n\n# for Xm, ym in dl: # m: 미니 배치\n#     print(ym.shape) # 결과: torch.Size([16, 1])\n\n)🗣️\n\nds  = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size = 16, shuffle=True) \n\n- Step2: 학습가능한 오브젝트들의 설정 (모델링과정 포함)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.Dropout(0.9),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters())\n\n- Step3: 학습 (=적합)\n\n🗣️\n\nX=X.to(“cuda:0”), y=y.to(“cuda:0”)를 할 수는 없으므로 미니배치 별로 GPU에 올림\nepoch을 500번씩 돌릴 필요는 없으므로 2번만 돌림\n\n\n\nfor epoc in range(1,3):\n    net.train()\n    #---에폭시작---# \n    for Xm,ym in dl:         \n        Xm = Xm.to(\"cuda:0\")\n        ym = ym.to(\"cuda:0\")\n        # 1 \n        ym_hat = net(Xm) \n        # 2 \n        loss = loss_fn(ym_hat,ym) \n        # 3 \n        loss.backward()\n        # 4 \n        optimizr.step()\n        optimizr.zero_grad()\n    #---에폭끝---# \n    net.eval()\n    #에폭마다 내가 보고싶은것들을 보여주는 코드\n    s = 0 \n    for Xm, ym in dl:\n        Xm = Xm.to(\"cuda:0\")\n        ym = ym.to(\"cuda:0\")\n        s = s + ((net(Xm) &gt; 0.5) == ym).float().sum()\n    acc = s/12665        \n    print(f\"# of epochs={epoc}   \\t train_acc = {acc:.4f}\")\n\n# of epochs=1        train_acc = 0.9860\n# of epochs=2        train_acc = 0.9931\n\n\n🗣️ 다른 방법 (이렇게 하면 쉬움)\nfor epoc in range(1,3):\n    net.train()\n    net.gpu()\n    #---에폭시작---# \n    for Xm,ym in dl:         \n        Xm = Xm.to(\"cuda:0\")\n        ym = ym.to(\"cuda:0\")\n        # 1 \n        ym_hat = net(Xm) \n        # 2 \n        loss = loss_fn(ym_hat,ym) \n        # 3 \n        loss.backward()\n        # 4 \n        optimizr.step()\n        optimizr.zero_grad()\n    #---에폭끝---# \n    net.eval()\n    net.to(\"cpu\")\n    #에폭마다 내가 보고싶은것들을 보여주는 코드\n    acc = ((net(X).data &gt; 0.5) == y).float().mean().item()\n    print(f\"# of epochs={epoc}   \\t train_acc = {acc:.4f}\")\n\n🗣️ 다른 방법 (net를 GPU로 유지하고 싶으면) =&gt; 강의안 코드\n\nmean 대신 sum\n하나의 미니배치에서 맞은 것의 개수를 s에 계속 누적 시킴 (for문)\nfor 문이 종료되고 s를 총 개수(X.shape)로 나누면 accuracy가 계산됨\n\n\n- Step4: 예측 & 결과분석\n🗣️(\n\n# net(X) # error\n\n\nnet은 cuda에 있고 X는 cpu에 있음\n\nnet을 cpu로 내릴 것인지, X를 cuda로 올릴 것인지 선택\n\nX를 cuda로 올리기 싫어서 미니배치를 사용하였으므로 net을 cpu로 내림\n\n)🗣️\n\nnet.to(\"cpu\")\n\nSequential(\n  (0): Linear(in_features=784, out_features=32, bias=True)\n  (1): Dropout(p=0.9, inplace=False)\n  (2): ReLU()\n  (3): Linear(in_features=32, out_features=1, bias=True)\n  (4): Sigmoid()\n)\n\n\ntrain acc\n\n((net(X) &gt; 0.5) == y).float().mean()\n\ntensor(0.9931)\n\n\ntest acc\n\n((net(XX) &gt; 0.5) == yy).float().mean()\n\ntensor(0.9967)\n\n\n🗣️ test도 잘 나오므로 오버피팅 X\n\n점점 비본질적인 코드가 늘어남 (=코드가 드럽다는 소리에요) –&gt; Trainer의 개념 등장\n\n\n🗣️\n\n딥러닝 가지고 분석하면 –&gt; 트레이너가 있는 다른 패키지를 써야함 (학부 수준)\n\n파이토치 라이트닝\n허깅페이스\n\n연구할때는 파이토치 이해해야 함"
  },
  {
    "objectID": "posts/07wk-2.html",
    "href": "posts/07wk-2.html",
    "title": "07wk-2: (합성곱신경망) – CNN 핵심레이어, CNN의 학습원리, FashionMNIST",
    "section": "",
    "text": "📘 Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\n📝 🗣️ ✍️ 🔬 ❓"
  },
  {
    "objectID": "posts/07wk-2.html#a.-torch.nn.relu",
    "href": "posts/07wk-2.html#a.-torch.nn.relu",
    "title": "07wk-2: (합성곱신경망) – CNN 핵심레이어, CNN의 학습원리, FashionMNIST",
    "section": "A. torch.nn.ReLU",
    "text": "A. torch.nn.ReLU"
  },
  {
    "objectID": "posts/07wk-2.html#b.-torch.nn.maxpool2d",
    "href": "posts/07wk-2.html#b.-torch.nn.maxpool2d",
    "title": "07wk-2: (합성곱신경망) – CNN 핵심레이어, CNN의 학습원리, FashionMNIST",
    "section": "B. torch.nn.MaxPool2d",
    "text": "B. torch.nn.MaxPool2d"
  },
  {
    "objectID": "posts/07wk-2.html#c.-torch.nn.conv2d",
    "href": "posts/07wk-2.html#c.-torch.nn.conv2d",
    "title": "07wk-2: (합성곱신경망) – CNN 핵심레이어, CNN의 학습원리, FashionMNIST",
    "section": "C. torch.nn.Conv2d",
    "text": "C. torch.nn.Conv2d\n(예시1) 연산방법, stride=2\n\nimg = torch.rand(1,1,4,4)\nconv = torch.nn.Conv2d(in_channels=1,out_channels=1,kernel_size=2,stride=2)\n\n\nimg\n\ntensor([[[[0.4497, 0.4023, 0.3869, 0.1770],\n          [0.6399, 0.1175, 0.1347, 0.2738],\n          [0.4462, 0.3765, 0.1285, 0.7986],\n          [0.9917, 0.9030, 0.9250, 0.5513]]]])\n\n\n\nconv(img)\n\ntensor([[[[ 0.0084,  0.0557],\n          [-0.1183,  0.1122]]]], grad_fn=&lt;ConvolutionBackward0&gt;)\n\n\n??\n\nconv.weight.data, conv.bias.data\n\n(tensor([[[[-0.0637,  0.4369],\n           [-0.2863, -0.0190]]]]),\n tensor([0.0468]))\n\n\n\n(img[:,  :,  :2,  :2] * conv.weight.data).sum()+conv.bias.data, conv(img)\n\n(tensor([0.0084]),\n tensor([[[[ 0.0084,  0.0557],\n           [-0.1183,  0.1122]]]], grad_fn=&lt;ConvolutionBackward0&gt;))\n\n\n\n(img[:,  :,  :2,  2:] * conv.weight.data).sum()+conv.bias.data, conv(img)\n\n(tensor([0.0557]),\n tensor([[[[ 0.0084,  0.0557],\n           [-0.1183,  0.1122]]]], grad_fn=&lt;ConvolutionBackward0&gt;))\n\n\n\n(img[:,  :,  :2,  2:] * conv.weight.data).sum()+conv.bias.data, conv(img)\n\n(tensor([0.0557]),\n tensor([[[[ 0.0084,  0.0557],\n           [-0.1183,  0.1122]]]], grad_fn=&lt;ConvolutionBackward0&gt;))\n\n\n\n(img[:,  :,  2:,  2:] * conv.weight.data).sum()+conv.bias.data, conv(img)\n\n(tensor([0.1122]),\n tensor([[[[ 0.0084,  0.0557],\n           [-0.1183,  0.1122]]]], grad_fn=&lt;ConvolutionBackward0&gt;))\n\n\n\n\n\n\n\n\nNote\n\n\n\n입력이 1장의 흑백이미지이고 출력도 1장의 흑백이미지일 경우 컨볼루션 계산과정 요약1\n\n윈도우생성: kernel_size = (?,?) 인 윈도우를 만듦\nsub-img생성: 입력 이미지에 윈도우를 통과시켜 (?,?) 크기의 sub-img를 만듦.\n연산: sub-img의 각 원소에 conv.weight의 값을 원소별로 (=element-wisely) 곱하고 결과를 더함. (만약에 conv.bias가 있다면 최종결과에 bias를 더함)\n이동&반복: 윈도우를 stride 만큼 이동하여 반복. (stride=1 이라면 한칸씩, stride=2 라면 두칸씩 이동)\n\n\n\n(예시2) – 재현\n“A guide to convolution arithmetic for deep learning” [@dumoulin2016guide] 에 나온 그림재현\n\nref: https://arxiv.org/abs/1603.07285\n\n🗣️ 우측 하단 작은 숫자: weight\n\n\n\nFig: conv2d 계산과정시각화\n\n\n\nimg = torch.tensor([\n    [3,3,2,1,0],\n    [0,0,1,3,1],\n    [3,1,2,2,3],\n    [2,0,0,2,2],\n    [2,0,0,0,1]\n]).reshape(1,1,5,5).float()\nimg\n\ntensor([[[[3., 3., 2., 1., 0.],\n          [0., 0., 1., 3., 1.],\n          [3., 1., 2., 2., 3.],\n          [2., 0., 0., 2., 2.],\n          [2., 0., 0., 0., 1.]]]])\n\n\n\nconv = torch.nn.Conv2d(in_channels=1,out_channels=1,kernel_size=3,bias=False) # bias=0 하드코딩해도 됨\nconv.weight.data = torch.tensor([[[\n    [ 0.0, 1.0, 2.0],\n    [ 2.0, 2.0, 0.0],\n    [ 0.0, 1.0, 2.0]\n]]])\n\n\nconv(img)\n\ntensor([[[[12., 12., 17.],\n          [10., 17., 19.],\n          [ 9.,  6., 14.]]]], grad_fn=&lt;ConvolutionBackward0&gt;)\n\n\n(예시3) 이동평균\n\nimg = torch.arange(1,17).float().reshape(1,1,4,4)\nimg\n\ntensor([[[[ 1.,  2.,  3.,  4.],\n          [ 5.,  6.,  7.,  8.],\n          [ 9., 10., 11., 12.],\n          [13., 14., 15., 16.]]]])\n\n\n\nconv = torch.nn.Conv2d(in_channels=1,out_channels=1,kernel_size=2,stride=1,bias=False)\nconv.weight.data = conv.weight.data*0 + 1/4\nconv.weight.data\n\ntensor([[[[0.2500, 0.2500],\n          [0.2500, 0.2500]]]])\n\n\n🗣️ 이동하면서 평균을 계산\n\nconv(img)\n\ntensor([[[[ 3.5000,  4.5000,  5.5000],\n          [ 7.5000,  8.5000,  9.5000],\n          [11.5000, 12.5000, 13.5000]]]], grad_fn=&lt;ConvolutionBackward0&gt;)\n\n\n(예시4) 2개의 이미지\n🗣️ (n,1,?,?), (1,3,?,?) 등도 가능\n- 개념: (1,1,?,?) \\(\\to\\) (1,1,?,?) 의 conv를 observation 별로 적용\n\nconv 에 포함된 파라메터 수는 (1,1,?,?) \\(\\to\\) (1,1,?,?) 인 경우와 (n,1,?,?) \\(\\to\\) (n,1,?,?)인 경우가 동일\n\n\nimgs = torch.arange(1,33).float().reshape(2,1,4,4)\nconv = torch.nn.Conv2d(in_channels=1,out_channels=1,kernel_size=2,stride=1,bias=False)\nconv.weight.data = conv.weight.data*0 + 1/4\n\n🗣️ 위에 있는 거 한 장, 아래에 있는 거 한 장\n\nimgs\n\ntensor([[[[ 1.,  2.,  3.,  4.],\n          [ 5.,  6.,  7.,  8.],\n          [ 9., 10., 11., 12.],\n          [13., 14., 15., 16.]]],\n\n\n        [[[17., 18., 19., 20.],\n          [21., 22., 23., 24.],\n          [25., 26., 27., 28.],\n          [29., 30., 31., 32.]]]])\n\n\n\nconv(imgs) # 이동평균\n\ntensor([[[[ 3.5000,  4.5000,  5.5000],\n          [ 7.5000,  8.5000,  9.5000],\n          [11.5000, 12.5000, 13.5000]]],\n\n\n        [[[19.5000, 20.5000, 21.5000],\n          [23.5000, 24.5000, 25.5000],\n          [27.5000, 28.5000, 29.5000]]]], grad_fn=&lt;ConvolutionBackward0&gt;)\n\n\n🗣️(\n\nconv.weight.shape\n\ntorch.Size([1, 1, 2, 2])\n\n\n\n숫자가 4개 (2*2)\n하나의 conv를 다른 이미지에도 적용\n\nconv 에 포함된 파라메터 수는 (1,1,?,?) \\(\\to\\) (1,1,?,?) 인 경우와 (n,1,?,?) \\(\\to\\) (n,1,?,?)인 경우가 동일\n\n\n)🗣️\n(예시5) 2개의 이미지, 2개의 out_channels\n🗣️ 같은 이미지에 conv를 2번씩 거는 경우\n- 개념: (1,1,?,?) \\(\\to\\) (1,1,?,?) 의 conv를 한번 적용, 그것과 별개로 (1,1,?,?) \\(\\to\\) (1,1,?,?) 인 다른 conv를 적용함. (즉 하나의 observation당 2번 conv변환) 이것을 observation별로 반복\n\n(1,1,?,?) \\(\\to\\) (1,2,?,?) 인 경우는 (1,1,?,?) \\(\\to\\) (1,1,?,?)인 경우보다 conv에 포함된 파라메터 수가 2배 많음\n그런데 (1,1,?,?) \\(\\to\\) (1,2,?,?) 인 경우와 (n,1,?,?) \\(\\to\\) (n,2,?,?)인 경우는 conv에 포함된 파라메터 수가 같음.\n따라서 (n,1,?,?) \\(\\to\\) (n,2,?,?) 인 경우는 (1,1,?,?) \\(\\to\\) (1,1,?,?)인 경우보다 conv에 포함된 파라메터 수가 2배 많음\n\n\nimg = torch.arange(1,33).float().reshape(2,1,4,4)\nconv = torch.nn.Conv2d(in_channels=1,out_channels=2,kernel_size=2,stride=1,bias=False)\n\n🗣️(\n\nconv.weight\n\nParameter containing:\ntensor([[[[-0.0698,  0.1491],\n          [ 0.3877,  0.0913]]],\n\n\n        [[[-0.2105,  0.0241],\n          [-0.4239,  0.2689]]]], requires_grad=True)\n\n\n\nimg.shape # 2장, 흑백, 4*4\n\ntorch.Size([2, 1, 4, 4])\n\n\n\nconv(img).shape\n\ntorch.Size([2, 2, 3, 3])\n\n\n)🗣️\n\nimg\n\ntensor([[[[ 1.,  2.,  3.,  4.],\n          [ 5.,  6.,  7.,  8.],\n          [ 9., 10., 11., 12.],\n          [13., 14., 15., 16.]]],\n\n\n        [[[17., 18., 19., 20.],\n          [21., 22., 23., 24.],\n          [25., 26., 27., 28.],\n          [29., 30., 31., 32.]]]])\n\n\n\nconv.weight.data[0] = conv.weight.data[0]*0 +1/4 # 평균을 의미 (bias=False)\nconv.weight.data[1] = conv.weight.data[0]*0\n\n\nconv(img)\n\ntensor([[[[ 3.5000,  4.5000,  5.5000],\n          [ 7.5000,  8.5000,  9.5000],\n          [11.5000, 12.5000, 13.5000]],\n\n         [[ 0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000]]],\n\n\n        [[[19.5000, 20.5000, 21.5000],\n          [23.5000, 24.5000, 25.5000],\n          [27.5000, 28.5000, 29.5000]],\n\n         [[ 0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000]]]], grad_fn=&lt;ConvolutionBackward0&gt;)\n\n\n🗣️ 하나의 이미지가 2개의 채널로 분리 됨 (하나의 채널은 이동평균, 다른 하나는 0)"
  },
  {
    "objectID": "posts/07wk-2.html#a.-data",
    "href": "posts/07wk-2.html#a.-data",
    "title": "07wk-2: (합성곱신경망) – CNN 핵심레이어, CNN의 학습원리, FashionMNIST",
    "section": "A. data",
    "text": "A. data\n아래의 4개의 이미지를 생각하자 .\n\nimg0 = torch.tensor([\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n]).reshape(1, 1, 16, 16) \nimg1 = 0.1-torch.einsum('nchw-&gt;ncwh', img0.clone())\nimg2 = torch.zeros((1, 1, 16, 16))\nfor i in range(16):\n    for j in range(16):\n        if j &lt;= i:  # 대각선 아래 삼각형\n            img2[0, 0, i, j] = 0.1\n# 빈 이미지\nimg3 = torch.zeros((1, 1, 16, 16))\nblock_size = 2\n# 블록 단위로 채우기\nfor i in range(0, 16, block_size):\n    for j in range(0, 16, block_size):\n        if ((i // block_size) + (j // block_size)) % 2 == 0:\n            img3[0, 0, i:i+block_size, j:j+block_size] = 0.1\n\n🗣️(\n\nimg0.shape # 16*16 흑백 이미지\n\ntorch.Size([1, 1, 16, 16])\n\n\n\nplt.imshow(img0.reshape(16,16),cmap=\"gray\")\n\n\n\n\n\n\n\n\n\n0.1이 흰색, 0이 검정색\n\n\nplt.imshow(img1.reshape(16,16),cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nplt.imshow(img2.reshape(16,16),cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nplt.imshow(img3.reshape(16,16),cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nimg3.shape\n\ntorch.Size([1, 1, 16, 16])\n\n\n\nimg3.reshape(16,16).shape\n\ntorch.Size([16, 16])\n\n\n\nimg3.squeeze().shape # 차원이 1인것은 줄어드는 method\n\ntorch.Size([16, 16])\n\n\n)🗣️\n\nfig, axs = plt.subplots(2,2)\nfig.set_figheight(8)\nfig.set_figwidth(8)\naxs[0][0].imshow(img0.squeeze(),cmap=\"gray\")\naxs[0][1].imshow(img1.squeeze(),cmap=\"gray\")\naxs[1][0].imshow(img2.squeeze(),cmap=\"gray\")\naxs[1][1].imshow(img3.squeeze(),cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nimgs = torch.concat([img0,img1,img2,img3],axis=0)\nimgs.shape\n\ntorch.Size([4, 1, 16, 16])"
  },
  {
    "objectID": "posts/07wk-2.html#b.-vertical-edge",
    "href": "posts/07wk-2.html#b.-vertical-edge",
    "title": "07wk-2: (합성곱신경망) – CNN 핵심레이어, CNN의 학습원리, FashionMNIST",
    "section": "B. vertical edge",
    "text": "B. vertical edge\n🗣️(\nx1 x2 x3 x4\nx5 x6 x7 x8\nx9 x10 x11 x12\nx13 x14 x15 x16\n\n[-1 1\n -1 1]\n\nx1 x2\nx5 x6\n에 적용하면\n-x1 x2\n-x5 x6\n다 더하면\n-x1 + x2 -x5 + x6\n= (x2-x1) + (x6-x5)\n둘 씩 비교하여 변화가 있으면 1, 없으면 0\n\n예시)\n0 0 1 1\n0 0 1 1\n0 0 1 1\n0 0 1 1\n적용 후\n0 1 0\n0 1 0\n0 1 0\n\n확장)\n0 0 0 1 1 1\n0 0 0 1 1 1\n0 0 0 1 1 1\n0 0 0 1 1 1\n0 0 0 1 1 1\n0 0 0 1 1 1\n적용 후\n0 0 1 0 0\n0 0 1 0 0\n0 0 1 0 0\n0 0 1 0 0\n0 0 1 0 0\n\nv_conv = torch.nn.Conv2d(\n    in_channels=1,\n    out_channels=1,\n    kernel_size=2,\n    bias=False\n)\n\n\nv_conv.weight.data = torch.tensor([[[\n    [-1.0, 1.0],\n    [-1.0, 1.0]\n]]])\n\n\nplt.imshow(v_conv(img0).squeeze().data, cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nplt.imshow(v_conv(img1).squeeze().data, cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nplt.imshow(v_conv(img2).squeeze().data, cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nplt.imshow(v_conv(img3).squeeze().data, cmap=\"gray\")\n\n\n\n\n\n\n\n\n\n회색: 값 변화 X, 검정색: 흰색-&gt;검정색, 흰색: 검정색-&gt;흰색\n이동평균과 kernel_size를 맞춰주면 밑의 코드와 같음\n\n)🗣️\n\nv_conv = torch.nn.Conv2d(\n    in_channels=1,\n    out_channels=1,\n    kernel_size=4,\n    bias=False\n)\n\n\nv_conv.weight.data = torch.tensor([[[\n    [ 0, 0, 0, 0],\n    [ 0, 1.0, -1.0, 0],\n    [0, 1.0, -1.0, 0],\n    [ 0, 0, 0, 0]\n]]])\n\n\n이 v_conv는 좌우방향의 픽셀변화, 즉 수직 방향의 엣지(vertical edge)를 감지하는데 적절하다.\n\n\nfig, axs = plt.subplots(2,2)\nfig.set_figheight(8)\nfig.set_figwidth(8)\naxs[0][0].imshow(v_conv(imgs)[0].squeeze().data,cmap=\"gray\")\naxs[0][1].imshow(v_conv(imgs)[1].squeeze().data,cmap=\"gray\")\naxs[1][0].imshow(v_conv(imgs)[2].squeeze().data,cmap=\"gray\")\naxs[1][1].imshow(v_conv(imgs)[3].squeeze().data,cmap=\"gray\")\n\n\n\n\n\n\n\n\n🗣️ 왼쪽과 오른쪽을 비교하여 edge를 걸었더니 모두 0이면 위아래임을 알 수 있음"
  },
  {
    "objectID": "posts/07wk-2.html#c.-horizontal-edge",
    "href": "posts/07wk-2.html#c.-horizontal-edge",
    "title": "07wk-2: (합성곱신경망) – CNN 핵심레이어, CNN의 학습원리, FashionMNIST",
    "section": "C. horizontal edge",
    "text": "C. horizontal edge\n✍️(\nx1 x2 x3 x4\nx5 x6 x7 x8\nx9 x10 x11 x12\nx13 x14 x15 x16\n\n[-1 -1\n  1 1]\n\nx1 x2\nx5 x6\n에 적용하면\n-x1 -x2\n x5 x6\n다 더하면\n-x1 - x2 + x5 + x6\n= (x5-x1) + (x6-x2)\n둘 씩 비교하여 변화가 있으면 1, 없으면 0\n\n예시)\n1 1 1 1\n1 1 1 1\n0 0 0 0\n0 0 0 0\n적용 후\n0 0 0\n1 1 1\n0 0 0\n\n확장)\n1 1 1 1 1 1\n1 1 1 1 1 1\n1 1 1 1 1 1\n0 0 0 0 0 0\n0 0 0 0 0 0\n0 0 0 0 0 0\n적용 후\n0 0 0 0 0\n0 0 0 0 0\n1 1 1 1 1\n0 0 0 0 0\n0 0 0 0 0\n)✍️\n\nh_conv = torch.nn.Conv2d(\n    in_channels=1,\n    out_channels=1,\n    kernel_size=4,\n    bias=False\n)\n\n\nh_conv.weight.data = torch.tensor([[[\n    [ 0, 0, 0, 0],\n    [ 0, -1.0, -1.0, 0],\n    [0, 1.0, 1.0, 0],\n    [ 0, 0, 0, 0]\n]]])\n\n\n이 h_conv는 위아레 방향의 픽셀변화, 즉 수평엣지(horizontal edge)를 감지하는데 적절하다.\n\n\nfig, axs = plt.subplots(2,2)\nfig.set_figheight(8)\nfig.set_figwidth(8)\naxs[0][0].imshow(h_conv(imgs)[0].squeeze().data,cmap=\"gray\")\naxs[0][1].imshow(h_conv(imgs)[1].squeeze().data,cmap=\"gray\")\naxs[1][0].imshow(h_conv(imgs)[2].squeeze().data,cmap=\"gray\")\naxs[1][1].imshow(h_conv(imgs)[3].squeeze().data,cmap=\"gray\")\n\n\n\n\n\n\n\n\n🗣️ 위쪽과 아래쪽을 비교하여 edge를 걸었더니 모두 0이면 좌우임을 알 수 있음"
  },
  {
    "objectID": "posts/07wk-2.html#d.-이동평균",
    "href": "posts/07wk-2.html#d.-이동평균",
    "title": "07wk-2: (합성곱신경망) – CNN 핵심레이어, CNN의 학습원리, FashionMNIST",
    "section": "D. 이동평균",
    "text": "D. 이동평균\n🗣️(\n\nm_conv = torch.nn.Conv2d(\n    in_channels=1,\n    out_channels=1,\n    kernel_size=4,\n)\nm_conv.weight.data = m_conv.weight.data*0 + 1/16 # 16개 pixel에 대한 평균\nm_conv.bias.data = m_conv.bias.data*0\n\n\nm_conv(img0).shape\n\ntorch.Size([1, 1, 13, 13])\n\n\n\nm_conv(img0).squeeze().shape\n\ntorch.Size([13, 13])\n\n\n\nplt.imshow(m_conv(img0).squeeze().data, cmap=\"gray\")\n\n\n\n\n\n\n\n\n\n평균은 smoothing 하는 효과\n\n\nplt.imshow(m_conv(img1).squeeze().data, cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nplt.imshow(m_conv(img2).squeeze().data, cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nplt.imshow(m_conv(img3).squeeze().data, cmap=\"gray\")\n\n\n\n\n\n\n\n\n\n평균은 회색 (검은 색으로 보이지만 아님)\n\n\nm_conv(img3)\n\ntensor([[[[0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n           0.0500, 0.0500, 0.0500, 0.0500, 0.0500],\n          [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n           0.0500, 0.0500, 0.0500, 0.0500, 0.0500],\n          [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n           0.0500, 0.0500, 0.0500, 0.0500, 0.0500],\n          [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n           0.0500, 0.0500, 0.0500, 0.0500, 0.0500],\n          [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n           0.0500, 0.0500, 0.0500, 0.0500, 0.0500],\n          [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n           0.0500, 0.0500, 0.0500, 0.0500, 0.0500],\n          [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n           0.0500, 0.0500, 0.0500, 0.0500, 0.0500],\n          [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n           0.0500, 0.0500, 0.0500, 0.0500, 0.0500],\n          [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n           0.0500, 0.0500, 0.0500, 0.0500, 0.0500],\n          [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n           0.0500, 0.0500, 0.0500, 0.0500, 0.0500],\n          [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n           0.0500, 0.0500, 0.0500, 0.0500, 0.0500],\n          [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n           0.0500, 0.0500, 0.0500, 0.0500, 0.0500],\n          [0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n           0.0500, 0.0500, 0.0500, 0.0500, 0.0500]]]],\n       grad_fn=&lt;ConvolutionBackward0&gt;)\n\n\n\n# plt.imshow(m_conv(img3).squeeze().data*0, cmap=\"gray\") # *0을 해도 검은 색으로 보임\n\n\nplt.imshow(m_conv(img3).squeeze().data, cmap=\"gray\", vmin=-1, vmax=1) # 실질적으로 어떤 색인지 알려면\n\n\n\n\n\n\n\n\n\nplt.imshow(m_conv(img3).squeeze().data*0, cmap=\"gray\", vmin=-1, vmax=1) # 실질적으로 어떤 색인지 알려면\n\n\n\n\n\n\n\n\n\nplt.imshow(m_conv(img3).squeeze().data*0-1, cmap=\"gray\", vmin=-1, vmax=1) # 검정색\n\n\n\n\n\n\n\n\n\nplt.imshow(m_conv(img3).squeeze().data*0+1, cmap=\"gray\", vmin=-1, vmax=1) # 흰색\n\n\n\n\n\n\n\n\n\nimgs.shape\n\ntorch.Size([4, 1, 16, 16])\n\n\n\nm_conv(imgs).shape\n\ntorch.Size([4, 1, 13, 13])\n\n\n)🗣️\n\nm_conv = torch.nn.Conv2d(\n    in_channels=1,\n    out_channels=1,\n    kernel_size=4,\n)\nm_conv.weight.data = m_conv.weight.data*0 + 1/16\nm_conv.bias.data = m_conv.bias.data*0 - 0.05 # 진짜 0이 됨\n\n\nfig, axs = plt.subplots(2,2)\nfig.set_figheight(8)\nfig.set_figwidth(8)\naxs[0][0].imshow(m_conv(imgs)[0].squeeze().data,cmap=\"gray\")\naxs[0][1].imshow(m_conv(imgs)[1].squeeze().data,cmap=\"gray\")\naxs[1][0].imshow(m_conv(imgs)[2].squeeze().data,cmap=\"gray\")\naxs[1][1].imshow(m_conv(imgs)[3].squeeze().data,cmap=\"gray\")\n\n\n\n\n\n\n\n\n\n🗣️\n\n이동평균을 했더니 0으로 나오면 체크무늬인 것을 알 수 있음\n3개의 필터에 모두 0이 안되면 대각선인 것을 알 수 있음\n\n\n🗣️(\n\n매우 다양한 조합 가능\n\n\nm_conv = torch.nn.Conv2d(\n    in_channels=1,\n    out_channels=1,\n    kernel_size=6, # 6으로 변경\n)\nm_conv.weight.data = m_conv.weight.data*0 + 1/16\nm_conv.bias.data = m_conv.bias.data*0 - 0.05\n\n\nfig, axs = plt.subplots(2,2)\nfig.set_figheight(8)\nfig.set_figwidth(8)\naxs[0][0].imshow(m_conv(imgs)[0].squeeze().data,cmap=\"gray\")\naxs[0][1].imshow(m_conv(imgs)[1].squeeze().data,cmap=\"gray\")\naxs[1][0].imshow(m_conv(imgs)[2].squeeze().data,cmap=\"gray\")\naxs[1][1].imshow(m_conv(imgs)[3].squeeze().data,cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nfig, axs = plt.subplots(2,2)\nfig.set_figheight(8)\nfig.set_figwidth(8)\naxs[0][0].imshow(m_conv(imgs)[0].squeeze().data,cmap=\"gray\")\naxs[0][1].imshow(m_conv(imgs)[1].squeeze().data,cmap=\"gray\")\naxs[1][0].imshow(m_conv(imgs)[2].squeeze().data,cmap=\"gray\")\naxs[1][1].imshow(m_conv(m_conv(imgs))[3].squeeze().data,cmap=\"gray\") # 한 번 더 걸면\n\n\n\n\n\n\n\n\n\nfig, axs = plt.subplots(2,2)\nfig.set_figheight(8)\nfig.set_figwidth(8)\naxs[0][0].imshow(m_conv(imgs)[0].squeeze().data,cmap=\"gray\")\naxs[0][1].imshow(m_conv(imgs)[1].squeeze().data,cmap=\"gray\")\naxs[1][0].imshow(m_conv(m_conv(imgs))[2].squeeze().data,cmap=\"gray\") # 이것도 한 번 더\naxs[1][1].imshow(m_conv(m_conv(imgs))[3].squeeze().data,cmap=\"gray\")\n\n\n\n\n\n\n\n\n)🗣️"
  },
  {
    "objectID": "posts/07wk-2.html#e.-cde-relu-mp",
    "href": "posts/07wk-2.html#e.-cde-relu-mp",
    "title": "07wk-2: (합성곱신경망) – CNN 핵심레이어, CNN의 학습원리, FashionMNIST",
    "section": "E. (C,D,E) + relu + mp",
    "text": "E. (C,D,E) + relu + mp\n🗣️(\n\nm_conv = torch.nn.Conv2d(\n    in_channels=1,\n    out_channels=1,\n    kernel_size=4,\n)\nm_conv.weight.data = m_conv.weight.data*0 + 1/16\nm_conv.bias.data = m_conv.bias.data*0 - 0.05 # 진짜 0이 됨\n\n\nm_conv(imgs).shape\n\ntorch.Size([4, 1, 13, 13])\n\n\n\nmp = torch.nn.MaxPool2d(kernel_size=13) # 13*13 중에 가장 큰 값을 뽑음\n\n\nmp(m_conv(imgs)) # 마지막만 0이 됨\n\ntensor([[[[5.0000e-02]]],\n\n\n        [[[5.0000e-02]]],\n\n\n        [[[5.0000e-02]]],\n\n\n        [[[9.3132e-10]]]], grad_fn=&lt;MaxPool2DWithIndicesBackward0&gt;)\n\n\n\nmp(h_conv(imgs)) # 처음만 0이 됨\n\ntensor([[[[0.0000]]],\n\n\n        [[[0.2000]]],\n\n\n        [[[0.1000]]],\n\n\n        [[[0.2000]]]], grad_fn=&lt;MaxPool2DWithIndicesBackward0&gt;)\n\n\n\nmp(v_conv(imgs)) # 두번째만 0이 됨\n\ntensor([[[[0.2000]]],\n\n\n        [[[0.0000]]],\n\n\n        [[[0.1000]]],\n\n\n        [[[0.2000]]]], grad_fn=&lt;MaxPool2DWithIndicesBackward0&gt;)\n\n\n\n여기서는 큰 의미는 없지만 relu도 같이 통과를 시키면 결과가 다양해짐\n\n\nrelu = torch.nn.ReLU()\n\n\nfig, axs = plt.subplots(2,2)\nfig.set_figheight(8)\nfig.set_figwidth(8)\naxs[0][0].imshow(relu(h_conv(imgs))[0].squeeze().data,cmap=\"gray\")\naxs[0][1].imshow(relu(h_conv(imgs))[1].squeeze().data,cmap=\"gray\")\naxs[1][0].imshow(relu(h_conv(imgs))[2].squeeze().data,cmap=\"gray\")\naxs[1][1].imshow(relu(h_conv(imgs))[3].squeeze().data,cmap=\"gray\")\n\n\n\n\n\n\n\n\n)🗣️\n\nrelu = torch.nn.ReLU()\nmp = torch.nn.MaxPool2d(kernel_size=13)\n\n\nmp(relu(v_conv(imgs)))\n\ntensor([[[[0.2000]]],\n\n\n        [[[0.0000]]],\n\n\n        [[[0.1000]]],\n\n\n        [[[0.2000]]]], grad_fn=&lt;MaxPool2DWithIndicesBackward0&gt;)\n\n\n\nmp(relu(h_conv(imgs)))\n\ntensor([[[[0.0000]]],\n\n\n        [[[0.2000]]],\n\n\n        [[[0.1000]]],\n\n\n        [[[0.2000]]]], grad_fn=&lt;MaxPool2DWithIndicesBackward0&gt;)\n\n\n\nmp(relu(m_conv(imgs)))\n\ntensor([[[[5.0000e-02]]],\n\n\n        [[[5.0000e-02]]],\n\n\n        [[[5.0000e-02]]],\n\n\n        [[[9.3132e-10]]]], grad_fn=&lt;MaxPool2DWithIndicesBackward0&gt;)\n\n\n🗣️ 매우 많은 숫자들이 구분하기 용이한 숫자들로 요약됨"
  },
  {
    "objectID": "posts/07wk-2.html#f.-대충-이런-구조",
    "href": "posts/07wk-2.html#f.-대충-이런-구조",
    "title": "07wk-2: (합성곱신경망) – CNN 핵심레이어, CNN의 학습원리, FashionMNIST",
    "section": "F. 대충 이런 구조",
    "text": "F. 대충 이런 구조\n🗣️(\n이미지1-&gt;h-&gt;r-&gt;mp-&gt;0,??,??\n      -&gt;v-&gt;r-&gt;mp-&gt;\n      -&gt;m-&gt;r-&gt;mp\n\n이미지1-&gt;(h,v,m)-&gt;r-&gt;mp-&gt;0,??,??\n이미지2-&gt;(h,v,m)-&gt;r-&gt;mp-&gt;0,??,??\n이미지3-&gt;(h,v,m)-&gt;r-&gt;mp-&gt;0,??,??\n이미지4-&gt;(h,v,m)-&gt;r-&gt;mp-&gt;0,??,??\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(in_channels=1,out_channels=3,kernel_size=4), # bias 사용\n    torch.nn.ReLU(), # 다양해짐\n    torch.nn.MaxPool2d(kernel_size=13),\n    torch.nn.Flatten()\n)\n\n\nnet[0].weight.shape\n\ntorch.Size([3, 1, 4, 4])\n\n\n1,1,4,4 --&gt; m_conv\n1,1,4,4 --&gt; h_conv\n1,1,4,4 --&gt; v_conv\n3,1,4,4 --&gt; conv\n\nnet[0].weight.data\n\ntensor([[[[-0.0833, -0.0289, -0.2051, -0.2370],\n          [-0.1144, -0.0212, -0.0276,  0.1908],\n          [-0.1374, -0.1581, -0.0825, -0.1222],\n          [-0.2006, -0.1606, -0.1211,  0.0583]]],\n\n\n        [[[ 0.2180, -0.1371, -0.0198, -0.1251],\n          [-0.0198, -0.0584,  0.1258,  0.0500],\n          [ 0.0558, -0.0605, -0.1558,  0.2098],\n          [ 0.0355, -0.0771,  0.0439,  0.0692]]],\n\n\n        [[[ 0.2496, -0.0280, -0.1691, -0.2486],\n          [-0.1302,  0.1365, -0.0934, -0.2321],\n          [-0.0914,  0.2089, -0.1784,  0.1483],\n          [ 0.1498,  0.0237,  0.2464,  0.0540]]]])\n\n\n\ntorch.concat(\n    [v_conv.weight.data,\n     h_conv.weight.data,\n     m_conv.weight.data],axis=0).shape\n\ntorch.Size([3, 1, 4, 4])\n\n\n\nnet[0].weight.data = torch.concat(\n    [v_conv.weight.data,\n     h_conv.weight.data,\n     m_conv.weight.data],axis=0)\nnet[0].weight.data\n\ntensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  1.0000, -1.0000,  0.0000],\n          [ 0.0000,  1.0000, -1.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000]]],\n\n\n        [[[ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000, -1.0000, -1.0000,  0.0000],\n          [ 0.0000,  1.0000,  1.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000]]],\n\n\n        [[[ 0.0625,  0.0625,  0.0625,  0.0625],\n          [ 0.0625,  0.0625,  0.0625,  0.0625],\n          [ 0.0625,  0.0625,  0.0625,  0.0625],\n          [ 0.0625,  0.0625,  0.0625,  0.0625]]]])\n\n\n\nnet[0].bias.data\n\ntensor([ 0.1274,  0.2041, -0.0989])\n\n\n\nnet[0].bias.data = torch.tensor([0.0,0.0, -0.05])\n\n\nnet(imgs)\n\ntensor([[2.0000e-01, 0.0000e+00, 5.0000e-02],\n        [0.0000e+00, 2.0000e-01, 5.0000e-02],\n        [1.0000e-01, 1.0000e-01, 5.0000e-02],\n        [2.0000e-01, 2.0000e-01, 9.3132e-10]], grad_fn=&lt;ViewBackward0&gt;)\n\n\n두번째 0\n첫번째 0\n0 없음\n네번째 0\n)🗣️\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(in_channels=1,out_channels=3,kernel_size=4), # bias 사용\n    torch.nn.ReLU(), # 다양해짐\n    torch.nn.MaxPool2d(kernel_size=13),\n    torch.nn.Flatten()\n)\nnet[0].weight.data = torch.concat(\n    [v_conv.weight.data,\n     h_conv.weight.data,\n     m_conv.weight.data],axis=0)\nnet[0].bias.data = torch.tensor([0.0,0.0, -0.05])\n\n\nplt.matshow(net(imgs).data,cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nnet(imgs).shape\n\ntorch.Size([4, 3])\n\n\n🗣️ 4개의 이미지를 각각 3개로 특징을 요약\n\n출력은 (n,3)으로 정리되어서 나온다. 이 시점부터는 더 이상 이미지가 입력이라고 생각하지 않아도 되고, 단순히 (n, 3) 크기의 숫자 데이터가 입력으로 주어진 것처럼 보면 된다. 즉 이제부터는 이 (n,3) 데이터를 입력으로 받는 신경망을 설계하면 된다."
  },
  {
    "objectID": "posts/07wk-2.html#g.-mp의-역할",
    "href": "posts/07wk-2.html#g.-mp의-역할",
    "title": "07wk-2: (합성곱신경망) – CNN 핵심레이어, CNN의 학습원리, FashionMNIST",
    "section": "G. mp의 역할?",
    "text": "G. mp의 역할?\n- 샘플이미지\n\nimg = torch.zeros((1, 1, 16, 16))\ntriangle_size = 4\nfor i in range(triangle_size):\n    for j in range(triangle_size):\n        if j &lt;= i:  # 아래 방향 직각삼각형 (왼쪽 위 꼭짓점 기준)\n            img[0, 0, i, j] = 1.0\n\n\nplt.imshow(img.squeeze(),cmap=\"gray\")\n\n\n\n\n\n\n\n\n- mp1 회\n\nmp = torch.nn.MaxPool2d(kernel_size=2)\nplt.imshow(mp(img).squeeze(),cmap=\"gray\")\n\n\n\n\n\n\n\n\n🗣️ 이미지가 1/4로 줄어듦\n- mp 2~4회\n\nmp = torch.nn.MaxPool2d(kernel_size=2)\nplt.imshow(mp(mp(img)).squeeze(),cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nmp = torch.nn.MaxPool2d(kernel_size=2)\nplt.imshow(mp(mp(mp(img))).squeeze(),cmap=\"gray\")\n\n\n\n\n\n\n\n\n- maxpooling은 이미지를 “캐리커처화” 한다고 비유할 수 있음. 디테일은 버리고, 중요한 특징만 뽑아서 과장되게 요약한다.\n\n🗣️ 사이즈를 줄이려고 사용, 중요한 정보도 손실 X\n\nCNN\n--&gt; 2d // flatten (conv(특징)-relu(특징다변화)-maxpooling(요약))\n--&gt; 1d // 단순신경망"
  },
  {
    "objectID": "posts/07wk-2.html#footnotes",
    "href": "posts/07wk-2.html#footnotes",
    "title": "07wk-2: (합성곱신경망) – CNN 핵심레이어, CNN의 학습원리, FashionMNIST",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n입력shape=(1,1,?,?) 이고 출력의shape=(1,1,?,?)일 경우↩︎"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Deep Learning",
    "section": "",
    "text": "Based on: https://guebin.github.io/DL2025/\n\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nJun 14, 2025\n\n\n15wk-1: (강화학습) – LunarLander\n\n\nsw1kwon \n\n\n\n\nJun 9, 2025\n\n\n14wk-2: (강화학습) – 4x4 Grid World q_table, Appedix B\n\n\nsw1kwon \n\n\n\n\nJun 4, 2025\n\n\n14wk-1: (강화학습) – 4x4 Grid World 환경의 이해\n\n\nsw1kwon \n\n\n\n\nJun 2, 2025\n\n\n13wk-2: (강화학습) – Bandit 환경 설계 및 풀이, 4x4 Grid World 게임설명, 환경구현, 에이전트(랜덤)구현\n\n\nsw1kwon \n\n\n\n\nMay 28, 2025\n\n\n13wk-1: (강화학습) – 강화학습 Intro, Bandit 게임 설명, Bandit 환경 설계 및 풀이\n\n\nsw1kwon \n\n\n\n\nMay 14, 2025\n\n\n11wk-1: (추천시스템) – Embedding 레이어, 사용자정의 네트워크, MF-based 추천시스템을 넘어서\n\n\nsw1kwon \n\n\n\n\nMay 12, 2025\n\n\n10wk-2: (추천시스템) – optimizer 사용 고급, 모델링 전략, MF-based 추천시스템\n\n\nsw1kwon \n\n\n\n\nApr 21, 2025\n\n\n07wk-2: (합성곱신경망) – CNN 핵심레이어, CNN의 학습원리, FashionMNIST\n\n\nsw1kwon \n\n\n\n\nApr 16, 2025\n\n\n07wk-1: (합성곱신경망) – CNN 자랑, CNN 핵심레이어\n\n\nsw1kwon \n\n\n\n\nApr 14, 2025\n\n\n06wk-2: (신경망) – 다항분류, FashionMNIST\n\n\nsw1kwon \n\n\n\n\nApr 9, 2025\n\n\n06wk-1: (신경망) – 데이터분석 코딩패턴\n\n\nsw1kwon \n\n\n\n\nApr 7, 2025\n\n\n05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법\n\n\nsw1kwon \n\n\n\n\nApr 2, 2025\n\n\n05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃\n\n\nsw1kwon \n\n\n\n\nMar 31, 2025\n\n\n04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST\n\n\nsw1kwon \n\n\n\n\nMar 26, 2025\n\n\n04wk-1: (신경망) – 로지스틱의 한계 극복\n\n\nsw1kwon \n\n\n\n\nMar 24, 2025\n\n\n03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계\n\n\nsw1kwon \n\n\n\n\nMar 19, 2025\n\n\n03wk-1: (회귀, 로지스틱) – 파이토치식 코딩패턴 (2), 로지스틱 모형\n\n\nsw1kwon \n\n\n\n\nMar 17, 2025\n\n\n02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)\n\n\nsw1kwon \n\n\n\n\nMar 10, 2025\n\n\n01wk-2, 02wk-1: (회귀) – 회귀모형, 손실함수, 파이토치를 이용한 추정\n\n\nsw1kwon \n\n\n\n\nMar 5, 2025\n\n\n01wk-1: (토치) – 강의소개, 파이토치 기본\n\n\nsw1kwon \n\n\n\n\nJan 1, 2025\n\n\nA1: Exercise – ver. 0505-1 #1\n\n\nsw1kwon \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/03wk-1.html",
    "href": "posts/03wk-1.html",
    "title": "03wk-1: (회귀, 로지스틱) – 파이토치식 코딩패턴 (2), 로지스틱 모형",
    "section": "",
    "text": "📘 Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\n📝 🗣️ ✍️ 🔬 ❓"
  },
  {
    "objectID": "posts/03wk-1.html#a.-bias의-사용",
    "href": "posts/03wk-1.html#a.-bias의-사용",
    "title": "03wk-1: (회귀, 로지스틱) – 파이토치식 코딩패턴 (2), 로지스틱 모형",
    "section": "A. bias의 사용",
    "text": "A. bias의 사용\n🗣️(\n\n저번 시간 코드\n\n\nnet = torch.nn.Linear(2, 1, bias=False)\nnet.weight.data = torch.tensor([[-5.0, 10.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(), lr=0.1) # lr: learning rate\n\n# step 1~4\nfor epoc in range(30):\n    # 1\n    yhat = net(X)\n    # 2\n    loss = loss_fn(yhat,y)\n    # 3\n    loss.backward()\n    # 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nnet.weight # 지난 시간 결과와 동일\n\nParameter containing:\ntensor([[2.4290, 4.0144]], requires_grad=True)\n\n\n\n이제 bias=True\n\n\n# net(X) = X@net.weight.T # 현재 이렇게 알고 있으나 사실은 아님\n\n\nnet.weight\n\nParameter containing:\ntensor([[2.4290, 4.0144]], requires_grad=True)\n\n\n\nprint(net.bias) # 현재는 bias=False\n\nNone\n\n\n\n# net(X) = X@net.weight.T + net.bias # 사실은 이게 맞음\n\n\n둘은 동일\n\ny = X@W + ϵ # y = net(X) + ϵ\ny = w0hat + x*w1hat + ϵ # y = net(x) + ϵ\n\nnet(X) = X@net.weight.T + net.bias 에서 X가 x로 바뀌면\n\nnet(x) = x@net.weight.T + net.bias\nnet(x) = w0hat + x*w1hat 이므로\nnet.bias에 해당하는 것은 w0hat\nnet.weight.T에 해당하는 것은 w1hat 으로 생각 가능\n\n위를 기반으로 net(x)를 만들면\n\nx는 (n,1)이므로 input 차원은 1\n\n\n\nnet = torch.nn.Linear(1,1,bias=True)\nnet\n\nLinear(in_features=1, out_features=1, bias=True)\n\n\n\nnet.weight # 1x1 matrix\n\nParameter containing:\ntensor([[0.3480]], requires_grad=True)\n\n\n\nnet.bias # length 1인 vector\n\nParameter containing:\ntensor([0.7757], requires_grad=True)\n\n\n\nnet.weight.T # net(x) = x@net.weight.T + net.bias 에서 net.weight.T는 w1hat\n\ntensor([[0.3480]], grad_fn=&lt;PermuteBackward0&gt;)\n\n\n\nnet.weight.data = torch.tensor([[10.0]])\nnet.weight.data\n\ntensor([[10.]])\n\n\n\nnet.bias.data = torch.tensor([[-5.0]]) # net(x) = x@net.weight.T + net.bias 에서 net.bias는 w0hat\nnet.bias.data\n\ntensor([[-5.]])\n\n\n\n위의 내용을 저번 시간 코드에 반영하면\n\nnet 수정, weight 및 bias 값 수정\nnet(X) -&gt; net(x)\n\n\n\nnet = torch.nn.Linear(1, 1, bias=True)\nnet.weight.data = torch.tensor([[10.0]])\nnet.bias.data = torch.tensor([[-5.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(), lr=0.1) # lr: learning rate\n\n# step 1~4\nfor epoc in range(30):\n    # 1\n    yhat = net(x)\n    # 2\n    loss = loss_fn(yhat,y)\n    # 3\n    loss.backward()\n    # 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nnet.weight\n\nParameter containing:\ntensor([[4.0144]], requires_grad=True)\n\n\n\nnet.bias\n\nParameter containing:\ntensor([[2.4290]], requires_grad=True)\n\n\n\n저번 시간 결과와 동일\n\n)🗣️\nnet에서 bias를 사용\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=1,\n    out_features=1,\n    bias=True\n) # net(x) = x@net.weight.T + net.bias \nnet.bias.data = torch.tensor([-5.0])\nnet.weight.data = torch.tensor([[10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n# step4를 위한 사전준비 \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = net(x)\n    # step2: loss\n    loss = loss_fn(yhat,y)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nnet.bias.data, net.weight.data\n\n(tensor([2.4290]), tensor([[4.0144]]))\n\n\n#"
  },
  {
    "objectID": "posts/03wk-1.html#b.-잘못된-코드",
    "href": "posts/03wk-1.html#b.-잘못된-코드",
    "title": "03wk-1: (회귀, 로지스틱) – 파이토치식 코딩패턴 (2), 로지스틱 모형",
    "section": "B. 잘못된(?) 코드",
    "text": "B. 잘못된(?) 코드\n🗣️ bias의 default는 True이므로 저번 시간 코드에서 bias를 지우면 bias=True가 됨\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n# step4를 위한 사전준비 \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = net(X)\n    # step2: loss\n    loss = loss_fn(yhat,y)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    optimizr.step()\n    optimizr.zero_grad()\n\n🗣️(\n\nnet.weight # 결과가 많이 달라짐\n\nParameter containing:\ntensor([[-1.1114,  4.0080]], requires_grad=True)\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(X).data, '--')\n\n\n\n\n\n\n\n\n\n그런데 결과를 시각화해보면 나쁘지 않음\n\n)🗣️\n- 결과시각화\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.data,'--')\nplt.title(f'net.weight={net.weight.data.reshape(-1)}');\n\n\n\n\n\n\n\n\n- 나쁘지 않은 이유?\n✍️ 바로 밑의 코드는 편의상 실행 X\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n)\nyhat = net(X) = X@net.weight.T + net.bias\n\nnet.weight\n\nParameter containing:\ntensor([[-1.1114,  4.0080]], requires_grad=True)\n\n\n\nnet.bias\n\nParameter containing:\ntensor([3.5562], requires_grad=True)\n\n\n🗣️(\n\n원래대로라면 절편, 기울기 총 2개의 parameter만 학습해야하는데 위의 결과는 3개를 학습함\nyhat 계산 과정을 살펴보면\n\n\nX[[0],:] # nx2 martix에서 첫 번째 observation만 뽑음\n\ntensor([[ 1.0000, -2.4821]])\n\n\n\nyhat[:1] # 이 yhat이 어떻게 나왔는지 보면\n\ntensor([[-7.5063]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\nX[[0],:] @ net.weight.T + net.bias\n\n\n-1.1114 * 1.0000 + 4.0080 * (-2.4821) + 3.5562 # 약간의 차이는 소수점 차이\n\n-7.503456799999999\n\n\n\n-2.4821은 x, 다음과 같이 정리하면\n\n\n-1.1114 * 1.0000 + 3.5562\n\n2.4448\n\n\n\n절편에 대한 True 값: 2.5, 기울기에 대한 True 값: 4\n\n즉, 절편을 2개로 나눠서 학습함 (비효율적)\n\n그러면 이게 틀린 것인가?\n\n회귀분석에서 이렇게 모델링하면 틀림 (통계학적 관점)\n하지만 학습 결과 자체는 맞음 (비효율적일뿐)\nAI나 DL 관점에서는 최적의 parameter 개수가 정해지지 않은 경우가 많아서\n비효율적이긴해도 잘못으로 까지는 생각 X\n\n\n)🗣️"
  },
  {
    "objectID": "posts/03wk-1.html#a.-hatbf-y",
    "href": "posts/03wk-1.html#a.-hatbf-y",
    "title": "03wk-1: (회귀, 로지스틱) – 파이토치식 코딩패턴 (2), 로지스틱 모형",
    "section": "A. \\(\\hat{\\bf y} = ??\\)",
    "text": "A. \\(\\hat{\\bf y} = ??\\)\n🗣️(\n\n일반적으로 회귀분석에서 설명 변수, 반응 변수 모두 연속형 변수이지만,\ny가 상태를 의미할 때가 있음 (ex. X = 점수, y = 합격/불합격)\n\n합격을 1, 불합격을 0으로 숫자화하면\ny는 0 또는 1만 가짐\n\n이러한 자료는 매우 많음\n\n)🗣️\n- \\({\\bf X}\\)를 가지고 \\({\\bf y}\\)를 맞추는 아래와 같은 문제\n\nx = torch.tensor([-6,-5,-4,-3,-2,-1, 0, 1, 2, 3, 4, 5, 6.0]).reshape(-1,1)\ny = torch.tensor([ 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1]).reshape(-1,1)\nplt.plot(x,y,'o')\n\n\n\n\n\n\n\n\n🗣️(\n\nx가 증가함에 따라 y가 1이 될 것 같고, x가 감소함에 따라 y가 0될 것 같음\n모델링을 어떻게?\n모델링: observed data를 보고 error-free한 structure를 찾는 것\n여기서 error-free한 structure는?\n\nerror-free: 운적인 요소가 없음\n\n운적인 요소?\n\n이 경우 0점인데 합격, 1점인데 불합격\n도저히 받아들이지 못할 수 있음\n(이렇게 경계에 있는데 운적인 요소로 결정되는 경우)\n\n이것을 일반적인 회귀분석처럼 underlying(error-free)이 있고 오차항을 정규분포에서 error를 뽑은 것으로 설명하면 X\n\n이전의 cafe 데이터는 이렇게 설명 가능\n\n차라리 underlying에서 x값에 대응하는 y값을 성공 확률로 하는 베르누이 시행으로 설명하면 그럴듯 함\n\nunderlying: 여기서는 관측값이 아니고 확률을 의미하는 곡선으로 해석\n성공 확률이 0.9인 베르누이 시행을 했는데 0.1인 확률의 결과가 나와도 어쩔 수 없음 (운적인 요소)\n오차: 베르누이 시행에 의해 생성되는 랜덤성\n\n통계학과식 모델링\n\nstructure(error-free)뿐만 아니라 (이것도 어려움, 여기까지는 비통계학과식)\n관측치를 error term을 이용해 설명 (운적인 요소가 어떻게 작용하는지)\n\nyhat\n\nunderlying\ny가 0 또는 1만 가지므로 yhat도 그래야하나 싶지만 X (회귀분석에서 오차항이 포함된 관측치를 따라가는 것과 동일)\nyhat은 0과 1사이의 숫자 (모델링 대상: 관측치가 아니라 추세선)\n\n\n다음과 같이 모델링을 해보면\n\n\nprob = torch.exp(x) / (torch.exp(x) + 1)\nplt.plot(x,y,'o')\nplt.plot(x,prob,'--')\n\n\n\n\n\n\n\n\n\n\\(\\frac{e^x}{e^x + 1}\\)\n\n\\(x\\)가 커지면 1에 가까워지고\n\\(x=0\\)이면 1/2\n\\(x\\)가 작아지면 0에 가까워짐\n\n하지만 이 수식은 이 경우에만 맞고 확장성이 떨어짐\n\n)🗣️\n- 아래와 같이 모형화 하면?\n\nplt.plot(x,y,'o', label=r\"observed data (with error) = $(x_i,y_i)$\")\nplt.plot(x,torch.exp(x)/(1+torch.exp(x)),'o--', label = \"underlying (without error)\")\nplt.legend()"
  },
  {
    "objectID": "posts/03wk-1.html#b.-hatbf-y-fracexptextlinrbf-x1exptextlinrbf-x",
    "href": "posts/03wk-1.html#b.-hatbf-y-fracexptextlinrbf-x1exptextlinrbf-x",
    "title": "03wk-1: (회귀, 로지스틱) – 파이토치식 코딩패턴 (2), 로지스틱 모형",
    "section": "B. \\(\\hat{\\bf y} = \\frac{\\exp(\\text{linr}({\\bf X}))}{1+\\exp(\\text{linr}({\\bf X}))}\\)",
    "text": "B. \\(\\hat{\\bf y} = \\frac{\\exp(\\text{linr}({\\bf X}))}{1+\\exp(\\text{linr}({\\bf X}))}\\)\n- 걱정: 산점도가 꼭 아래와 같은 방식이 아니라면 어쩌지?\n\nplt.plot(x,y,'o')\n\n\n\n\n\n\n\n\n\n\\(x\\)가 증가할수록 \\(y\\)가 0이 된다면?\n0근처에서 변화가 일어나지 않고 2근처에서 변화가 일어난다면?\n변화가 좀 더 급하게 (혹은 완만하게 일어난다면?)\n\n🗣️(\n\n\\(\\frac{e^{-x}}{e^{-x} + 1}\\)\n합격률이 낮은 경우\nstrict하게 결과가 나뉘는 경우(ex. 장학금)\n\n\nplt.plot(x,y,'o', label=r\"observed data (with error) = $(x_i,y_i)$\")\nplt.plot(x,torch.exp(-x)/(1+torch.exp(-x)),'o--', label = \"underlying (without error)\")\nplt.legend()\n\n\n\n\n\n\n\n\n\nplt.plot(x,y,'o', label=r\"observed data (with error) = $(x_i,y_i)$\")\nplt.plot(x,torch.exp(-x+3)/(1+torch.exp(-x+3)),'o--', label = \"underlying (without error)\")\nplt.legend()\n\n\n\n\n\n\n\n\n\nplt.plot(x,y,'o', label=r\"observed data (with error) = $(x_i,y_i)$\")\nplt.plot(x,torch.exp(5*x+3)/(1+torch.exp(5*x+3)),'o--', label = \"underlying (without error)\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n이러한 5*x+3 등을 일반화하면\n\n5x+3 = w0hat + w1hat  x : 회귀분석 선형 모형\n= w0hat + w1hat * x = linr(x) # x를 linear transform시킴\n\n\n🔬 0근처에서 변화가 일어나지 않고 2근처에서 변화가 일어난다면?\n\nplt.plot(x,y,'o', label=r\"observed data (with error) = $(x_i,y_i)$\")\nplt.plot(x,torch.exp(x-2)/(1+torch.exp(x-2)),'o--', label = \"underlying (without error)\")\nplt.legend()\n\n\n\n\n\n\n\n\n🔬 변화가 좀 더 급하게 일어난다면?\n\nplt.plot(x,y,'o', label=r\"observed data (with error) = $(x_i,y_i)$\")\nplt.plot(x,torch.exp(3*x)/(1+torch.exp(3*x)),'o--', label = \"underlying (without error)\")\nplt.legend()\n\n\n\n\n\n\n\n\n🔬 변화가 좀 더 완만하게 일어난다면?\n\nplt.plot(x,y,'o', label=r\"observed data (with error) = $(x_i,y_i)$\")\nplt.plot(x,torch.exp(x/3)/(1+torch.exp(x/3)),'o--', label = \"underlying (without error)\")\nplt.legend()\n\n\n\n\n\n\n\n\n)🗣️\n\nplt.plot(x,y,'o', label=r\"observed data (with error) = $(x_i,y_i)$\")\nplt.plot(x,torch.exp(5*x+3)/(1+torch.exp(5*x+3)),'o--', label = \"underlying (without error)\")\nplt.legend()\n\n\n\n\n\n\n\n\n- 걱정해결\n\n#plt.plot(x,y,'o', label=r\"observed data (with error) = $(x_i,y_i)$\")\nplt.plot(x,torch.exp(x)/(1+torch.exp(x)),'o--', label = \"underlying type1 (without error)\", color=\"C1\")\nplt.plot(x,torch.exp(5*x)/(1+torch.exp(5*x)),'o--', label = \"underlying type2 (without error)\", color=\"C2\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n회귀 vs 로지스틱\n\n\\({\\bf X} \\to {\\bf y}\\) 에 대한 패턴이 \\(\\text{linr}({\\bf X}) \\approx {\\bf y}\\) 이라면 회귀!\n\\({\\bf X} \\to {\\bf y}\\) 에 대한 패턴이 \\(\\frac{\\exp(\\text{linr}({\\bf X}))}{1+\\exp(\\text{linr}({\\bf X}))} \\approx {\\bf y}\\) 이라면 로지스틱!\n\n\n\n🗣️(\n\nX를 linear transform했더니 선 자체가 y와 비슷 =&gt; 회귀\n위의 그래프를 그리는 식으로 했더니 y와 비슷 =&gt; 로지스틱\n\n정확히는 확률이 y와 비슷하다면 (y 자체는 0 또는 1)\n\n\n)🗣️"
  },
  {
    "objectID": "posts/03wk-1.html#c.-로지스틱-모형",
    "href": "posts/03wk-1.html#c.-로지스틱-모형",
    "title": "03wk-1: (회귀, 로지스틱) – 파이토치식 코딩패턴 (2), 로지스틱 모형",
    "section": "C. 로지스틱 모형",
    "text": "C. 로지스틱 모형\n- \\(x\\)가 커질수록 (혹은 작아질수록) \\(y=1\\)이 잘나오는 모형은 아래와 같이 설계할 수 있음 &lt;— 외우세요!!!\n\n\\(y_i \\sim {\\cal B}(\\pi_i),\\quad\\) where \\(\\pi_i = \\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)} = \\frac{1}{1+\\exp(-w_0-w_1x_i)}\\)\n\\(\\hat{y}_i= \\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\frac{1}{1+\\exp(-\\hat{w}_0-\\hat{w}_1x_i)}\\)\n🗣️\n\n\\(\\pi_i\\)는 확률을 의미\n\\(\\frac{e^{x}}{1 + e^{x}}\\) = \\(\\frac{1}{e^{-x} + 1}\\) 에서 \\(x\\) 대신 \\(w_0+w_1x_i\\)\n책 마다 다르지만 오른쪽처럼 많이 씀\n\n\n- 회귀모형과 로지스틱 모형의 비교\n\n회귀모형: \\(y_i \\sim {\\cal N}(w_0+w_1x_i, \\sigma^2)\\)1\n로지스틱: \\(y_i \\sim {\\cal B}\\big(\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\big)\\)\n🗣️\n\n회귀모형: 오차항의 관점에서 해석\n로지스틱(y가 0 또는 1): 위의 곡선을 나타내는 일반적인 수식\n\n=&gt; 이 수식값을 토대로 베르누이 시행을 하면 오차항까지 설명 가능한 모델이 됨\n\n\n\n- 우리가 예측하고 싶은것\n\n회귀모형: 정규분포의 평균을 예측하고 싶음. 즉 \\(w_0+w_1x_i\\)를 예측하고 싶음. 예측값으로는 \\(\\hat{w}_0 + \\hat{w}_1x_i\\)를 사용!\n로지스틱: 베르누이의 평균을 예측하고 싶음. 즉 \\(\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\)를 예측하고 싶음. 예측값으로는 \\(\\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}\\)를 사용!\n🗣️\n\n둘 다 \\(\\hat{w}_0\\), \\(\\hat{w}_1\\)를 추정하면 각각 직선과 곡선이 결정됨\n베르누이의 평균은 \\(p\\)\n\n즉, 확률을 예측하고 싶음"
  },
  {
    "objectID": "posts/03wk-1.html#footnotes",
    "href": "posts/03wk-1.html#footnotes",
    "title": "03wk-1: (회귀, 로지스틱) – 파이토치식 코딩패턴 (2), 로지스틱 모형",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n원래는 이렇게 썼었지.. \\(y_i = w_0 + w_1x_i + \\epsilon_i \\quad \\epsilon_i \\sim {\\cal N}(0,\\sigma^2)\\)↩︎"
  },
  {
    "objectID": "posts/13wk-2.html",
    "href": "posts/13wk-2.html",
    "title": "13wk-2: (강화학습) – Bandit 환경 설계 및 풀이, 4x4 Grid World 게임설명, 환경구현, 에이전트(랜덤)구현",
    "section": "",
    "text": "📘 Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\n📝 🗣️ ✍️ 🔬 ❓"
  },
  {
    "objectID": "posts/13wk-2.html#a.-대충-개념만-실습",
    "href": "posts/13wk-2.html#a.-대충-개념만-실습",
    "title": "13wk-2: (강화학습) – Bandit 환경 설계 및 풀이, 4x4 Grid World 게임설명, 환경구현, 에이전트(랜덤)구현",
    "section": "A. 대충 개념만 실습",
    "text": "A. 대충 개념만 실습\n\naction_space = [0,1] \nactions_deque = collections.deque(maxlen=500)\nrewards_deque =  collections.deque(maxlen=500)\n#---#\n\n\nfor _ in range(10):\n    action = np.random.choice(action_space)\n    if action == 1:\n        reward = 10 \n    else:\n        reward = 1\n    actions_deque.append(action)\n    rewards_deque.append(reward)\n\n\nactions_deque\n\ndeque([np.int64(1),\n       np.int64(0),\n       np.int64(0),\n       np.int64(1),\n       np.int64(0),\n       np.int64(0),\n       np.int64(0),\n       np.int64(1),\n       np.int64(1),\n       np.int64(0)],\n      maxlen=500)\n\n\n\nrewards_deque\n\ndeque([10, 1, 1, 10, 1, 1, 1, 10, 10, 1], maxlen=500)\n\n\n\nactions_numpy = np.array(actions_deque)\nrewards_numpy = np.array(rewards_deque)\n\n\nq0 = rewards_numpy[actions_numpy == 0].mean()\nq1 = rewards_numpy[actions_numpy == 1].mean()\nq_table = np.array([q0,q1])\nq_table\n\narray([ 1., 10.])\n\n\n\naction = q_table.argmax()\n\n\nfor _ in range(5):\n    action = q_table.argmax()\n    if action == 1:\n        reward = 10 \n    else:\n        reward = 1\n    actions_deque.append(action)\n    rewards_deque.append(reward)\n    actions_numpy = np.array(actions_deque)\n    rewards_numpy = np.array(rewards_deque)    \n    q0 = rewards_numpy[actions_numpy == 0].mean()\n    q1 = rewards_numpy[actions_numpy == 1].mean()\n    q_table = np.array([q0,q1])\n\n\nactions_numpy\n\narray([1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1])\n\n\n\nrewards_numpy\n\narray([10,  1,  1, 10,  1,  1,  1, 10, 10,  1, 10, 10, 10, 10, 10])"
  },
  {
    "objectID": "posts/13wk-2.html#b.-클래스를-이용한-구현",
    "href": "posts/13wk-2.html#b.-클래스를-이용한-구현",
    "title": "13wk-2: (강화학습) – Bandit 환경 설계 및 풀이, 4x4 Grid World 게임설명, 환경구현, 에이전트(랜덤)구현",
    "section": "B. 클래스를 이용한 구현",
    "text": "B. 클래스를 이용한 구현\n\nclass Bandit:\n    def __init__(self):\n        self.reward = None \n    def step(self,action):\n        if action == 0:\n            self.reward = 1\n        else: \n            self.reward = 10 \n        return self.reward \n\n\nclass Agent:\n    def __init__(self):\n        pass \n    def act(self):\n        # 만약에 경험이 20보다 작음 --&gt; 랜덤액션 \n        # 경험이 20보다 크면 --&gt; action = q_table.argmax()\n        pass \n    def save_experience(self):\n        # 데이터 저장 \n        pass \n    def learn(self):\n        # q_table 을 업데이트하는 과정 \n        pass\n\n🗣️(\n에이전트(=플레이어) 액션 –&gt; 보상, 다음상태\n\nenv = Bandit()\n\n\nenv.step(1)\n\n10\n\n\n\nclass Agent:\n    def __init__(self):\n        self.action = None\n        self.action_space = [0,1]\n        self.q_table = None\n    def act(self):\n        if n_experience &lt; 20:\n            self.action = np.random.choice(self.action_space)\n        else:\n            self.action = self.q_table.argmax()\n        # 만약에 경험이 20보다 작음 --&gt; 랜덤액션 \n        # 경험이 20보다 크면 --&gt; action = q_table.argmax()\n        pass \n    def save_experience(self):\n        # 데이터 저장 \n        pass \n    def learn(self):\n        # q_table 을 업데이트하는 과정 \n        pass\n\n\n아래를 먼저 채우고 그에 맞춰 위의 __init__을 채움\n\n\nclass Agent:\n    def __init__(self):\n        self.action = None\n        self.action_space = [0,1]\n        self.q_table = None\n        self.n_experience = 0\n    def act(self):\n        if self.n_experience &lt; 20:\n            self.action = np.random.choice(self.action_space)\n        else:\n            self.action = self.q_table.argmax() \n    def save_experience(self):\n        # 데이터 저장 \n        pass \n    def learn(self):\n        # q_table 을 업데이트하는 과정 \n        pass\n\n\nclass Agent:\n    def __init__(self):\n        self.action = None\n        self.reward = None\n        self.actions = collections.deque(maxlen=500)\n        self.rewards = collections.deque(maxlen=500)\n        self.action_space = [0,1]\n        self.q_table = None\n        self.n_experience = 0\n    def act(self):\n        if self.n_experience &lt; 20:\n            self.action = np.random.choice(self.action_space)\n        else:\n            self.action = self.q_table.argmax() \n    def save_experience(self):\n        self.actions.append(self.action)\n        self.rewards.append(self.reward)\n        self.n_experience = self.n_experience + 1 \n    def learn(self):\n        # q_table 을 업데이트하는 과정\n        q0 = rewards[actions == 0].mean() # 행동0을 했을 때 얻는 보상의 평균값\n        q1 = rewards[actions == 1].mean() # 행동1을 했을 때 얻는 보상의 평균값\n        self.q_table = np.array([q0, q1])\n\n\nclass Agent:\n    def __init__(self):\n        self.action = None\n        self.reward = None\n        self.actions = collections.deque(maxlen=500)\n        self.rewards = collections.deque(maxlen=500)\n        self.action_space = [0,1]\n        self.q_table = None\n        self.n_experience = 0\n    def act(self):\n        if self.n_experience &lt; 20:\n            self.action = np.random.choice(self.action_space)\n        else:\n            self.action = self.q_table.argmax() \n    def save_experience(self):\n        self.actions.append(self.action)\n        self.rewards.append(self.reward)\n        self.n_experience = self.n_experience + 1 \n    def learn(self):\n        if self.n_experience &lt; 20:\n            pass\n        else:\n            # q_table 을 업데이트하는 과정\n            actions = np.array(self.actions)\n            rewards = np.array(self.rewards)\n            q0 = rewards[actions == 0].mean() # 행동0을 했을 때 얻는 보상의 평균값\n            q1 = rewards[actions == 1].mean() # 행동1을 했을 때 얻는 보상의 평균값\n            self.q_table = np.array([q0, q1])\n\n\nenv = Bandit()\nplayer = Agent()\n\n\nplayer.act()\n\n\nplayer.action\n\nnp.int64(1)\n\n\n\n행동을 하기는 하나 어떤 행동을 보기가 직관적이지 않음\n\n\nclass Agent:\n    def __init__(self):\n        self.action = None\n        self.reward = None\n        self.actions = collections.deque(maxlen=500)\n        self.rewards = collections.deque(maxlen=500)\n        self.action_space = [0,1]\n        self.q_table = None\n        self.n_experience = 0\n    def act(self):\n        if self.n_experience &lt; 20:\n            self.action = np.random.choice(self.action_space)\n        else:\n            self.action = self.q_table.argmax()\n        print(f\"버튼{self.action}누름!\")\n    def save_experience(self):\n        self.actions.append(self.action)\n        self.rewards.append(self.reward)\n        self.n_experience = self.n_experience + 1 \n    def learn(self):\n        if self.n_experience &lt; 20:\n            pass\n        else:\n            # q_table 을 업데이트하는 과정\n            actions = np.array(self.actions)\n            rewards = np.array(self.rewards)\n            q0 = rewards[actions == 0].mean() # 행동0을 했을 때 얻는 보상의 평균값\n            q1 = rewards[actions == 1].mean() # 행동1을 했을 때 얻는 보상의 평균값\n            self.q_table = np.array([q0, q1])\n\n\nenv = Bandit()\nplayer = Agent()\n\n\nplayer.act()\n\n버튼1누름!\n\n\n\nplayer.action\n\nnp.int64(1)\n\n\n\n실질적 동작\n\n\nplayer.act()\nprint(player.action)\n\n버튼1누름!\n1\n\n\n\nplayer.act()\nenv.step(player.action)\n\n버튼1누름!\n\n\n10\n\n\n\nplayer.act()\nplayer.reward = env.step(player.action)\nprint(player.action, player.reward)\n\n버튼0누름!\n0 1\n\n\n\nplayer.actions # history가 있을 줄 알았는데 없음\n\ndeque([], maxlen=500)\n\n\n\nplayer.act()\nplayer.reward = env.step(player.action)\nplayer.save_experience()\nprint(player.action, player.reward)\n\n버튼0누름!\n0 1\n\n\n\nplayer.actions\n\ndeque([np.int64(0)], maxlen=500)\n\n\n\nplayer.rewards\n\ndeque([1], maxlen=500)\n\n\n\n저장된 것을 바탕으로 q_table을 만들어야 함\n\n\nplayer.act()\nplayer.reward = env.step(player.action)\nplayer.save_experience() # 데이터를 저장\nplayer.learn() # 저장된 데이터를 학습\n\n버튼1누름!\n\n\n\nplayer.actions\n\ndeque([np.int64(0), np.int64(1), np.int64(1)], maxlen=500)\n\n\n\nplayer.rewards\n\ndeque([1, 10, 10], maxlen=500)\n\n\n\nplayer.q_table # 없는 이유: n_experience &lt; 20\n\n\nenv = Bandit()\nplayer = Agent()\n\n\nfor _ in range(19):\n    player.act()\n    player.reward = env.step(player.action)\n    player.save_experience() # 데이터를 저장\n    player.learn() # 저장된 데이터를 학습\n\n버튼0누름!\n버튼1누름!\n버튼0누름!\n버튼1누름!\n버튼0누름!\n버튼0누름!\n버튼1누름!\n버튼0누름!\n버튼0누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼0누름!\n버튼0누름!\n버튼1누름!\n버튼1누름!\n버튼0누름!\n버튼0누름!\n버튼0누름!\n\n\n\nplayer.actions\n\ndeque([np.int64(0),\n       np.int64(1),\n       np.int64(0),\n       np.int64(1),\n       np.int64(0),\n       np.int64(0),\n       np.int64(1),\n       np.int64(0),\n       np.int64(0),\n       np.int64(1),\n       np.int64(1),\n       np.int64(1),\n       np.int64(0),\n       np.int64(0),\n       np.int64(1),\n       np.int64(1),\n       np.int64(0),\n       np.int64(0),\n       np.int64(0)],\n      maxlen=500)\n\n\n\nplayer.rewards\n\ndeque([1, 10, 1, 10, 1, 1, 10, 1, 1, 10, 10, 10, 1, 1, 10, 10, 1, 1, 1],\n      maxlen=500)\n\n\n\nplayer.q_table # 없는 이유: n_experience &lt; 20\n\n\nenv = Bandit()\nplayer = Agent()\n\n\nfor _ in range(40):\n    player.act()\n    player.reward = env.step(player.action)\n    player.save_experience() # 데이터를 저장\n    player.learn() # 저장된 데이터를 학습\n\n버튼0누름!\n버튼1누름!\n버튼0누름!\n버튼0누름!\n버튼1누름!\n버튼0누름!\n버튼1누름!\n버튼0누름!\n버튼0누름!\n버튼0누름!\n버튼1누름!\n버튼1누름!\n버튼0누름!\n버튼0누름!\n버튼0누름!\n버튼0누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼0누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n\n\n\nplayer.actions\n\ndeque([np.int64(0),\n       np.int64(1),\n       np.int64(0),\n       np.int64(0),\n       np.int64(1),\n       np.int64(0),\n       np.int64(1),\n       np.int64(0),\n       np.int64(0),\n       np.int64(0),\n       np.int64(1),\n       np.int64(1),\n       np.int64(0),\n       np.int64(0),\n       np.int64(0),\n       np.int64(0),\n       np.int64(1),\n       np.int64(1),\n       np.int64(1),\n       np.int64(0),\n       np.int64(1),\n       np.int64(1),\n       np.int64(1),\n       np.int64(1),\n       np.int64(1),\n       np.int64(1),\n       np.int64(1),\n       np.int64(1),\n       np.int64(1),\n       np.int64(1),\n       np.int64(1),\n       np.int64(1),\n       np.int64(1),\n       np.int64(1),\n       np.int64(1),\n       np.int64(1),\n       np.int64(1),\n       np.int64(1),\n       np.int64(1),\n       np.int64(1)],\n      maxlen=500)\n\n\n\nplayer.rewards\n\ndeque([1,\n       10,\n       1,\n       1,\n       10,\n       1,\n       10,\n       1,\n       1,\n       1,\n       10,\n       10,\n       1,\n       1,\n       1,\n       1,\n       10,\n       10,\n       10,\n       1,\n       10,\n       10,\n       10,\n       10,\n       10,\n       10,\n       10,\n       10,\n       10,\n       10,\n       10,\n       10,\n       10,\n       10,\n       10,\n       10,\n       10,\n       10,\n       10,\n       10],\n      maxlen=500)\n\n\n\nplayer.q_table\n\narray([ 1., 10.])\n\n\n\n게임 종료 조건이 필요할 것 같음\n\n\nnp.array(player.rewards)[-20:] # 최근 20번째\n\narray([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n       10, 10, 10])\n\n\n\nnp.array(player.rewards)[-20:].mean() &gt; 9.5\n\nnp.True_\n\n\n\nenv = Bandit()\nplayer = Agent()\n\n\nfor _ in range(100):\n    player.act()\n    player.reward = env.step(player.action)\n    player.save_experience() # 데이터를 저장\n    player.learn() # 저장된 데이터를 학습\n    if np.array(player.rewards)[-20:].mean() &gt; 9.5:\n        print(\"---게임클리어---\")\n        break\n\n버튼0누름!\n버튼1누름!\n버튼1누름!\n버튼0누름!\n버튼1누름!\n버튼0누름!\n버튼1누름!\n버튼0누름!\n버튼0누름!\n버튼0누름!\n버튼0누름!\n버튼1누름!\n버튼1누름!\n버튼0누름!\n버튼0누름!\n버튼0누름!\n버튼1누름!\n버튼1누름!\n버튼0누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n---게임클리어---\n\n\n\nfor _ in range(100):\n    player.act()\n    player.reward = env.step(player.action)\n    player.save_experience() # 데이터를 저장\n    player.learn() # 저장된 데이터를 학습\n    if np.array(player.rewards)[-20:].mean() &gt; 9.5:\n        print(\"---게임클리어---\")\n        break\n\n버튼1누름!\n---게임클리어---\n\n\n\n위와 같은 경우를 피하기 위해서\n\n\nenv = Bandit()\nplayer = Agent()\n\n\nfor _ in range(100):\n    player.act()\n    player.reward = env.step(player.action)\n    player.save_experience() # 데이터를 저장\n    player.learn() # 저장된 데이터를 학습\n    if player.n_experience &lt; 20:\n        pass\n    else:\n        if np.array(player.rewards)[-20:].mean() &gt; 9.5:\n            print(\"---게임클리어---\")\n            break\n\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼0누름!\n버튼1누름!\n버튼0누름!\n버튼0누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼0누름!\n버튼0누름!\n버튼1누름!\n버튼0누름!\n버튼0누름!\n버튼1누름!\n버튼0누름!\n버튼0누름!\n버튼1누름!\n버튼0누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n---게임클리어---\n\n\n\n정리\n\nenv = Bandit()\nplayer = Agent()\nfor _ in range(100):\n    # step1: agent action\n    player.act()\n    # step2: action --&gt; state, reward\n    player.reward = env.step(player.action)\n    # step3: agent가 데이터를 축적하고 학습\n    player.save_experience() # 데이터를 저장\n    player.learn() # 저장된 데이터를 학습\n    # --- 강화학습의 종료를 결정 --- #\n    if player.n_experience &lt; 20:\n        pass\n    else:\n        if np.array(player.rewards)[-20:].mean() &gt; 9.5:\n            print(\"---게임클리어---\")\n            break\n)🗣️\n\n\nclass Agent:\n    def __init__(self):\n        self.action = None \n        self.reward = None \n        self.actions = collections.deque(maxlen=500)\n        self.rewards = collections.deque(maxlen=500)\n        self.action_space = [0,1] \n        self.q_table = None \n        self.n_experience = 0\n    def act(self):\n        if self.n_experience &lt; 20:\n            self.action = np.random.choice(self.action_space)\n        else: \n            self.action = self.q_table.argmax()\n        print(f\"버튼{self.action}누름!\")\n    def save_experience(self):\n        self.actions.append(self.action)\n        self.rewards.append(self.reward)\n        self.n_experience = self.n_experience + 1\n    def learn(self):\n        if self.n_experience &lt; 20:\n            pass\n        else:\n            # q_table 을 업데이트하는 과정 \n            actions = np.array(self.actions)\n            rewards = np.array(self.rewards)\n            q0 = rewards[actions == 0].mean() # 행동0을했을때 얻는 보상의 평균값\n            q1 = rewards[actions == 1].mean()# 행동1을했을때 얻는 보상의 평균값\n            self.q_table = np.array([q0,q1])\n\n\nenv = Bandit()\nplayer = Agent()\nfor _ in range(100):\n    # step1: agent action \n    player.act()\n    # step2: action --&gt; state, reward\n    player.reward = env.step(player.action)\n    # step3: agent가 데이터를 축적하고 학습\n    player.save_experience() # 데이터를 저장\n    player.learn() #저장된 데이터를 학습 \n    #---강화학습의 종료를 결정--#\n    if player.n_experience &lt; 20:\n        pass \n    else: \n        if np.array(player.rewards)[-20:].mean() &gt; 9.5:\n            print(\"---게임클리어---\")\n            break\n\n버튼1누름!\n버튼0누름!\n버튼1누름!\n버튼0누름!\n버튼0누름!\n버튼1누름!\n버튼0누름!\n버튼1누름!\n버튼0누름!\n버튼0누름!\n버튼0누름!\n버튼1누름!\n버튼0누름!\n버튼1누름!\n버튼0누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼0누름!\n버튼0누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n---게임클리어---"
  },
  {
    "objectID": "posts/13wk-2.html#a.-게임설명",
    "href": "posts/13wk-2.html#a.-게임설명",
    "title": "13wk-2: (강화학습) – Bandit 환경 설계 및 풀이, 4x4 Grid World 게임설명, 환경구현, 에이전트(랜덤)구현",
    "section": "A. 게임설명",
    "text": "A. 게임설명\n- 문제설명: 4x4 그리드월드에서 상하좌우로 움직이는 에이전트가 목표점에 도달하도록 하는 게임\n\n백문이 불여일견: https://claude.ai/public/artifacts/76e13820-2b51-4e7e-a514-00190de17c45 (출처: 클로드)\n\n🗣️(\n\n에이전트 환경\n에이전트 행동 - 상하좌우로 이동 –&gt; 4개의 행동 = 0,1,2,3\n환경은 보상을 줌 -&gt; -1, -10, +100 중 하나를 줌\n\n-1: 격자 안에 에이전트가 있음 & 에이전트의 위치가 (3,3)이 아닐 때\n+100: (격자 안에 에이전트가 있음 &) 에이전트의 위치가 (3,3)일 때\n-10: 에이전트가 격자 안에 있지 않음\n\n에이전트 &lt;—&gt; 환경\n\n에이전트 –(action)–&gt; 환경\n에이전트 &lt;–(reward, state)– 환경\n\n\n)🗣️\n- GridWorld에서 사용되는 주요변수\n\nState: 각 격자 셀이 하나의 상태이며, 에이전트는 이러한 상태 중 하나에 있을 수 있음.\nAction: 에이전트는 현재상태에서 다음상태로 이동하기 위해 상,하,좌,우 중 하나의 행동을 취할 수 있음.\nReward: 에이전트가 현재상태에서 특정 action을 하면 얻어지는 보상.\nTerminated: 하나의 에피소드가 종료되었음을 나타내는 상태."
  },
  {
    "objectID": "posts/13wk-2.html#b.-시각화",
    "href": "posts/13wk-2.html#b.-시각화",
    "title": "13wk-2: (강화학습) – Bandit 환경 설계 및 풀이, 4x4 Grid World 게임설명, 환경구현, 에이전트(랜덤)구현",
    "section": "B. 시각화",
    "text": "B. 시각화\n\ndef show(states):\n    fig = plt.Figure()\n    ax = fig.subplots()\n    ax.matshow(np.zeros([4,4]), cmap='bwr',alpha=0.0)\n    sc = ax.scatter(0, 0, color='red', s=500)  \n    ax.text(0, 0, 'start', ha='center', va='center')\n    ax.text(3, 3, 'end', ha='center', va='center')\n    # Adding grid lines to the plot\n    ax.set_xticks(np.arange(-.5, 4, 1), minor=True)\n    ax.set_yticks(np.arange(-.5, 4, 1), minor=True)\n    ax.grid(which='minor', color='black', linestyle='-', linewidth=2)\n    state_space = gym.spaces.MultiDiscrete([4,4])\n    def update(t):\n        if states[t] in state_space:\n            s1,s2 = states[t]\n            states[t] = [s2,s1]\n            sc.set_offsets(states[t])\n        else:\n            s1,s2 = states[t]\n            s1 = s1 + 0.5 if s1 &lt; 0 else (s1 - 0.5 if s1 &gt; 3 else s1)\n            s2 = s2 + 0.5 if s2 &lt; 0 else (s2 - 0.5 if s2 &gt; 3 else s2)\n            states[t] = [s2,s1]       \n            sc.set_offsets(states[t])\n    ani = FuncAnimation(fig,update,frames=len(states))\n    display(IPython.display.HTML(ani.to_jshtml()))\n\n🗣️(\n\n위 코드는 공부할 필요 없고, 사용 방법을 알면 됨\n\n\nshow(\n    [[0,0],[0,1]]\n)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\nshow(\n    [[0,0],[0,1],[0,2],[0,3],[0,4]]\n) # 밖으로 나감\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n)🗣️\n\nshow([[0,0],[1,0],[2,0],[3,0],[4,0]]) # show 사용방법\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/exercise-f1.html",
    "href": "posts/exercise-f1.html",
    "title": "A1: Exercise – ver. 0505-1 #1",
    "section": "",
    "text": "문제풀이에 필요한 모듈은 스스로 import 할 것\nimport torch"
  },
  {
    "objectID": "posts/exercise-f1.html#벡터와-행렬",
    "href": "posts/exercise-f1.html#벡터와-행렬",
    "title": "A1: Exercise – ver. 0505-1 #1",
    "section": "$. 벡터와 행렬",
    "text": "$. 벡터와 행렬\n(1) 아래와 같이 length 5 인 vector를 torch.tensor로 선언하는 코드를 작성하라.\n\\[{\\bf x} = [1,2,3,4,5]\\]\n(풀이)\n\nx = torch.tensor([1,2,3,4,5])\nx\n\ntensor([1, 2, 3, 4, 5])\n\n\n(2) 아래와 같은 2x2 matrix 를 torch.tensor로 선언하는 코드를 작성하라.\n\\[{\\bf A} = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix}\\]\n(풀이?)\n\nA = torch.tensor([[1,2],[3,4]])\nA\n\ntensor([[1, 2],\n        [3, 4]])\n\n\n(3) 아래와 같은 matrix 를 torch.tensor로 선언하는 코드를 작성하라.\n\\[{\\bf W} = \\begin{bmatrix} 2.5  \\\\  4 \\end{bmatrix}\\]\n(풀이?)\n\nW = torch.tensor([[2.5],[4]])\nW\n\ntensor([[2.5000],\n        [4.0000]])\n\n\n(4) 아래와 같은 matrix 를 torch.tensor로 선언하는 코드를 작성하라.\n\\[{\\bf x} = \\begin{bmatrix} 2.5  & 4 \\end{bmatrix}\\]\n(풀이?)\n\nx = torch.tensor([[2.5, 4]])\nx\n\ntensor([[2.5000, 4.0000]])"
  },
  {
    "objectID": "posts/exercise-f1.html#concat-stack",
    "href": "posts/exercise-f1.html#concat-stack",
    "title": "A1: Exercise – ver. 0505-1 #1",
    "section": "$. concat, stack",
    "text": "$. concat, stack\na,b가 아래와 같이 주어졌다고 하자.\n\na = torch.tensor([1]*10)\nb = torch.tensor([2]*10)\n\n(관찰?)\n\na\n\ntensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n\n\n\na.shape\n\ntorch.Size([10])\n\n\n\nb\n\ntensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n\n\n(실험?)\n\ntorch.tensor([[1]*10])\n\ntensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n\n\n\ntorch.tensor([[1]*10]).shape\n\ntorch.Size([1, 10])\n\n\n아래를 잘 읽고 물음에 답하라.\n(1) 주어진 a,b와 torch.concat를 이용하여 아래와 같은 배열을 만들어라.\ntensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n\ntorch.concat([a.reshape(-1,1), b.reshape(-1,1)])\n\ntensor([[1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2]])\n\n\n(풀이?)\n\ntorch.concat([a,b])\n\ntensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n\n\n(2) 주어진 a,b 와 torch.concat,.reshape를 이용하여 아래와 같은 배열을 만들어라.\ntensor([[1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2]])\n(풀이)\n\ntorch.concat([a.reshape(-1,1), b.reshape(-1,1)])\n\ntensor([[1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2]])\n\n\n(관찰?)\n\na.reshape(-1,1)\n\ntensor([[1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1]])\n\n\n\na\n\ntensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n\n\n(3) 주어진 a,b 와 torch.concat,.reshape를 이용하여 아래와 같은 배열을 만들어라.\ntensor([[1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2]])\n(풀이?)\n\ntorch.concat([a,b])\n\ntensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n\n\n\ntorch.concat([a,b]).reshape(-1,2)\n\ntensor([[1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [2, 2],\n        [2, 2],\n        [2, 2],\n        [2, 2],\n        [2, 2]])\n\n\n\ntorch.concat([a.reshape(-1,1),b.reshape(-1,1)], axis=1)\n\ntensor([[1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2]])\n\n\n(4) 주어진 a,b와 torch.stack 을 이용하여 아래와 같은 배열을 만들어라.\ntensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]\n(풀이?)\n\ntorch.stack([a,b])\n\ntensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2]])\n\n\n(관찰?)\n\ntorch.stack([a,b], axis=1)\n\ntensor([[1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2]])\n\n\n(5) 주어진 a,b와 torch.stack을 이용하여 아래와 같은 배열을 만들어라.\ntensor([[1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2]])\n(풀이?)\n\ntorch.stack([a,b], axis=1)\n\ntensor([[1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2]])"
  },
  {
    "objectID": "posts/exercise-f1.html#행렬곱",
    "href": "posts/exercise-f1.html#행렬곱",
    "title": "A1: Exercise – ver. 0505-1 #1",
    "section": "$. 행렬곱",
    "text": "$. 행렬곱\n(1) 아래와 같은 텐서를 고려하자.\n\na = torch.tensor([1,2,3,4,5]).reshape(-1,1)\nb = torch.tensor([3,2,1,1,2]).reshape(-1,1)\n\n@ 연산자를 이용하여 \\(\\sum_{i=1}^{5}a_ib_i\\)를 계산하라.\n(풀이)\n\na.T @ b\n\ntensor([[24]])\n\n\n(2) 아래와 같은 텐서를 고려하자.\n\ntorch.manual_seed(0)\nx = torch.randn(100).reshape(-1,1)\n\n@연산자를 이용하여 \\(\\sum_{i=1}^{100}x_i^2\\)을 계산하라.\n(풀이?)\n\nx.T @ x\n\ntensor([[105.0856]])\n\n\n\ny = x.squeeze()\ny @ y\n\ntensor(105.0856)"
  },
  {
    "objectID": "posts/exercise-f1.html#인덱싱",
    "href": "posts/exercise-f1.html#인덱싱",
    "title": "A1: Exercise – ver. 0505-1 #1",
    "section": "$. 인덱싱",
    "text": "$. 인덱싱\n아래와 같은 배열을 선언하라.\n\ntorch.manual_seed(1)\nx = torch.randn(12).reshape(3,4)\nx\n\ntensor([[ 0.6614,  0.2669,  0.0617,  0.6213],\n        [-0.4519, -0.1661, -1.5228,  0.3817],\n        [-1.0276, -0.5631, -0.8923, -0.0583]])\n\n\n(1) 1열을 추출하는 코드를 작성하라. 즉 결과가 아래와 같이 나오도록 하라.\ntensor([[ 0.6614],\n        [-0.4519],\n        [-1.0276]])\n(풀이?)\n\nx[:,0]\n\ntensor([ 0.6614, -0.4519, -1.0276])\n\n\n\nx[:,0].reshape(-1,1)\n\ntensor([[ 0.6614],\n        [-0.4519],\n        [-1.0276]])\n\n\n\nx[:,0].unsqueeze(1)\n\ntensor([[ 0.6614],\n        [-0.4519],\n        [-1.0276]])\n\n\n(2) 2-3열을 추출하는 코드를 작성하라. 즉 결과가 아래와 같이 나오도록 하라.\ntensor([[ 0.2669,  0.0617],\n        [-0.1661, -1.5228],\n        [-0.5631, -0.8923]])\n(풀이?)\n\nx[:,1:3]\n\ntensor([[ 0.2669,  0.0617],\n        [-0.1661, -1.5228],\n        [-0.5631, -0.8923]])\n\n\n\nx[:,[1,2]]\n\ntensor([[ 0.2669,  0.0617],\n        [-0.1661, -1.5228],\n        [-0.5631, -0.8923]])\n\n\n(3) 2-3행을 추출하는 코드를 작성하라. 즉 결과가 아래와 같이 나오도록 하라.\ntensor([[-0.4519, -0.1661, -1.5228,  0.3817],\n        [-1.0276, -0.5631, -0.8923, -0.0583]])\n\n(풀이?)\n\nx[1:,:]\n\ntensor([[-0.4519, -0.1661, -1.5228,  0.3817],\n        [-1.0276, -0.5631, -0.8923, -0.0583]])\n\n\n\nx[1:3,:]\n\ntensor([[-0.4519, -0.1661, -1.5228,  0.3817],\n        [-1.0276, -0.5631, -0.8923, -0.0583]])\n\n\n\nx[[1,2],:]\n\ntensor([[-0.4519, -0.1661, -1.5228,  0.3817],\n        [-1.0276, -0.5631, -0.8923, -0.0583]])\n\n\n(관찰?)\n\nx[1:2,:]\n\ntensor([[-0.4519, -0.1661, -1.5228,  0.3817]])"
  },
  {
    "objectID": "posts/exercise-f1.html#torch.einsum",
    "href": "posts/exercise-f1.html#torch.einsum",
    "title": "A1: Exercise – ver. 0505-1 #1",
    "section": "$. torch.einsum",
    "text": "$. torch.einsum\n(1) 아래에 코드중 X.t()에 대응하는 코드를 torch.einsum으로 구현하라.\n\nX = torch.randn(5,2)\nX.t()\n\ntensor([[-0.1955,  0.4224, -0.4212, -1.5727,  3.5870],\n        [-0.9656,  0.2673, -0.5107, -0.1232, -1.8313]])\n\n\n(풀이?)\n\ntorch.einsum('ij-&gt;ji', X)\n\ntensor([[-0.1955,  0.4224, -0.4212, -1.5727,  3.5870],\n        [-0.9656,  0.2673, -0.5107, -0.1232, -1.8313]])\n\n\n(2) 아래에 코드중 X@b에 대응하는 코드를 torch.einsum으로 구현하라.\n\nX = torch.randn(5,2)\nb = torch.randn(2,1)\nX@b\n\ntensor([[ 3.0610],\n        [ 1.1183],\n        [-5.5600],\n        [ 2.2772],\n        [-1.3251]])\n\n\n(풀이?)\n\ntorch.einsum('ij,jk-&gt;ik', X, b)\n\ntensor([[ 3.0610],\n        [ 1.1183],\n        [-5.5600],\n        [ 2.2772],\n        [-1.3251]])\n\n\n(3) 아래에 코드중 linr(X)에 대응하는 코드를 torch.einsum으로 구현하라.\n\nX =  torch.randn(5,2)\nlinr = torch.nn.Linear(2,1,bias=False)\nlinr(X)\n\ntensor([[-0.1186],\n        [-0.1857],\n        [ 0.1783],\n        [ 0.2444],\n        [ 0.4162]], grad_fn=&lt;MmBackward0&gt;)\n\n\n(풀이?)\n\nW = linr.weight\n\n\nW.shape\n\ntorch.Size([1, 2])\n\n\n\ntorch.einsum('ij,kj-&gt;ik', X, W)   # shape: (5,1)\n\ntensor([[-0.1186],\n        [-0.1857],\n        [ 0.1783],\n        [ 0.2444],\n        [ 0.4162]], grad_fn=&lt;ViewBackward0&gt;)"
  },
  {
    "objectID": "posts/10wk-2.html",
    "href": "posts/10wk-2.html",
    "title": "10wk-2: (추천시스템) – optimizer 사용 고급, 모델링 전략, MF-based 추천시스템",
    "section": "",
    "text": "📘 Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\n📝 🗣️ ✍️ 🔬 ❓"
  },
  {
    "objectID": "posts/10wk-2.html#a.-optimizer-사용-고급",
    "href": "posts/10wk-2.html#a.-optimizer-사용-고급",
    "title": "10wk-2: (추천시스템) – optimizer 사용 고급, 모델링 전략, MF-based 추천시스템",
    "section": "A. optimizer 사용 고급",
    "text": "A. optimizer 사용 고급\n# 회귀분석 – 안알려줬던 기술..\n주어진 자료가 아래와 같다고 하자.\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\nx = x.reshape(-1,1)\nones= torch.ones(100).reshape(-1,1)\nX = torch.concat([ones,x],axis=-1)\nϵ = torch.randn(100).reshape(-1,1)*0.5\ny = 2.5+ 4*x + ϵ\n\n\nplt.plot(x,y,'o')\n\n\n\n\n\n\n\n\n\nw = torch.tensor(10.0,requires_grad=True)\nb = torch.tensor(-5.0,requires_grad=True)\n\n\nplt.plot(x,y,'o')\nplt.plot(x,(x*w + b).data,'--')\n\n\n\n\n\n\n\n\ntorch.optim.SGD를 이용하여 What을 update하라. 학습률은 0.1로 설정하고 30회 update하라.\n(풀이)\n🗣️(\n\nloss_fn = torch.nn.MSELoss()\n# optimizr = torch.optim.SGD(net.parameters())\nfor epoc in range(30):\n    yhat = x*w + b\n    loss = loss_fn(yhat,y)\n    loss.backward()\n    w.data = w.data - 0.1*w.grad\n    b.data = b.data - 0.1*b.grad\n    w.grad=None\n    b.grad=None\n\n\nyhat = x*w + b 이런 식이라 optimizr 사용 불가\n\n\nw,b\n\n(tensor(4.0144, requires_grad=True), tensor(2.4290, requires_grad=True))\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,(x*w + b).data,'--')\n\n\n\n\n\n\n\n\n\n이렇게 하려면 update 공식을 전부 알고 있어야 하므로 optimizer를 사용하고 싶음 (SGD만 바꿔서)\n\n\n# torch.optim.SGD?\n\nInit signature:\ntorch.optim.SGD(\n    params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]], Iterable[Tuple[str, torch.Tensor]]],\n    lr: Union[float, torch.Tensor] = 0.001,\n\nIterable 예시: 리스트\n\n학습하고 싶은 parameter들이 network 형태로 짜져 있지 않아도 리스트 형식으로 전달해주면 됨\n\n\n\nw = torch.tensor(10.0,requires_grad=True)\nb = torch.tensor(-5.0,requires_grad=True)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD([w,b],lr=0.1)\nfor epoc in range(30):\n    yhat = x*w +b \n    loss = loss_fn(yhat,y) \n    loss.backward()\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nw,b\n\n(tensor(4.0144, requires_grad=True), tensor(2.4290, requires_grad=True))\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,(x*w + b).data,'--')\n\n\n\n\n\n\n\n\n)🗣️\n\nw = torch.tensor(10.0,requires_grad=True)\nb = torch.tensor(-5.0,requires_grad=True)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD([w,b],lr=0.1)\nfor epoc in range(30):\n    yhat = x*w +b \n    loss = loss_fn(yhat,y) \n    loss.backward()\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nw,b\n\n(tensor(4.0144, requires_grad=True), tensor(2.4290, requires_grad=True))\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,(x*w + b).data,'--')\n\n\n\n\n\n\n\n\n#\n# 2025-중간고사 3번\n\ntorch.manual_seed(43052)\ndist = torch.distributions.Exponential(1/2)\nx = dist.sample((10000,1))\n\n주어진 자료 \\(x_i\\)에 대하여 함수 \\(l(\\lambda)\\)를 최대화하는 \\(\\lambda\\)를 경사하강법 기반의 알고리즘을 이용하여 추정하라. 단 이때 \\(\\lambda\\)의 초기 추정값은 1로 설정하라.\n\\[\nl(\\lambda) =\\frac{1}{n} \\sum_{i=1}^{n}\\log f(x_i), \\quad f(x_i) = \\frac{1}{\\lambda} e^{-\\frac{x_i}{\\lambda}}, \\quad x_i \\geq 0\n\\]\nhint\n\n\\(l(\\lambda)\\)를 최대화하는 \\(\\lambda\\)는 \\(-l(\\lambda)\\)를 최소화합니다.\n이론적으로는 \\(l(\\lambda)\\)를 최대화하는 \\(\\lambda\\)는 x.mean()입니다. 즉 제대로 \\(\\lambda\\)를 추정한다면 x.mean()이 나오도록 되어있습니다.\n저는 경사하강법을 이용했고 학습률은 0.05로 설정했습니다. 1000회 update하니까 잘 수렴했습니다.\n\n(풀이)\n🗣️(\n\nlamb = torch.tensor(1.0, requires_grad=True) # matrix [[1.0]]가 아니라 scalar여도 상관 X\n\n\n-x\n\ntensor([[-0.9071],\n        [-1.0760],\n        [-0.0572],\n        ...,\n        [-0.3747],\n        [-1.2479],\n        [-0.9108]])\n\n\n\n-x/lamb\n\ntensor([[-0.9071],\n        [-1.0760],\n        [-0.0572],\n        ...,\n        [-0.3747],\n        [-1.2479],\n        [-0.9108]], grad_fn=&lt;DivBackward0&gt;)\n\n\n\ntorch.exp(-x/lamb)\n\ntensor([[0.4037],\n        [0.3410],\n        [0.9444],\n        ...,\n        [0.6875],\n        [0.2871],\n        [0.4022]], grad_fn=&lt;ExpBackward0&gt;)\n\n\n\nfx = torch.exp(-x/lamb)/lamb\nl = torch.log(fx).mean()\n\n\nfor i in range(1000):\n    fx = torch.exp(-x/lamb)/lamb\n    l = torch.log(fx).mean()\n    (-l).backward()\n    lamb.data = lamb.data - 0.1*lamb.grad\n    lamb.grad = None\n\n\nlamb\n\ntensor(1.9874, requires_grad=True)\n\n\n\nx.mean()\n\ntensor(1.9874)\n\n\n\n다른 방법 (문법이 중요, iterable로 입력)\n\n\nlamb = torch.tensor(1.0, requires_grad=True)\noptimizr = torch.optim.SGD([lamb], lr=0.1)\n\n\nfor i in range(1000):\n    fx = torch.exp(-x/lamb)/lamb\n    l = torch.log(fx).mean()\n    (-l).backward()\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nlamb\n\ntensor(1.9874, requires_grad=True)\n\n\n)🗣️\n\nlamb = torch.tensor(1.0,requires_grad=True)\noptimizr = torch.optim.SGD([lamb],  lr =0.05)\n\n\nfor i in range(1000):\n    fx = torch.exp(-x/lamb)/lamb\n    l = torch.log(fx).mean()\n    (-l).backward()\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nlamb\n\ntensor(1.9874, requires_grad=True)\n\n\n#"
  },
  {
    "objectID": "posts/10wk-2.html#b.-모델링-전략",
    "href": "posts/10wk-2.html#b.-모델링-전략",
    "title": "10wk-2: (추천시스템) – optimizer 사용 고급, 모델링 전략, MF-based 추천시스템",
    "section": "B. 모델링 전략",
    "text": "B. 모델링 전략\n# 2025-중간고사 4번 – 자유 낙하 운동이란 어떤 물체가 일정한 높이에서 떨어져 지면에 도달하기 까지 걸리는 시간을 다루는 물리학 개념이다. 다음은 물리학의 자유 낙하 운동에서 착안하여 생성한 데이터이다.\n\ntorch.manual_seed(43052)\nh = torch.rand(100)*100\nh,_ = h.sort()\nh = h.reshape(100,1)\nt = torch.sqrt(2*h/9.8) + torch.randn([100,1])*0.1\n\n여기에서 \\(h\\)는 낙하전의 높이(단위: m), \\(t\\)는 해당높이에서 물치가 지면에 도달하기 까지 걸리는 시간(단위:초)을 의미한다. 예를 들어 아래의 자료는 \\(h=99.3920, t=4.4583\\)를 의미하는데\n\nh[-1], t[-1]\n\n(tensor([99.3920]), tensor([4.4583]))\n\n\n이것은 높이 \\(99.3920\\)m에서 낙하한 물체가 약 \\(4.4583\\)초만에 지면에 도달했음을 의미한다. 아래의 그림은 \\(x\\)축에 \\(h\\), \\(y\\)축에 \\(t\\)를 두고 해당 데이터를 산점도로 시각화 한 것이다.\n\nplt.plot(h,t,'o',alpha=0.5)\nplt.xlabel('Height (m)')\nplt.ylabel('Time to fall (sec)')\nplt.title('Free Fall Time vs Height')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n그래프를 보면 높이가 높을 수록 낙하시간도 길어지는 경향이 관찰된다. 다만 동일한 높이라 하더라도 낙하시간이 조금씩 차이나는 경우가 있는데, 이는 사람이 시간측정을 수동으로 하며 발생하는 실험오차 때문이다. 이러한 오차에도 불구하고 \\(h\\)와 \\(t\\)사이에는 일정한 규칙이 존재하는듯 하다. 물리학과 교수님께 자문을 요청한 결과 자유낙하에 걸리는 시간은 \\(\\sqrt{h}\\)에 비례함을 알 수 있었고 이를 근거로 아래와 같은 모형을 설계하였다.\n\\[t_i = \\beta_0 + \\beta_1 \\sqrt{h_i}+\\epsilon_i, \\quad \\epsilon_i \\sim {\\cal N}(0,\\sigma^2)\\]\n위의 모형을 활용하여 높이 \\(h\\)로부터 낙하시간 \\(t\\)를 예측하는 신경망 모델을 설계하고 학습하라. 학습한 신경망 모델을 활용하여 높이 40m,60m,80m 에서 물체를 자유낙하 시켰을때 지면에 도달하기까지 걸리는 시간을 각각 예측하라.\nhint\n\n\\(y_i = t_i\\) 로 생각하시고 \\(x_i= \\sqrt{h}_i\\)로 생각하시면 그냥 회귀모형이죠?\n답은 \\(2.8571\\)초, \\(3.4493\\)초, \\(4.0406\\)초 근처로 나오면 됩니다.\n제시된 모형(\\(t_i = \\beta_0 + \\beta_1 \\sqrt{h_i}+\\epsilon_i\\))을 무시하고 04wk-2와 같은 방식으로 신경망을 설계하고 푸셔도 만점으로 인정합니다.\n\n🗣️(\n\nh -&gt; t\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1)\n)\noptimizr = torch.optim.Adam(net.parameters())\nloss_fn = torch.nn.MSELoss()\n#--#\nfor epoc in range(100):\n    # 1\n    that = net(h)\n    # 2\n    loss = loss_fn(that,t)\n    # 3\n    loss.backward()\n    # 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(h,t,'o',alpha=0.5)\nplt.xlabel('Height (m)')\nplt.ylabel('Time to fall (sec)')\nplt.title('Free Fall Time vs Height')\nplt.grid(True)\nplt.plot(h,that.data,'--')\nplt.show()\n\n\n\n\n\n\n\n\n\nepoch을 2,000으로 증가\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1)\n)\noptimizr = torch.optim.Adam(net.parameters())\nloss_fn = torch.nn.MSELoss()\n#--#\nfor epoc in range(2000):\n    # 1\n    that = net(h)\n    # 2\n    loss = loss_fn(that,t)\n    # 3\n    loss.backward()\n    # 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(h,t,'o',alpha=0.5)\nplt.xlabel('Height (m)')\nplt.ylabel('Time to fall (sec)')\nplt.title('Free Fall Time vs Height')\nplt.grid(True)\nplt.plot(h,that.data,'--')\nplt.show()\n\n\n\n\n\n\n\n\n\nhh = torch.tensor([40,60,80]).float().reshape(3,1)\nnet(hh)\n\ntensor([[2.9389],\n        [3.4704],\n        [4.0018]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\n다르게 푼다면\n\nlinr1 = torch.nn.Linear(1,32)\nrelu = torch.nn.ReLU()\nlinr2 = torch.nn.Linear(32,1)\n\n#---#\nfor epoc in range(2000):\n    #1\n    that = linr2(relu(linr1(h)))\n    #2\n    loss = loss_fn(that,t)\n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\noptimizr는 어떻게?\n\n\nnet.parameters()\n\n&lt;generator object Module.parameters at 0x7f7f45c5d510&gt;\n\n\n\n리스트는 아니지만 generator\n\n\n# list(net.parameters())\n\n\n리스트로 만들 수 있으므로 이전 코드에 리스트만 해줘도 다 돌아감\noptimizr = torch.optim.Adam(list(net.parameters())) 도 되지만 아래와 같이 할 수도 있음\n\nlinr1 = torch.nn.Linear(1,32)\nrelu = torch.nn.ReLU() # parameter 없음\nlinr2 = torch.nn.Linear(32,1)\nlist(linr1.parameters()) + list(linr2.parameters())\n\nlinr1 = torch.nn.Linear(1,32)\nrelu = torch.nn.ReLU()\nlinr2 = torch.nn.Linear(32,1)\noptimizr = torch.optim.Adam(list(linr1.parameters()) + list(linr2.parameters()))\nloss_fn = torch.nn.MSELoss()\n#---#\nfor epoc in range(2000):\n    #1\n    that = linr2(relu(linr1(h)))\n    #2\n    loss = loss_fn(that,t)\n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(h,t,'o',alpha=0.5)\nplt.plot(h,that.data,'--')\n\n\n\n\n\n\n\n\n\nNetwork를 쓰면 편하지만 괜히 이렇게 풀어도 되긴 함\n지금까지는\n\ntorch.nn.Sequential : 순방향으로 흐름\n하지만 경우에 따라 Network가 그렇게 안 될 수도 있음\n그런 경우는 여러 Network를 짜서 조합 (위와 같이)\n\n\n)🗣️\n(풀이)\n🗣️(\n\n원래 풀이 (기존의 물리 이론 활용)\n\n\nx = torch.sqrt(h)\ny = t\nnet = torch.nn.Linear(1,1)\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(6000):\n    #1\n    yhat = net(x)\n    #2\n    loss = loss_fn(yhat,y)\n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(h,t,'o',alpha=0.5)\nplt.plot(h,yhat.data,'--')\n\n\n\n\n\n\n\n\n\nhh = torch.tensor([40,60,80]).float().reshape(3,1)\nxx = torch.sqrt(hh)\nnet(xx)\n\ntensor([[2.8532],\n        [3.4889],\n        [4.0249]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\n모델링에 있어 정답이 없어지는 추세..\n\n)🗣️\n\nlinr1 = torch.nn.Linear(1,32)\nrelu = torch.nn.ReLU()\nlinr2 = torch.nn.Linear(32,1)\noptimizr = torch.optim.Adam(list(linr1.parameters()) + list(linr2.parameters()))\nloss_fn = torch.nn.MSELoss()\n#---#\nfor epoc in range(2000):\n    #1\n    that = linr2(relu(linr1(h)))\n    #2\n    loss = loss_fn(that,t)\n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(h,t,'o',alpha=0.5)\nplt.plot(h,that.data,'--')\n\n\n\n\n\n\n\n\n\nhh = torch.tensor([40,60,80]).float().reshape(3,1)\nnet(hh)\n\ntensor([[2.8631],\n        [3.5162],\n        [4.0079]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n(풀이2)\n\nx = torch.sqrt(h)\ny = t \nnet = torch.nn.Linear(1,1)\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(6000):\n    #1\n    yhat = net(x) \n    #2\n    loss = loss_fn(yhat,y)\n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(h,t,'o',alpha=0.5)\nplt.plot(h,yhat.data,'--')\n\n\n\n\n\n\n\n\n\nhh = torch.tensor([40,60,80]).float().reshape(3,1)\nxx = torch.sqrt(hh)\nnet(xx)\n\ntensor([[2.8613],\n        [3.4889],\n        [4.0180]], grad_fn=&lt;AddmmBackward0&gt;)"
  },
  {
    "objectID": "posts/10wk-2.html#a.-data-나는-solo",
    "href": "posts/10wk-2.html#a.-data-나는-solo",
    "title": "10wk-2: (추천시스템) – optimizer 사용 고급, 모델링 전략, MF-based 추천시스템",
    "section": "A. Data: 나는 SOLO",
    "text": "A. Data: 나는 SOLO\n- Data\n\ndf_view = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2025/main/posts/iamsolo.csv',index_col=0)\ndf_view\n\n\n\n\n\n\n\n\n영식(IN)\n영철(IN)\n영호(IS)\n광수(IS)\n상철(EN)\n영수(EN)\n규빈(ES)\n다호(ES)\n\n\n\n\n옥순(IN)\nNaN\n4.02\n3.45\n3.42\n0.84\n1.12\n0.43\n0.49\n\n\n영자(IN)\n3.93\n3.99\n3.63\n3.43\n0.98\n0.96\n0.52\nNaN\n\n\n정숙(IS)\n3.52\n3.42\n4.05\n4.06\n0.39\nNaN\n0.93\n0.99\n\n\n영숙(IS)\n3.43\n3.57\nNaN\n3.95\n0.56\n0.52\n0.89\n0.89\n\n\n순자(EN)\n1.12\nNaN\n0.59\n0.43\n4.01\n4.16\n3.52\n3.38\n\n\n현숙(EN)\n0.94\n1.05\n0.32\n0.45\n4.02\n3.78\nNaN\n3.54\n\n\n서연(ES)\n0.51\n0.56\n0.88\n0.89\n3.50\n3.64\n4.04\n4.10\n\n\n보람(ES)\n0.48\n0.51\n1.03\nNaN\n3.52\n4.00\n3.82\nNaN\n\n\n하니(I)\n4.85\n4.82\nNaN\n4.98\n4.53\n4.39\n4.45\n4.52\n\n\n\n\n\n\n\n- 데이터를 이해할 때 필요한 가정들 – 제가 마음대로 설정했어요..\n\n궁합이 잘맞으면 5점, 잘 안맞으면 0점 이다.\nMBTI 성향에 따라서 궁함의 정도가 다르다. 특히 I/E의 성향일치가 중요하다.\n하니는 모든 사람들과 대체로 궁합이 잘 맞는다."
  },
  {
    "objectID": "posts/10wk-2.html#b.-아이디어",
    "href": "posts/10wk-2.html#b.-아이디어",
    "title": "10wk-2: (추천시스템) – optimizer 사용 고급, 모델링 전략, MF-based 추천시스템",
    "section": "B. 아이디어",
    "text": "B. 아이디어\n- 목표: NaN을 추정\n- 수동추론: 그럴듯한 숫자를 추정해보자.\n\n옥순(IN),영식(IN)의 궁합은? \\(\\to\\) 잘 맞을듯\n서연(ES),규빈(ES)의 궁합은? \\(\\to\\) 잘 맞을듯\n영자(IN),다호(ES)의 궁합은? \\(\\to\\) 잘 안맞을듯\n하니(I),영호(IS)의 궁합은? \\(\\to\\)엄청 잘 맞을듯\n\n- 좀 더 체계적인 추론 전략\n\nsig = torch.nn.Sigmoid()\n\n(1) 옥순(IN)과 영식(IN)의 궁합 \\(\\approx\\) 옥순의I/E성향\\(\\times\\)영식의I/E성향 \\(+\\) 옥순의N/S성향\\(\\times\\)영식의N/S성향\n🗣️(\n\nI에 가까울수록 2에 가깝고 E에 가까울수록 -2에 가깝다고 가정\nN에 가까울수록 2에 가깝고 S에 가까울수록 -2에 가깝다고 가정\n\n\n옥순성향 =  torch.tensor([1.9, 1.9])\n영식성향 =  torch.tensor([1.9, 1.9])\n\n\n(옥순성향 * 영식성향)\n\ntensor([3.6100, 3.6100])\n\n\n\n(옥순성향 * 영식성향).sum()\n\ntensor(7.2200)\n\n\n\nsig = torch.nn.Sigmoid()\n\n\nsig((옥순성향 * 영식성향).sum()) # 확률이 아니라 평점으로 생각 (0~1)\n\ntensor(0.9993)\n\n\n\nsig((옥순성향 * 영식성향).sum())*5\n\ntensor(4.9963)\n\n\n\n나름 근거는 있음\n\n\n옥순성향 =  torch.tensor([0, 1.9])\n영식성향 =  torch.tensor([1.9, 1.9])\nsig((옥순성향 * 영식성향).sum())*5 # 조금 감소\n\ntensor(4.8683)\n\n\n\n옥순성향 =  torch.tensor([1.9, 1.9])\n영식성향 =  torch.tensor([-1.9, -1.9])\n(옥순성향 * 영식성향).sum()\n\ntensor(-7.2200)\n\n\n\nsig((옥순성향 * 영식성향).sum())*5\n\ntensor(0.0037)\n\n\n\n옥순성향 =  torch.tensor([1.9, 1.9])\n영식성향 =  torch.tensor([1.9, -1.9])\nsig((옥순성향 * 영식성향).sum())*5\n\ntensor(2.5000)\n\n\n)🗣️\n\n옥순성향 =  torch.tensor([1.9, 1.9])\n영식성향 =  torch.tensor([1.9, 1.9])\nsig((옥순성향 *  영식성향).sum())*5\n\ntensor(4.9963)\n\n\n(2) 서연(ES)과 규빈(ES)의 궁합 \\(\\approx\\) 서연의I/E성향\\(\\times\\)규빈의I/E성향 \\(+\\) 서연의N/S성향\\(\\times\\)규빈의N/S성향\n\n서연성향 =  torch.tensor([-1.9, -1.9])\n규빈성향 =  torch.tensor([-1.9, -1.9])\nsig((서연성향 *  규빈성향).sum())*5\n\ntensor(4.9963)\n\n\n(3) 영자(IN)와 다호(ES)의 궁합 \\(\\approx\\) 영자I/E성향\\(\\times\\)다호I/E성향 \\(+\\) 영자N/S성향\\(\\times\\)다호의N/S성향\n\n영자성향 =  torch.tensor([1.9, 1.9])\n다호성향 =  torch.tensor([-1.9, -1.9])\nsig((영자성향 *  다호성향).sum())*5\n\ntensor(0.0037)\n\n\n(4) 하니(I)와 영호(IS)의 궁합 \\(\\approx\\) 하니I/E성향\\(\\times\\)영호I/E성향 \\(+\\) 하니N/S성향\\(\\times\\)영호의N/S성향 \\(+\\) 하니의매력\n🗣️(\n\n하니성향 =  torch.tensor([1.9, 0])\n영호성향 =  torch.tensor([1.9, -1.9])\nsig((하니성향 * 영호성향).sum())*5\n\ntensor(4.8683)\n\n\n\n하니성향 =  torch.tensor([1.9, 0])\n영호성향 =  torch.tensor([1.9, -1.9])\nsig((하니성향 * 영호성향).sum())*5\n\ntensor(4.8683)\n\n\n\n하니성향 =  torch.tensor([1.9, 0])\n영호성향 =  torch.tensor([-1.9, -1.9])\nsig((하니성향 * 영호성향).sum())*5\n\ntensor(0.1317)\n\n\n\n하니는 다 맞는다고 가정하였으므로 일괄적으로 상수를 더할 필요가 있음\n\n\n하니성향 =  torch.tensor([1.9, 0])\n영호성향 =  torch.tensor([-1.9, -1.9])\nsig((하니성향 * 영호성향).sum() + 5)*5\n\ntensor(4.0030)\n\n\n\n하니성향 =  torch.tensor([1.9, 0])\n하니매력 =  torch.tensor(5)\n영호성향 =  torch.tensor([-1.9, -1.9])\nsig((하니성향 *  영호성향).sum() + 하니매력)*5\n\ntensor(4.0030)\n\n\n\n하니성향 =  torch.tensor([1.9, 0])\n하니매력 =  torch.tensor(5)\n영호성향 =  torch.tensor([1.9, -1.9])\nsig((하니성향 *  영호성향).sum() + 하니매력)*5 # 성향이 맞는다면 5 근처\n\ntensor(4.9991)\n\n\n)🗣️\n\n하니성향 =  torch.tensor([1.9, 0])\n하니매력 =  torch.tensor(5)\n영호성향 =  torch.tensor([1.9, -1.9])\nsig((하니성향 *  영호성향).sum() + 하니매력)*5\n\ntensor(4.9991)\n\n\n- 전체 사용자의 설정값\n🗣️(\n\nI, N = 1.8, 1.8\n\n\n옥순성향  = torch.tensor([I,N])\n영자성향 = torch.tensor([I,N])\n정숙성향 = torch.tensor([I,-N])\n영숙성향 = torch.tensor([I,-N])\n순자성향 = torch.tensor([-I,N])\n현숙성향 = torch.tensor([-I,N])\n서연성향 = torch.tensor([-I,-N])\n보람성향 = torch.tensor([-I,-N])\n하니성향 = torch.tensor([I,0])\n\n\n[옥순성향,영자성향,정숙성향,영숙성향,순자성향,현숙성향,서연성향,보람성향,하니성향] # torch 들을 묶은 리스트\n\n[tensor([1.8000, 1.8000]),\n tensor([1.8000, 1.8000]),\n tensor([ 1.8000, -1.8000]),\n tensor([ 1.8000, -1.8000]),\n tensor([-1.8000,  1.8000]),\n tensor([-1.8000,  1.8000]),\n tensor([-1.8000, -1.8000]),\n tensor([-1.8000, -1.8000]),\n tensor([1.8000, 0.0000])]\n\n\n\ntorch.stack([옥순성향,영자성향,정숙성향,영숙성향,순자성향,현숙성향,서연성향,보람성향,하니성향]) # matrix\n\ntensor([[ 1.8000,  1.8000],\n        [ 1.8000,  1.8000],\n        [ 1.8000, -1.8000],\n        [ 1.8000, -1.8000],\n        [-1.8000,  1.8000],\n        [-1.8000,  1.8000],\n        [-1.8000, -1.8000],\n        [-1.8000, -1.8000],\n        [ 1.8000,  0.0000]])\n\n\n\ntorch.stack([옥순성향,영자성향,정숙성향,영숙성향,순자성향,현숙성향,서연성향,보람성향,하니성향]).shape\n\ntorch.Size([9, 2])\n\n\n\n9: 출연자의 수 / 2: 성향의 수\n\n\nW = torch.stack([옥순성향,영자성향,정숙성향,영숙성향,순자성향,현숙성향,서연성향,보람성향,하니성향])\n\n\n하니의 매력 점수도 만들고 싶음\n\n\ntorch.tensor([0,0,0,0,0,0,0,0,5])\n\ntensor([0, 0, 0, 0, 0, 0, 0, 0, 5])\n\n\n\ntorch.tensor([0,0,0,0,0,0,0,0,5]).reshape(-1,1)\n\ntensor([[0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [0],\n        [5]])\n\n\n\n옥순성향  = torch.tensor([I,N])\n영자성향 = torch.tensor([I,N])\n정숙성향 = torch.tensor([I,-N])\n영숙성향 = torch.tensor([I,-N])\n순자성향 = torch.tensor([-I,N])\n현숙성향 = torch.tensor([-I,N])\n서연성향 = torch.tensor([-I,-N])\n보람성향 = torch.tensor([-I,-N])\n하니성향 = torch.tensor([I,0])\nW = torch.stack([옥순성향,영자성향,정숙성향,영숙성향,순자성향,현숙성향,서연성향,보람성향,하니성향])\nb1 = torch.tensor([0,0,0,0,0,0,0,0,5]).reshape(-1,1).float()\nW,b1\n\n(tensor([[ 1.8000,  1.8000],\n         [ 1.8000,  1.8000],\n         [ 1.8000, -1.8000],\n         [ 1.8000, -1.8000],\n         [-1.8000,  1.8000],\n         [-1.8000,  1.8000],\n         [-1.8000, -1.8000],\n         [-1.8000, -1.8000],\n         [ 1.8000,  0.0000]]),\n tensor([[0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [5.]]))\n\n\n\n영식성향  = torch.tensor([I,N])\n영철성향 = torch.tensor([I,N])\n영호성향 = torch.tensor([I,-N])\n광수성향 = torch.tensor([I,-N])\n상철성향 = torch.tensor([-I,N])\n영수성향 = torch.tensor([-I,N])\n규빈성향 = torch.tensor([-I,-N])\n다호성향 = torch.tensor([-I,-N])\nM = torch.stack([영식성향,영철성향,영호성향,광수성향,상철성향,영수성향,규빈성향,다호성향])\nb2 = torch.tensor([0,0,0,0,0,0,0,0]).reshape(-1,1).float()\n\n\nW.shape, M.shape, b1.shape, b2.shape\n\n(torch.Size([9, 2]),\n torch.Size([8, 2]),\n torch.Size([9, 1]),\n torch.Size([8, 1]))\n\n\n)🗣️\n\nI, N = 1.8, 0.9\n\n\n옥순성향  = torch.tensor([I,N])\n영자성향 = torch.tensor([I,N])\n정숙성향 = torch.tensor([I,-N])\n영숙성향 = torch.tensor([I,-N])\n순자성향 = torch.tensor([-I,N])\n현숙성향 = torch.tensor([-I,N])\n서연성향 = torch.tensor([-I,-N])\n보람성향 = torch.tensor([-I,-N])\n하니성향 = torch.tensor([I,0])\nW = torch.stack([옥순성향,영자성향,정숙성향,영숙성향,순자성향,현숙성향,서연성향,보람성향,하니성향])\nb1 = torch.tensor([0,0,0,0,0,0,0,0,5]).reshape(-1,1).float()\nW,b1\n\n(tensor([[ 1.8000,  0.9000],\n         [ 1.8000,  0.9000],\n         [ 1.8000, -0.9000],\n         [ 1.8000, -0.9000],\n         [-1.8000,  0.9000],\n         [-1.8000,  0.9000],\n         [-1.8000, -0.9000],\n         [-1.8000, -0.9000],\n         [ 1.8000,  0.0000]]),\n tensor([[0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [5.]]))\n\n\n\n영식성향  = torch.tensor([I,N])\n영철성향 = torch.tensor([I,N])\n영호성향 = torch.tensor([I,-N])\n광수성향 = torch.tensor([I,-N])\n상철성향 = torch.tensor([-I,N])\n영수성향 = torch.tensor([-I,N])\n규빈성향 = torch.tensor([-I,-N])\n다호성향 = torch.tensor([-I,-N])\nM = torch.stack([영식성향,영철성향,영호성향,광수성향,상철성향,영수성향,규빈성향,다호성향])\nb2 = torch.tensor([0,0,0,0,0,0,0,0]).reshape(-1,1).float()\n\n\nW.shape, M.shape, b1.shape, b2.shape\n\n(torch.Size([9, 2]),\n torch.Size([8, 2]),\n torch.Size([9, 1]),\n torch.Size([8, 1]))\n\n\n- 아래의 행렬곱 관찰\n🗣️(\n\nW.shape, M.shape, b1.shape, b2.shape\n\n(torch.Size([9, 2]),\n torch.Size([8, 2]),\n torch.Size([9, 1]),\n torch.Size([8, 1]))\n\n\n\ndf_view\n\n\n\n\n\n\n\n\n영식(IN)\n영철(IN)\n영호(IS)\n광수(IS)\n상철(EN)\n영수(EN)\n규빈(ES)\n다호(ES)\n\n\n\n\n옥순(IN)\nNaN\n4.02\n3.45\n3.42\n0.84\n1.12\n0.43\n0.49\n\n\n영자(IN)\n3.93\n3.99\n3.63\n3.43\n0.98\n0.96\n0.52\nNaN\n\n\n정숙(IS)\n3.52\n3.42\n4.05\n4.06\n0.39\nNaN\n0.93\n0.99\n\n\n영숙(IS)\n3.43\n3.57\nNaN\n3.95\n0.56\n0.52\n0.89\n0.89\n\n\n순자(EN)\n1.12\nNaN\n0.59\n0.43\n4.01\n4.16\n3.52\n3.38\n\n\n현숙(EN)\n0.94\n1.05\n0.32\n0.45\n4.02\n3.78\nNaN\n3.54\n\n\n서연(ES)\n0.51\n0.56\n0.88\n0.89\n3.50\n3.64\n4.04\n4.10\n\n\n보람(ES)\n0.48\n0.51\n1.03\nNaN\n3.52\n4.00\n3.82\nNaN\n\n\n하니(I)\n4.85\n4.82\nNaN\n4.98\n4.53\n4.39\n4.45\n4.52\n\n\n\n\n\n\n\n\nb1 + b2.T # (9,1) + (1,8) 안되야하는데 됨(브로드캐스팅)\n\ntensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0.],\n        [5., 5., 5., 5., 5., 5., 5., 5.]])\n\n\n[a        [ c d .... 0 ]       a+c  a+d  ... 0\n b                             b+c  b+d  ... 0 \n ...  +                   =    ...\n 5]                            5  5  5  ...  5  \n\nW@M.T\n\ntensor([[ 6.4800,  6.4800,  0.0000,  0.0000,  0.0000,  0.0000, -6.4800, -6.4800],\n        [ 6.4800,  6.4800,  0.0000,  0.0000,  0.0000,  0.0000, -6.4800, -6.4800],\n        [ 0.0000,  0.0000,  6.4800,  6.4800, -6.4800, -6.4800,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  6.4800,  6.4800, -6.4800, -6.4800,  0.0000,  0.0000],\n        [ 0.0000,  0.0000, -6.4800, -6.4800,  6.4800,  6.4800,  0.0000,  0.0000],\n        [ 0.0000,  0.0000, -6.4800, -6.4800,  6.4800,  6.4800,  0.0000,  0.0000],\n        [-6.4800, -6.4800,  0.0000,  0.0000,  0.0000,  0.0000,  6.4800,  6.4800],\n        [-6.4800, -6.4800,  0.0000,  0.0000,  0.0000,  0.0000,  6.4800,  6.4800],\n        [ 3.2400,  3.2400,  3.2400,  3.2400, -3.2400, -3.2400, -3.2400, -3.2400]])\n\n\n[ a b    [ e g ...          [ae+bf ag+bh ...\n  c d      f h ... ]       \n  ...\n  ... ]\n\nsig(W @ M.T + b1 @ b2.T) * 5\n\ntensor([[4.9923, 4.9923, 2.5000, 2.5000, 2.5000, 2.5000, 0.0077, 0.0077],\n        [4.9923, 4.9923, 2.5000, 2.5000, 2.5000, 2.5000, 0.0077, 0.0077],\n        [2.5000, 2.5000, 4.9923, 4.9923, 0.0077, 0.0077, 2.5000, 2.5000],\n        [2.5000, 2.5000, 4.9923, 4.9923, 0.0077, 0.0077, 2.5000, 2.5000],\n        [2.5000, 2.5000, 0.0077, 0.0077, 4.9923, 4.9923, 2.5000, 2.5000],\n        [2.5000, 2.5000, 0.0077, 0.0077, 4.9923, 4.9923, 2.5000, 2.5000],\n        [0.0077, 0.0077, 2.5000, 2.5000, 2.5000, 2.5000, 4.9923, 4.9923],\n        [0.0077, 0.0077, 2.5000, 2.5000, 2.5000, 2.5000, 4.9923, 4.9923],\n        [4.8116, 4.8116, 4.8116, 4.8116, 0.1884, 0.1884, 0.1884, 0.1884]])\n\n\n\ndf_view\n\n\n\n\n\n\n\n\n영식(IN)\n영철(IN)\n영호(IS)\n광수(IS)\n상철(EN)\n영수(EN)\n규빈(ES)\n다호(ES)\n\n\n\n\n옥순(IN)\nNaN\n4.02\n3.45\n3.42\n0.84\n1.12\n0.43\n0.49\n\n\n영자(IN)\n3.93\n3.99\n3.63\n3.43\n0.98\n0.96\n0.52\nNaN\n\n\n정숙(IS)\n3.52\n3.42\n4.05\n4.06\n0.39\nNaN\n0.93\n0.99\n\n\n영숙(IS)\n3.43\n3.57\nNaN\n3.95\n0.56\n0.52\n0.89\n0.89\n\n\n순자(EN)\n1.12\nNaN\n0.59\n0.43\n4.01\n4.16\n3.52\n3.38\n\n\n현숙(EN)\n0.94\n1.05\n0.32\n0.45\n4.02\n3.78\nNaN\n3.54\n\n\n서연(ES)\n0.51\n0.56\n0.88\n0.89\n3.50\n3.64\n4.04\n4.10\n\n\n보람(ES)\n0.48\n0.51\n1.03\nNaN\n3.52\n4.00\n3.82\nNaN\n\n\n하니(I)\n4.85\n4.82\nNaN\n4.98\n4.53\n4.39\n4.45\n4.52\n\n\n\n\n\n\n\n\n경향은 맞는 것 같은데 가운데 부분은 조정이 필요해 보임\n\n\nI, N = 1.8, 0.9\n\n\n옥순성향  = torch.tensor([I,N])\n영자성향 = torch.tensor([I,N])\n정숙성향 = torch.tensor([I,-N])\n영숙성향 = torch.tensor([I,-N])\n순자성향 = torch.tensor([-I,N])\n현숙성향 = torch.tensor([-I,N])\n서연성향 = torch.tensor([-I,-N])\n보람성향 = torch.tensor([-I,-N])\n하니성향 = torch.tensor([I,0])\nW = torch.stack([옥순성향,영자성향,정숙성향,영숙성향,순자성향,현숙성향,서연성향,보람성향,하니성향])\nb1 = torch.tensor([0,0,0,0,0,0,0,0,5]).reshape(-1,1).float()\nW,b1\n\n(tensor([[ 1.8000,  0.9000],\n         [ 1.8000,  0.9000],\n         [ 1.8000, -0.9000],\n         [ 1.8000, -0.9000],\n         [-1.8000,  0.9000],\n         [-1.8000,  0.9000],\n         [-1.8000, -0.9000],\n         [-1.8000, -0.9000],\n         [ 1.8000,  0.0000]]),\n tensor([[0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [5.]]))\n\n\n\n영식성향  = torch.tensor([I,N])\n영철성향 = torch.tensor([I,N])\n영호성향 = torch.tensor([I,-N])\n광수성향 = torch.tensor([I,-N])\n상철성향 = torch.tensor([-I,N])\n영수성향 = torch.tensor([-I,N])\n규빈성향 = torch.tensor([-I,-N])\n다호성향 = torch.tensor([-I,-N])\nM = torch.stack([영식성향,영철성향,영호성향,광수성향,상철성향,영수성향,규빈성향,다호성향])\nb2 = torch.tensor([0,0,0,0,0,0,0,0]).reshape(-1,1).float()\n\n\nsig(W @ M.T + b1 @ b2.T) * 5\n\ntensor([[4.9144, 4.9144, 4.5954, 4.5954, 0.4046, 0.4046, 0.0856, 0.0856],\n        [4.9144, 4.9144, 4.5954, 4.5954, 0.4046, 0.4046, 0.0856, 0.0856],\n        [4.5954, 4.5954, 4.9144, 4.9144, 0.0856, 0.0856, 0.4046, 0.4046],\n        [4.5954, 4.5954, 4.9144, 4.9144, 0.0856, 0.0856, 0.4046, 0.4046],\n        [0.4046, 0.4046, 0.0856, 0.0856, 4.9144, 4.9144, 4.5954, 4.5954],\n        [0.4046, 0.4046, 0.0856, 0.0856, 4.9144, 4.9144, 4.5954, 4.5954],\n        [0.0856, 0.0856, 0.4046, 0.4046, 4.5954, 4.5954, 4.9144, 4.9144],\n        [0.0856, 0.0856, 0.4046, 0.4046, 4.5954, 4.5954, 4.9144, 4.9144],\n        [4.8116, 4.8116, 4.8116, 4.8116, 0.1884, 0.1884, 0.1884, 0.1884]])\n\n\n\ndf_view\n\n\n\n\n\n\n\n\n영식(IN)\n영철(IN)\n영호(IS)\n광수(IS)\n상철(EN)\n영수(EN)\n규빈(ES)\n다호(ES)\n\n\n\n\n옥순(IN)\nNaN\n4.02\n3.45\n3.42\n0.84\n1.12\n0.43\n0.49\n\n\n영자(IN)\n3.93\n3.99\n3.63\n3.43\n0.98\n0.96\n0.52\nNaN\n\n\n정숙(IS)\n3.52\n3.42\n4.05\n4.06\n0.39\nNaN\n0.93\n0.99\n\n\n영숙(IS)\n3.43\n3.57\nNaN\n3.95\n0.56\n0.52\n0.89\n0.89\n\n\n순자(EN)\n1.12\nNaN\n0.59\n0.43\n4.01\n4.16\n3.52\n3.38\n\n\n현숙(EN)\n0.94\n1.05\n0.32\n0.45\n4.02\n3.78\nNaN\n3.54\n\n\n서연(ES)\n0.51\n0.56\n0.88\n0.89\n3.50\n3.64\n4.04\n4.10\n\n\n보람(ES)\n0.48\n0.51\n1.03\nNaN\n3.52\n4.00\n3.82\nNaN\n\n\n하니(I)\n4.85\n4.82\nNaN\n4.98\n4.53\n4.39\n4.45\n4.52\n\n\n\n\n\n\n\n\n완전히 맞지는 않지만 이런 식으로 하면 될 것 같음\n\n정확한 수치는 optimizer가 찾게\n\n\n)🗣️\n\nsig(W @ M.T + b1 + b2.T)*5\n\ntensor([[4.9144, 4.9144, 4.5954, 4.5954, 0.4046, 0.4046, 0.0856, 0.0856],\n        [4.9144, 4.9144, 4.5954, 4.5954, 0.4046, 0.4046, 0.0856, 0.0856],\n        [4.5954, 4.5954, 4.9144, 4.9144, 0.0856, 0.0856, 0.4046, 0.4046],\n        [4.5954, 4.5954, 4.9144, 4.9144, 0.0856, 0.0856, 0.4046, 0.4046],\n        [0.4046, 0.4046, 0.0856, 0.0856, 4.9144, 4.9144, 4.5954, 4.5954],\n        [0.4046, 0.4046, 0.0856, 0.0856, 4.9144, 4.9144, 4.5954, 4.5954],\n        [0.0856, 0.0856, 0.4046, 0.4046, 4.5954, 4.5954, 4.9144, 4.9144],\n        [0.0856, 0.0856, 0.4046, 0.4046, 4.5954, 4.5954, 4.9144, 4.9144],\n        [4.9987, 4.9987, 4.9987, 4.9987, 4.2660, 4.2660, 4.2660, 4.2660]])\n\n\n\ndf_view\n\n\n\n\n\n\n\n\n영식(IN)\n영철(IN)\n영호(IS)\n광수(IS)\n상철(EN)\n영수(EN)\n규빈(ES)\n다호(ES)\n\n\n\n\n옥순(IN)\nNaN\n4.02\n3.45\n3.42\n0.84\n1.12\n0.43\n0.49\n\n\n영자(IN)\n3.93\n3.99\n3.63\n3.43\n0.98\n0.96\n0.52\nNaN\n\n\n정숙(IS)\n3.52\n3.42\n4.05\n4.06\n0.39\nNaN\n0.93\n0.99\n\n\n영숙(IS)\n3.43\n3.57\nNaN\n3.95\n0.56\n0.52\n0.89\n0.89\n\n\n순자(EN)\n1.12\nNaN\n0.59\n0.43\n4.01\n4.16\n3.52\n3.38\n\n\n현숙(EN)\n0.94\n1.05\n0.32\n0.45\n4.02\n3.78\nNaN\n3.54\n\n\n서연(ES)\n0.51\n0.56\n0.88\n0.89\n3.50\n3.64\n4.04\n4.10\n\n\n보람(ES)\n0.48\n0.51\n1.03\nNaN\n3.52\n4.00\n3.82\nNaN\n\n\n하니(I)\n4.85\n4.82\nNaN\n4.98\n4.53\n4.39\n4.45\n4.52\n\n\n\n\n\n\n\n- 모델링\n\\[{\\tt df\\_view} \\approx sig\\left({\\bf W}@{\\bf M}^\\top + bias \\right) \\times 5\\]\n- 자료를 아래와 같이 정리한다면?\n🗣️(\n\ndf_view.stack()\n\n옥순(IN)  영철(IN)    4.02\n        영호(IS)    3.45\n        광수(IS)    3.42\n        상철(EN)    0.84\n        영수(EN)    1.12\n                  ... \n하니(I)   광수(IS)    4.98\n        상철(EN)    4.53\n        영수(EN)    4.39\n        규빈(ES)    4.45\n        다호(ES)    4.52\nLength: 63, dtype: float64\n\n\n\ndf_view.stack().reset_index()\n\n\n\n\n\n\n\n\nlevel_0\nlevel_1\n0\n\n\n\n\n0\n옥순(IN)\n영철(IN)\n4.02\n\n\n1\n옥순(IN)\n영호(IS)\n3.45\n\n\n2\n옥순(IN)\n광수(IS)\n3.42\n\n\n3\n옥순(IN)\n상철(EN)\n0.84\n\n\n4\n옥순(IN)\n영수(EN)\n1.12\n\n\n...\n...\n...\n...\n\n\n58\n하니(I)\n광수(IS)\n4.98\n\n\n59\n하니(I)\n상철(EN)\n4.53\n\n\n60\n하니(I)\n영수(EN)\n4.39\n\n\n61\n하니(I)\n규빈(ES)\n4.45\n\n\n62\n하니(I)\n다호(ES)\n4.52\n\n\n\n\n63 rows × 3 columns\n\n\n\n위의 데이터를 가지고\n  옥순     영철  \na1 a2 a' b1 b2 b' =&gt; a1b1 + a2b2 + a'+b' = yhat 의 네트워크를 짜고 싶음\n\ndf_train = df_view.stack().reset_index().set_axis(['여성출연자','남성출연자','궁합점수'],axis=1)\ndf_train\n\n\n\n\n\n\n\n\n여성출연자\n남성출연자\n궁합점수\n\n\n\n\n0\n옥순(IN)\n영철(IN)\n4.02\n\n\n1\n옥순(IN)\n영호(IS)\n3.45\n\n\n2\n옥순(IN)\n광수(IS)\n3.42\n\n\n3\n옥순(IN)\n상철(EN)\n0.84\n\n\n4\n옥순(IN)\n영수(EN)\n1.12\n\n\n...\n...\n...\n...\n\n\n58\n하니(I)\n광수(IS)\n4.98\n\n\n59\n하니(I)\n상철(EN)\n4.53\n\n\n60\n하니(I)\n영수(EN)\n4.39\n\n\n61\n하니(I)\n규빈(ES)\n4.45\n\n\n62\n하니(I)\n다호(ES)\n4.52\n\n\n\n\n63 rows × 3 columns\n\n\n\n\n숫자화를 시켜야 함\n\n\nset(df_train.여성출연자)\n\n{'보람(ES)',\n '서연(ES)',\n '순자(EN)',\n '영숙(IS)',\n '영자(IN)',\n '옥순(IN)',\n '정숙(IS)',\n '하니(I)',\n '현숙(EN)'}\n\n\n\n{name: i for i,name in enumerate(set(df_train.여성출연자))}\n\n{'정숙(IS)': 0,\n '영숙(IS)': 1,\n '하니(I)': 2,\n '서연(ES)': 3,\n '보람(ES)': 4,\n '현숙(EN)': 5,\n '순자(EN)': 6,\n '옥순(IN)': 7,\n '영자(IN)': 8}\n\n\n\ndf_train.여성출연자.map({name: i for i,name in enumerate(set(df_train.여성출연자))})\n\n0     7\n1     7\n2     7\n3     7\n4     7\n     ..\n58    2\n59    2\n60    2\n61    2\n62    2\nName: 여성출연자, Length: 63, dtype: int64\n\n\n\ntorch.tensor(df_train.여성출연자.map({name: i for i,name in enumerate(set(df_train.여성출연자))})) # 63개\n\ntensor([7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n        1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 3, 3, 3, 3, 3, 3,\n        3, 3, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2])\n\n\n\n모형에 돌리려면 one hot encoding 하는 것이 편함\n\n\n# torch.nn.functional.one_hot(torch.tensor(df_train.여성출연자.map({name: i for i,name in enumerate(set(df_train.여성출연자))})))\n\ntensor([[0, 0, 0, 0, 0, 0, 0, 1, 0],\n        [0, 0, 0, 0, 0, 0, 0, 1, 0],\n\n9차원을 속성 개수 2개(2차원), 1개(0차원)로 맞추려면 linear transform 하면 될 것 같음\n\nX1 = torch.nn.functional.one_hot(torch.tensor(df_train.여성출연자.map({name: i for i,name in enumerate(set(df_train.여성출연자))}))).float()\nX2 = torch.nn.functional.one_hot(torch.tensor(df_train.남성출연자.map({name: i for i,name in enumerate(set(df_train.남성출연자))}))).float()\n\n\nX1.shape, X2.shape\n\n(torch.Size([63, 9]), torch.Size([63, 8]))\n\n\n\n# 63,9 --&gt; 63,2\nl1 = torch.nn.Linear(9,2, bias=False) # bias는 필요 없을 것 같음\nl1(X1).shape\n\ntorch.Size([63, 2])\n\n\n\n# 63,9 --&gt; 63,2\nl1 = torch.nn.Linear(9,2, bias=False) # bias는 필요 없을 것 같음\nl1(X1).shape\n\ntorch.Size([63, 2])\n\n\n\nl1 = torch.nn.Linear(9,2, bias=False)\nb1 = torch.nn.Linear(9,1, bias=False) # 절대적인 매력\nb1(X1).shape\n\ntorch.Size([63, 1])\n\n\n\n남성까지 반영\n\n\nl1 = torch.nn.Linear(9,2,bias=False)\nb1 = torch.nn.Linear(9,1,bias=False)\nl2 = torch.nn.Linear(8,2,bias=False)\nb2 = torch.nn.Linear(8,1,bias=False)\n\n\nl1(X1)[:3], l2(X2)[:3]\n\n(tensor([[ 0.2745, -0.1854],\n         [ 0.2745, -0.1854],\n         [ 0.2745, -0.1854]], grad_fn=&lt;SliceBackward0&gt;),\n tensor([[ 0.3284,  0.1675],\n         [-0.1163,  0.2470],\n         [-0.2877,  0.2392]], grad_fn=&lt;SliceBackward0&gt;))\n\n\n\nl1(X1) * l2(X2) # 63,2 (I/E, N/S)\n(l1(X1) * l2(X2)).sum(axis=1) # 63,1\n\ntensor([ 0.0591, -0.0777, -0.1233, -0.0217, -0.1010,  0.0349, -0.0662,  0.0569,\n         0.1020, -0.0365, -0.0898, -0.0431, -0.0752,  0.0590,  0.0728,  0.1109,\n        -0.0117, -0.0624, -0.0485,  0.0639, -0.0644,  0.0530,  0.0608,  0.0078,\n        -0.0285,  0.0046,  0.0347, -0.0204, -0.0223, -0.0714, -0.0934,  0.0005,\n        -0.0755,  0.0055, -0.0362,  0.0099,  0.0120,  0.0039, -0.0002, -0.0056,\n        -0.0005, -0.0047, -0.0469, -0.0373, -0.0532, -0.0510,  0.0196, -0.0401,\n        -0.0209, -0.0038,  0.0261, -0.0131,  0.0900,  0.0006,  0.0963, -0.0085,\n        -0.0034,  0.0039, -0.0213, -0.0008, -0.0173,  0.0024, -0.0090],\n       grad_fn=&lt;SumBackward1&gt;)\n\n\n\n# (l1(X1) * l2(X2)).sum(axis=1).reshape(-1,1) # vector\n\n\n# (l1(X1) * l2(X2)).sum(axis=1).reshape(-1,1) + b1(X1) + b2(X2) # 각각의 매력 점수를 더함\n\nsig((l1(X1) * l2(X2)).sum(axis=1).reshape(-1,1) + b1(X1) + b2(X2))*5 # 0~5\n# 궁합 matrix로 적합할 수 있는 최초의 직선\n\nyhat = sig((l1(X1) * l2(X2)).sum(axis=1).reshape(-1,1) + b1(X1) + b2(X2))*5\n\n)🗣️\n\ndf_train = df_view.stack().reset_index().set_axis(['여성출연자','남성출연자','궁합점수'],axis=1)\ndf_train\n\n\n\n\n\n\n\n\n여성출연자\n남성출연자\n궁합점수\n\n\n\n\n0\n옥순(IN)\n영철(IN)\n4.02\n\n\n1\n옥순(IN)\n영호(IS)\n3.45\n\n\n2\n옥순(IN)\n광수(IS)\n3.42\n\n\n3\n옥순(IN)\n상철(EN)\n0.84\n\n\n4\n옥순(IN)\n영수(EN)\n1.12\n\n\n...\n...\n...\n...\n\n\n58\n하니(I)\n광수(IS)\n4.98\n\n\n59\n하니(I)\n상철(EN)\n4.53\n\n\n60\n하니(I)\n영수(EN)\n4.39\n\n\n61\n하니(I)\n규빈(ES)\n4.45\n\n\n62\n하니(I)\n다호(ES)\n4.52\n\n\n\n\n63 rows × 3 columns\n\n\n\n\n{name: i for i,name in enumerate(set(df_train.여성출연자))}\n\n{'영숙(IS)': 0,\n '영자(IN)': 1,\n '정숙(IS)': 2,\n '현숙(EN)': 3,\n '하니(I)': 4,\n '순자(EN)': 5,\n '보람(ES)': 6,\n '옥순(IN)': 7,\n '서연(ES)': 8}\n\n\n\nX1 = torch.nn.functional.one_hot(torch.tensor(df_train.여성출연자.map({name: i for i,name in enumerate(set(df_train.여성출연자))}))).float()\nX2 = torch.nn.functional.one_hot(torch.tensor(df_train.남성출연자.map({name: i for i,name in enumerate(set(df_train.남성출연자))}))).float()\n\n\nl1 = torch.nn.Linear(9,2,bias=False)\nb1 = torch.nn.Linear(9,1,bias=False)\nl2 = torch.nn.Linear(8,2,bias=False)\nb2 = torch.nn.Linear(8,1,bias=False)\n\n\nyhat = sig((l1(X1) * l2(X2)).sum(axis=1).reshape(-1,1) + b1(X1) + b2(X2))*5"
  },
  {
    "objectID": "posts/10wk-2.html#c.-학습",
    "href": "posts/10wk-2.html#c.-학습",
    "title": "10wk-2: (추천시스템) – optimizer 사용 고급, 모델링 전략, MF-based 추천시스템",
    "section": "C. 학습",
    "text": "C. 학습\n🗣️(\n\n# torch.tensor(df_train.궁합점수).reshape(-1,1)\n\n참고)\n        [4.9800],\n        [4.5300],\n        [4.3900],\n        [4.4500],\n        [4.5200]], dtype=torch.float64)\n.float()을 붙이면 , dtype=torch.float64 꼬리표 사라짐\n\ndf_train = df_view.stack().reset_index().set_axis(['여성출연자','남성출연자','궁합점수'],axis=1)\n여성인덱스 = {'옥순(IN)':0, '영자(IN)':1, '정숙(IS)':2, '영숙(IS)':3, '순자(EN)':4, '현숙(EN)':5, '서연(ES)':6, '보람(ES)':7, '하니(I)':8}\n남성인덱스 = {'영식(IN)':0, '영철(IN)':1, '영호(IS)':2, '광수(IS)':3, '상철(EN)':4, '영수(EN)':5, '규빈(ES)':6, '다호(ES)':7}\nX1 = torch.nn.functional.one_hot(torch.tensor(df_train.여성출연자.map(여성인덱스))).float()\nX2 = torch.nn.functional.one_hot(torch.tensor(df_train.남성출연자.map(남성인덱스))).float()\ny = torch.tensor(df_train.궁합점수).reshape(-1,1).float()\n\n\nX1.shape, X2.shape, y.shape\n\n(torch.Size([63, 9]), torch.Size([63, 8]), torch.Size([63, 1]))\n\n\n\nyhat과 y를 비슷하게 하려면 loss 필요\n\nloss는 MSE로\nfloat이 나오므로 엔트로피를 쓸 수는 없음\n\n참고\n\nMSE Loss는 보통 실수 전역을 가정하지만 이 경우(0~5)에도 결과는 좋음\nactivation function인 sigmoid에 5를 곱해도 결과가 좋음\n\n\n\nloss_fn = torch.nn.MSELoss() \nl1 = torch.nn.Linear(9,2,bias=False)\nl2 = torch.nn.Linear(8,2,bias=False)\nW_features = l1(X1) \nM_features = l2(X2)\n\n\n(W_features * M_features).shape\n\ntorch.Size([63, 2])\n\n\n\n(W_features * M_features).sum(axis=1).shape # 궁합이 잘 맞으면 값이 커짐\n\ntorch.Size([63])\n\n\n\n(W_features * M_features).sum(axis=1).reshape(-1,1).shape # 63,1 궁합이 잘 맞으면 값이 커짐\n\ntorch.Size([63, 1])\n\n\n\nb1 = torch.nn.Linear(9,1,bias=False) # 매력 network\nb2 = torch.nn.Linear(8,1,bias=False)\nW_bias = b1(X1)\nM_bias = b2(X2)\n\n\n((W_features * M_features).sum(axis=1).reshape(-1,1) + W_bias + M_bias).shape # 궁합이 잘 맞으면 값이 커짐\n\ntorch.Size([63, 1])\n\n\n\n# (W_features * M_features).sum(axis=1).reshape(-1,1) + W_bias + M_bias # 궁합이 잘 맞으면 값이 커짐\n\n\nsig = torch.nn.Sigmoid()\n# sig((W_features * M_features).sum(axis=1).reshape(-1,1) + W_bias + M_bias)*5\n\n\n정리\n\ndf_train = df_view.stack().reset_index().set_axis(['여성출연자','남성출연자','궁합점수'],axis=1)\n여성인덱스 = {'옥순(IN)':0, '영자(IN)':1, '정숙(IS)':2, '영숙(IS)':3, '순자(EN)':4, '현숙(EN)':5, '서연(ES)':6, '보람(ES)':7, '하니(I)':8}\n남성인덱스 = {'영식(IN)':0, '영철(IN)':1, '영호(IS)':2, '광수(IS)':3, '상철(EN)':4, '영수(EN)':5, '규빈(ES)':6, '다호(ES)':7}\nX1 = torch.nn.functional.one_hot(torch.tensor(df_train.여성출연자.map(여성인덱스))).float()\nX2 = torch.nn.functional.one_hot(torch.tensor(df_train.남성출연자.map(남성인덱스))).float()\ny = torch.tensor(df_train.궁합점수).reshape(-1,1).float()\nloss_fn = torch.nn.MSELoss() \nl1 = torch.nn.Linear(9,2,bias=False)\nl2 = torch.nn.Linear(8,2,bias=False)\nb1 = torch.nn.Linear(9,1,bias=False)\nb2 = torch.nn.Linear(8,1,bias=False)\nsig = torch.nn.Sigmoid()\nW_features = l1(X1) \nM_features = l2(X2)\nW_bias = b1(X1)\nM_bias = b2(X2)\nyhat = sig((W_features * M_features).sum(axis=1).reshape(-1,1) + W_bias + M_bias)*5\nloss = loss_fn(yhat,y)\nloss.backward()\n\nupdate를 해야하는데 parameter가 l1,l2,b1,b2에 모두 있음 =&gt; optimizer를 쓰고 싶음\n\ndf_train = df_view.stack().reset_index().set_axis(['여성출연자','남성출연자','궁합점수'],axis=1)\n여성인덱스 = {'옥순(IN)':0, '영자(IN)':1, '정숙(IS)':2, '영숙(IS)':3, '순자(EN)':4, '현숙(EN)':5, '서연(ES)':6, '보람(ES)':7, '하니(I)':8}\n남성인덱스 = {'영식(IN)':0, '영철(IN)':1, '영호(IS)':2, '광수(IS)':3, '상철(EN)':4, '영수(EN)':5, '규빈(ES)':6, '다호(ES)':7}\nX1 = torch.nn.functional.one_hot(torch.tensor(df_train.여성출연자.map(여성인덱스))).float()\nX2 = torch.nn.functional.one_hot(torch.tensor(df_train.남성출연자.map(남성인덱스))).float()\ny = torch.tensor(df_train.궁합점수).reshape(-1,1).float()\n#----#\nloss_fn = torch.nn.MSELoss() \nl1 = torch.nn.Linear(9,2,bias=False)\nl2 = torch.nn.Linear(8,2,bias=False)\nb1 = torch.nn.Linear(9,1,bias=False)\nb2 = torch.nn.Linear(8,1,bias=False)\nparams = list(l1.parameters()) + list(l2.parameters())  + list(b1.parameters()) + list(b2.parameters())\noptimizr = torch.optim.Adam(params) \nsig = torch.nn.Sigmoid()\n#----#\nW_features = l1(X1) \nM_features = l2(X2)\nW_bias = b1(X1)\nM_bias = b2(X2)\nyhat = sig((W_features * M_features).sum(axis=1).reshape(-1,1) + W_bias + M_bias)*5\nloss = loss_fn(yhat,y)\nloss.backward()\n\n학습 시작\n\n\ndf_train = df_view.stack().reset_index().set_axis(['여성출연자','남성출연자','궁합점수'],axis=1)\n여성인덱스 = {'옥순(IN)':0, '영자(IN)':1, '정숙(IS)':2, '영숙(IS)':3, '순자(EN)':4, '현숙(EN)':5, '서연(ES)':6, '보람(ES)':7, '하니(I)':8}\n남성인덱스 = {'영식(IN)':0, '영철(IN)':1, '영호(IS)':2, '광수(IS)':3, '상철(EN)':4, '영수(EN)':5, '규빈(ES)':6, '다호(ES)':7}\nX1 = torch.nn.functional.one_hot(torch.tensor(df_train.여성출연자.map(여성인덱스))).float()\nX2 = torch.nn.functional.one_hot(torch.tensor(df_train.남성출연자.map(남성인덱스))).float()\ny = torch.tensor(df_train.궁합점수).reshape(-1,1).float()\n#----#\nloss_fn = torch.nn.MSELoss() \nl1 = torch.nn.Linear(9,2,bias=False)\nl2 = torch.nn.Linear(8,2,bias=False)\nb1 = torch.nn.Linear(9,1,bias=False)\nb2 = torch.nn.Linear(8,1,bias=False)\nparams = list(l1.parameters()) + list(l2.parameters())  + list(b1.parameters()) + list(b2.parameters())\noptimizr = torch.optim.Adam(params) \nsig = torch.nn.Sigmoid()\n#----#\nfor epoc in range(100):\n    #step1\n    W_features = l1(X1) \n    M_features = l2(X2)\n    W_bias = b1(X1)\n    M_bias = b2(X2)\n    yhat = sig((W_features * M_features).sum(axis=1).reshape(-1,1) + W_bias + M_bias)*5\n    #step2\n    loss = loss_fn(yhat,y)\n    #stpe3\n    loss.backward()\n    #step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\ny[:5], yhat[:5] # 비슷해야하는데 안 비슷함\n\n(tensor([[4.0200],\n         [3.4500],\n         [3.4200],\n         [0.8400],\n         [1.1200]]),\n tensor([[2.7421],\n         [2.5621],\n         [2.9185],\n         [2.5075],\n         [2.8614]], grad_fn=&lt;SliceBackward0&gt;))\n\n\n\nepoch을 3,000 으로\n\n\ndf_train = df_view.stack().reset_index().set_axis(['여성출연자','남성출연자','궁합점수'],axis=1)\n여성인덱스 = {'옥순(IN)':0, '영자(IN)':1, '정숙(IS)':2, '영숙(IS)':3, '순자(EN)':4, '현숙(EN)':5, '서연(ES)':6, '보람(ES)':7, '하니(I)':8}\n남성인덱스 = {'영식(IN)':0, '영철(IN)':1, '영호(IS)':2, '광수(IS)':3, '상철(EN)':4, '영수(EN)':5, '규빈(ES)':6, '다호(ES)':7}\nX1 = torch.nn.functional.one_hot(torch.tensor(df_train.여성출연자.map(여성인덱스))).float()\nX2 = torch.nn.functional.one_hot(torch.tensor(df_train.남성출연자.map(남성인덱스))).float()\ny = torch.tensor(df_train.궁합점수).reshape(-1,1).float()\n#----#\nloss_fn = torch.nn.MSELoss() \nl1 = torch.nn.Linear(9,2,bias=False)\nl2 = torch.nn.Linear(8,2,bias=False)\nb1 = torch.nn.Linear(9,1,bias=False)\nb2 = torch.nn.Linear(8,1,bias=False)\nparams = list(l1.parameters()) + list(l2.parameters())  + list(b1.parameters()) + list(b2.parameters())\noptimizr = torch.optim.Adam(params) \nsig = torch.nn.Sigmoid()\n#----#\nfor epoc in range(3000):\n    #step1\n    W_features = l1(X1) \n    M_features = l2(X2)\n    W_bias = b1(X1)\n    M_bias = b2(X2)\n    yhat = sig((W_features * M_features).sum(axis=1).reshape(-1,1) + W_bias + M_bias)*5\n    #step2\n    loss = loss_fn(yhat,y)\n    #stpe3\n    loss.backward()\n    #step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\ny[:5], yhat[:5]\n\n(tensor([[4.0200],\n         [3.4500],\n         [3.4200],\n         [0.8400],\n         [1.1200]]),\n tensor([[3.6914],\n         [3.5355],\n         [3.6526],\n         [0.6727],\n         [0.8341]], grad_fn=&lt;SliceBackward0&gt;))\n\n\n\n된 것 같음, 5,000으로\n\n\ndf_train = df_view.stack().reset_index().set_axis(['여성출연자','남성출연자','궁합점수'],axis=1)\n여성인덱스 = {'옥순(IN)':0, '영자(IN)':1, '정숙(IS)':2, '영숙(IS)':3, '순자(EN)':4, '현숙(EN)':5, '서연(ES)':6, '보람(ES)':7, '하니(I)':8}\n남성인덱스 = {'영식(IN)':0, '영철(IN)':1, '영호(IS)':2, '광수(IS)':3, '상철(EN)':4, '영수(EN)':5, '규빈(ES)':6, '다호(ES)':7}\nX1 = torch.nn.functional.one_hot(torch.tensor(df_train.여성출연자.map(여성인덱스))).float()\nX2 = torch.nn.functional.one_hot(torch.tensor(df_train.남성출연자.map(남성인덱스))).float()\ny = torch.tensor(df_train.궁합점수).reshape(-1,1).float()\n#----#\nloss_fn = torch.nn.MSELoss() \nl1 = torch.nn.Linear(9,2,bias=False)\nl2 = torch.nn.Linear(8,2,bias=False)\nb1 = torch.nn.Linear(9,1,bias=False)\nb2 = torch.nn.Linear(8,1,bias=False)\nparams = list(l1.parameters()) + list(l2.parameters())  + list(b1.parameters()) + list(b2.parameters())\noptimizr = torch.optim.Adam(params) \nsig = torch.nn.Sigmoid()\n#----#\nfor epoc in range(5000):\n    #step1\n    W_features = l1(X1) \n    M_features = l2(X2)\n    W_bias = b1(X1)\n    M_bias = b2(X2)\n    yhat = sig((W_features * M_features).sum(axis=1).reshape(-1,1) + W_bias + M_bias)*5\n    #step2\n    loss = loss_fn(yhat,y)\n    #stpe3\n    loss.backward()\n    #step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\ny[:5], yhat[:5] # 비슷함\n\n(tensor([[4.0200],\n         [3.4500],\n         [3.4200],\n         [0.8400],\n         [1.1200]]),\n tensor([[4.0586],\n         [3.4643],\n         [3.4175],\n         [0.8539],\n         [0.9135]], grad_fn=&lt;SliceBackward0&gt;))\n\n\n)🗣️\n\n#df_view\ndf_train = df_view.stack().reset_index().set_axis(['여성출연자','남성출연자','궁합점수'],axis=1)\n여성인덱스 = {'옥순(IN)':0, '영자(IN)':1, '정숙(IS)':2, '영숙(IS)':3, '순자(EN)':4, '현숙(EN)':5, '서연(ES)':6, '보람(ES)':7, '하니(I)':8}\n남성인덱스 = {'영식(IN)':0, '영철(IN)':1, '영호(IS)':2, '광수(IS)':3, '상철(EN)':4, '영수(EN)':5, '규빈(ES)':6, '다호(ES)':7}\nX1 = torch.nn.functional.one_hot(torch.tensor(df_train.여성출연자.map(여성인덱스))).float()\nX2 = torch.nn.functional.one_hot(torch.tensor(df_train.남성출연자.map(남성인덱스))).float()\ny = torch.tensor(df_train.궁합점수).reshape(-1,1).float()\n#----#\nloss_fn = torch.nn.MSELoss() \nl1 = torch.nn.Linear(9,2,bias=False)\nl2 = torch.nn.Linear(8,2,bias=False)\nb1 = torch.nn.Linear(9,1,bias=False)\nb2 = torch.nn.Linear(8,1,bias=False)\nparams = list(l1.parameters()) + list(l2.parameters())  + list(b1.parameters()) + list(b2.parameters())\noptimizr = torch.optim.Adam(params)\nsig = torch.nn.Sigmoid()\n#----#\nfor epoc in range(5000):\n    #step1\n    W_features = l1(X1) \n    M_features = l2(X2) \n    W_bias = b1(X1)\n    M_bais = b2(X2)\n    yhat = sig((W_features * M_features).sum(axis=1).reshape(-1,1) + W_bias + M_bais)*5\n    #step2\n    loss = loss_fn(yhat,y)\n    #step3\n    loss.backward()\n    #step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\ny[:5], yhat[:5]\n\n(tensor([[4.0200],\n         [3.4500],\n         [3.4200],\n         [0.8400],\n         [1.1200]]),\n tensor([[4.0370],\n         [3.4701],\n         [3.4334],\n         [0.8374],\n         [0.9061]], grad_fn=&lt;SliceBackward0&gt;))"
  },
  {
    "objectID": "posts/10wk-2.html#d.-예측",
    "href": "posts/10wk-2.html#d.-예측",
    "title": "10wk-2: (추천시스템) – optimizer 사용 고급, 모델링 전략, MF-based 추천시스템",
    "section": "D. 예측",
    "text": "D. 예측\n🗣️(\n\ndf_test = pd.DataFrame({'여성출연자':['옥순(IN)','하니(I)'],'남성출연자':['영식(IN)','영호(IS)']})\ndf_test\n\n\n\n\n\n\n\n\n여성출연자\n남성출연자\n\n\n\n\n0\n옥순(IN)\n영식(IN)\n\n\n1\n하니(I)\n영호(IS)\n\n\n\n\n\n\n\n\ndf_train[:2] # 궁합 점수가 궁금함\n\n\n\n\n\n\n\n\n여성출연자\n남성출연자\n궁합점수\n\n\n\n\n0\n옥순(IN)\n영철(IN)\n4.02\n\n\n1\n옥순(IN)\n영호(IS)\n3.45\n\n\n\n\n\n\n\n\ndf_test.여성출연자.map(여성인덱스)\n\n0    0\n1    8\nName: 여성출연자, dtype: int64\n\n\n\ntorch.tensor(df_test.여성출연자.map(여성인덱스))\n\ntensor([0, 8])\n\n\n\ntorch.nn.functional.one_hot(torch.tensor(df_test.여성출연자.map(여성인덱스)))\n\ntensor([[1, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 1]])\n\n\n\nXX1 = torch.nn.functional.one_hot(torch.tensor(df_test.여성출연자.map(여성인덱스)))\n\n\nXX1.shape, X1.shape\n\n(torch.Size([2, 9]), torch.Size([63, 9]))\n\n\n\nXX2 = torch.nn.functional.one_hot(torch.tensor(df_test.남성출연자.map(남성인덱스)))\n\n\nXX2.shape # 차원이 이상함\n\ntorch.Size([2, 3])\n\n\n\nXX2\n\ntensor([[1, 0, 0],\n        [0, 0, 1]])\n\n\n\ndf_test.남성출연자\n\n0    영식(IN)\n1    영호(IS)\nName: 남성출연자, dtype: object\n\n\n\n남성인덱스\n\n{'영식(IN)': 0,\n '영철(IN)': 1,\n '영호(IS)': 2,\n '광수(IS)': 3,\n '상철(EN)': 4,\n '영수(EN)': 5,\n '규빈(ES)': 6,\n '다호(ES)': 7}\n\n\n\ntorch.tensor(df_test.남성출연자.map(남성인덱스))\n\ntensor([0, 2])\n\n\n\ntorch.nn.functional.one_hot(torch.tensor(df_test.남성출연자.map(남성인덱스)))\n\ntensor([[1, 0, 0],\n        [0, 0, 1]])\n\n\n\n0,1,2 총 3개의 class만 있다고 판단한 것 같음\n\n\nXX1 = torch.nn.functional.one_hot(torch.tensor(df_test.여성출연자.map(여성인덱스)),num_classes=9).float() # 운 좋게 하니가 마지막 참가자라 아까는 이상 없었음\nXX2 = torch.nn.functional.one_hot(torch.tensor(df_test.남성출연자.map(남성인덱스)),num_classes=8).float()\n\n\nl1(XX1) # 학습된 parameter\n\ntensor([[-0.1969, -1.1841],\n        [ 0.7690, -1.0187]], grad_fn=&lt;MmBackward0&gt;)\n\n\n\ndf_test\n\n\n\n\n\n\n\n\n여성출연자\n남성출연자\n\n\n\n\n0\n옥순(IN)\n영식(IN)\n\n\n1\n하니(I)\n영호(IS)\n\n\n\n\n\n\n\n\n(l1(XX1) * l2(XX2)).sum(axis=1).reshape(2,1)\n\ntensor([[1.9070],\n        [0.4191]], grad_fn=&lt;ViewBackward0&gt;)\n\n\n\n하니와 영호는 I만 맞아서 궁합이 오히려 안 좋게 나옴\n\n\nb1(XX1) # 여성 참가자의 매력 (하니는 점수가 높음)\n\ntensor([[-1.3766],\n        [ 1.2688]], grad_fn=&lt;MmBackward0&gt;)\n\n\n\nb2(XX2) # 남성 참가자의 매력\n\ntensor([[0.8753],\n        [0.9267]], grad_fn=&lt;MmBackward0&gt;)\n\n\n\n최종 점수는\n\n\nsig((l1(XX1) * l2(XX2)).sum(axis=1).reshape(2,1) + b1(XX1) + b2(XX2))*5 # 그럴듯 함\n\ntensor([[4.0154],\n        [4.6590]], grad_fn=&lt;MulBackward0&gt;)\n\n\n)🗣️\n\ndf_view\n\n\n\n\n\n\n\n\n영식(IN)\n영철(IN)\n영호(IS)\n광수(IS)\n상철(EN)\n영수(EN)\n규빈(ES)\n다호(ES)\n\n\n\n\n옥순(IN)\nNaN\n4.02\n3.45\n3.42\n0.84\n1.12\n0.43\n0.49\n\n\n영자(IN)\n3.93\n3.99\n3.63\n3.43\n0.98\n0.96\n0.52\nNaN\n\n\n정숙(IS)\n3.52\n3.42\n4.05\n4.06\n0.39\nNaN\n0.93\n0.99\n\n\n영숙(IS)\n3.43\n3.57\nNaN\n3.95\n0.56\n0.52\n0.89\n0.89\n\n\n순자(EN)\n1.12\nNaN\n0.59\n0.43\n4.01\n4.16\n3.52\n3.38\n\n\n현숙(EN)\n0.94\n1.05\n0.32\n0.45\n4.02\n3.78\nNaN\n3.54\n\n\n서연(ES)\n0.51\n0.56\n0.88\n0.89\n3.50\n3.64\n4.04\n4.10\n\n\n보람(ES)\n0.48\n0.51\n1.03\nNaN\n3.52\n4.00\n3.82\nNaN\n\n\n하니(I)\n4.85\n4.82\nNaN\n4.98\n4.53\n4.39\n4.45\n4.52\n\n\n\n\n\n\n\n\ndf_train[:2]\n\n\n\n\n\n\n\n\n여성출연자\n남성출연자\n궁합점수\n\n\n\n\n0\n옥순(IN)\n영철(IN)\n4.02\n\n\n1\n옥순(IN)\n영호(IS)\n3.45\n\n\n\n\n\n\n\n적합된 네트워크를 바탕으로 아래의 값에 대한 예측을 수행하라.\n\ndf_test = pd.DataFrame({'여성출연자':['옥순(IN)','하니(I)'],'남성출연자':['영식(IN)','영호(IS)']})\ndf_test\n\n\n\n\n\n\n\n\n여성출연자\n남성출연자\n\n\n\n\n0\n옥순(IN)\n영식(IN)\n\n\n1\n하니(I)\n영호(IS)\n\n\n\n\n\n\n\n\nXX1 = torch.nn.functional.one_hot(torch.tensor(df_test.여성출연자.map(여성인덱스)),num_classes=9).float()\nXX2 = torch.nn.functional.one_hot(torch.tensor(df_test.남성출연자.map(남성인덱스)),num_classes=8).float()\n\n\nsig((l1(XX1) * l2(XX2)).sum(axis=1).reshape(2,1) + b1(XX1) + b2(XX2))*5\n\ntensor([[3.9640],\n        [4.6568]], grad_fn=&lt;MulBackward0&gt;)"
  },
  {
    "objectID": "posts/14wk-1.html",
    "href": "posts/14wk-1.html",
    "title": "14wk-1: (강화학습) – 4x4 Grid World 환경의 이해",
    "section": "",
    "text": "📘 Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\n📝 🗣️ ✍️ 🔬 ❓"
  },
  {
    "objectID": "posts/14wk-1.html#a.-데이터-축적",
    "href": "posts/14wk-1.html#a.-데이터-축적",
    "title": "14wk-1: (강화학습) – 4x4 Grid World 환경의 이해",
    "section": "A. 데이터 축적",
    "text": "A. 데이터 축적\n- 랜덤에이전트를 이용해 무작위로 100,000 에피소드를 진행해보자.\n\nplayer = RandomAgent()\nenv = GridWorld()\nscores = [] \nscore = 0 \n#\nfor e in range(1,100000):\n    #---에피소드시작---#\n    while True:\n        # step1 -- 액션선택\n        player.act()\n        # step2 -- 환경반응 \n        player.next_state, player.reward, player.terminated = env.step(player.action)\n        # step3 -- 경험기록 & 학습 \n        player.save_experience()\n        player.learn()\n        # step4 --종료 조건 체크 & 후속 처리\n        if env.terminated:\n            score = score + player.reward\n            scores.append(score)\n            score = 0 \n            player.state = env.reset() \n            break\n        else: \n            score = score + player.reward            \n            player.state = player.next_state\n\n\n\n\n\n\n\nImportant\n\n\n\n강의노트 수정 2025-06-12\n노규호학생의 도움으로 예전강의의 오류를 발견하여 수정하였습니다.\n# 수정전\n...\n        if env.terminated:\n            ...\n        else: \n            score = score + player.reward\n            scores.append(score)            \n            player.state = player.next_state\n            \n# 수정후\n        if env.terminated:\n            ...\n        else: \n            score = score + player.reward\n#            scores.append(score)            ### &lt;--- 여기를 주석처리해야함!! \n            player.state = player.next_state\n:::\n\n::: {#ef29fdf9-b027-4d88-8bd7-1e5c6d3b08d9 .cell tags='[]' execution_count=5}\n``` {.python .cell-code}\nplayer.n_experience\n\n326581\n\n\n\n\n🗣️\n\n한 에피소드 당 평균 3번 정도"
  },
  {
    "objectID": "posts/14wk-1.html#b.-첫번째-q_table",
    "href": "posts/14wk-1.html#b.-첫번째-q_table",
    "title": "14wk-1: (강화학습) – 4x4 Grid World 환경의 이해",
    "section": "B. 첫번째 q_table",
    "text": "B. 첫번째 q_table\n- 밴딧게임에서는 \\(q(a)\\) 를 정의했었음.\n\n\\(q(0) = 1\\)\n\\(q(1) = 10\\)\n\n- 여기에서는 \\(q(s_1,s_2,a)\\)를 정의해야함!\n\n\n\n\n\n\nNote\n\n\n\n직관적으로 아래의 그림이 떠오름 \n그림에 대응하는 \\(q(s_1,s_2,a)\\)의 값은 아래와 같음\n\n\\(a=0\\)\\(a=1\\)\\(a=2\\)\\(a=3\\)\n\n\n\\(a=0 \\Leftrightarrow \\text{\\tt action=right}\\)\n\\[ \\begin{bmatrix}\nq(0,0,0) & q(0,1,0) & q(0,2,0) & q(0,3,0) \\\\\nq(1,0,0) & q(1,1,0) & q(1,2,0) & q(1,3,0) \\\\\nq(2,0,0) & q(2,1,0) & q(2,2,0) & q(2,3,0) \\\\\nq(3,0,0) & q(3,1,0) &q(3,2,0) & q(3,3,0) \\\\\n\\end{bmatrix} =  \\begin{bmatrix}\n-1 & -1 & -1 & -10 \\\\\n-1 & -1 & -1 & -10 \\\\\n-1 & -1 & -1 & -10 \\\\\n-1 & -1 & 100 &  \\text{-} \\\\\n\\end{bmatrix}\n\\]\n\n\n\\(a=1 \\Leftrightarrow \\text{\\tt action=left}\\)\n\\[ \\begin{bmatrix}\nq(0,0,1) & q(0,1,1) & q(0,2,1) & q(0,3,1) \\\\\nq(1,0,1) & q(1,1,1) & q(1,2,1) & q(1,3,1) \\\\\nq(2,0,1) & q(2,1,1) & q(2,2,1) & q(2,3,1) \\\\\nq(3,0,1) & q(3,1,1) &q(3,2,1) & q(3,3,1) \\\\\n\\end{bmatrix} = \\begin{bmatrix}\n-10 & -1 & -1 & -1 \\\\\n-10& -1 & -1 & -1 \\\\\n-10 & -1 & -1 & -1 \\\\\n-10 & -1 & -1 &  \\text{-} \\\\\n\\end{bmatrix}\n\\]\n\n\n\\(a=2 \\Leftrightarrow \\text{\\tt action=down}\\)\n\\[  \\begin{bmatrix}\nq(0,0,2) & q(0,1,2) & q(0,2,2) & q(0,3,2) \\\\\nq(1,0,2) & q(1,1,2) & q(1,2,2) & q(1,3,2) \\\\\nq(2,0,2) & q(2,1,2) & q(2,2,2) & q(2,3,2) \\\\\nq(3,0,2) & q(3,1,2) &q(3,2,2) & q(3,3,2) \\\\\n\\end{bmatrix} = \\begin{bmatrix}\n-1 & -1 & -1 & -1 \\\\\n-1& -1 & -1 & -1 \\\\\n-1 & -1 & -1 & 100\\\\\n-10 & -10 & -10 &  \\text{-} \\\\\n\\end{bmatrix}\n\\]\n\n\n\\(a=3 \\Leftrightarrow \\text{\\tt action=up}\\)\n\\[  \\begin{bmatrix}\nq(0,0,3) & q(0,1,3) & q(0,2,3) & q(0,3,3) \\\\\nq(1,0,3) & q(1,1,3) & q(1,2,3) & q(1,3,3) \\\\\nq(2,0,3) & q(2,1,3) & q(2,2,3) & q(2,3,3) \\\\\nq(3,0,3) & q(3,1,3) &q(3,2,3) & q(3,3,3) \\\\\n\\end{bmatrix} =\\begin{bmatrix}\n-10 & -10 & -10 & -10\\\\\n-1& -1 & -1 & -1 \\\\\n-1 & -1 & -1 & -1 \\\\\n-1 & -1 & -1 &  \\text{-} \\\\\n\\end{bmatrix}\n\\]\n\n\n\n\n\n- 데이터를 바탕으로 \\(q(s_1,s_2,a)\\)를 구해보자.\n🗣️(\n\nplayer.states[0], player.actions[0], player.rewards[0]\n\n(array([0, 0]), np.int64(1), -10)\n\n\nq(0, 0, 1) = -10\n✍️ 이 경우에 게임이 끝났음\n\nplayer.states[1], player.actions[1], player.rewards[1]\n\n(array([0, 0]), np.int64(2), -1)\n\n\nq(0, 0, 2) = -1\n\nplayer.states[2], player.actions[2], player.rewards[2]\n\n(array([1, 0]), np.int64(1), -10)\n\n\n\nq_table 만들기\n\n\nq_table = np.zeros([4,4,4])\nq_table\n\narray([[[0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.]],\n\n       [[0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.]],\n\n       [[0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.]],\n\n       [[0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.]]])\n\n\n\nfor (s1,s2), a, r in zip(player.states, player.actions, player.rewards):\n    q_table[s1,s2,a] = q_table[s1,s2,a] + r # [s1,s2,s3]에서 받은 보상(r)을 계속 더함\n\n\nq_table[:,:,0]\n\narray([[-29987., -10133.,  -3694., -12710.],\n       [-10197.,  -7066.,  -3646., -14840.],\n       [ -3761.,  -3648.,  -2312.,  -9980.],\n       [ -1361.,  -1446.,  91000.,      0.]])\n\n\n아래와 같은 경우를 기대하였으나 그렇지 않음\n-1 -1 -1 -10\n-1 -1 -1 -10\n-1 -1 -1 -10\n-1 -1 100 -\ncount를 계산하여 평균을 구해야 할 것 같음\n\nq_table = np.zeros([4,4,4])\ncount = np.zeros([4,4,4])\n\n\nfor (s1,s2), a, r in zip(player.states, player.actions, player.rewards):\n    q_table[s1,s2,a] = q_table[s1,s2,a] + r\n    count[s1,s2,a] = count[s1,s2,a] + 1\n\n\nq_table[:,:,0]\n\narray([[-29987., -10133.,  -3694., -12710.],\n       [-10197.,  -7066.,  -3646., -14840.],\n       [ -3761.,  -3648.,  -2312.,  -9980.],\n       [ -1361.,  -1446.,  91000.,      0.]])\n\n\n\ncount[:,:,0]\n\narray([[29987., 10133.,  3694.,  1271.],\n       [10197.,  7066.,  3646.,  1484.],\n       [ 3761.,  3648.,  2312.,   998.],\n       [ 1361.,  1446.,   910.,     0.]])\n\n\n\nq_table[...,0] # 동일 코드\n\narray([[-29987., -10133.,  -3694., -12710.],\n       [-10197.,  -7066.,  -3646., -14840.],\n       [ -3761.,  -3648.,  -2312.,  -9980.],\n       [ -1361.,  -1446.,  91000.,      0.]])\n\n\n\ncount[...,0] # 동일 코드\n\narray([[29987., 10133.,  3694.,  1271.],\n       [10197.,  7066.,  3646.,  1484.],\n       [ 3761.,  3648.,  2312.,   998.],\n       [ 1361.,  1446.,   910.,     0.]])\n\n\n\nq_table[...,1]\n\narray([[-301600.,  -10110.,   -3881.,   -1306.],\n       [-101040.,   -6958.,   -3589.,   -1430.],\n       [ -38240.,   -3584.,   -2295.,    -913.],\n       [ -13030.,   -1492.,    -936.,       0.]])\n\n\n\ncount[...,1]\n\narray([[30160., 10110.,  3881.,  1306.],\n       [10104.,  6958.,  3589.,  1430.],\n       [ 3824.,  3584.,  2295.,   913.],\n       [ 1303.,  1492.,   936.,     0.]])\n\n\nq_table을 count로 나누면 아래와 같은 결과가 나올 것 같음\n-10 -1 -1 -1\n-10 -1 -1 -1\n-10 -1 -1 -1\n-10 -1 -1 -\n\nq_table / count\n\n/tmp/ipykernel_2313654/1678126644.py:1: RuntimeWarning: invalid value encountered in divide\n  q_table / count\n\n\narray([[[ -1., -10.,  -1., -10.],\n        [ -1.,  -1.,  -1., -10.],\n        [ -1.,  -1.,  -1., -10.],\n        [-10.,  -1.,  -1., -10.]],\n\n       [[ -1., -10.,  -1.,  -1.],\n        [ -1.,  -1.,  -1.,  -1.],\n        [ -1.,  -1.,  -1.,  -1.],\n        [-10.,  -1.,  -1.,  -1.]],\n\n       [[ -1., -10.,  -1.,  -1.],\n        [ -1.,  -1.,  -1.,  -1.],\n        [ -1.,  -1.,  -1.,  -1.],\n        [-10.,  -1., 100.,  -1.]],\n\n       [[ -1., -10., -10.,  -1.],\n        [ -1.,  -1., -10.,  -1.],\n        [100.,  -1., -10.,  -1.],\n        [ nan,  nan,  nan,  nan]]])\n\n\n\n없는 값이 존재함\n\n\n(q_table / count)[...,0]\n\n/tmp/ipykernel_2313654/878353018.py:1: RuntimeWarning: invalid value encountered in divide\n  (q_table / count)[...,0]\n\n\narray([[ -1.,  -1.,  -1., -10.],\n       [ -1.,  -1.,  -1., -10.],\n       [ -1.,  -1.,  -1., -10.],\n       [ -1.,  -1., 100.,  nan]])\n\n\n\nnan 위치의 값은 원래 없으므로 count가 안 됨\n\n\ncount[...,0]\n\narray([[29987., 10133.,  3694.,  1271.],\n       [10197.,  7066.,  3646.,  1484.],\n       [ 3761.,  3648.,  2312.,   998.],\n       [ 1361.,  1446.,   910.,     0.]])\n\n\n\n0으로 나누는 것이 문제가 되므로 다음과 같이 하면\n\n\ncount[count == 0] = 0.000001\nq_table = q_table / count\n\n\nq_table[...,0]\n\narray([[ -1.,  -1.,  -1., -10.],\n       [ -1.,  -1.,  -1., -10.],\n       [ -1.,  -1.,  -1., -10.],\n       [ -1.,  -1., 100.,   0.]])\n\n\n)🗣️\n\nplayer.states[0], player.actions[0], player.rewards[0]\n\n(array([0, 0]), 0, -1)\n\n\n\nq_table = np.zeros((4,4,4))\ncount = np.zeros((4,4,4))\n\n\nmemory =  zip(player.states, player.actions, player.rewards)\nfor (s1,s2), a, r in memory:\n    q_table[s1,s2,a] = q_table[s1,s2,a] + r\n    count[s1,s2,a] = count[s1,s2,a] + 1 \n\n\ncount[count==0] = 0.001 \n\n\nq_table = q_table / count\n\n\nq_table[...,0], q_table[...,1], q_table[...,2], q_table[...,3]\n\n(array([[ -1.,  -1.,  -1., -10.],\n        [ -1.,  -1.,  -1., -10.],\n        [ -1.,  -1.,  -1., -10.],\n        [ -1.,  -1., 100.,   0.]]),\n array([[-10.,  -1.,  -1.,  -1.],\n        [-10.,  -1.,  -1.,  -1.],\n        [-10.,  -1.,  -1.,  -1.],\n        [-10.,  -1.,  -1.,   0.]]),\n array([[ -1.,  -1.,  -1.,  -1.],\n        [ -1.,  -1.,  -1.,  -1.],\n        [ -1.,  -1.,  -1., 100.],\n        [-10., -10., -10.,   0.]]),\n array([[-10., -10., -10., -10.],\n        [ -1.,  -1.,  -1.,  -1.],\n        [ -1.,  -1.,  -1.,  -1.],\n        [ -1.,  -1.,  -1.,   0.]]))\n\n\n- count를 사용하지 않는 방법은 없을까? – 테크닉\n🗣️(\n\n부스팅 알고리즘을 잘 알면 이해하기 쉬움\n\n예시)\n어떤 액션을 했을 때 받는 보상 80 / 학습률: 0.1 / 초기값 50\n80 - 50 = 30\n50 + 3 = 53\n80 - 53 = 27\n53 + 2.7 = 55.7\n...\n80 근처로 가게 됨\n\nq_table = np.zeros([4,4,4])\nfor (s1,s2), a, r in zip(player.states, player.actions, player.rewards):\n    qhat = q_table[s1,s2,a]\n    q = r\n    diff = q - qhat\n    q_table[s1,s2,a] = q_table[s1,s2,a] + 0.01*diff\n\n\nq_table\n\narray([[[ -1.        , -10.        ,  -1.        , -10.        ],\n        [ -1.        ,  -1.        ,  -1.        , -10.        ],\n        [ -1.        ,  -1.        ,  -1.        , -10.        ],\n        [ -9.99997166,  -0.99999801,  -0.99999585,  -9.99998066]],\n\n       [[ -1.        , -10.        ,  -1.        ,  -1.        ],\n        [ -1.        ,  -1.        ,  -1.        ,  -1.        ],\n        [ -1.        ,  -1.        ,  -1.        ,  -1.        ],\n        [ -9.99999667,  -0.99999943,  -0.99999928,  -0.9999994 ]],\n\n       [[ -1.        , -10.        ,  -1.        ,  -1.        ],\n        [ -1.        ,  -1.        ,  -1.        ,  -1.        ],\n        [ -1.        ,  -1.        ,  -1.        ,  -1.        ],\n        [ -9.99955952,  -0.9998965 ,  99.99218879,  -0.99983567]],\n\n       [[ -0.99999885,  -9.99997946,  -9.99998584,  -0.99999546],\n        [ -0.99999951,  -0.99999969,  -9.9999924 ,  -0.99999986],\n        [ 99.98933337,  -0.99991786,  -9.99916195,  -0.99991703],\n        [  0.        ,   0.        ,   0.        ,   0.        ]]])\n\n\n\nq_table[...,0]\n\narray([[-1.        , -1.        , -1.        , -9.99997166],\n       [-1.        , -1.        , -1.        , -9.99999667],\n       [-1.        , -1.        , -1.        , -9.99955952],\n       [-0.99999885, -0.99999951, 99.98933337,  0.        ]])\n\n\n\nq_table[...,0].round(2)\n\narray([[ -1.  ,  -1.  ,  -1.  , -10.  ],\n       [ -1.  ,  -1.  ,  -1.  , -10.  ],\n       [ -1.  ,  -1.  ,  -1.  , -10.  ],\n       [ -1.  ,  -1.  ,  99.99,   0.  ]])\n\n\n)🗣️\n\nq_table = np.zeros((4,4,4))\nmemory =  zip(player.states, player.actions, player.rewards)\nfor (s1,s2), a, r in memory:\n    qhat = q_table[s1,s2,a] # 내가 생각했던갓\n    q = r # 실제값\n    diff = q-qhat # 차이\n    q_table[s1,s2,a] = q_table[s1,s2,a]  + 0.01*diff# update\n\n\nq_table.round(2)\n\narray([[[ -1.  , -10.  ,  -1.  , -10.  ],\n        [ -1.  ,  -1.  ,  -1.  , -10.  ],\n        [ -1.  ,  -1.  ,  -1.  , -10.  ],\n        [-10.  ,  -1.  ,  -1.  , -10.  ]],\n\n       [[ -1.  , -10.  ,  -1.  ,  -1.  ],\n        [ -1.  ,  -1.  ,  -1.  ,  -1.  ],\n        [ -1.  ,  -1.  ,  -1.  ,  -1.  ],\n        [-10.  ,  -1.  ,  -1.  ,  -1.  ]],\n\n       [[ -1.  , -10.  ,  -1.  ,  -1.  ],\n        [ -1.  ,  -1.  ,  -1.  ,  -1.  ],\n        [ -1.  ,  -1.  ,  -1.  ,  -1.  ],\n        [-10.  ,  -1.  ,  99.99,  -1.  ]],\n\n       [[ -1.  , -10.  , -10.  ,  -1.  ],\n        [ -1.  ,  -1.  , -10.  ,  -1.  ],\n        [ 99.99,  -1.  , -10.  ,  -1.  ],\n        [  0.  ,   0.  ,   0.  ,   0.  ]]])"
  },
  {
    "objectID": "posts/14wk-1.html#c.-첫번째-q_table보다-나은-것",
    "href": "posts/14wk-1.html#c.-첫번째-q_table보다-나은-것",
    "title": "14wk-1: (강화학습) – 4x4 Grid World 환경의 이해",
    "section": "C. 첫번째 q_table보다 나은 것?",
    "text": "C. 첫번째 q_table보다 나은 것?\n- 첫번째 q_table을 알고있다고 가정하자.\n\n- 정책시각화 (합리적인 행동)\n\n- 이게 최선의 정책일까?\n\n🗣️\n\n큰 숫자 따라가기?\n(2,2)에서 오른쪽과 아래는 -1 이 아니라 99로 수정?\n\n오른쪽이나 아래로 가면 100이 보장이 되어 있음\n\n(1,2)에서 왼쪽과 아래쪽은 reward가 똑같은 것이 맞는가?\n\n아래로 가면 99가 보장이 되어 있으므로 98로 수정?\n\n이런 식으로 100점을 기준으로 점차 재조정이 되어야 할 것 같음"
  },
  {
    "objectID": "posts/11wk-1.html",
    "href": "posts/11wk-1.html",
    "title": "11wk-1: (추천시스템) – Embedding 레이어, 사용자정의 네트워크, MF-based 추천시스템을 넘어서",
    "section": "",
    "text": "📘 Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\n📝 🗣️ ✍️ 🔬 ❓"
  },
  {
    "objectID": "posts/11wk-1.html#a.-임베딩레이어",
    "href": "posts/11wk-1.html#a.-임베딩레이어",
    "title": "11wk-1: (추천시스템) – Embedding 레이어, 사용자정의 네트워크, MF-based 추천시스템을 넘어서",
    "section": "A. 임베딩레이어",
    "text": "A. 임베딩레이어\n- 모티브: torch.nn.functional.one_hot + torch.nn.Linear 를 매번 쓰는건 너무 귀찮지 않어?\n🗣️(\n\ntorch.manual_seed(43052)\n#x  = ['옥순', '영숙', '하니', '옥순', '영숙'] \nx = torch.tensor([0,1,2,0,1])\nlinr = torch.nn.Linear(3,1,bias=False)\nlinr(torch.nn.functional.one_hot(x).float())\n\ntensor([[-0.2002],\n        [-0.4890],\n        [ 0.2081],\n        [-0.2002],\n        [-0.4890]], grad_fn=&lt;MmBackward0&gt;)\n\n\n\n지난 시간까지는 위처럼 했음\n\n\ntorch.manual_seed(43052)\n#x  = ['옥순', '영숙', '하니', '옥순', '영숙'] \nx = torch.tensor([0,1,2,0,1])\nX = torch.nn.functional.one_hot(x).float()\nlinr = torch.nn.Linear(3,1,bias=False)\nlinr(X)\n\ntensor([[-0.2002],\n        [-0.4890],\n        [ 0.2081],\n        [-0.2002],\n        [-0.4890]], grad_fn=&lt;MmBackward0&gt;)\n\n\n\nx, X\n\n(tensor([0, 1, 2, 0, 1]),\n tensor([[1., 0., 0.],\n         [0., 1., 0.],\n         [0., 0., 1.],\n         [1., 0., 0.],\n         [0., 1., 0.]]))\n\n\n\nlinr.weight\n\nParameter containing:\ntensor([[-0.2002, -0.4890,  0.2081]], requires_grad=True)\n\n\n\nX @ linr.weight.T\n\ntensor([[-0.2002],\n        [-0.4890],\n        [ 0.2081],\n        [-0.2002],\n        [-0.4890]], grad_fn=&lt;MmBackward0&gt;)\n\n\n)🗣️\n\ntorch.manual_seed(43052)\n#x  = ['옥순', '영숙', '하니', '옥순', '영숙'] \nx = torch.tensor([0,1,2,0,1])\nX = torch.nn.functional.one_hot(x).float()\nlinr = torch.nn.Linear(3,1,bias=False)\nlinr(X)\n\ntensor([[-0.2002],\n        [-0.4890],\n        [ 0.2081],\n        [-0.2002],\n        [-0.4890]], grad_fn=&lt;MmBackward0&gt;)\n\n\n- 계산방식\n\n\\({\\boldsymbol x}= \\begin{bmatrix} 0 \\\\ 1 \\\\ 2 \\\\ 0 \\\\ 1 \\end{bmatrix} \\Longrightarrow {\\bf X}= \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{bmatrix}\\)\n\\(\\text{linr}({\\bf X})= \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{bmatrix}\\begin{bmatrix} -0.2002 \\\\ -0.4890 \\\\ 0.2081 \\end{bmatrix} = \\begin{bmatrix} -0.2002 \\\\ -0.4890 \\\\ 0.2081 \\\\ -0.2002 \\\\ -0.4890 \\end{bmatrix}\\)\n\n- torch.nn.functional.one_hot + torch.nn.Linear 를 함께처리해주는 레이어 torch.nn.Embedding 존재\n🗣️(\n\n다른 방식으로 할 수도 있음\n\n\ntorch.manual_seed(43052)\n#x  = ['옥순', '영숙', '하니', '옥순', '영숙'] \nx = torch.tensor([0,1,2,0,1])\nebdd = torch.nn.Embedding(3,1)\nebdd(x) # 이렇게 하면 숫자들이 나옴 (위와는 다름)\n\ntensor([[-0.8178],\n        [-0.7052],\n        [-0.5843],\n        [-0.8178],\n        [-0.7052]], grad_fn=&lt;EmbeddingBackward0&gt;)\n\n\n\n#x  = ['옥순', '영숙', '하니', '옥순', '영숙'] \nx = torch.tensor([0,1,2,0,1])\nebdd = torch.nn.Embedding(3,1)\nebdd(x)\n\ntensor([[-0.6179],\n        [ 1.9949],\n        [-0.4724],\n        [-0.6179],\n        [ 1.9949]], grad_fn=&lt;EmbeddingBackward0&gt;)\n\n\n\nebdd.weight\n\nParameter containing:\ntensor([[-0.6179],\n        [ 1.9949],\n        [-0.4724]], requires_grad=True)\n\n\n\nlinr.weight\n\nParameter containing:\ntensor([[-0.2002, -0.4890,  0.2081]], requires_grad=True)\n\n\nebdd.weight.data = torch.tensor([[-0.2002],[-0.4890],[0.2081]]) # 이전 linr의 parameter로 덮어쓰면\n\ntorch.manual_seed(43052)\n#x  = ['옥순', '영숙', '하니', '옥순', '영숙'] \nx = torch.tensor([0,1,2,0,1])\nebdd = torch.nn.Embedding(3,1)\nebdd.weight.data = torch.tensor([[-0.2002],[-0.4890],[0.2081]])\nebdd(x)\n\ntensor([[-0.2002],\n        [-0.4890],\n        [ 0.2081],\n        [-0.2002],\n        [-0.4890]], grad_fn=&lt;EmbeddingBackward0&gt;)\n\n\n\nlinr(X) # 위와 동일\n\ntensor([[-0.2002],\n        [-0.4890],\n        [ 0.2081],\n        [-0.2002],\n        [-0.4890]], grad_fn=&lt;MmBackward0&gt;)\n\n\n\nEmbedding에는 one hot encoding 후 linr 을 할 때의 차원을 넣어주면 됨\n\n)🗣️\n\n#x  = ['옥순', '영숙', '하니', '옥순', '영숙'] \nx = torch.tensor([0,1,2,0,1])\nebdd = torch.nn.Embedding(3,1)\nebdd.weight.data = torch.tensor([[-0.2002],[-0.4890],[0.2081]])\nebdd(x)\n\ntensor([[-0.2002],\n        [-0.4890],\n        [ 0.2081],\n        [-0.2002],\n        [-0.4890]], grad_fn=&lt;EmbeddingBackward0&gt;)\n\n\n\n\\(\\text{ebdd}({\\boldsymbol x})= \\text{linr}\\big(\\text{onehot}({\\boldsymbol x})\\big) = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{bmatrix}\\begin{bmatrix} -0.2002 \\\\ -0.4890 \\\\ 0.2081 \\end{bmatrix} = \\begin{bmatrix} -0.2002 \\\\ -0.4890 \\\\ 0.2081 \\\\ -0.2002 \\\\ -0.4890 \\end{bmatrix}\\)\n우리가 이전에 구현했던 코드 “onehot + linr” 와 “ebdd”는 정확하게 동일한 동작을 수행함.\n\n- 결론: 아래의 두개의 코드는 같다.\nx= torch.tensor([0,1,2,0,1])\n\n## 코드1 \nlinr = torch.nn.Linear(3,1) \nlinr(torch.nn.functional.one_hot(x))\n\n## 코드2 \nebdd = torch.nn.Embedding(3,1)\nebdd(x)"
  },
  {
    "objectID": "posts/11wk-1.html#b.-mf-based-추천시스템-재설계",
    "href": "posts/11wk-1.html#b.-mf-based-추천시스템-재설계",
    "title": "11wk-1: (추천시스템) – Embedding 레이어, 사용자정의 네트워크, MF-based 추천시스템을 넘어서",
    "section": "B. MF-based 추천시스템 재설계",
    "text": "B. MF-based 추천시스템 재설계\n아래의 자료를 활용하여 추천시스템을 설계하고자한다.\n\ndf_view = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2025/main/posts/iamsolo.csv',index_col=0)\ndf_view\n\n\n\n\n\n\n\n\n영식(IN)\n영철(IN)\n영호(IS)\n광수(IS)\n상철(EN)\n영수(EN)\n규빈(ES)\n다호(ES)\n\n\n\n\n옥순(IN)\nNaN\n4.02\n3.45\n3.42\n0.84\n1.12\n0.43\n0.49\n\n\n영자(IN)\n3.93\n3.99\n3.63\n3.43\n0.98\n0.96\n0.52\nNaN\n\n\n정숙(IS)\n3.52\n3.42\n4.05\n4.06\n0.39\nNaN\n0.93\n0.99\n\n\n영숙(IS)\n3.43\n3.57\nNaN\n3.95\n0.56\n0.52\n0.89\n0.89\n\n\n순자(EN)\n1.12\nNaN\n0.59\n0.43\n4.01\n4.16\n3.52\n3.38\n\n\n현숙(EN)\n0.94\n1.05\n0.32\n0.45\n4.02\n3.78\nNaN\n3.54\n\n\n서연(ES)\n0.51\n0.56\n0.88\n0.89\n3.50\n3.64\n4.04\n4.10\n\n\n보람(ES)\n0.48\n0.51\n1.03\nNaN\n3.52\n4.00\n3.82\nNaN\n\n\n하니(I)\n4.85\n4.82\nNaN\n4.98\n4.53\n4.39\n4.45\n4.52\n\n\n\n\n\n\n\n\ndf_train = df_view.stack().reset_index().set_axis(['W','M','y'],axis=1)\n여성인덱스 = {'옥순(IN)':0, '영자(IN)':1, '정숙(IS)':2, '영숙(IS)':3, '순자(EN)':4, '현숙(EN)':5, '서연(ES)':6, '보람(ES)':7, '하니(I)':8}\n남성인덱스 = {'영식(IN)':0, '영철(IN)':1, '영호(IS)':2, '광수(IS)':3, '상철(EN)':4, '영수(EN)':5, '규빈(ES)':6, '다호(ES)':7}\nx1 = torch.tensor(df_train['W'].map(여성인덱스)) # length-n int vector \nx2 = torch.tensor(df_train['M'].map(남성인덱스)) # length-n int vector \ny = torch.tensor(df_train['y']).float().reshape(-1,1) # (n,1) float vector\n\n임베딩레이어를 활용하여 MF-based 추천시스템을 설계하라.\n(풀이)\n🗣️(\n# 지난 시간에는 x1이 one hot encoding 된 형태\nX1 = torch.nn.functional.one_hot(x1)\n\nx1 # 이제는 이 상태에서 바로 학습을 시키려고 함 (임베딩 레이어 활용)\n\ntensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3,\n        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6,\n        6, 6, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8])\n\n\n\n이전 시간 코드를 참고하여 수정하면\n\n#----#\nloss_fn = torch.nn.MSELoss() \nl1 = torch.nn.Linear(9,2,bias=False)\nl2 = torch.nn.Linear(8,2,bias=False)\nb1 = torch.nn.Linear(9,1,bias=False)\nb2 = torch.nn.Linear(8,1,bias=False)\nparams = list(l1.parameters()) + list(l2.parameters())  + list(b1.parameters()) + list(b2.parameters())\noptimizr = torch.optim.Adam(params) \nsig = torch.nn.Sigmoid()\n#----#\nfor epoc in range(100):\n    #step1\n    W_features = l1(X1) \n    M_features = l2(X2)\n    W_bias = b1(X1)\n    M_bias = b2(X2)\n    yhat = sig((W_features * M_features).sum(axis=1).reshape(-1,1) + W_bias + M_bias)*5\n    #step2\n    loss = loss_fn(yhat,y)\n    #stpe3\n    loss.backward()\n    #step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n#df_view\nloss_fn = torch.nn.MSELoss() \nebdd1 = torch.nn.Embedding(9,2)\nebdd2 = torch.nn.Embedding(8,2)\nb1 = torch.nn.Embedding(9,1)\nb2 = torch.nn.Embedding(8,1)\nparams = list(ebdd1.parameters()) + list(ebdd2.parameters())  + list(b1.parameters()) + list(b2.parameters())\noptimizr = torch.optim.Adam(params)\nsig = torch.nn.Sigmoid()\n#----#\nfor epoc in range(5000):\n    #step1\n    W_features = ebdd1(x1) \n    M_features = ebdd2(x2) \n    W_bias = b1(x1)\n    M_bais = b2(x2)\n    yhat = sig((W_features * M_features).sum(axis=1).reshape(-1,1) + W_bias + M_bais)*5\n    #step2\n    loss = loss_fn(yhat,y)\n    #step3\n    loss.backward()\n    #step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\ny[:5], yhat[:5] # 그럭저럭 잘 맞추고 있음\n\n(tensor([[4.0200],\n         [3.4500],\n         [3.4200],\n         [0.8400],\n         [1.1200]]),\n tensor([[3.6066],\n         [3.6236],\n         [3.6976],\n         [0.7890],\n         [0.8583]], grad_fn=&lt;SliceBackward0&gt;))\n\n\n)🗣️\n\n#df_view\nloss_fn = torch.nn.MSELoss() \nebdd1 = torch.nn.Embedding(9,2)\nebdd2 = torch.nn.Embedding(8,2)\nb1 = torch.nn.Embedding(9,1)\nb2 = torch.nn.Embedding(8,1)\nparams = list(ebdd1.parameters()) + list(ebdd2.parameters())  + list(b1.parameters()) + list(b2.parameters())\noptimizr = torch.optim.Adam(params)\nsig = torch.nn.Sigmoid()\n#----#\nfor epoc in range(5000):\n    #step1\n    W_features = ebdd1(x1) \n    M_features = ebdd2(x2) \n    W_bias = b1(x1)\n    M_bais = b2(x2)\n    yhat = sig((W_features * M_features).sum(axis=1).reshape(-1,1) + W_bias + M_bais)*5\n    #step2\n    loss = loss_fn(yhat,y)\n    #step3\n    loss.backward()\n    #step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\ny[:5], yhat[:5]\n\n(tensor([[4.0200],\n         [3.4500],\n         [3.4200],\n         [0.8400],\n         [1.1200]]),\n tensor([[3.9809],\n         [3.4865],\n         [3.4730],\n         [0.8163],\n         [0.9715]], grad_fn=&lt;SliceBackward0&gt;))"
  },
  {
    "objectID": "posts/11wk-1.html#a.-사용자정의-네트워크-사용법",
    "href": "posts/11wk-1.html#a.-사용자정의-네트워크-사용법",
    "title": "11wk-1: (추천시스템) – Embedding 레이어, 사용자정의 네트워크, MF-based 추천시스템을 넘어서",
    "section": "A. 사용자정의 네트워크 사용법",
    "text": "A. 사용자정의 네트워크 사용법\n# 예비학습1: net(X)와 사실 net.forward(X)는 같다.\n🗣️(\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\n\n\nX = torch.randn(5,1)\nnet(X)\n\ntensor([[0.5705],\n        [0.7858],\n        [0.8796],\n        [0.8451],\n        [0.8138]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\nnet.forward(X)\n\ntensor([[0.5705],\n        [0.7858],\n        [0.8796],\n        [0.8451],\n        [0.8138]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\nnet(X)과 net.forward(X)는 동일\nnet.forward(X)는 function이어서 이를 통해 nex(X)를 다시 정의할 수 있음\n\n\ndef func(x):\n    return \"메롱\"\n\n\nfunc(33)\n\n'메롱'\n\n\n\nfunc('sss')\n\n'메롱'\n\n\n\nnet.forward = func\n\n\nnet.forward(X)\n\n'메롱'\n\n\n\nnet(X)\n\n'메롱'\n\n\n)🗣️\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nX = torch.randn(5,1)\n\n\nnet(X)\n#net.forward(X)\n\ntensor([[0.3340],\n        [0.4480],\n        [0.3143],\n        [0.2375],\n        [0.2066]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n그래서 net.forward를 재정의하면 net(X)의 기능을 재정의 할 수 있다.\n\ndef func(x):\n    return \"메롱\"\n\n\nnet.forward = func \n\n\nnet.forward(X) \n\n'메롱'\n\n\n\nnet(X)\n\n'메롱'\n\n\n#\n# 예비학습2: torch.nn.Module을 상속받아서 네트워크를 만들면 (= “class XXX(torch.nn.Module):” 와 같은 방식으로 클래스를 선언하면) 약속된 아키텍처를 가진 네트워크를 찍어내는 함수를 만들 수 있다.\n\n\n\n\n\n\nNote\n\n\n\n클래스의 기초가 부족한 분들은 아래의 링크에서\n\nhttps://guebin.github.io/PP2024/\n\n11wk-2, 12wk-2, 13wk-2, 14wk-2 에 대한내용을 학습하시길 바랍니다.\n\n\n\n🗣️ 이전에 만든 사용자 정의 레이어와 방식 비슷\n\n(예제1) – torch.nn.Module의 상속을 이용하여 아래와 동일한 아키텍처를 가지는 네트워크를 설계하라.\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True), # linr1\n    torch.nn.Sigmoid(),#sig\n    torch.nn.Linear(in_features=1,out_features=1,bias=False) # linr2 \n)\n\n\nx = torch.tensor([[1.0]])\n\n\nnet(x)\n\ntensor([[-0.5737]], grad_fn=&lt;MmBackward0&gt;)\n\n\n(풀이)\n🗣️(\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True), # linr1\n    torch.nn.Sigmoid(),#sig\n    torch.nn.Linear(in_features=1,out_features=1,bias=False) # linr2 \n)\n\n\nx = torch.tensor([[1.0]])\n\n\nnet(x)\n\ntensor([[-0.3695]], grad_fn=&lt;MmBackward0&gt;)\n\n\n\nclass MyNet1(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linr1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.sig = torch.nn.Sigmoid()\n        self.linr2 = torch.nn.Linear(in_features=1,out_features=1,bias=False)\n    def forward(self,x):\n        #net(x): x --&gt; linr --&gt; sig --&gt; linr\n        out = self.linr2(self.sig(self.linr1(x))) # 구분을 위해 linr1 linr2\n        return out\n\n\nnet = MyNet1()\n\n\nnet(x) # 값은 달라지지만 동일한 기능을 수행\n\ntensor([[-0.0929]], grad_fn=&lt;MmBackward0&gt;)\n\n\n)🗣️\n\nclass MyNet1(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linr1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.sig = torch.nn.Sigmoid()\n        self.linr2 = torch.nn.Linear(in_features=1,out_features=1,bias=False)\n    def forward(self,x):\n        out = self.linr2(self.sig(self.linr1(x)))\n        return out \n\n(예시2) – torch.nn.Module의 상속을 이용하여 아래와 동일한 동작을 하는 네트워크를 설계하라.\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=1,out_features=1,bias=False)\n)\n\n(풀이)\n\nclass MyNet2(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linr1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.relu = torch.nn.ReLU()\n        self.linr2 = torch.nn.Linear(in_features=1,out_features=1,bias=False)\n    def forward(self,X):\n        netout = self.linr2(self.relu(self.linr1(x)))\n        return netout\n\n사용자 정의 네트워크를 만드는 방법\nstep1: 아래와 코드를 복사하여 틀을 만든다. (이건 무조건 고정임, XXXX 자리는 원하는 이름을 넣는다)\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 netout을 구할때 사용할 레이어를 정의 \n        \n        ## 정의 끝\n    def forward(self,X):\n        ## netout을 어떻게 구할것인지 정의 \n        \n        ## 정의 끝\n        return netout\n\nforward의 입력: X는 net(X)에 사용하는 X임\nforward의 출력: netout은 net.forward(X) 함수의 리턴값임\n당연히 X/netout은 다른 변수로 써도 무방 (예를들면 input/output 이라든지)\n\nstep2: def __init__(self):에 yhat을 구하기 위해 필요한 재료를 레이어를 정의하고 이름을 붙인다. 이름은 항상 self.xxx 와 같은 식으로 정의한다.\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 netout을 구할때 사용할 레이어를 정의 \n        self.xxx1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.xxx2 = torch.nn.Sigmoid()\n        self.xxx3 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        ## 정의 끝\n    def forward(self,X):\n        ## netout을 어떻게 구할것인지 정의 \n        \n        ## 정의 끝\n        return netout\nstep3: def forward:에 “X –&gt; netout” 으로 가는 과정을 묘사한 코드를 작성하고 netout을 리턴하도록 한다.\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 netout 구할때 사용할 레이어를 정의 \n        self.xxx1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.xxx2 = torch.nn.Sigmoid()\n        self.xxx3 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        ## 정의 끝\n    def forward(self,X):\n        ## netout을 어떻게 구할것인지 정의 \n        u = self.xxx1(X) \n        v = self.xxx2(u)\n        netout = self.xxx3(v) \n        ## 정의 끝\n        return netout\n#\n# 실습(2025-중간고사 4번): 자유 낙하 운동이란 어떤 물체가 일정한 높이에서 떨어져 지면에 도달하기 까지 걸리는 시간을 다루는 물리학 개념이다. 다음은 물리학의 자유 낙하 운동에서 착안하여 생성한 데이터이다.\n\ntorch.manual_seed(43052)\nh = torch.rand(100)*100\nh,_ = h.sort()\nh = h.reshape(100,1)\nt = torch.sqrt(2*h/9.8) + torch.randn([100,1])*0.1\n\n여기에서 \\(h\\)는 낙하전의 높이(단위: m), \\(t\\)는 해당높이에서 물치가 지면에 도달하기 까지 걸리는 시간(단위:초)을 의미한다. 예를 들어 아래의 자료는 \\(h=99.3920, t=4.4583\\)를 의미하는데\n\nh[-1], t[-1]\n\n(tensor([99.3920]), tensor([4.4583]))\n\n\n이것은 높이 \\(99.3920\\)m에서 낙하한 물체가 약 \\(4.4583\\)초만에 지면에 도달했음을 의미한다. 아래의 그림은 \\(x\\)축에 \\(h\\), \\(y\\)축에 \\(t\\)를 두고 해당 데이터를 산점도로 시각화 한 것이다.\n\nplt.plot(h,t,'o',alpha=0.5)\nplt.xlabel('Height (m)')\nplt.ylabel('Time to fall (sec)')\nplt.title('Free Fall Time vs Height')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n그래프를 보면 높이가 높을 수록 낙하시간도 길어지는 경향이 관찰된다. 다만 동일한 높이라 하더라도 낙하시간이 조금씩 차이나는 경우가 있는데, 이는 사람이 시간측정을 수동으로 하며 발생하는 실험오차 때문이다. 이러한 오차에도 불구하고 \\(h\\)와 \\(t\\)사이에는 일정한 규칙이 존재하는듯 하다. 물리학과 교수님께 자문을 요청한 결과 자유낙하에 걸리는 시간은 \\(\\sqrt{h}\\)에 비례함을 알 수 있었고 이를 근거로 아래와 같은 모형을 설계하였다.\n\\[t_i = \\beta_0 + \\beta_1 \\sqrt{h_i}+\\epsilon_i, \\quad \\epsilon_i \\sim {\\cal N}(0,\\sigma^2)\\]\n위의 모형을 활용하여 높이 \\(h\\)로부터 낙하시간 \\(t\\)를 예측하는 신경망 모델을 설계하고 학습하라. 학습한 신경망 모델을 활용하여 높이 40m,60m,80m 에서 물체를 자유낙하 시켰을때 지면에 도달하기까지 걸리는 시간을 각각 예측하라.\n(풀이)\n🗣️(\n\nh –&gt; sqrt –&gt; linr –&gt; t_hat\n\n\nclass FreeFallNet(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linr = torch.nn.Linear(1,1)\n    def forward(self,h):\n        netout = self.linr(torch.sqrt(h))\n        return netout\n\n\nnet = FreeFallNet()\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(2000):\n    #1\n    netout = net(h)\n    #2\n    loss = loss_fn(netout,t)\n    #3\n    loss.backward()\n    #4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(h,t,'o',alpha=0.5)\nplt.xlabel('Height (m)')\nplt.ylabel('Time to fall (sec)')\nplt.title('Free Fall Time vs Height')\nplt.plot(h,net(h).data,'--')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nnet = FreeFallNet()\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(10000):\n    #1\n    netout = net(h)\n    #2\n    loss = loss_fn(netout,t)\n    #3\n    loss.backward()\n    #4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(h,t,'o',alpha=0.5)\nplt.xlabel('Height (m)')\nplt.ylabel('Time to fall (sec)')\nplt.title('Free Fall Time vs Height')\nplt.plot(h,net(h).data,'--')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n코드가 깔끔함\n\n\nhh = torch.tensor([20,30,40,50,60,70]).reshape(6,1)\nnet(hh)\n\ntensor([[2.0253],\n        [2.4746],\n        [2.8534],\n        [3.1872],\n        [3.4889],\n        [3.7664]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n# 지난 시간 코드 (xx 추가됨)\nhh = torch.tensor([40,60,80]).float().reshape(3,1)\nxx = torch.sqrt(hh)\nnet(xx)\n)🗣️\n\nclass FreeFallNet(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linr = torch.nn.Linear(1,1)\n    def forward(self,h):\n        netout = self.linr(torch.sqrt(h))\n        return netout    \n\n\nnet = FreeFallNet()\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(10000):\n    #1\n    netout = net(h)\n    #2\n    loss = loss_fn(netout,t)\n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(h,t,'o',alpha=0.5)\nplt.xlabel('Height (m)')\nplt.ylabel('Time to fall (sec)')\nplt.title('Free Fall Time vs Height')\nplt.plot(h,net(h).data,'--')\n\n\n\n\n\n\n\n\n\nhh = torch.tensor([20,30,40,50,60,70]).reshape(6,1)\nnet(hh)\n\ntensor([[2.0253],\n        [2.4746],\n        [2.8534],\n        [3.1872],\n        [3.4889],\n        [3.7664]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n#"
  },
  {
    "objectID": "posts/11wk-1.html#b.-mf-based-추천시스템-재설계-1",
    "href": "posts/11wk-1.html#b.-mf-based-추천시스템-재설계-1",
    "title": "11wk-1: (추천시스템) – Embedding 레이어, 사용자정의 네트워크, MF-based 추천시스템을 넘어서",
    "section": "B. MF-based 추천시스템 재설계",
    "text": "B. MF-based 추천시스템 재설계\n아래의 자료를 활용하여 추천시스템을 설계하고자한다.\n\ndf_view = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2024/main/posts/solo.csv',index_col=0)\ndf_view\n\n\n\n\n\n\n\n\n영식(IN)\n영철(IN)\n영호(IS)\n광수(IS)\n상철(EN)\n영수(EN)\n규빈(ES)\n다호(ES)\n\n\n\n\n옥순(IN)\nNaN\n4.02\n3.45\n3.42\n0.84\n1.12\n0.43\n0.49\n\n\n영자(IN)\n3.93\n3.99\n3.63\n3.43\n0.98\n0.96\n0.52\nNaN\n\n\n정숙(IS)\n3.52\n3.42\n4.05\n4.06\n0.39\nNaN\n0.93\n0.99\n\n\n영숙(IS)\n3.43\n3.57\nNaN\n3.95\n0.56\n0.52\n0.89\n0.89\n\n\n순자(EN)\n1.12\nNaN\n0.59\n0.43\n4.01\n4.16\n3.52\n3.38\n\n\n현숙(EN)\n0.94\n1.05\n0.32\n0.45\n4.02\n3.78\nNaN\n3.54\n\n\n서연(ES)\n0.51\n0.56\n0.88\n0.89\n3.50\n3.64\n4.04\n4.10\n\n\n보람(ES)\n0.48\n0.51\n1.03\nNaN\n3.52\n4.00\n3.82\nNaN\n\n\n하니(I)\n4.85\n4.82\nNaN\n4.98\n4.53\n4.39\n4.45\n4.52\n\n\n\n\n\n\n\n사용자정의 네트워크를 이용하여 MF-based 추천시스템을 설계하라.\n(풀이1) – net(x1,x2)\n🗣️(\n\n이전 풀이가 너무 복잡하여 yhat을 다음과 같이 바꾸고 싶음\n\n#df_view\nloss_fn = torch.nn.MSELoss() \nebdd1 = torch.nn.Embedding(9,2)\nebdd2 = torch.nn.Embedding(8,2)\nb1 = torch.nn.Embedding(9,1)\nb2 = torch.nn.Embedding(8,1)\nparams = list(ebdd1.parameters()) + list(ebdd2.parameters())  + list(b1.parameters()) + list(b2.parameters())\noptimizr = torch.optim.Adam(params)\nsig = torch.nn.Sigmoid()\n#----#\nfor epoc in range(5000):\n    #step1\n    # W_features = ebdd1(x1) \n    # M_features = ebdd2(x2) \n    # W_bias = b1(x1)\n    # M_bais = b2(x2)\n    # yhat = sig((W_features * M_features).sum(axis=1).reshape(-1,1) + W_bias + M_bais)*5\n    yhat = net(x1,x2)\n    #step2\n    loss = loss_fn(yhat,y)\n    #step3\n    loss.backward()\n    #step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n이에 맞춰 network를 설계하면\n\n\n#df_view\nclass MFbased1(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.ebdd1 = torch.nn.Embedding(9,2)\n        self.ebdd2 = torch.nn.Embedding(8,2)\n        self.b1 = torch.nn.Embedding(9,1)\n        self.b2 = torch.nn.Embedding(8,1)\n        self.sig = torch.nn.Sigmoid()\n    def forward(self,x1,x2):\n        W_features = self.ebdd1(x1) \n        M_features = self.ebdd2(x2) \n        W_bias = self.b1(x1)\n        M_bais = self.b2(x2)\n        yhat = self.sig((W_features * M_features).sum(axis=1).reshape(-1,1) + W_bias + M_bais)*5\n        return yhat\n\nnet = MFbased1()\nloss_fn = torch.nn.MSELoss() \n# params = list(ebdd1.parameters()) + list(ebdd2.parameters())  + list(b1.parameters()) + list(b2.parameters())\n# 이렇게 net을 선언하면 net.parameters()와 동일\noptimizr = torch.optim.Adam(net.parameters())\n#----#\nfor epoc in range(10000):\n    #step1\n    yhat = net(x1,x2)\n    #step2\n    loss = loss_fn(yhat,y)\n    #step3\n    loss.backward()\n    #step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\ny[:5], yhat[:5] # 잘 적합됨\n\n(tensor([[4.0200],\n         [3.4500],\n         [3.4200],\n         [0.8400],\n         [1.1200]]),\n tensor([[4.0793],\n         [3.4667],\n         [3.3657],\n         [0.9102],\n         [0.9532]], grad_fn=&lt;SliceBackward0&gt;))\n\n\n\n# list(net.parameters()) # parameter == 이전 params 확인 코드\n\n)🗣️\n\n#df_view\nclass MFbased1(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.ebdd1 = torch.nn.Embedding(9,2)\n        self.ebdd2 = torch.nn.Embedding(8,2)\n        self.b1 = torch.nn.Embedding(9,1)\n        self.b2 = torch.nn.Embedding(8,1)        \n        self.sig = torch.nn.Sigmoid()\n    def forward(self,x1,x2):\n        W_features = self.ebdd1(x1) \n        M_features = self.ebdd2(x2) \n        W_bias = self.b1(x1)\n        M_bais = self.b2(x2)\n        yhat = self.sig((W_features * M_features).sum(axis=1).reshape(-1,1) + W_bias + M_bais)*5        \n        return yhat\nnet = MFbased1()\nloss_fn = torch.nn.MSELoss() \noptimizr = torch.optim.Adam(net.parameters())\n#----#\nfor epoc in range(10000):\n    #step1\n    yhat = net(x1,x2)\n    #step2\n    loss = loss_fn(yhat,y)\n    #step3\n    loss.backward()\n    #step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\ny[:5], yhat[:5]\n\n(tensor([[4.0200],\n         [3.4500],\n         [3.4200],\n         [0.8400],\n         [1.1200]]),\n tensor([[4.0800],\n         [3.4664],\n         [3.3650],\n         [0.9111],\n         [0.9538]], grad_fn=&lt;SliceBackward0&gt;))\n\n\n(풀이2) – net(X)\n🗣️(\n\nx1, x2\n\n(tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3,\n         3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6,\n         6, 6, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8]),\n tensor([1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 6, 7, 0, 1, 3,\n         4, 5, 6, 7, 0, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 7, 0, 1, 2, 3, 4, 5,\n         6, 7, 0, 1, 2, 4, 5, 6, 0, 1, 3, 4, 5, 6, 7]))\n\n\n\nX = torch.stack([x1,x2],axis=1) \n\n\nclass MFbased2(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.ebdd1 = torch.nn.Embedding(9,2)\n        self.ebdd2 = torch.nn.Embedding(8,2)\n        self.b1 = torch.nn.Embedding(9,1)\n        self.b2 = torch.nn.Embedding(8,1)        \n        self.sig = torch.nn.Sigmoid()\n    def forward(self,X):\n        x1 = X[:,0] # 분리\n        x2 = X[:,1]\n        W_features = self.ebdd1(x1) \n        M_features = self.ebdd2(x2) \n        W_bias = self.b1(x1)\n        M_bais = self.b2(x2)\n        yhat = self.sig((W_features * M_features).sum(axis=1).reshape(-1,1) + W_bias + M_bais)*5        \n        return yhat\nnet = MFbased2()\nloss_fn = torch.nn.MSELoss() \noptimizr = torch.optim.Adam(net.parameters())\n#----#\nfor epoc in range(10000):\n    #step1\n    yhat = net(X)\n    #step2\n    loss = loss_fn(yhat,y)\n    #step3\n    loss.backward()\n    #step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\ny[:5], yhat[:5] # 잘 적합됨\n\n(tensor([[4.0200],\n         [3.4500],\n         [3.4200],\n         [0.8400],\n         [1.1200]]),\n tensor([[4.0800],\n         [3.4664],\n         [3.3651],\n         [0.9111],\n         [0.9538]], grad_fn=&lt;SliceBackward0&gt;))\n\n\n\n사용자 정의 네트워크를 이용하면 지저분한 부분을 위에(class) 몰아넣고 아래는 깔끔하게 정리할 수 있음\n\n)🗣️\n\nX = torch.stack([x1,x2],axis=1) \n\n\nclass MFbased2(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.ebdd1 = torch.nn.Embedding(9,2)\n        self.ebdd2 = torch.nn.Embedding(8,2)\n        self.b1 = torch.nn.Embedding(9,1)\n        self.b2 = torch.nn.Embedding(8,1)        \n        self.sig = torch.nn.Sigmoid()\n    def forward(self,X):\n        x1 = X[:,0]\n        x2 = X[:,1]\n        W_features = self.ebdd1(x1) \n        M_features = self.ebdd2(x2) \n        W_bias = self.b1(x1)\n        M_bais = self.b2(x2)\n        yhat = self.sig((W_features * M_features).sum(axis=1).reshape(-1,1) + W_bias + M_bais)*5        \n        return yhat\nnet = MFbased2()\nloss_fn = torch.nn.MSELoss() \noptimizr = torch.optim.Adam(net.parameters())\n#----#\nfor epoc in range(10000):\n    #step1\n    yhat = net(X)\n    #step2\n    loss = loss_fn(yhat,y)\n    #step3\n    loss.backward()\n    #step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\ny[:5], yhat[:5]\n\n(tensor([[4.0200],\n         [3.4500],\n         [3.4200],\n         [0.8400],\n         [1.1200]]),\n tensor([[4.0800],\n         [3.4664],\n         [3.3651],\n         [0.9111],\n         [0.9538]], grad_fn=&lt;SliceBackward0&gt;))"
  },
  {
    "objectID": "posts/11wk-1.html#a.-nn-based-방식",
    "href": "posts/11wk-1.html#a.-nn-based-방식",
    "title": "11wk-1: (추천시스템) – Embedding 레이어, 사용자정의 네트워크, MF-based 추천시스템을 넘어서",
    "section": "A. NN-based 방식",
    "text": "A. NN-based 방식\n아래의 자료를 활용하여 추천시스템을 설계하고자한다.\n\ndf_view = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2025/main/posts/iamsolo.csv',index_col=0)\ndf_view\n\n\n\n\n\n\n\n\n영식(IN)\n영철(IN)\n영호(IS)\n광수(IS)\n상철(EN)\n영수(EN)\n규빈(ES)\n다호(ES)\n\n\n\n\n옥순(IN)\nNaN\n4.02\n3.45\n3.42\n0.84\n1.12\n0.43\n0.49\n\n\n영자(IN)\n3.93\n3.99\n3.63\n3.43\n0.98\n0.96\n0.52\nNaN\n\n\n정숙(IS)\n3.52\n3.42\n4.05\n4.06\n0.39\nNaN\n0.93\n0.99\n\n\n영숙(IS)\n3.43\n3.57\nNaN\n3.95\n0.56\n0.52\n0.89\n0.89\n\n\n순자(EN)\n1.12\nNaN\n0.59\n0.43\n4.01\n4.16\n3.52\n3.38\n\n\n현숙(EN)\n0.94\n1.05\n0.32\n0.45\n4.02\n3.78\nNaN\n3.54\n\n\n서연(ES)\n0.51\n0.56\n0.88\n0.89\n3.50\n3.64\n4.04\n4.10\n\n\n보람(ES)\n0.48\n0.51\n1.03\nNaN\n3.52\n4.00\n3.82\nNaN\n\n\n하니(I)\n4.85\n4.82\nNaN\n4.98\n4.53\n4.39\n4.45\n4.52\n\n\n\n\n\n\n\n\n#df_view\ndf_train = df_view.stack().reset_index().set_axis(['여성출연자','남성출연자','궁합점수'],axis=1)\n여성인덱스 = {'옥순(IN)':0, '영자(IN)':1, '정숙(IS)':2, '영숙(IS)':3, '순자(EN)':4, '현숙(EN)':5, '서연(ES)':6, '보람(ES)':7, '하니(I)':8}\n남성인덱스 = {'영식(IN)':0, '영철(IN)':1, '영호(IS)':2, '광수(IS)':3, '상철(EN)':4, '영수(EN)':5, '규빈(ES)':6, '다호(ES)':7}\nx1 = torch.tensor(df_train.여성출연자.map(여성인덱스))\nx2 = torch.tensor(df_train.남성출연자.map(남성인덱스))\ny = torch.tensor(df_train.궁합점수).reshape(-1,1).float()\n\nNN-based 추천시스템을 설계하라.\n(풀이1) – 실패\n🗣️(\n\nclass NNbased1(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.ebdd1 = torch.nn.Embedding(9,2)\n        self.ebdd2 = torch.nn.Embedding(8,2)\n        self.b1 = torch.nn.Embedding(9,1)\n        self.b2 = torch.nn.Embedding(8,1)\n        self.sig = torch.nn.Sigmoid()\n        self.mlp = torch.nn.Sequential(\n            torch.nn.Linear(6,1),\n            torch.nn.Sigmoid()\n        )\n    def forward(self,x1,x2):\n        W_features = self.ebdd1(x1) \n        M_features = self.ebdd2(x2) \n        W_bias = self.b1(x1)\n        M_bias = self.b2(x2)\n        # yhat = self.sig((W_features * M_features).sum(axis=1).reshape(-1,1) + W_bias + M_bais)*5\n        Z = torch.concat([W_features, M_features, W_bias, M_bias], axis=1)\n        # Z ---&gt; yhat (n,6) -&gt; (n,1)\n        yhat = self.mlp(Z) * 5\n        return yhat\n\n\nnet = NNbased1()\nloss_fn = torch.nn.MSELoss() \noptimizr = torch.optim.Adam(net.parameters())\n#----#\nfor epoc in range(5000):\n    #step1\n    yhat = net(x1,x2)\n    #step2\n    loss = loss_fn(yhat,y)\n    #step3\n    loss.backward()\n    #step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat[:5], y[:5] # 전혀 맞지 않음\n\n(tensor([[2.1566],\n         [1.6486],\n         [2.0613],\n         [1.9107],\n         [2.3132]], grad_fn=&lt;SliceBackward0&gt;),\n tensor([[4.0200],\n         [3.4500],\n         [3.4200],\n         [0.8400],\n         [1.1200]]))\n\n\n\n모델이 너무 단순해서?\n\n)🗣️\n\nclass NNbased1(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        #--#\n        self.ebdd1 = torch.nn.Embedding(9,2)\n        self.ebdd2 = torch.nn.Embedding(8,2)\n        self.b1 = torch.nn.Embedding(9,1)\n        self.b2 = torch.nn.Embedding(8,1)\n        self.sig = torch.nn.Sigmoid()\n        self.mlp = torch.nn.Sequential(\n            torch.nn.Linear(6,1),\n            torch.nn.Sigmoid()\n        )\n    def forward(self,x1,x2):\n        W_feature = self.ebdd1(x1)\n        W_bias = self.b1(x1)\n        M_feature = self.ebdd2(x2)\n        M_bias = self.b2(x2)\n        #yhat = sig((W_feature * M_feature).sum(axis=1).reshape(-1,1) + W_bias + M_bias ) * 5 \n        Z = torch.concat([W_feature, M_feature, W_bias, M_bias],axis=1)\n        yhat = self.mlp(Z) * 5 \n        return yhat\n\n\nnet = NNbased1()\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.1) # 이게 편해요!!\n#--# \nfor epoc in range(5000):\n    # 1\n    yhat = net(x1,x2) \n    # 2\n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat[:5], y[:5]\n\n(tensor([[2.1563],\n         [1.6488],\n         [2.0608],\n         [1.9119],\n         [2.3126]], grad_fn=&lt;SliceBackward0&gt;),\n tensor([[4.0200],\n         [3.4500],\n         [3.4200],\n         [0.8400],\n         [1.1200]]))\n\n\n(풀이2) – 에라 모르겠다 깊은신경망..\n🗣️(\n\nclass NNbased2(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.ebdd1 = torch.nn.Embedding(9,2)\n        self.ebdd2 = torch.nn.Embedding(8,2)\n        self.b1 = torch.nn.Embedding(9,1)\n        self.b2 = torch.nn.Embedding(8,1)\n        self.sig = torch.nn.Sigmoid()\n        self.mlp = torch.nn.Sequential(\n            torch.nn.Linear(6,15),\n            torch.nn.ReLU(),\n            torch.nn.Linear(15,15),\n            torch.nn.ReLU(),\n            torch.nn.Linear(15,1),\n            torch.nn.Sigmoid()\n        )\n    def forward(self,x1,x2):\n        W_features = self.ebdd1(x1) \n        M_features = self.ebdd2(x2) \n        W_bias = self.b1(x1)\n        M_bias = self.b2(x2)\n        # yhat = self.sig((W_features * M_features).sum(axis=1).reshape(-1,1) + W_bias + M_bais)*5\n        Z = torch.concat([W_features, M_features, W_bias, M_bias], axis=1)\n        # Z ---&gt; yhat (n,6) -&gt; (n,1)\n        yhat = self.mlp(Z) * 5\n        return yhat\n\n\nnet = NNbased2()\nloss_fn = torch.nn.MSELoss() \noptimizr = torch.optim.Adam(net.parameters())\n#----#\nfor epoc in range(5000):\n    #step1\n    yhat = net(x1,x2)\n    #step2\n    loss = loss_fn(yhat,y)\n    #step3\n    loss.backward()\n    #step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat[:5], y[:5] # 너무 잘 맞는 느낌 (overfitting 의심)\n\n(tensor([[4.0179],\n         [3.4466],\n         [3.4170],\n         [0.8365],\n         [1.1180]], grad_fn=&lt;SliceBackward0&gt;),\n tensor([[4.0200],\n         [3.4500],\n         [3.4200],\n         [0.8400],\n         [1.1200]]))\n\n\n(옥순-영식), (영자-다호), (하니-영호) 를 예측해보자.\n\ndf_view\n\n\n\n\n\n\n\n\n영식(IN)\n영철(IN)\n영호(IS)\n광수(IS)\n상철(EN)\n영수(EN)\n규빈(ES)\n다호(ES)\n\n\n\n\n옥순(IN)\nNaN\n4.02\n3.45\n3.42\n0.84\n1.12\n0.43\n0.49\n\n\n영자(IN)\n3.93\n3.99\n3.63\n3.43\n0.98\n0.96\n0.52\nNaN\n\n\n정숙(IS)\n3.52\n3.42\n4.05\n4.06\n0.39\nNaN\n0.93\n0.99\n\n\n영숙(IS)\n3.43\n3.57\nNaN\n3.95\n0.56\n0.52\n0.89\n0.89\n\n\n순자(EN)\n1.12\nNaN\n0.59\n0.43\n4.01\n4.16\n3.52\n3.38\n\n\n현숙(EN)\n0.94\n1.05\n0.32\n0.45\n4.02\n3.78\nNaN\n3.54\n\n\n서연(ES)\n0.51\n0.56\n0.88\n0.89\n3.50\n3.64\n4.04\n4.10\n\n\n보람(ES)\n0.48\n0.51\n1.03\nNaN\n3.52\n4.00\n3.82\nNaN\n\n\n하니(I)\n4.85\n4.82\nNaN\n4.98\n4.53\n4.39\n4.45\n4.52\n\n\n\n\n\n\n\n{'옥순(IN)': 0, '영자(IN)': 1, '정숙(IS)': 2, '영숙(IS)': 3, '순자(EN)': 4,\n '현숙(EN)': 5, '서연(ES)': 6, '보람(ES)': 7, '하니(I)': 8}\n\n{'영식(IN)': 0, '영철(IN)': 1, '영호(IS)': 2, '광수(IS)': 3, '상철(EN)': 4,\n '영수(EN)': 5, '규빈(ES)': 6, '다호(ES)': 7}\n\nxx1 = torch.tensor([0,1,8])\nxx2 = torch.tensor([0,7,2])\n\n\nnet(xx1,xx2)\n\ntensor([[3.3455],\n        [1.3572],\n        [4.9131]], grad_fn=&lt;MulBackward0&gt;)\n\n\n\n4, 0.5, 5근처 정도가 맞는 것 같음 (overfitting)\nepoch을 2,000으로 줄이면\n\n\nnet = NNbased2()\nloss_fn = torch.nn.MSELoss() \noptimizr = torch.optim.Adam(net.parameters())\n#----#\nfor epoc in range(2000):\n    #step1\n    yhat = net(x1,x2)\n    #step2\n    loss = loss_fn(yhat,y)\n    #step3\n    loss.backward()\n    #step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat[:5], y[:5]\n\n(tensor([[4.0040],\n         [3.4680],\n         [3.4130],\n         [0.8093],\n         [1.1156]], grad_fn=&lt;SliceBackward0&gt;),\n tensor([[4.0200],\n         [3.4500],\n         [3.4200],\n         [0.8400],\n         [1.1200]]))\n\n\n\nnet(xx1,xx2) # 비슷함\n\ntensor([[3.8184],\n        [0.5261],\n        [4.9015]], grad_fn=&lt;MulBackward0&gt;)\n\n\n\n✍️ 강의 영상(overfitting)과 다르게 잘 되긴 하였음\n강의 영상처럼 모형 단순화\n\n\nclass NNbased2(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.ebdd1 = torch.nn.Embedding(9,2)\n        self.ebdd2 = torch.nn.Embedding(8,2)\n        self.b1 = torch.nn.Embedding(9,1)\n        self.b2 = torch.nn.Embedding(8,1)\n        self.sig = torch.nn.Sigmoid()\n        self.mlp = torch.nn.Sequential(\n            torch.nn.Linear(6,15),\n            torch.nn.ReLU(),\n            torch.nn.Linear(15,1),\n            torch.nn.Sigmoid()\n        )\n    def forward(self,x1,x2):\n        W_features = self.ebdd1(x1) \n        M_features = self.ebdd2(x2) \n        W_bias = self.b1(x1)\n        M_bias = self.b2(x2)\n        # yhat = self.sig((W_features * M_features).sum(axis=1).reshape(-1,1) + W_bias + M_bais)*5\n        Z = torch.concat([W_features, M_features, W_bias, M_bias], axis=1)\n        # Z ---&gt; yhat (n,6) -&gt; (n,1)\n        yhat = self.mlp(Z) * 5\n        return yhat\n\n\nnet = NNbased2()\nloss_fn = torch.nn.MSELoss() \noptimizr = torch.optim.Adam(net.parameters())\n#----#\nfor epoc in range(2000):\n    #step1\n    yhat = net(x1,x2)\n    #step2\n    loss = loss_fn(yhat,y)\n    #step3\n    loss.backward()\n    #step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat[:5], y[:5]\n\n(tensor([[3.6244],\n         [3.5508],\n         [3.5255],\n         [0.7445],\n         [1.0485]], grad_fn=&lt;SliceBackward0&gt;),\n tensor([[4.0200],\n         [3.4500],\n         [3.4200],\n         [0.8400],\n         [1.1200]]))\n\n\n\nnet(xx1,xx2)\n\ntensor([[3.5422],\n        [0.9444],\n        [4.9080]], grad_fn=&lt;MulBackward0&gt;)\n\n\n\n✍️ 이번에는 강의 영상과 다르게 잘 안됨\n밑의 강의 노트 코드: 랜덤으로 해도 안정적으로 결과가 잘 나옴\nepoch을 줄이기만 하여도 overfitting 방지 효과가 있음 (early stopping)\n\n)🗣️\n\nclass NNbased2(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        #--#\n        self.ebdd1 = torch.nn.Embedding(9,2)\n        self.ebdd2 = torch.nn.Embedding(8,2)\n        self.b1 = torch.nn.Embedding(9,1)\n        self.b2 = torch.nn.Embedding(8,1)\n        self.sig = torch.nn.Sigmoid()\n        self.mlp = torch.nn.Sequential(\n            torch.nn.Linear(6,15),\n            torch.nn.ReLU(),\n            torch.nn.Linear(15,1),\n            torch.nn.Sigmoid()\n        )\n    def forward(self,x1,x2):\n        W_feature = self.ebdd1(x1)\n        W_bias = self.b1(x1)\n        M_feature = self.ebdd2(x2)\n        M_bias = self.b2(x2)\n        #yhat = sig((W_feature * M_feature).sum(axis=1).reshape(-1,1) + W_bias + M_bias ) * 5 \n        Z = torch.concat([W_feature, M_feature, W_bias, M_bias],axis=1)\n        yhat = self.mlp(Z) * 5 \n        return yhat\n\n\nnet = NNbased2()\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.1)\n#--# \nfor epoc in range(3000):\n    # 1\n    yhat = net(x1,x2) \n    # 2\n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat[:10], y[:10]\n\n(tensor([[4.0395],\n         [3.4880],\n         [3.4527],\n         [0.8548],\n         [1.1290],\n         [0.4416],\n         [0.5041],\n         [3.9470],\n         [4.0075],\n         [3.6544]], grad_fn=&lt;SliceBackward0&gt;),\n tensor([[4.0200],\n         [3.4500],\n         [3.4200],\n         [0.8400],\n         [1.1200],\n         [0.4300],\n         [0.4900],\n         [3.9300],\n         [3.9900],\n         [3.6300]]))\n\n\n(옥순-영식), (영자-다호), (하니-영호) 를 예측해보자.\n\ndf_view\n\n\n\n\n\n\n\n\n영식(IN)\n영철(IN)\n영호(IS)\n광수(IS)\n상철(EN)\n영수(EN)\n규빈(ES)\n다호(ES)\n\n\n\n\n옥순(IN)\nNaN\n4.02\n3.45\n3.42\n0.84\n1.12\n0.43\n0.49\n\n\n영자(IN)\n3.93\n3.99\n3.63\n3.43\n0.98\n0.96\n0.52\nNaN\n\n\n정숙(IS)\n3.52\n3.42\n4.05\n4.06\n0.39\nNaN\n0.93\n0.99\n\n\n영숙(IS)\n3.43\n3.57\nNaN\n3.95\n0.56\n0.52\n0.89\n0.89\n\n\n순자(EN)\n1.12\nNaN\n0.59\n0.43\n4.01\n4.16\n3.52\n3.38\n\n\n현숙(EN)\n0.94\n1.05\n0.32\n0.45\n4.02\n3.78\nNaN\n3.54\n\n\n서연(ES)\n0.51\n0.56\n0.88\n0.89\n3.50\n3.64\n4.04\n4.10\n\n\n보람(ES)\n0.48\n0.51\n1.03\nNaN\n3.52\n4.00\n3.82\nNaN\n\n\n하니(I)\n4.85\n4.82\nNaN\n4.98\n4.53\n4.39\n4.45\n4.52\n\n\n\n\n\n\n\n\nxx1 = torch.tensor([0,1,8])\nxx2 = torch.tensor([0,7,2])\n\n\nnet(xx1,xx2)\n\ntensor([[3.9317],\n        [0.6682],\n        [4.9322]], grad_fn=&lt;MulBackward0&gt;)"
  },
  {
    "objectID": "posts/11wk-1.html#b.-ncf-he2017neural",
    "href": "posts/11wk-1.html#b.-ncf-he2017neural",
    "title": "11wk-1: (추천시스템) – Embedding 레이어, 사용자정의 네트워크, MF-based 추천시스템을 넘어서",
    "section": "B. NCF [@he2017neural]",
    "text": "B. NCF [@he2017neural]\n- MF-based와 NN-base를 합친것\n🗣️(\nMF-based    특징1*특징2\nNN-based    [특징1, 특징2] --&gt; nn\n\n# 그림 설명\nUser: 남성 출연자, Item: 여성 출연자로 생각\n\nMF User Vector: 남성 출연자의 특징, MF Item Vector: 여성 출연자의 특징\n(위의 두 특징 벡터 만드는 방식은 embedding layer: one hot encoding + linear)\nMF User Vector MF Item Vector --Element-wise Product--&gt; GMF Layer\nGMF Layer에서 Score로 바로 가면 MF-based\n\nMLP User Vector: 남성 출연자의 특징, MLP Item Vector: 여성 출연자의 특징\nMLP User Vector MLP Item Vector ---concat---&gt;\n    ---ReLU ... Linear Transform ... ReLu---&gt; MLP Layer X\nMLP Layer X에서 바로 Score로 가면 NN-based\n\n요즘 많이 쓰이는 혼합 방식:\nGMF Layer와 MLP Layer X로 적당히 조합하여 하나의 Layer를 만들고\nLinear, Sigmoid 등을 이용하여 마무리\n)🗣️"
  },
  {
    "objectID": "posts/05wk-1.html",
    "href": "posts/05wk-1.html",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "",
    "text": "📘 Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\n📝 🗣️ ✍️ 🔬 ❓"
  },
  {
    "objectID": "posts/05wk-1.html#a.-데이터",
    "href": "posts/05wk-1.html#a.-데이터",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "A. 데이터",
    "text": "A. 데이터\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\neps = torch.randn(100)*0.5\ny = x * 4 + 2.5 + eps\nx,y = x.reshape(-1,1), y.reshape(-1,1)\n\n\nplt.plot(x,y,'o')"
  },
  {
    "objectID": "posts/05wk-1.html#b.-학습",
    "href": "posts/05wk-1.html#b.-학습",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "B. 학습",
    "text": "B. 학습\n\n🗣️ 현재 수준에서는 다음처럼 생각\n\ny가 연속: MSELoss\ny가 0 또는 1만: BCELoss\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.1)\n## \nfor epoc in range(200):\n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = loss_fn(yhat,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n\n\n\nnet[0].weight, net[0].bias\n\n(Parameter containing:\n tensor([[4.0042]], requires_grad=True),\n Parameter containing:\n tensor([2.4459], requires_grad=True))"
  },
  {
    "objectID": "posts/05wk-1.html#c.-예측",
    "href": "posts/05wk-1.html#c.-예측",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "C. 예측",
    "text": "C. 예측\n온도가 0.1 도일때, 커피를 얼마나 팔까?\n\n0.1 * 4.0042 + 2.4459 \n\n2.84632\n\n\n\nxx = torch.tensor([[0.1]])\nnet(xx)\n\ntensor([[2.8463]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n온도가 0.2도일때 커피를 얼마나 팔까?\n\n0.2 * 4.0042 + 2.4459 \n\n3.24674\n\n\n\nxx = torch.tensor([[0.2]])\nnet(xx)\n\ntensor([[3.2467]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n온도가 [0.1, 0.2] 일때의 예측값을 한번에 보고 싶다면?\n\nxx = torch.tensor([[0.1],\n                   [0.2]])\nnet(xx)\n\ntensor([[2.8463],\n        [3.2467]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\n\n\n\n\n\nNote\n\n\n\n이거 질문이 와서 좀 더 자세히 설명하겠습니다. (아직 net(x)의 계산 과정을 선형 변환 관점에서 수식으로 정리하는 데 익숙하지 않으셔서 그럴 수 있습니다. 이건 단순 산수라서 하나씩 차근차근 따라가다 보면 충분히 이해하실 수 있어요. 처음부터 바로 이해되지 않더라도 전혀 걱정하실 필요 없습니다.)\n하나의 값 \\(x\\)에 대하여 \\(net(x)\\)는 아래를 의미하는 연산을 합니다.\nnet(x) = 4.0042 * x + 2.4459  = net[0].weight * x + net[0].bias\n사실 위의 과정을 수식으로 엄밀하게 쓰면 아래와 같습니다.\n\\[net(\\begin{bmatrix} x \\end{bmatrix}) = 2.4459 + \\begin{bmatrix} x \\end{bmatrix} \\begin{bmatrix} 4.0042 \\end{bmatrix}\\]\n여기에서 \\(\\begin{bmatrix} x \\end{bmatrix}\\) 와 \\(\\begin{bmatrix} 4.0042  \\end{bmatrix}\\) 는 모두 \\(1\\times 1\\) matrix를 의미합니다. 만약에 \\(2 \\times 1\\) matrix \\({\\bf x} = \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix}\\)를 네트워크의 입력으로 고려한다면 아래와 같이 됩니다.\n\\[net({\\bf x})=net\\left(\\begin{bmatrix}x_1 \\\\ x_2 \\end{bmatrix}\\right) = 2.4459 + \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} \\begin{bmatrix} 4.0042 \\end{bmatrix} = \\begin{bmatrix} 2.4459 + 4.0042 x_1 \\\\ 2.4459 + 4.0042 x_2\\end{bmatrix} \\]\n따라서 \\({\\bf xx} = \\begin{bmatrix} 0.1 \\\\ 0.2 \\end{bmatrix}\\) 를 네트워크의 입력으로 넣으면\n\\[net({\\bf xx})= \\begin{bmatrix} 2.4459 + 4.0042 \\times 0.1 \\\\ 2.4459 + 4.0042 \\times 0.2\\end{bmatrix}= \\begin{bmatrix} 2.8463 \\\\ 3.2467 \\end{bmatrix}\\]\n와 같이 계산되겠죠."
  },
  {
    "objectID": "posts/05wk-1.html#a.-오버피팅",
    "href": "posts/05wk-1.html#a.-오버피팅",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "A. 오버피팅",
    "text": "A. 오버피팅\n- 오버피팅이란?\n\n위키: In mathematical modeling, overfitting is “the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit to additional data or predict future observations reliably”. (수학적 모델링에서 과적합이란 “어떤 모델이 주어진 데이터에 너무 꼭 맞춰져 있어서, 새로운 데이터나 미래의 결과를 잘 예측하지 못할 수 있는 상태”를 의미한다.)\n제 개념: 데이터를 “데이터 = 언더라잉 + 오차”라고 생각할때 우리가 데이터로부터 적합할 것은 언더라잉인데 오차항을 적합하고 있는 현상."
  },
  {
    "objectID": "posts/05wk-1.html#b.-오버피팅-예시",
    "href": "posts/05wk-1.html#b.-오버피팅-예시",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "B. 오버피팅 예시",
    "text": "B. 오버피팅 예시\n🗣️ 네트워크의 표현력이 너무 좋을 때\n- \\(m\\)이 매우 클때 아래의 네트워크 거의 무엇이든 맞출 수 있다고 보면 된다.\n\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{h}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n- 그런데 종종 맞추지 말아야 할 것들도 맞춘다.\n\\[\\text{model:} \\quad y_i = (0\\times x_i) + \\epsilon_i,~~ \\text{where}~ \\epsilon_i \\sim N(0,0.01^2)\\]\n🗣️ y는 x에 대한 식 X / underlying = 0 / structure: 허구, 오차항이 만들어낸 우연\n\ntorch.manual_seed(5) \nx = torch.linspace(0,1,100).reshape(100,1)\ny = torch.randn(100).reshape(100,1)*0.01\nplt.plot(x,y,'--o',alpha=0.5)\n\n\n\n\n\n\n\n\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(512,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(1000):\n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = loss_fn(yhat,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'--o',alpha=0.5)\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n\n\n🗣️ 0으로 적합하지 않은 것은 다 틀림"
  },
  {
    "objectID": "posts/05wk-1.html#c.-오버피팅이라는-뚜렷한-증거-train-test",
    "href": "posts/05wk-1.html#c.-오버피팅이라는-뚜렷한-증거-train-test",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "C. 오버피팅이라는 뚜렷한 증거! (train / test)",
    "text": "C. 오버피팅이라는 뚜렷한 증거! (train / test)\n🗣️ 0보다 주황색 선이 더 좋은 것 같다는 주장에 대한 반박 (예측)\n- 데이터의 분리하여 보자.\n\ntorch.manual_seed(5) \nx_all = torch.linspace(0,1,100).reshape(100,1)\ny_all = torch.randn(100).reshape(100,1)*0.01\nx,xx = x_all[:80], x_all[80:]\ny,yy = y_all[:80], y_all[80:]\nplt.plot(x,y,'--o',alpha=0.5,label=\"training\")\nplt.plot(xx,yy,'--o',alpha=0.5,label=\"test\")\nplt.legend()\n\n\n\n\n\n\n\n\n- train만 학습\n🗣️ B와 똑같은 조건\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(512,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(1000):\n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = loss_fn(yhat,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- training data로 학습한 net를 training data 에 적용\n\nplt.plot(x_all,y_all,'--o',alpha=0.5,color=\"gray\")\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n\n\n\ntraining에서는 그럭저럭 잘 맞춤\n\n- training data로 학습한 net를 test data 에 적용\n\nplt.plot(x_all,y_all,'--o',alpha=0.5,color=\"gray\")\nplt.plot(x,net(x).data,'--')\nplt.plot(xx,net(xx).data,'--')\n\n\n\n\n\n\n\n\n\ntrain에서는 그럭저럭 잘 맞추는데 test에서는 엉망이다 = overfit\n\n🗣️ random이기 때문에 trend는 없음"
  },
  {
    "objectID": "posts/05wk-1.html#d.-시벤코정리의-올바른-이해",
    "href": "posts/05wk-1.html#d.-시벤코정리의-올바른-이해",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "D. 시벤코정리의 올바른 이해",
    "text": "D. 시벤코정리의 올바른 이해\n\n\n\n\n\n\nNote\n\n\n\n시벤코의 항변(?) [@cybenko1989approximation]\n하나의 은닉층을 가지는 아래와 같은 꼴의 네트워크 \\(net: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\)는\nnet = torch.nn.Sequential(\n    torch.nn.Linear(p,???),\n    torch.nn.Sigmoid(), ## &lt;-- 여기에 렐루를 써도 된다. \n    torch.nn.Linear(???,q)\n)\n모든 보렐가측함수\n\\[f: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\]\n를 원하는 정확도로 “근사”시킬 수 있다. 쉽게 말하면 \\({\\bf X} \\to {\\bf y}\\) 인 어떠한 복잡한 규칙라도 하나의 은닉층을 가진 신경망이 원하는 정확도로 근사시킨다는 의미이다. 그렇지만 이러한 규칙이 네크워크가 학습하지 못했던 자료 (처음 보는 자료, unseen data) \\({\\bf XX}_{m \\times p}\\), \\({\\bf yy}_{m \\times q}\\) 에 대하여서도 올바르게 적용된다라는 보장은 없다. 시벤코는 단지 net가 가지는 표현력의 한계를 수학적으로 밝혔을 뿐이다."
  },
  {
    "objectID": "posts/05wk-1.html#a.-오버피팅의-해결",
    "href": "posts/05wk-1.html#a.-오버피팅의-해결",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "A. 오버피팅의 해결",
    "text": "A. 오버피팅의 해결\n- 오버피팅의 해결책: 드랍아웃\n- 데이터\n\ntorch.manual_seed(5) \nx_all = torch.linspace(0,1,100).reshape(100,1)\ny_all = torch.randn(100).reshape(100,1)*0.01\n#plt.plot(x_all,y_all,'--o',alpha=0.5)\nx,y = x_all[:80], y_all[:80]\nxx,yy = x_all[80:], y_all[80:]\nplt.plot(x,y,'--o',color=\"C0\")\nplt.plot(xx,yy,'--o',color=\"C1\")\n\n\n\n\n\n\n\n\n- 학습\n🗣️ torch.nn.Dropout(0.8) 추가 (학습 시 일부만 사용)\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(0.8),\n    torch.nn.Linear(512,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(1000):\n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = loss_fn(yhat,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과시각화 (잘못된 사용)\n\nplt.plot(x_all,y_all,'--o',alpha=0.5,color=\"gray\")\nplt.plot(x,net(x).data,'--')\nplt.plot(xx,net(xx).data,'--')\n\n\n\n\n\n\n\n\n- 결과시각화 (올바른 사용)\n\nnet.training \n\nTrue\n\n\n🗣️ 평가 모드로 바꾸기\n\nnet.eval()\n\nSequential(\n  (0): Linear(in_features=1, out_features=512, bias=True)\n  (1): ReLU()\n  (2): Dropout(p=0.8, inplace=False)\n  (3): Linear(in_features=512, out_features=1, bias=True)\n)\n\n\n\nnet.training\n\nFalse\n\n\n\nplt.plot(x_all,y_all,'--o',alpha=0.5,color=\"gray\")\nplt.plot(x,net(x).data,'--')\nplt.plot(xx,net(xx).data,'--')\n\n\n\n\n\n\n\n\n🗣️ 어느 정도 0으로 떨어짐, 오버피팅 문제가 완전히 해결되지는 않았지만 어느정도 완화"
  },
  {
    "objectID": "posts/05wk-1.html#b.-드랍아웃-레이어",
    "href": "posts/05wk-1.html#b.-드랍아웃-레이어",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "B. 드랍아웃 레이어",
    "text": "B. 드랍아웃 레이어\n- 드랍아웃의 성질1: 드랍아웃의 계산방식을 이해해보자.\n🗣️ default= 0.5\n\nu = torch.randn(10,2)\nd = torch.nn.Dropout(0.9)\nu\n\ntensor([[ 0.5951,  0.2245],\n        [ 0.8238,  0.5230],\n        [ 0.4772, -1.0465],\n        [-0.6826,  0.4257],\n        [ 0.5113,  0.4130],\n        [-0.3946,  0.0827],\n        [ 1.4149, -1.7569],\n        [ 0.3142, -0.9964],\n        [-0.4613,  0.3530],\n        [-0.2743, -0.5558]])\n\n\n\nd(u)\n\ntensor([[0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, -0.0000],\n        [-0.0000, 0.0000],\n        [5.1128, 4.1303],\n        [-0.0000, 0.0000],\n        [0.0000, -0.0000],\n        [0.0000, -0.0000],\n        [-0.0000, 3.5305],\n        [-0.0000, -0.0000]])\n\n\n\n90%의 드랍아웃: 드랍아웃층의 입력 중 임의로 90%를 골라서 결과를 0으로 만든다. + 그리고 0이 되지않고 살아남은 값들은 10배 만큼 값이 커진다.\n남은값을 10배 키우는 이유? 출력의 평균값을 보정하기 위해서\n\n- 드랍아웃의 성질2: 드랍아웃을 on/off 하는 방법을 이해해보자.\n\nu = torch.randn(10,2)\nu\n\ntensor([[ 0.8395,  1.8825],\n        [-0.0415, -2.3987],\n        [-0.3658, -1.3403],\n        [-1.4066,  0.7178],\n        [-1.0465,  0.9663],\n        [-1.2350,  1.3424],\n        [-1.1903,  0.3955],\n        [ 0.4236, -0.7882],\n        [-0.4348,  0.2669],\n        [-0.9102, -0.3219]])\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Dropout(0.9)\n)\nnet\n\nSequential(\n  (0): Dropout(p=0.9, inplace=False)\n)\n\n\n\nu,net(u)\n\n(tensor([[ 0.8395,  1.8825],\n         [-0.0415, -2.3987],\n         [-0.3658, -1.3403],\n         [-1.4066,  0.7178],\n         [-1.0465,  0.9663],\n         [-1.2350,  1.3424],\n         [-1.1903,  0.3955],\n         [ 0.4236, -0.7882],\n         [-0.4348,  0.2669],\n         [-0.9102, -0.3219]]),\n tensor([[  0.0000,   0.0000],\n         [ -0.0000,  -0.0000],\n         [ -0.0000,  -0.0000],\n         [-14.0662,   0.0000],\n         [ -0.0000,   0.0000],\n         [-12.3497,   0.0000],\n         [ -0.0000,   0.0000],\n         [  4.2361,  -0.0000],\n         [ -0.0000,   0.0000],\n         [ -0.0000,  -3.2190]]))\n\n\n🗣️ 매번 어떤 노드가 죽을지 모름 (다 0이 되기도 함)\n❓ 비율? 확률?\n\nnet.training\n\nTrue\n\n\n\nnet.eval() # 드랍아웃이 무력화\n\nSequential(\n  (0): Dropout(p=0.9, inplace=False)\n)\n\n\n\nu,net(u)\n\n(tensor([[ 0.8395,  1.8825],\n         [-0.0415, -2.3987],\n         [-0.3658, -1.3403],\n         [-1.4066,  0.7178],\n         [-1.0465,  0.9663],\n         [-1.2350,  1.3424],\n         [-1.1903,  0.3955],\n         [ 0.4236, -0.7882],\n         [-0.4348,  0.2669],\n         [-0.9102, -0.3219]]),\n tensor([[ 0.8395,  1.8825],\n         [-0.0415, -2.3987],\n         [-0.3658, -1.3403],\n         [-1.4066,  0.7178],\n         [-1.0465,  0.9663],\n         [-1.2350,  1.3424],\n         [-1.1903,  0.3955],\n         [ 0.4236, -0.7882],\n         [-0.4348,  0.2669],\n         [-0.9102, -0.3219]]))\n\n\n- 드랍아웃레이어 정리\n\n계산: (1) 입력의 일부를 임의로 0으로 만드는 역할 (2) 0이 안된것들은 스칼라배하여 드랍아웃을 통과한 모든 숫자들의 총합이 대체로 일정하게 되도록 조정\non/off: 학습시에는 dropout on / 학습을 하지 않을 경우는 dropout off\n느낌: 일부러 패널티를 안고 학습하는 느낌..\n효과: 오버피팅을 억제하는 효과가 있음\n\n🗣️ 랜덤 포레스트와 동일\n\n참고: 오버피팅을 잡는 방법은 드랍아웃만 있는게 아니다..\n\n🗣️ 근본: 시각화 후 데이터에 맞춘 모델을 찾음 (어려움) / 실제: 시벤코 정리로 적합을 한 후 드랍아웃을 걸어 오버피팅 방지"
  },
  {
    "objectID": "posts/05wk-1.html#c.-드랍아웃-레이어의-위치",
    "href": "posts/05wk-1.html#c.-드랍아웃-레이어의-위치",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "C. 드랍아웃 레이어의 위치",
    "text": "C. 드랍아웃 레이어의 위치\n- ReLU,dropout의 특이한 성질: \\(\\text{dropout}(\\text{relu}({\\bf x}))=\\text{relu}(\\text{dropout}({\\bf x}))\\)\n🗣️ 둘 다 x를 그대로 내보내거나 0으로 만듦 (순서 상관 없이 결과 동일)\n\nu = torch.randn(10,2)\nr = torch.nn.ReLU()\nd = torch.nn.Dropout()\n\n\ntorch.manual_seed(0)\nd(r(u))\n\ntensor([[0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.5372],\n        [2.6658, 2.1870],\n        [0.3798, 0.0000],\n        [0.0000, 1.6593],\n        [0.9300, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000]])\n\n\n\ntorch.manual_seed(0)\nr(d(u))\n\ntensor([[0.0000, 0.0000],\n        [-0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.5372],\n        [2.6658, 2.1870],\n        [0.3798, -0.0000],\n        [0.0000, 1.6593],\n        [0.9300, 0.0000],\n        [0.0000, 0.0000],\n        [-0.0000, 0.0000]])\n\n\n- 다른 활성화함수는 성립안함\n🗣️ 활성화 함수: 비선형 함수, activation 함수\n\nu = torch.randn(10,2)\ns = torch.nn.Sigmoid()\nd = torch.nn.Dropout()\n\n\ntorch.manual_seed(0)\nd(s(u))\n\ntensor([[0.4801, 0.0000],\n        [0.0000, 1.4006],\n        [0.3487, 0.0000],\n        [0.0000, 1.2299],\n        [0.9213, 1.6180],\n        [1.1322, 0.0000],\n        [0.0000, 1.4407],\n        [0.6015, 1.4349],\n        [0.0000, 1.7626],\n        [0.0000, 0.0000]])\n\n\n\ntorch.manual_seed(0)\ns(d(u))\n\ntensor([[0.0907, 0.5000],\n        [0.5000, 0.8452],\n        [0.0427, 0.5000],\n        [0.5000, 0.7183],\n        [0.4218, 0.9472],\n        [0.6300, 0.5000],\n        [0.5000, 0.8691],\n        [0.1561, 0.8657],\n        [0.5000, 0.9822],\n        [0.5000, 0.5000]])\n\n\n- 결론: 드랍아웃은 활성화 함수 바로 뒤에 오는게 맞음. (그렇지 않다면 0을 만들 수 없는걸?) 그렇지만 ReLU의 경우 활성화 함수 직전에 취하기도 함.\n🗣️ ReLU는 순서를 바꾸는 것이 계산 상에 효율이 있다고 함"
  },
  {
    "objectID": "posts/05wk-1.html#d.-평균보정의-필요성-선택학습",
    "href": "posts/05wk-1.html#d.-평균보정의-필요성-선택학습",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "D. 평균보정의 필요성 (선택학습)",
    "text": "D. 평균보정의 필요성 (선택학습)\n\n\n\n\n\n\nNote\n\n\n\n90%의 드랍아웃에서 출력결과에 왜 x10하는지 좀 더 자세히 설명한 챕터입니다. 궁금하시다면 읽어보시고 아니라면 넘어가셔도 무방합니다.\n\n\n- 아래의 데이터를 관찰하자.\n\nx,_ = torch.randn(300).sort()\ny = relu(20*x) + torch.randn(300)\nx,y = x.reshape(-1,1), y.reshape(-1,1)\n\n\nplt.plot(x,y,'o')\n\n\n\n\n\n\n\n\n- 적합해보자.\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1000),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(0.1),\n    torch.nn.Linear(1000,1,bias=False),\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(5000):\n    ## 1 \n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nnet.eval()\n\nSequential(\n  (0): Linear(in_features=1, out_features=1000, bias=True)\n  (1): ReLU()\n  (2): Dropout(p=0.1, inplace=False)\n  (3): Linear(in_features=1000, out_features=1, bias=False)\n)\n\n\n\nnet.training\n\nFalse\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n\n\n- 주황색선이나오는 이유 설명해보자.\n\nU = net[:-1](x).data \nW = net[-1].weight.T \n\n아래3개는 동일한코드임\n\nnet(x).reshape(-1)[:10] # 코드1\n\ntensor([-0.9858, -0.5127, -0.4687,  0.0514,  0.0558,  0.2089,  0.2213,  0.2619,\n         0.2691,  0.2823], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\n(U@W).reshape(-1)[:10] # 코드2\n\ntensor([-0.9858, -0.5127, -0.4687,  0.0514,  0.0558,  0.2089,  0.2213,  0.2619,\n         0.2691,  0.2823], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\n((U*W.reshape(-1)).sum(axis=1))[:10] # 코드3\n\ntensor([-0.9858, -0.5127, -0.4687,  0.0514,  0.0558,  0.2089,  0.2213,  0.2619,\n         0.2691,  0.2823], grad_fn=&lt;SliceBackward0&gt;)\n\n\n따라서 아래의 주황색선들의 .sum(axis=1) 하기만 하면 net(x)의 결과가 된다.\n\nplt.plot(x,U*W.reshape(-1).data,color=\"C1\",alpha=0.02);\n\n\n\n\n\n\n\n\n- 즉 왼쪽의 주황색선1이 모두 합쳐져서 오른쪽의 점선이된다.\n\nfig,ax = plt.subplots(1,2,figsize=(9,3))\nax[0].plot(x,U*W.reshape(-1).data,color=\"C1\",alpha=0.02);\nax[0].set_title(\"1,000 ReLUs\")\nax[1].plot(x,net(x).data,'--',color=\"C1\")\nax[1].set_title(r\"$net({\\bf x})$=sum(1,000 ReLUs)\");\n\n\n\n\n\n\n\n\n\n만약에 왼쪽의 주황색선이 10%만 사용되어서 100개의 렐루만 사용되었다면? 대충 x10을 해줘야 net(x) 가 나오지 않겠어요?"
  },
  {
    "objectID": "posts/05wk-1.html#footnotes",
    "href": "posts/05wk-1.html#footnotes",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n1000개가 있음↩︎"
  },
  {
    "objectID": "posts/13wk-1.html",
    "href": "posts/13wk-1.html",
    "title": "13wk-1: (강화학습) – 강화학습 Intro, Bandit 게임 설명, Bandit 환경 설계 및 풀이",
    "section": "",
    "text": "📘 Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\n📝 🗣️ ✍️ 🔬 ❓"
  },
  {
    "objectID": "posts/13wk-1.html#a.-대충-개념만-실습",
    "href": "posts/13wk-1.html#a.-대충-개념만-실습",
    "title": "13wk-1: (강화학습) – 강화학습 Intro, Bandit 게임 설명, Bandit 환경 설계 및 풀이",
    "section": "A. 대충 개념만 실습",
    "text": "A. 대충 개념만 실습\n🗣️(\n\naction_space = [0,1]\naction = np.random.choice(action_space)\naction\n\nnp.int64(1)\n\n\n\naction space: agent가 할 수 있는 action들의 집합\n처음 action은 random으로 뽑음\n\n\nif action == 1:\n    reward = 10\nelif action == 0:\n    reward = 1\nelse:\n    pass\n\n\nreward\n\n10\n\n\nif action == 1:\n    reward = 10\nelse:\n    reward = 1\n\n동일 코드\n\n\naction_space = [0,1]\naction = np.random.choice(action_space)\nif action == 1:\n    reward = 10\nelse:\n    reward = 1\n(action, reward)\n\n(np.int64(0), 1)\n\n\n\naction과 reward의 history를 컴퓨터에 저장할 공간이 필요함\n\n게임을 오래하면 필요한 메모리 공간이 매우 커지므로 다음과 같은 자료형 필요\n\n\n\nactions = collections.deque(maxlen=5) # list? numpy? 비슷한 것\n\n\nactions\n\ndeque([], maxlen=5)\n\n\n\nactions.append(action)\n\n\nactions\n\ndeque([np.int64(0)], maxlen=5)\n\n\n\naction_space = [0,1]\nactions = collections.deque(maxlen=5)\n#---#\n\n\naction = np.random.choice(action_space)\nif action == 1:\n    reward = 10\nelse:\n    reward = 1\nactions.append(action)\n\n\nactions\n\ndeque([np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1)],\n      maxlen=5)\n\n\n\n위의 두 코드를 5번 실행하니 deque([np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1)], maxlen=5) 과 같은 결과를 얻었음\n한 번 더 실행한다면 이전 결과가 밀리면서 사라짐\n\ndeque([np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1)], maxlen=5)\n\n\n\naction_space = [0,1]\nactions_deque = collections.deque(maxlen=500)\nrewards_deque = collections.deque(maxlen=500)\n#---#\n\n\nfor _ in range(10):\n    action = np.random.choice(action_space)\n    if action == 1:\n        reward = 10\n    else:\n        reward = 1\n    actions_deque.append(action)\n    rewards_deque.append(reward)\n\n\nactions_deque\n\ndeque([np.int64(0),\n       np.int64(0),\n       np.int64(1),\n       np.int64(1),\n       np.int64(0),\n       np.int64(0),\n       np.int64(0),\n       np.int64(1),\n       np.int64(0),\n       np.int64(1)],\n      maxlen=500)\n\n\n\nrewards_deque\n\ndeque([1, 1, 10, 10, 1, 1, 1, 10, 1, 10], maxlen=500)\n\n\n\nnp.array(actions_deque) == 1\n\narray([False, False,  True,  True, False, False, False,  True, False,\n        True])\n\n\n\n브로드캐스팅을 하기 위해 numpy 활용\n\n\nactions_numpy = np.array(actions_deque)\nrewards_numpy = np.array(rewards_deque)\n\n\nactions_numpy\n\narray([0, 0, 1, 1, 0, 0, 0, 1, 0, 1])\n\n\n\nrewards_numpy\n\narray([ 1,  1, 10, 10,  1,  1,  1, 10,  1, 10])\n\n\n\nrewards_numpy[actions_numpy == 1]\n\narray([10, 10, 10, 10])\n\n\n\nrewards_numpy[actions_numpy == 1].mean()\n\nnp.float64(10.0)\n\n\n\n여기서는 reward가 일정하지만 random하게 주는 경우도 있음\n\nq0 = 0을 눌렀을때 받는 보상의 평균\nq1 = 1을 눌렀을때 받는 보상의 평균\nq_table = [q0, q1]\n\nq0 = rewards_numpy[actions_numpy == 0].mean()\nq1 = rewards_numpy[actions_numpy == 1].mean()\nq_table = np.array([q0,q1])\nq_table\n\narray([ 1., 10.])\n\n\n\nq_table을 보고 action 하는 것을 코드로 구현\n\n\nq_table.argmax()\n\nnp.int64(1)\n\n\n\naction = q_table.argmax()\n\n\nfor _ in range(10):\n    action = q_table.argmax() # 이제는 action을 random으로 하는 것이 아니라 q_table을 보고 함\n    if action == 1:\n        reward = 10\n    else:\n        reward = 1\n    actions_deque.append(action)\n    rewards_deque.append(reward)\n    actions_numpy = np.array(actions_deque)\n    rewards_numpy = np.array(rewards_deque)\n    q0 = rewards_numpy[actions_numpy == 0].mean()\n    q1 = rewards_numpy[actions_numpy == 1].mean()\n    q_table = np.array([q0,q1]) # q_table update\n\n\nrewards_numpy\n\narray([ 1,  1, 10, 10,  1,  1,  1, 10,  1, 10, 10, 10, 10, 10, 10, 10, 10,\n       10, 10, 10])\n\n\n\n처음에는 random이다가 끝에는 10점을 받는 것을 알 수 있음\n\n\nactions_numpy\n\narray([0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n\n\n)🗣️\n\naction_space = [0,1] \nactions_deque = collections.deque(maxlen=500)\nrewards_deque =  collections.deque(maxlen=500)\n#---#\n\n\nfor _ in range(10):\n    action = np.random.choice(action_space)\n    if action == 1:\n        reward = 10 \n    else:\n        reward = 1\n    actions_deque.append(action)\n    rewards_deque.append(reward)\n\n\nactions_deque\n\ndeque([0, 1, 0, 0, 0, 1, 0, 1, 1, 0], maxlen=500)\n\n\n\nrewards_deque\n\ndeque([1, 10, 1, 1, 1, 10, 1, 10, 10, 1], maxlen=500)\n\n\n\nactions_numpy = np.array(actions_deque)\nrewards_numpy = np.array(rewards_deque)\n\n\nq0 = rewards_numpy[actions_numpy == 0].mean()\nq1 = rewards_numpy[actions_numpy == 1].mean()\nq_table = np.array([q0,q1])\nq_table\n\narray([ 1., 10.])\n\n\n\naction = q_table.argmax()\n\n\nfor _ in range(5):\n    action = q_table.argmax()\n    if action == 1:\n        reward = 10 \n    else:\n        reward = 1\n    actions_deque.append(action)\n    rewards_deque.append(reward)\n    actions_numpy = np.array(actions_deque)\n    rewards_numpy = np.array(rewards_deque)    \n    q0 = rewards_numpy[actions_numpy == 0].mean()\n    q1 = rewards_numpy[actions_numpy == 1].mean()\n    q_table = np.array([q0,q1])\n\n\nactions_numpy\n\narray([0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1])\n\n\n\nrewards_numpy\n\narray([ 1, 10,  1,  1,  1, 10,  1, 10, 10,  1, 10, 10, 10, 10, 10])"
  },
  {
    "objectID": "posts/13wk-1.html#b.-클래스를-이용한-구현",
    "href": "posts/13wk-1.html#b.-클래스를-이용한-구현",
    "title": "13wk-1: (강화학습) – 강화학습 Intro, Bandit 게임 설명, Bandit 환경 설계 및 풀이",
    "section": "B. 클래스를 이용한 구현",
    "text": "B. 클래스를 이용한 구현\n🗣️(\n\n강화학습에서 객체라고 불릴 수 있는 것: Agent, Environment\n\nAgent가 하는 행동: action, 저장(Environment의 reward)\nEnvironment가 하는 행동: reward(action을 받아서)\n\n\n\nclass Bandit:\n    def __init__(self):\n        pass # 초기값 패스\n    def step(self, action):\n        # action --&gt; reward\n        if action == 0:\n            reward = 1\n        else:\n            reward = 10\n        return reward\n\n\nenv = Bandit()\n\n\nenv.step(1)\n\n10\n\n\n\nenv.step(0)\n\n1\n\n\n\nenv의 reward도 저장하게 하고 싶다면\n\n\nclass Bandit:\n    def __init__(self):\n        self.reward = None\n    def step(self, action):\n        # action --&gt; reward\n        if action == 0:\n            self.reward = 1\n        else:\n            self.reward = 10\n        return self.reward\n\n\nenv = Bandit()\n\n\nenv.step(1)\n\n10\n\n\n\nenv.reward\n\n10\n\n\n\nenv.step(0)\n\n1\n\n\n\nenv.reward\n\n1\n\n\n\nclass Agent:\n    def __init__(self):\n        pass\n    def act(self):\n        # 만약에 경험이 20보다 작음 --&gt; 랜덤 액션\n        # 경험이 20보다 크면 --&gt; action = q_table.argmax()\n        pass\n    def save_experience(self):\n        # 데이터\n        pass\n    def learn(self):\n        # q_table을 업데이트하는 과정\n        pass\n\n\n다음 시간에 이어서\n\n)🗣️\n\nclass Bandit:\n    def __init__(self):\n        self.reward = None \n    def step(self,action):\n        if action == 0:\n            self.reward = 1\n        else: \n            self.reward = 10 \n        return self.reward \n\n\nenv = Bandit()\n\n\nclass Agent:\n    def __init__(self):\n        pass \n    def act(self):\n        # 만약에 경험이 20보다 작음 --&gt; 랜덤액션 \n        # 경험이 20보다 크면 --&gt; action = q_tabel.argmax()\n        pass \n    def save_experience(self):\n        # 데이터 저장 \n        pass \n    def learn(self):\n        # q_table 을 업데이트하는 과정 \n        pass\n\n\n\n\n\n\n\nImportant\n\n\n\n앞으로의 수업에서는 아래에 해당하는 클래스의 기본 개념을 숙지하셔야 합니다. (13wk-2 주차 강의듣기전까지 꼭!)\n\n클래스와 인스턴스의 개념, __init__, self, 메소드\n클래스의 상속\n\n관련하여 제가 작년에 수업한 자료는 아래와 같습니다\n\nhttps://guebin.github.io/PP2024/posts/11wk-2.html 에서 1-7까지..\nhttps://guebin.github.io/PP2024/posts/14wk-2.html 에서 8-A\n\n물론, 꼭 제 강의노트로만 공부하셔야하는것은 아닙니다. 제 수업 외에도 클래스를 잘 설명하는 다양한 자료들이 많이 있으니 자유롭게 참고하여 학습하시기 바랍니다."
  },
  {
    "objectID": "posts/15wk-1.html",
    "href": "posts/15wk-1.html",
    "title": "15wk-1: (강화학습) – LunarLander",
    "section": "",
    "text": "📘 Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\n\n\n\n\n\n\n\n\nType\nWhat It Means\nWhen I Use It\n\n\n\n\n📝 Lecture\nOriginal material from the professor’s notes\nWhen I’m referencing core concepts or provided code\n\n\n🗣️ In-Class Note\nVerbal explanations shared during the lecture\nWhen I want to record something the professor said in class but didn’t include in the official notes\n\n\n✍️ My Note\nMy thoughts, interpretations, or additional explanations\nWhen I reflect on or explain something in my own words\n\n\n🔬 Experiment\nCode I tried out or changed to explore further\nWhen I test variations or go beyond the original example\n\n\n❓ Question\nQuestions I had while studying\nWhen I want to revisit or research something more deeply\n\n\n\n📝 🗣️ ✍️ 🔬 ❓\n\n1. 강의노트 원본 및 영상 링크\nhttps://guebin.github.io/DL2025/posts/15wk-1.html\n\n\n2. Imports 📝\n\n\n\n\n\n\nNote\n\n\n\n코랩사용자는 아래코드 실행후 실습할것 \n!pip install swig\n!pip install gymnasium[box2d]\n학과서버사용자는 가상환경에서 아래를 설치\nconda install conda-forge::gymnasium-box2d \n\n\n\nimport gymnasium as gym\n#--#\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.animation import FuncAnimation\nimport IPython\n#--#\nimport collections\nimport random\n#--#\nimport torch\n\n\ndef show(imgs,jump=10):\n    imgs = imgs[::jump]\n    fig = plt.Figure()\n    ax = fig.subplots()\n    def update(i):\n        ax.imshow(imgs[i])\n    ani = FuncAnimation(fig,update,frames=len(imgs))\n    display(IPython.display.HTML(ani.to_jshtml()))\n\n\n\n3. 예비학습 📝\n- random.sample()의 용법을 살펴보자.\n🗣️(\n\n예시1\n\n[1,2,3,4,5] 중 2개를 뽑음\n\n예시2\n\n3개 중 2개를 뽑음\n\n\n\ns = [[0,0], [0,2], [3,2]]\na = [0,1,2]\nmemory = list(zip(s,a))\nmemory\n\n[([0, 0], 0), ([0, 2], 1), ([3, 2], 2)]\n\n\n)🗣️\n# 예시1\n\nrandom.sample([1,2,3,4,5],2)\n\n[3, 2]\n\n\n# 예시2\n\ns = [[0,0], [0,2], [3,2]]\na = [0,1,2]\nmemory = list(zip(s,a))\nrandom.sample(memory,2)\n\n[([0, 2], 1), ([0, 0], 0)]\n\n\n\n\n4. env: LunarLander 📝\n🗣️(\n\n환경을 직접 만들지 않고 기존에 있는 클래스 활용\n게임 설명\n\n지형이 바뀜\n바람의 영향도 조금 있음\n목적: 잘 조정을 해서 깃발 안에 떨어지게 함\n\n\n)🗣️\n- ref: https://gymnasium.farama.org/environments/box2d/lunar_lander/\n- Lunar Lander: 요약\nObservation Space (State Space) – 8개의 변수\n\n착륙선의 x 좌표\n착륙선의 y 좌표\n착륙선의 x 속도\n착륙선의 y 속도\n착륙선의 각도\n착륙선의 각속도\n왼쪽 다리가 땅에 닿아있는지 여부 (1 또는 0)\n오른쪽 다리가 땅에 닿아있는지 여부 (1 또는 0)\n\nAction Space – 4개의 변수\n\n{0 : 아무 행동도 하지 않음}\n{1 : 왼쪽 엔진 발사 (오른쪽으로 기울임)}\n{2 : 메인 엔진 발사 (위로 밀어 올림)}\n{3 : 오른쪽 엔진 발사 (왼쪽으로 기울임)}\n\nReward\n\n거리 보상: 착륙 패드에 가까울수록 보상 증가\n속도 보상: 속도가 낮을수록 보상 증가\n각도 보상: 각도가 수직에 가까울수록 보상 증가\n착륙 다리 보상: 다리가 착륙 패드에 닿으면 보상\n연료 사용 패널티: 엔진 사용 시 패널티\n안전한 착륙 보상: 안정적으로 착륙 시 큰 보상 (+100~+140)\n충돌 패널티: 착륙 패드 이외의 장소에 충돌 시 패널티 (-100)\n\n- 환경생성\n\nenv = gym.make(\"LunarLander-v3\", render_mode = \"rgb_array\")\nenv \n\n&lt;frozen importlib._bootstrap&gt;:228: RuntimeWarning: Your system is avx2 capable but pygame was not built with support for it. The performance of some of your blits could be adversely affected. Consider enabling compile time detection with environment variables like PYGAME_DETECT_AVX2=1 if you are compiling without cross compilation.\n\n\n&lt;TimeLimit&lt;OrderEnforcing&lt;PassiveEnvChecker&lt;LunarLander&lt;LunarLander-v3&gt;&gt;&gt;&gt;&gt;\n\n\n- state_space\n🗣️(\n\nenv.observation_space\n\nBox([ -2.5        -2.5       -10.        -10.         -6.2831855 -10.\n  -0.         -0.       ], [ 2.5        2.5       10.        10.         6.2831855 10.\n  1.         1.       ], (8,), float32)\n\n\n\n무엇을 의미하는지 잘 모르겠음\n✍️ 범위?\n샘플을 뽑아보면\n\n)🗣️\n\nenv.observation_space.sample()\n\narray([-9.2788523e-01,  2.1088607e+00,  3.9729960e-03,  4.4444327e+00,\n        6.4698160e-01,  5.2979026e+00,  9.8654026e-01,  6.8356961e-01],\n      dtype=float32)\n\n\n\n8개의 숫자가 포함된 array가 나옴\n이 8개의 숫자는 각각 상태를 의미함\n\n- action_space\n🗣️(\n\nenv.action_space\n\nDiscrete(4)\n\n\n\n샘플을 뽑아보면\n\n)🗣️\n\nenv.action_space.sample()\n\nnp.int64(1)\n\n\n\n0,1,2,3 중 하나가 랜덤으로 뽑힘\n\n- env.reset()\n\nenv.reset()\n\n(array([ 0.00563831,  1.4064701 ,  0.5710932 , -0.19778925, -0.00652668,\n        -0.12936108,  0.        ,  0.        ], dtype=float32),\n {})\n\n\n🗣️(\n\nenv.start() 느낌\n두 개의 return 값\n\n\n{ }: 추가적인 information\n\n\n)🗣️\n- env.render()\n🗣️(\n\nenv.render()\n\narray([[[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        ...,\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        ...,\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        ...,\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       ...,\n\n       [[255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        ...,\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255]],\n\n       [[255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        ...,\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255]],\n\n       [[255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        ...,\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255]]], dtype=uint8)\n\n\n\nenv.render().shape\n\n(400, 600, 3)\n\n\n\n이미지 같음\n현재의 게임 화면을 그림으로 rendering 하여 볼 수 있게 해줌\n\nplt.imshow 함수 사용\n\n\n)🗣️\n\nplt.imshow(env.render())\n\n\n\n\n\n\n\n\n- env.step\n\nenv.step??\n\n\nSignature: env.step(action: 'ActType') -&gt; 'tuple[ObsType, SupportsFloat, bool, bool, dict[str, Any]]'\nSource:   \n    def step(\n        self, action: ActType\n    ) -&gt; tuple[ObsType, SupportsFloat, bool, bool, dict[str, Any]]:\n        \"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\n        Args:\n            action: The environment step action\n        Returns:\n            The environment step ``(observation, reward, terminated, truncated, info)`` with `truncated=True`\n            if the number of steps elapsed &gt;= max episode steps\n        \"\"\"\n        observation, reward, terminated, truncated, info = self.env.step(action)\n        self._elapsed_steps += 1\n        if self._elapsed_steps &gt;= self._max_episode_steps:\n            truncated = True\n        return observation, reward, terminated, truncated, info\nFile:      ~/anaconda3/envs/dl2025/lib/python3.9/site-packages/gymnasium/wrappers/common.py\nType:      method\n\n\n\n\n리턴되는 값은 observation, reward, terminated, truncated, info\n우리가 쓰는 값은 observation, reward, terminated, truncated\n\n🗣️(\n\naction을 입력으로 받음\ntruncated\n\n1,000번의 프레임 동안만 게임 플레이 가능\n계속 올리면 게임이 끝나지 않기 때문에\n\n정상적으로 플레이하다가 clear\n\nterminated = True\ntruncated = False\n\n정상적으로 플레이하다가 die\n\nterminated = True\ntruncated = False\n\n정상적으로 플레이하다가 timeout\n\nterminated = False\ntruncated = True\n\n\n\nenv.step(0)\n\n(array([ 0.01127691,  1.4014435 ,  0.5703218 , -0.22344746, -0.01291902,\n        -0.12785819,  0.        ,  0.        ], dtype=float32),\n np.float64(-0.955798700878546),\n False,\n False,\n {})\n\n\n\nobservation, reward, terminated, truncated 순\ninfo는 비어 있음\n\n)🗣️\n- play\n첫시작화면\n\nenv.reset()\nplt.imshow(env.render())\n\n\n\n\n\n\n\n\n플레이해보자\n🗣️(\nAction Space -- 4개의 변수\n\n{0 : 아무 행동도 하지 않음}\n{1 : 왼쪽 엔진 발사 (오른쪽으로 기울임)}\n{2 : 메인 엔진 발사 (위로 밀어 올림)}\n{3 : 오른쪽 엔진 발사 (왼쪽으로 기울임)}\n\nenv.step(0)\nplt.imshow(env.render())\n\n\n\n\n\n\n\n\n\nenv.step(0)\nplt.imshow(env.render())\n\n\n\n\n\n\n\n\n\n매우 느림\n10번 정도 반복 실행 하면 (세부 action은 강의 영상과는 다름)\n\n\nfor _ in range(10):\n    env.step(0)\n    plt.imshow(env.render())\n\n\n\n\n\n\n\n\n\nfor _ in range(10):\n    env.step(0)\n    plt.imshow(env.render())\n\n\n\n\n\n\n\n\n\nfor _ in range(10):\n    env.step(0)\n    plt.imshow(env.render())\n\n\n\n\n\n\n\n\n\nfor _ in range(3):\n    env.step(3)\n    plt.imshow(env.render())\n\n\n\n\n\n\n\n\n\nfor _ in range(3):\n    env.step(2)\n    plt.imshow(env.render())\n\n\n\n\n\n\n\n\n\nfor _ in range(5):\n    env.step(0)\n    env.step(3)\n    plt.imshow(env.render())\n\n\n\n\n\n\n\n\n\nfor _ in range(5):\n    env.step(0)\n    env.step(0)\n    env.step(0)\n    plt.imshow(env.render())\n\n\n\n\n\n\n\n\n\nprint(env.step(0))\n\n(array([ 0.21715555, -0.04394788,  0.40055856, -0.02491728, -0.06356283,\n       -0.31115538,  0.        ,  0.        ], dtype=float32), -100, True, False, {})\n\n\n\nreward: -100, terminated: True =&gt; die\n\n)🗣️\n\nfor _ in range(5):\n    env.step(0) \n    env.step(3) \nplt.imshow(env.render())\n\n\n\n\n\n\n\n\n\n\n5. 시각화 📝\n🗣️(\n\nenv.reset()\n\n(array([-1.2360573e-03,  1.4078571e+00, -1.2521335e-01, -1.3613933e-01,\n         1.4390640e-03,  2.8362691e-02,  0.0000000e+00,  0.0000000e+00],\n       dtype=float32),\n {})\n\n\n\nstate, _ = env.reset()\nstate\n\narray([-0.00307007,  1.4083712 , -0.31098348, -0.1132924 ,  0.00356426,\n        0.07044236,  0.        ,  0.        ], dtype=float32)\n\n\n\nimgs: 이미지를 저장할 리스트\nshow: 처음에 정의한 함수\n\n)🗣️\n\nstate, _ = env.reset()\nimgs = []\nfor t in range(500):\n    action = env.action_space.sample()\n    next_state, reward, terminated, truncated, _ = env.step(action)\n    imgs.append(env.render())\n    state = next_state \n    if terminated or truncated:\n        break\n\n\nshow(imgs)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n6. RandomAgent 📝\n🗣️(\nclass RandomAgent:\n    def __init__(self):\n        pass\n    def act(self):\n        pass\n    def learn(self):\n        pass\n    def save_experience(self):\n        self.states.append(self.state)\n        self.actions.append(self.action)\n        self.rewards.append(self.reward)\n        self.next_states.append(self.next_state)\n        self.terminations.append(self.terminated)\nclass RandomAgent:\n    def __init__(self):\n        self.state = None\n        self.action = None\n        self.reward = None\n        self.next_state = None\n        self.terminated = None\n        #---#\n        self.states = collections.deque(maxlen = 5000)\n        self.actions = collections.deque(maxlen = 5000)\n        self.rewards = collections.deque(maxlen = 5000)\n        self.next_states = collections.deque(maxlen = 5000)\n        self.terminations = collections.deque(maxlen = 5000)\n    def act(self):\n        pass\n    def learn(self):\n        pass\n    def save_experience(self):\n        self.states.append(self.state)\n        self.actions.append(self.action)\n        self.rewards.append(self.reward)\n        self.next_states.append(self.next_state)\n        self.terminations.append(self.terminated)\n\ntruncated는 굳이 쓸 필요가 없을 것 같아 저장 X\n\n\nclass RandomAgent:\n    def __init__(self):\n        self.action_space = gym.spaces.Discrete(4)\n        #---#\n        self.state = None\n        self.action = None\n        self.reward = None\n        self.next_state = None\n        self.terminated = None\n        #---#\n        self.states = collections.deque(maxlen = 5000)\n        self.actions = collections.deque(maxlen = 5000)\n        self.rewards = collections.deque(maxlen = 5000)\n        self.next_states = collections.deque(maxlen = 5000)\n        self.terminations = collections.deque(maxlen = 5000)\n    def act(self):\n        self.action = self.action_space.sample()\n    def learn(self):\n        pass\n    def save_experience(self):\n        self.states.append(self.state)\n        self.actions.append(self.action)\n        self.rewards.append(self.reward)\n        self.next_states.append(self.next_state)\n        self.terminations.append(self.terminated)\n\n\nstep 1: action\nstep 2: 전달\nstep 3: save & learn\nstep 4: 다음 iteration 준비\n\n\nenv = gym.make(\"LunarLander-v3\", render_mode = \"rgb_array\")\nplayer = RandomAgent()\nplayer.state,_ = env.reset()\nfor e in range(1,101):\n    while True:\n        # step1\n        player.act()\n        # step2\n        player.next_state, player.reward, player.terminated, player.truncated, _ = env.step(player.action)\n        # step3\n        player.save_experience()\n        player.learn()\n        # step4 \n        if player.terminated or player.truncated: \n            player.state, _ = env.reset()\n            break \n        else: \n            player.state = player.next_state\n\n\n잘 저장되어 있는지 확인\n\n\n# player.states # numpy array\n\n\n# player.actions\n\n\nplayer.truncated\n\nFalse\n\n\n\n# player.terminations\n\n\n참고) 강의 노트 원본 (아래) RandomAgent는 save_experience에서 torch.tensor가 들어가 있음\n7.4 전까지는 그냥 없는 버전으로 실행하였고 (강의 노트 원본 코드 제외, 강의 노트 원본 코드는 실행 안 함)\n7.4부터는 원본 버전으로 실행\n\n)🗣️\n\nclass RandomAgent:\n    def __init__(self):\n        self.action_spcae = gym.spaces.Discrete(4)\n        self.n_experieces = 0 \n        #---#\n        self.state = None \n        self.action = None \n        self.reward = None \n        self.next_state = None \n        self.terminated = None \n        #---#\n        self.states = collections.deque(maxlen = 5000)\n        self.actions = collections.deque(maxlen = 5000)\n        self.rewards = collections.deque(maxlen = 5000)\n        self.next_states = collections.deque(maxlen = 5000)\n        self.terminations = collections.deque(maxlen = 5000)\n    def act(self):\n        self.action = self.action_spcae.sample()\n    def learn(self):\n        pass \n    def save_experience(self):\n        self.states.append(torch.tensor(self.state))\n        self.actions.append(self.action)\n        self.rewards.append(self.reward)\n        self.next_states.append(torch.tensor(self.next_state))\n        self.terminations.append(self.terminated)\n        self.n_experieces = self.n_experieces+1\n\n\nenv = gym.make(\"LunarLander-v3\", render_mode = \"rgb_array\")\nplayer = RandomAgent()\nplayer.state,_ = env.reset()\nfor e in range(1,101):\n    while True:\n        # step1\n        player.act()\n        # step2\n        player.next_state, player.reward, player.terminated, player.truncated, _ = env.step(player.action)\n        # step3\n        player.save_experience()\n        player.learn()\n        # step4 \n        if player.terminated or player.truncated: \n            player.state, _ = env.reset()\n            break \n        else: \n            player.state = player.next_state\n\n\n\n7. q_net 📝\n\n# 이제 우리가 할것: q_table --&gt; action 을 결정해야함. \n\n# 4x4 그리드 -- 복습 \n# q_table[상태] = [행동0을했을때 품질, 행동1을했을때품질, 행동2를했을때품질, 행동3을했을때품질]  \n# 행동 = argmax(q_table[상태])\n\n# 루나랜더 -- 오늘 할것 \n# q_net[8개의숫자] = [행동0을했을때 품질, 행동1을했을때품질, 행동2를했을때품질, 행동3을했을때품질] # 결국 숫자8개를 숫자4개로 만들어주는 적당한 q_net을 구성\n# 행동 = argmax(q_net[8개의숫자])\n\n🗣️(\n\n과거\n\nq_table[0,0, 0] = ??\nq_table[0,0, 1] = ??\nq_table[0,0, 2] = ??\nq_table[0,0, 3] = ??\n#---#\nq_table[0,1, 0] = ??\nq_table[0,1, 1] = ??\nq_table[0,1, 2] = ??\nq_table[0,1, 3] = ??\n\n현재\n\n숫자가 연속형이라 까다로움\n\n\n\nenv.observation_space.sample()\n\narray([ 0.38724837,  0.19059889, -6.182767  ,  3.6453786 , -3.1740656 ,\n        8.74314   ,  0.31359115,  0.6998068 ], dtype=float32)\n\n\n\nenv.observation_space.sample()\n\narray([-0.54199886,  0.37739053, -6.8368096 ,  8.243433  , -1.4476558 ,\n       -4.5691466 ,  0.67033297,  0.26339018], dtype=float32)\n\n\nq_table[0.38724837,  0.19059889, -6.182767  ,  3.6453786 , -3.1740656 , 8.74314   ,  0.31359115,  0.6998068, 0] = ??\nq_table[0.38724837,  0.19059889, -6.182767  ,  3.6453786 , -3.1740656 , 8.74314   ,  0.31359115,  0.6998068, 1] = ??\nq_table[0.38724837,  0.19059889, -6.182767  ,  3.6453786 , -3.1740656 , 8.74314   ,  0.31359115,  0.6998068, 2] = ??\nq_table[0.38724837,  0.19059889, -6.182767  ,  3.6453786 , -3.1740656 , 8.74314   ,  0.31359115,  0.6998068, 3] = ??\n#---#\nq_table[-0.54199886,  0.37739053, -6.8368096 ,  8.243433  , -1.4476558 , -4.5691466 ,  0.67033297,  0.26339018, 0] = ??\nq_table[-0.54199886,  0.37739053, -6.8368096 ,  8.243433  , -1.4476558 , -4.5691466 ,  0.67033297,  0.26339018, 1] = ??\nq_table[-0.54199886,  0.37739053, -6.8368096 ,  8.243433  , -1.4476558 , -4.5691466 ,  0.67033297,  0.26339018, 2] = ??\nq_table[-0.54199886,  0.37739053, -6.8368096 ,  8.243433  , -1.4476558 , -4.5691466 ,  0.67033297,  0.26339018, 3] = ??\n)🗣️\n- 전략: 4x4에서 q_table에 대응하는 뭔가가 있으면 된다. 그런데 q_table와 같이 테이블 형식으로는 힘들것 같다. \\(\\to\\) q_net를 만들자.\n\n4x4 grid: 상태공간의 차원은 2차원이며 가질수 있는 값은 16개, 각 상태공간에서 할수 있는 행동이 4개 -&gt; 총 16*4의 경우의 수에 대한 reward만 조사하면 되었음\nLunarLander: 상태공간의 차원은 8차원이지만 가질수 있는 값의 범위는 무한대 -&gt; 무수히 많은 경우에 대한 reward 값을 조사하는건 현실적으로 불가능\n\n상황\n\nstate = player.states[100]\naction = player.actions[100]\nreward = player.rewards[100]\nnext_state = player.next_states[100]\nterminated = player.terminations[100]\n\n1. q_net\n🗣️(\n\n# player.q_net # 현재 없어서 error\n\n\nplayer.q_net = torch.nn.Sequential(\n    torch.nn.Linear(8,256),\n    torch.nn.ReLU(),\n    torch.nn.Linear(256,128),\n    torch.nn.ReLU(),\n    torch.nn.Linear(128,64),\n    torch.nn.ReLU(),\n    torch.nn.Linear(64,4)\n)\n\n\n4개의 층\n\n\nplayer.q_net\n\nSequential(\n  (0): Linear(in_features=8, out_features=256, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=256, out_features=128, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=128, out_features=64, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=64, out_features=4, bias=True)\n)\n\n\n\ntorch.tensor(env.observation_space.sample())\n\ntensor([-1.3189,  0.9664,  2.3762, -7.5418,  5.8477,  0.6544,  0.3398,  0.7094])\n\n\n\nplayer.q_net(torch.tensor(env.observation_space.sample()))\n\ntensor([-0.1090,  0.2078, -0.2280,  0.0221], grad_fn=&lt;ViewBackward0&gt;)\n\n\n\n8개의 숫자를 넣으면 4개의 숫자가 나옴\n\n\nstate = torch.tensor(env.observation_space.sample())\nplayer.q_net(state)\n\ntensor([-0.0012,  0.0180, -0.3318, -0.1024], grad_fn=&lt;ViewBackward0&gt;)\n\n\n\nnotation 정리 (강의 노트 상황 설정 전)\n\n\nstate = env.observation_space.sample()\ns = torch.tensor(state)\nplayer.q_net(s)\n\ntensor([-0.1517, -0.0282, -0.1357, -0.0040], grad_fn=&lt;ViewBackward0&gt;)\n\n\n\n상황 설정 후\n\n\nstate = player.states[100]\naction = player.actions[100]\nreward = player.rewards[100]\nnext_state = player.next_states[100]\nterminated = player.terminations[100]\n\n\nplayer.q_net(torch.tensor(state))\n\ntensor([ 0.0353,  0.0744, -0.0374, -0.0312], grad_fn=&lt;ViewBackward0&gt;)\n\n\n)🗣️\n\nplayer.q_net = torch.nn.Sequential(\n    torch.nn.Linear(8,256),\n    torch.nn.ReLU(),\n    torch.nn.Linear(256,128),\n    torch.nn.ReLU(),\n    torch.nn.Linear(128,64),\n    torch.nn.ReLU(),\n    torch.nn.Linear(64,4)\n)\n\n\nplayer.q_net(state)\n\ntensor([-0.1211,  0.1420,  0.0979, -0.1142], grad_fn=&lt;ViewBackward0&gt;)\n\n\n\n8개의 숫자가 들어가서 4개의 숫자가 나옴\n\n2. q_hat\n🗣️(\n\nstate = torch.tensor(env.observation_space.sample())\nplayer.q_net(state)\n\ntensor([-0.0392, -0.0271, -0.1871, -0.0522], grad_fn=&lt;ViewBackward0&gt;)\n\n\n\naction 0,1,2,3을 했을 때의 품질\n\n\nstate = torch.tensor(env.observation_space.sample())\naction = 0\nplayer.q_net(state)[action]\n\ntensor(-0.0842, grad_fn=&lt;SelectBackward0&gt;)\n\n\n\nnotation 정리 (강의 노트 상황 설정 전)\n\n\nstate = env.observation_space.sample()\ns = torch.tensor(state)\na = action = 0\nplayer.q_net(s)[a]\n\ntensor(-0.1071, grad_fn=&lt;SelectBackward0&gt;)\n\n\n\n상황 설정 후\n\n\nstate = player.states[100]\naction = player.actions[100]\nreward = player.rewards[100]\nnext_state = player.next_states[100]\nterminated = player.terminations[100]\n\n\nq_hat = player.q_net(torch.tensor(state))[action]\n\n\nq_hat\n\ntensor(0.0744, grad_fn=&lt;SelectBackward0&gt;)\n\n\n)🗣️\n\nq_hat = player.q_net(state)[action]\n\n3. q (\\(q = r + 0.99 \\times {\\tt future}\\))\n🗣️(\n\nenv.step(action)\n\n(array([-0.01383076,  1.4314287 , -0.69949836,  0.442844  ,  0.01585995,\n         0.15681908,  0.        ,  0.        ], dtype=float32),\n np.float64(-0.30288280327448547),\n False,\n False,\n {})\n\n\n\n# next_state, reward, terminated, truncated, _ = env.step(action)\n# future = player.qnet(torch.tensor(next_state)).max()\n# reward + 0.99 * future\n\n\n상황 설정 후\n\n\nstate = player.states[100]\naction = player.actions[100]\nreward = player.rewards[100]\nnext_state = player.next_states[100]\nterminated = player.terminations[100]\n\n\nfuture = player.q_net(torch.tensor(next_state)).max()\nq = reward + 0.99 * future\n\n\nq\n\ntensor(0.6048, grad_fn=&lt;AddBackward0&gt;)\n\n\n\nq_hat은 현재 엉터리 값\n목표: q_hat \\(\\approx\\) q\n그러나 y가 주어져 있는 이전 상황 y_hat \\(\\approx\\) y 와 달리 현재는 q 도 네트워크에서 나옴\n\nreward만 주어져 있고 나머지는 아니라 애매함\n\nq를 주어진 값으로 생각하면\n\n\nfuture\n\ntensor(0.0752, grad_fn=&lt;MaxBackward1&gt;)\n\n\n\nfuture = player.q_net(torch.tensor(next_state)).max().data\nq = reward + 0.99 * future\n\n\nq_hat, q\n\n(tensor(0.0744, grad_fn=&lt;SelectBackward0&gt;), tensor(0.6048))\n\n\n\nq_hat과 q가 비슷해질 때까지 학습이 되겠다고 생각 가능\n\n\nif terminated: \n    q = reward # q는 꼬리표가 없는 숫자 \nelse: \n    future = player.q_net(torch.tensor(next_state)).max().data # future에 꼬리표가 있으면 q에도 꼬리표가 생기므로 꼬리표 제거 \n    q = reward + 0.99 * future # q는 꼬리표가 없는 숫자 \n\n)🗣️\n\nif terminated: \n    q = reward # q는 꼬리표가 없는 숫자 \nelse: \n    future = player.q_net(next_state).max().data # future에 꼬리표가 있으면 q에도 꼬리표가 생기므로 꼬리표 제거 \n    q = reward + 0.99 * future # q는 꼬리표가 없는 숫자 \n\n4. q_hat 을 점점 q 와 비슷하게 만드는 과정 = player.q_net를 학습하는 과정\n🗣️(\n\n여기서부터는 강의 노트 원본 버전으로 Agent 실행\n\n\nclass RandomAgent:\n    def __init__(self):\n        self.action_spcae = gym.spaces.Discrete(4)\n        self.n_experieces = 0 \n        #---#\n        self.state = None \n        self.action = None \n        self.reward = None \n        self.next_state = None \n        self.terminated = None \n        #---#\n        self.states = collections.deque(maxlen = 5000)\n        self.actions = collections.deque(maxlen = 5000)\n        self.rewards = collections.deque(maxlen = 5000)\n        self.next_states = collections.deque(maxlen = 5000)\n        self.terminations = collections.deque(maxlen = 5000)\n    def act(self):\n        self.action = self.action_spcae.sample()\n    def learn(self):\n        pass \n    def save_experience(self):\n        self.states.append(torch.tensor(self.state))\n        self.actions.append(self.action)\n        self.rewards.append(self.reward)\n        self.next_states.append(torch.tensor(self.next_state))\n        self.terminations.append(self.terminated)\n        self.n_experieces = self.n_experieces+1\n\n\nenv = gym.make(\"LunarLander-v3\", render_mode = \"rgb_array\")\nplayer = RandomAgent()\nplayer.state,_ = env.reset()\nfor e in range(1,101):\n    while True:\n        # step1\n        player.act()\n        # step2\n        player.next_state, player.reward, player.terminated, player.truncated, _ = env.step(player.action)\n        # step3\n        player.save_experience()\n        player.learn()\n        # step4 \n        if player.terminated or player.truncated: \n            player.state, _ = env.reset()\n            break \n        else: \n            player.state = player.next_state\n\n\nstate = player.states[100]\naction = player.actions[100]\nreward = player.rewards[100]\nnext_state = player.next_states[100]\nterminated = player.terminations[100]\n\n\nplayer.q_net = torch.nn.Sequential(\n    torch.nn.Linear(8,256),\n    torch.nn.ReLU(),\n    torch.nn.Linear(256,128),\n    torch.nn.ReLU(),\n    torch.nn.Linear(128,64),\n    torch.nn.ReLU(),\n    torch.nn.Linear(64,4)\n)\n\n\nplayer.q_net(state)\n\ntensor([ 0.0076, -0.0058, -0.0310,  0.1106], grad_fn=&lt;ViewBackward0&gt;)\n\n\n\nq_hat = player.q_net(state)[action]\n\n\nif terminated: \n    q = reward # q는 꼬리표가 없는 숫자 \nelse: \n    future = player.q_net(next_state).max().data # future에 꼬리표가 있으면 q에도 꼬리표가 생기므로 꼬리표 제거 \n    q = reward + 0.99 * future # q는 꼬리표가 없는 숫자 \n\n\n이전 코드 실행 끝\n\n\n# loss = (q_hat - q)**2\n# loss를 점차 줄이면됨\n\n\nplayer.q_net.parameters()를 학습해야하므로 optimizer가 필요함\n\n\nplayer.optimizr = torch.optim.Adam(player.q_net.parameters())\n\n\nq_hat\n\ntensor(0.0076, grad_fn=&lt;SelectBackward0&gt;)\n\n\n\nq\n\ntensor(-0.3956)\n\n\n\nq_hat과 q가 스칼라이므로 loss를 스칼라로 코드를 짜서 계산하려고 함\n벡터로 계산하는 것이 좋지만 당장 쓰기 까다로워서 (지저분 함)\n\n\nplayer.optimizr = torch.optim.Adam(player.q_net.parameters())\nmemory = list(zip(player.states, player.actions, player.rewards, player.next_states, player.terminations))\n\n\nlen(memory)\n\n5000\n\n\n\nmemory[0]\n\n(tensor([-0.0021,  1.4146, -0.2150,  0.1644,  0.0025,  0.0487,  0.0000,  0.0000]),\n np.int64(1),\n np.float64(0.03960169070262623),\n tensor([-0.0043,  1.4177, -0.2233,  0.1385,  0.0066,  0.0826,  0.0000,  0.0000]),\n False)\n\n\n\nmemory[1]\n\n(tensor([-0.0043,  1.4177, -0.2233,  0.1385,  0.0066,  0.0826,  0.0000,  0.0000]),\n np.int64(1),\n np.float64(-0.4859194165555596),\n tensor([-0.0066,  1.4203, -0.2332,  0.1118,  0.0127,  0.1223,  0.0000,  0.0000]),\n False)\n\n\n\nmemory[2]\n\n(tensor([-0.0066,  1.4203, -0.2332,  0.1118,  0.0127,  0.1223,  0.0000,  0.0000]),\n np.int64(0),\n np.float64(0.2302028958607707),\n tensor([-0.0089,  1.4222, -0.2333,  0.0851,  0.0188,  0.1223,  0.0000,  0.0000]),\n False)\n\n\n\nloss 계산\n\n\nloss = 0\nfor s, a, r, ss, tmd in memory:\n    qhat = player.q_net(s)[a]\n    if tmd:\n        q = r\n    else:\n        future = player.q_net(ss).max().data\n        q = r + 0.99 * future\n    loss = loss + (q_hat - q)**2\nloss = loss / 5000\n\n\nloss\n\ntensor(126.6637, grad_fn=&lt;DivBackward0&gt;)\n\n\n여러 경험이 있는데,\n저장된 것을 업데이트할 때\n1 2 3 ... 5000 -- 업데이트 --&gt;\n2~5001 -- 업데이트 --&gt;\n3~5002 -- 업데이트 --&gt;\n이런 식으로 전부 하지말고\n몇개 씩만 뽑아서 업데이트를 하면\n학습이 조금 더 안정적으로 잘 됨\n\nloss = 0\nmini_batch = random.sample(memory, 64)\nfor s, a, r, ss, tmd in mini_batch:\n    qhat = player.q_net(s)[a]\n    if tmd:\n        q = r\n    else:\n        future = player.q_net(ss).max().data\n        q = r + 0.99 * future\n    loss = loss + (q_hat - q)**2\nloss = loss / 64\n\n\nloss\n\ntensor(6.0927, grad_fn=&lt;DivBackward0&gt;)\n\n\n\n정리\n\n\nplayer.optimizr = torch.optim.Adam(player.q_net.parameters())\nfor epoc in range(5):\n    memory = list(zip(player.states, player.actions, player.rewards, player.next_states, player.terminations))\n    mini_batch = random.sample(memory,64)\n    # step1-2 \n    loss = 0\n    for s,a,r,ss,tmd in mini_batch:\n        q_hat = player.q_net(s)[a]\n        if tmd: \n            q = r \n        else: \n            future = player.q_net(ss).max().data \n            q = r + 0.99 * future\n        loss = loss + (q_hat-q)**2\n    loss = loss / 64\n    # step3\n    loss.backward()\n    # step4 \n    player.optimizr.step()\n    player.optimizr.zero_grad()\n\n)🗣️\n\n# loss = (q_hat - q)**2\n# loss를 점차 줄이면됨\n\n\nplayer.optimizr = torch.optim.Adam(player.q_net.parameters())\nfor epoc in range(5):\n    memory = list(zip(player.states, player.actions, player.rewards, player.next_states, player.terminations))\n    mini_batch = random.sample(memory,64)\n    # step1-2 \n    loss = 0\n    for s,a,r,ss,tmd in mini_batch:\n        q_hat = player.q_net(s)[a]\n        if tmd: \n            q = r \n        else: \n            future = player.q_net(ss).max().data \n            q = r + 0.99 * future\n        loss = loss + (q_hat-q)**2\n    loss = loss / 64\n    # step3\n    loss.backward()\n    # step4 \n    player.optimizr.step()\n    player.optimizr.zero_grad()\n\n5. 행동..?\n🗣️(\n\nplayer.q_net(s) # 현재 상태 넣기\n\ntensor([-0.1928, -0.0458, -0.0677,  0.0760], grad_fn=&lt;ViewBackward0&gt;)\n\n\n\nplayer.q_net(s).argmax()\n\ntensor(3)\n\n\n\nplayer.q_net(s).argmax().item() # action\n\n3\n\n\n\n# 이전에는 아래와 같은 방식\n## 1. 특정 시점 이전에는 계속 랜덤액션만\n## 2. 특정 시점 이후에는 계속 q_table에서 도출되는 행동만 \n# 이번에는 아래와 같이 해보자. \n## 1. 처음에는 랜덤액션\n## 2. 점차 에피소드가 지날수록, q_net에서 근거한 행동만\n\n\nrandom.random() # 0과 1 사이\n\n0.36176671095762414\n\n\n\nplayer.state\n\narray([ 1.2628555e-03,  1.3995621e+00,  1.2789896e-01, -5.0480115e-01,\n       -1.4565670e-03, -2.8971046e-02,  0.0000000e+00,  0.0000000e+00],\n      dtype=float32)\n\n\n\nplayer.eps = 0.5\nif random.random() &lt; player.eps:\n    player.action = player.action_space.sample()\nelse:\n    state = torch.tensor(player.state)\n    player.action = player.q_net(state).argmax().item()\n\n\n# 다음 에피소드에서는 아래와 같이 확률을 조금 낮게\nplayer.eps = player.eps*0.99\n\n)🗣️\n\n# 이전에는 아래와 같은 방식\n## 1. 특정 시점 이전에는 계속 랜덤액션만\n## 2. 특정 시점 이후에는 계속 q_table에서 도출되는 행동만 \n# 이번에는 아래와 같이 해보자. \n## 1. 처음에는 랜덤액션\n## 2. 점차 에피소드가 지날수록, q_net에서 근거한 행동만\n\n\nplayer.eps = 0.5 \nif random.random() &lt; player.eps: \n    player.action = player.action_spcae.sample()\nelse:\n    state = torch.tensor(player.state)\n    player.action = player.q_net(state).argmax().item()\n\n\n# 다음에피소드에서는 아래와 같이 확률을 조금 낮게 \nplayer.eps = player.eps* 0.99 \n\n\n\n8. Agent 📝\n🗣️(\n\n위의 내용들을 종합하여 실제로 동작하는 Agent를 만들려고 함\n\n\nclass Agent(RandomAgent):\n    def __init__(self):\n        super().__init__()\n        self.eps = 1.0\n        self.q_net = torch.nn.Sequential(\n            torch.nn.Linear(8,256),\n            torch.nn.ReLU(),\n            torch.nn.Linear(256,128),\n            torch.nn.ReLU(),\n            torch.nn.Linear(128,64),\n            torch.nn.ReLU(),\n            torch.nn.Linear(64,4)\n        )\n        self.optimizr = torch.optim.Adam(self.q_net.parameters())\n    def act(self):\n        if random.random() &lt; self.eps:\n            self.action = self.action_space.sample()\n        else:\n            state = torch.tensor(self.state)\n            self.action = self.q_net(state).argmax().item()\n    def learn():\n        self.optimizr = torch.optim.Adam(self.q_net.parameters())\n        for epoc in range(1): # 5번도 너무 많으므로 1번으로 줄임\n            memory = list(zip(self.states, self.actions, self.rewards, self.next_states, self.terminations))\n            mini_batch = random.sample(memory,64)\n            # step1-2 \n            loss = 0\n            for s,a,r,ss,tmd in mini_batch:\n                q_hat = self.q_net(s)[a]\n                if tmd: \n                    q = r \n                else: \n                    future = self.q_net(ss).max().data \n                    q = r + 0.99 * future\n                loss = loss + (q_hat-q)**2\n            loss = loss / 64\n            # step3\n            loss.backward()\n            # step4 \n            self.optimizr.step()\n            self.optimizr.zero_grad()\n\n)🗣️\n\nclass Agent(RandomAgent):\n    def __init__(self):\n        super().__init__()\n        self.eps = 1.0 \n        self.q_net = torch.nn.Sequential(\n            torch.nn.Linear(8,256),\n            torch.nn.ReLU(),\n            torch.nn.Linear(256,128),\n            torch.nn.ReLU(),\n            torch.nn.Linear(128,64),\n            torch.nn.ReLU(),\n            torch.nn.Linear(64,4)\n        )\n        self.optimizr = torch.optim.Adam(self.q_net.parameters())\n    def act(self):\n        if random.random() &lt; self.eps: \n            self.action = self.action_spcae.sample()\n        else:\n            state = torch.tensor(self.state)\n            self.action = self.q_net(state).argmax().item()\n    def learn(self):\n        if self.n_experieces &gt; 64:\n            for epoc in range(1):\n                memory = list(zip(self.states, self.actions, self.rewards, self.next_states, self.terminations))\n                mini_batch = random.sample(memory,64)\n                # step1-2 \n                loss = 0\n                for s,a,r,ss,tmd in mini_batch:\n                    q_hat = self.q_net(s)[a]\n                    if tmd: \n                        q = r \n                    else: \n                        future = self.q_net(ss).max().data \n                        q = r + 0.99 * future\n                    loss = loss + (q_hat-q)**2\n                loss = loss / 64\n                # step3\n                loss.backward()\n                # step4 \n                self.optimizr.step()\n                self.optimizr.zero_grad()        \n\n\n\n9. Solve 📝\n🗣️(\nenv = gym.make(\"LunarLander-v3\", render_mode = \"rgb_array\")\nplayer = Agent()\nplayer.state, _ = env.reset()\n#---#\nfor e in range(1,2001):\n    #---에피소드시작---#\n    while True:\n        # step1\n        player.act()\n        # step2\n        player.next_state, player.reward, player.terminated, player.truncated, _ = env.step(player.action)\n        # step3\n        player.save_experience()\n        player.learn()\n        # step4\n        if player.terminated or player.truncated:\n            player.state, _ = env.reset()\n        else:\n            player.state = player.next_state\n    #---에피소드끝---#\n    player.eps = player.eps * 0.995\n\nscore를 계산할 필요가 있음\n공식 문서를 보면 한 에피소드에서 200점을 받으면 solution으로 간주해도 좋다고 함\n\nenv = gym.make(\"LunarLander-v3\", render_mode = \"rgb_array\")\nplayer = Agent()\nplayer.state, _ = env.reset()\nscore = 0\nscores = []\n#---#\nfor e in range(1,2001):\n    #---에피소드시작---#\n    while True:\n        # step1\n        player.act()\n        # step2\n        player.next_state, player.reward, player.terminated, player.truncated, _ = env.step(player.action)\n        # step3\n        player.save_experience()\n        player.learn()\n        # step4\n        if player.terminated or player.truncated:\n            score = score + player.reward\n            scores.append(score)\n            score = 0\n            player.state, _ = env.reset()\n        else:\n            score = score + player.reward\n            player.state = player.next_state\n    #---에피소드끝---#\n    player.eps = player.eps * 0.995\n\n에피소드 별 플레이 타임도 궁금함\n\nenv = gym.make(\"LunarLander-v3\", render_mode = \"rgb_array\")\nplayer = Agent()\nplayer.state, _ = env.reset()\nscore = 0\nscores = []\nplaytime = 0\nplaytimes = []\n#---#\nfor e in range(1,2001):\n    #---에피소드시작---#\n    while True:\n        # step1\n        player.act()\n        # step2\n        player.next_state, player.reward, player.terminated, player.truncated, _ = env.step(player.action)\n        # step3\n        player.save_experience()\n        player.learn()\n        # step4\n        if player.terminated or player.truncated:\n            score = score + player.reward\n            scores.append(score)\n            score = 0\n            playtimes.append(playtime)\n            player.state, _ = env.reset()\n        else:\n            score = score + player.reward\n            playtime = playtime + 1\n            player.state = player.next_state\n    #---에피소드끝---#\n    player.eps = player.eps * 0.995\n\nn_experences가 없으면 batch를 뽑을 때 error가 날 수 있으므로 RandomAgent에 추가 후 코드 수정\n\n참고: n_experieces (n 없음)\n7.4에서 이미 수정된 강의노트 버전(RandomAgent)을 실행하긴 하여 Agent 수정 과정부터 있음\n\n\n\nclass Agent(RandomAgent):\n    def __init__(self):\n        super().__init__()\n        self.eps = 1.0 \n        self.q_net = torch.nn.Sequential(\n            torch.nn.Linear(8,256),\n            torch.nn.ReLU(),\n            torch.nn.Linear(256,128),\n            torch.nn.ReLU(),\n            torch.nn.Linear(128,64),\n            torch.nn.ReLU(),\n            torch.nn.Linear(64,4)\n        )\n        self.optimizr = torch.optim.Adam(self.q_net.parameters())\n    def act(self):\n        if random.random() &lt; self.eps: \n            self.action = self.action_spcae.sample()\n        else:\n            state = torch.tensor(self.state)\n            self.action = self.q_net(state).argmax().item()\n    def learn(self):\n        if self.n_experieces &gt; 64:\n            for epoc in range(1):\n                memory = list(zip(self.states, self.actions, self.rewards, self.next_states, self.terminations))\n                mini_batch = random.sample(memory,64)\n                # step1-2 \n                loss = 0\n                for s,a,r,ss,tmd in mini_batch:\n                    q_hat = self.q_net(s)[a]\n                    if tmd: \n                        q = r \n                    else: \n                        future = self.q_net(ss).max().data \n                        q = r + 0.99 * future\n                    loss = loss + (q_hat-q)**2\n                loss = loss / 64\n                # step3\n                loss.backward()\n                # step4 \n                self.optimizr.step()\n                self.optimizr.zero_grad()        \n\n\n짝수번째마다 출력을 하고 싶음\n오래 걸리므로 일단 20번만\n이외 추가된 내용\n\nstep4 playtime = 0, break\n\n\n\nenv = gym.make(\"LunarLander-v3\", render_mode = \"rgb_array\")\nplayer = Agent()\nplayer.state, _ = env.reset()\nscore = 0\nscores = []\nplaytime = 0\nplaytimes = []\n#---#\nfor e in range(1,21):\n    #---에피소드시작---#\n    while True:\n        # step1\n        player.act()\n        # step2\n        player.next_state, player.reward, player.terminated, player.truncated, _ = env.step(player.action)\n        # step3\n        player.save_experience()\n        player.learn()\n        # step4\n        if player.terminated or player.truncated:\n            score = score + player.reward\n            scores.append(score)\n            score = 0\n            playtimes.append(playtime)\n            playtime = 0\n            player.state, _ = env.reset()\n            break\n        else:\n            score = score + player.reward\n            playtime = playtime + 1\n            player.state = player.next_state\n    #---에피소드끝---#\n    player.eps = player.eps * 0.995\n    if (e % 2) == 0:\n        print(\n            f\"에피소드{e}\\t\",\n            f\"경험: {player.n_experieces}\\t\",\n            f\"점수(평균): {np.mean(scores[-100:]):.2f}\\t\", # 최근 100번만\n            f\"게임시간(평균): {np.mean(playtimes[-100:]):.2f}\\t\",\n            f\"돌발행동: {player.eps:.2f}\\t\",\n        )\n\n에피소드2    경험: 212     점수(평균): -386.56     게임시간(평균): 105.00    돌발행동: 0.99 \n에피소드4    경험: 396     점수(평균): -261.93     게임시간(평균): 98.00     돌발행동: 0.98 \n에피소드6    경험: 564     점수(평균): -226.24     게임시간(평균): 93.00     돌발행동: 0.97 \n에피소드8    경험: 801     점수(평균): -222.69     게임시간(평균): 99.12     돌발행동: 0.96 \n에피소드10   경험: 945     점수(평균): -212.39     게임시간(평균): 93.50     돌발행동: 0.95 \n에피소드12   경험: 1138    점수(평균): -193.89     게임시간(평균): 93.83     돌발행동: 0.94 \n에피소드14   경험: 1358    점수(평균): -184.52     게임시간(평균): 96.00     돌발행동: 0.93 \n에피소드16   경험: 1570    점수(평균): -180.59     게임시간(평균): 97.12     돌발행동: 0.92 \n에피소드18   경험: 1732    점수(평균): -174.40     게임시간(평균): 95.22     돌발행동: 0.91 \n에피소드20   경험: 1936    점수(평균): -170.77     게임시간(평균): 95.80     돌발행동: 0.90 \n\n\n\n# env = gym.make(\"LunarLander-v3\", render_mode = \"rgb_array\")\n# player = Agent()\n# player.state, _ = env.reset()\n# score = 0\n# scores = []\n# playtime = 0\n# playtimes = []\n# #---#\n# for e in range(1,2001):\n#     #---에피소드시작---#\n#     while True:\n#         # step1\n#         player.act()\n#         # step2\n#         player.next_state, player.reward, player.terminated, player.truncated, _ = env.step(player.action)\n#         # step3\n#         player.save_experience()\n#         player.learn()\n#         # step4\n#         if player.terminated or player.truncated:\n#             score = score + player.reward\n#             scores.append(score)\n#             score = 0\n#             playtimes.append(playtime)\n#             playtime = 0\n#             player.state, _ = env.reset()\n#             break\n#         else:\n#             score = score + player.reward\n#             playtime = playtime + 1\n#             player.state = player.next_state\n#     #---에피소드끝---#\n#     player.eps = player.eps * 0.995\n#     if (e % 2) == 0:\n#         print(\n#             f\"에피소드{e}\\t\",\n#             f\"경험: {player.n_experieces}\\t\",\n#             f\"점수(평균): {np.mean(scores[-100:]):.2f}\\t\", # 최근 100번만\n#             f\"게임시간(평균): {np.mean(playtimes[-100:]):.2f}\\t\",\n#             f\"돌발행동: {player.eps:.2f}\\t\",\n#         )\n#     if np.mean(scores[-100:]) &gt; 200:\n#         print(\"--루나랜더 클리어(2025.06.17.)--\")\n#         break\n\n\n🔬\n\n실행하였으나 시간이 지나자 결과가 원상 복귀 되어 일단 보류\n\n에피소드2 경험: 173 점수(평균): -213.37 게임시간(평균): 85.50 돌발행동: 0.99\n에피소드168 경험: 22060 점수(평균): -69.89 게임시간(평균): 150.31 돌발행동: 0.43\n에피소드226 경험: 44217 점수(평균): -45.61 게임시간(평균): 288.84 돌발행동: 0.32\n에피소드306 경험: 79354 점수(평균): -63.40 게임시간(평균): 433.97 돌발행동: 0.22\n에피소드322 경험: 86479 점수(평균): -80.99 게임시간(평균): 452.58 돌발행동: 0.20\n에피소드382 경험: 106714 점수(평균): -200.86 게임시간(평균): 402.77 돌발행동: 0.15\n에피소드416 경험: 123862 점수(평균): -264.81 게임시간(평균): 406.12 돌발행동: 0.12\n\n한 번 더 해봤는데 비슷한 결과\n\n에피소드10 경험: 821 점수(평균): -188.66 게임시간(평균): 81.10 돌발행동: 0.95\n에피소드110 경험: 11691 점수(평균): -108.81 게임시간(평균): 107.70 돌발행동: 0.58\n에피소드270 경험: 59490 점수(평균): -4.08 게임시간(평균): 387.21 돌발행동: 0.26\n에피소드330 경험: 82537 점수(평균): -59.13 게임시간(평균): 410.44 돌발행동: 0.19\n에피소드400 경험: 103908 점수(평균): -197.65 게임시간(평균): 337.59 돌발행동: 0.13\n\n\n\n)🗣️\n\nenv = gym.make(\"LunarLander-v3\", render_mode = \"rgb_array\")\nplayer = Agent()\nplayer.state, _ = env.reset()\nscore = 0\nplaytime = 0\nscores = [] \nplaytimes = []\n#---#\nfor e in range(1,2001):\n    #---에피소드시작---#\n    while True:\n        #step1\n        player.act()\n        #step2\n        player.next_state, player.reward, player.terminated, player.truncated, _ = env.step(player.action)\n        #step3\n        player.save_experience()\n        player.learn()\n        #step4\n        if player.terminated or player.truncated:\n            score = score + player.reward\n            scores.append(score)\n            score = 0\n            playtimes.append(playtime)\n            playtime = 0\n            player.state, _ = env.reset()\n            break\n        else: \n            score = score + player.reward\n            playtime = playtime + 1 \n            player.state = player.next_state\n    #---에피소드끝---#\n    player.eps = player.eps * 0.995\n    if (e % 50) ==0:\n        print(\n            f\"에피소드: {e}\\t\",\n            f\"경험: {player.n_experieces}\\t\",\n            f\"점수(평균): {np.mean(scores[-100:]):.2f}\\t\",\n            f\"게임시간(평균): {np.mean(playtimes[-100:]):.2f}\\t\",\n            f\"돌방행동: {player.eps:.2f}\\t\",\n        )\n    if np.mean(scores[-100:]) &gt; 200:\n        print(\"--루나랜더 클리어(2025.06.14.)--\")\n        break\n\n에피소드: 50     경험: 5568    점수(평균): -126.60     게임시간(평균): 110.36    돌방행동: 0.78 \n\n\n\n아래코드 실행하면 제가 실습에 사용한 파일 받아올수있어요\n!wget https://github.com/guebin/DL2025/raw/main/posts/q_net.pth\n\n\nplayer_dummy = Agent()\nplayer_dummy.q_net.load_state_dict(\n    torch.load(\"q_net.pth\")\n)\nplayer_dummy.state, _ = env.reset()\nimgs = []\n\n\nplayer_dummy.eps = 0 \nwhile True:\n    player_dummy.act()\n    player_dummy.next_state, player_dummy.reward, player_dummy.terminated, player_dummy.truncated, _ = env.step(player_dummy.action)\n    imgs.append(env.render())\n    if player_dummy.terminated or player_dummy.truncated:\n        break\n    else:\n        player_dummy.state = player_dummy.next_state\n\n\nshow(imgs)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n🗣️(\n\n만약 학습이 잘 되었다면\n\n\n# list(player.q_net.parameters()) # 여기에 값들이 잘 저장되어 있음\n\n\n저장 방법\n\n\n# player.q_net.state_dict() # 이러한 함수가 있음\n\n\n# torch.save(player.q_net.state_dict(), \"test.pth\")\n\nplayer_dummy = Agent()\nplayer_dummy.q_net.load_state_dict(\n    torch.load(\"test.pth\")\n)\nplayer_dummy.state, _ = env.reset()\nimgs = []\n\ndummy에도 같은 값이 있음\nq_net으로 해보면\n\n\nplayer_dummy = Agent()\nplayer_dummy.q_net.load_state_dict(\n    torch.load(\"q_net.pth\")\n)\nplayer_dummy.state, _ = env.reset()\nimgs = []\n\n\nplayer_dummy.eps = 0 \nwhile True:\n    player_dummy.act()\n    player_dummy.next_state, player_dummy.reward, player_dummy.terminated, player_dummy.truncated, _ = env.step(player_dummy.action)\n    imgs.append(env.render())\n    if player_dummy.terminated or player_dummy.truncated:\n        break\n    else:\n        player_dummy.state = player_dummy.next_state\n\n\nshow(imgs)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\nenv.reset()이 실행되어 환경이 바뀌어도 잘 됨\n\n)🗣️"
  },
  {
    "objectID": "posts/03wk-2.html",
    "href": "posts/03wk-2.html",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "",
    "text": "📘 Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\n📝 🗣️ ✍️ 🔬 ❓"
  },
  {
    "objectID": "posts/03wk-2.html#a.-로지스틱-모형",
    "href": "posts/03wk-2.html#a.-로지스틱-모형",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "A. 로지스틱 모형",
    "text": "A. 로지스틱 모형\n- \\(x\\)가 커질수록 (혹은 작아질수록) \\(y=1\\)이 잘나오는 모형은 아래와 같이 설계할 수 있음 &lt;— 외우세요!!!\n\n\\(y_i \\sim {\\cal B}(\\pi_i),\\quad\\) where \\(\\pi_i = \\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)} = \\frac{1}{1+\\exp(-w_0-w_1x_i)}\\)\n\\(\\hat{y}_i= \\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\frac{1}{1+\\exp(-\\hat{w}_0-\\hat{w}_1x_i)}\\)\n\n- 회귀모형과 로지스틱 모형의 비교\n\n회귀모형: \\(y_i \\sim {\\cal N}(w_0+w_1x_i, \\sigma^2)\\)1\n로지스틱: \\(y_i \\sim {\\cal B}\\big(\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\big)\\)\n\n- 우리가 예측하고 싶은것\n\n회귀모형: 정규분포의 평균을 예측하고 싶음. 즉 \\(w_0+w_1x_i\\)를 예측하고 싶음. 예측값으로는 \\(\\hat{w}_0 + \\hat{w}_1x_i\\)를 사용!\n로지스틱: 베르누이의 평균을 예측하고 싶음. 즉 \\(\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\)를 예측하고 싶음. 예측값으로는 \\(\\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}\\)를 사용!"
  },
  {
    "objectID": "posts/03wk-2.html#b.-데이터-스펙과-취업",
    "href": "posts/03wk-2.html#b.-데이터-스펙과-취업",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "B. 데이터 – 스펙과 취업",
    "text": "B. 데이터 – 스펙과 취업\n🗣️(\n\n데이터 만들기\n\n\ntorch.linspace(-1,1,2000)\n\ntensor([-1.0000, -0.9990, -0.9980,  ...,  0.9980,  0.9990,  1.0000])\n\n\n\nlen(torch.linspace(-1,1,2000))\n\n2000\n\n\n\nx = torch.linspace(-1,1,2000).reshape(2000,1)\nx\n\ntensor([[-1.0000],\n        [-0.9990],\n        [-0.9980],\n        ...,\n        [ 0.9980],\n        [ 0.9990],\n        [ 1.0000]])\n\n\n\n이 상태에서 선형 변환을 한다면\n\n-1 + x*5 : 선형 모델\n로지스틱 모형은\n\n\n\nx = torch.linspace(-1,1,2000).reshape(2000,1)\nprob = torch.exp(-1 + x*5) / (1+ torch.exp(-1 + x*5))\nplt.plot(x,prob)\n\n\n\n\n\n\n\n\n\n다른 방법 (보기 좋게)\n\n\nx = torch.linspace(-1,1,2000).reshape(2000,1)\nw0, w1 = -1, 5\nprob = torch.exp(w0 + x*w1) / (1+ torch.exp(w0 + x*w1))\nplt.plot(x,prob)\n\n\n\n\n\n\n\n\n\nprob\n\ntensor([[0.0025],\n        [0.0025],\n        [0.0025],\n        ...,\n        [0.9818],\n        [0.9819],\n        [0.9820]])\n\n\n\nprob.shape\n\ntorch.Size([2000, 1])\n\n\n\ny 만들기 (prob로 베르누이 시행)\n\n\ntorch.bernoulli(prob)\n\ntensor([[0.],\n        [0.],\n        [0.],\n        ...,\n        [1.],\n        [1.],\n        [1.]])\n\n\n\ntorch.bernoulli(prob).shape\n\ntorch.Size([2000, 1])\n\n\n\nseed 고정 후 시각화\n\n\ntorch.manual_seed(43052)\nx = torch.linspace(-1,1,2000).reshape(2000,1)\nw0, w1 = -1, 5\nprob = torch.exp(w0 + x*w1) / (1+ torch.exp(w0 + x*w1))\ny = torch.bernoulli(prob)\n\n\nplt.plot(x,y) # 보기 쉽지는 않음 \n\n\n\n\n\n\n\n\n\nplt.plot(x,y, 'o') # 점들이 너무 많이 겹침\n\n\n\n\n\n\n\n\n\nplt.plot(x,y,'.',alpha=0.03) # 투명도 조절\n\n\n\n\n\n\n\n\n\nx가 증가할수록 y는 1이 나올 가능성이 높아지고\nx가 감소할수록 y는 0이 나올 가능성이 높아짐\n\n\nplt.plot(x,y,'.',alpha=0.03) # 관측(error 포함)\nplt.plot(x,prob,'--') # 실체 데이터에서는 관측 불가능 (error-free structure)\n\n\n\n\n\n\n\n\n)🗣️\n\ntorch.manual_seed(43052)\nx = torch.linspace(-1,1,2000).reshape(2000,1)\nw0,w1 = -1, 5\nprob = torch.exp(w0+w1*x) / (1+torch.exp(w0+w1*x)) \ny = torch.bernoulli(prob)\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x[0],y[0],'.',label=r\"$(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--r',label=r\"prob (true, unknown) = $\\frac{exp(-1+5x)}{1+exp(-1+5x)}$\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n🗣️\n\nprob: 확률\n파란색 점: 관측값\n목표: 빨간색 선 잘 맞추기\n\n방법: 최초의 곡선을 그리고 update"
  },
  {
    "objectID": "posts/03wk-2.html#c.-step1-net-설계-모델링",
    "href": "posts/03wk-2.html#c.-step1-net-설계-모델링",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "C. Step1: net 설계 (모델링)",
    "text": "C. Step1: net 설계 (모델링)\n- 최초의 곡선을 그려보자.\n\n최초의직선: \\(\\hat{y}_i= \\hat{w}_0+\\hat{w}_1x_i\\) 에서 아무 \\(\\hat{w}_0\\), \\(\\hat{w}_1\\) 을 설정하면 된다.\n최초의곡선: \\(\\hat{y}_i= \\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\frac{1}{1+\\exp(-\\hat{w}_0-\\hat{w}_1x_i)}\\) 에서 아무 \\(\\hat{w}_0\\), \\(\\hat{w}_1\\) 을 설정하면 된다.\n\n\n\n\n\n\n\nNote\n\n\n\n일단은 초기 설정값을 \\(\\hat{w}_0 = -0.8\\), \\(\\hat{w}_1 = -0.3\\) 으로 하자. (실제값은 \\(w_0=-1\\), \\(w_1=5\\) 이다)\n\n\n# 방법1 – l1, sigmoid\n🗣️(\n\nw0hat = -4\nw1hat = 10\nyhat = torch.exp(w0hat + w1hat*x) / (1+ torch.exp(w0hat + w1hat*x))\n\n\nyhat\n\ntensor([[8.3153e-07],\n        [8.3989e-07],\n        [8.4833e-07],\n        ...,\n        [9.9748e-01],\n        [9.9750e-01],\n        [9.9753e-01]])\n\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x, yhat, '--')\n\n\n\n\n\n\n\n\n\nyhat을 다음과 같이 할 수도 있음\n\n\nlinr = torch.nn.Linear(1,1)\n# linr(x)\n\n\ndef sigmoid(x):\n    return torch.exp(x) / (1+ torch.exp(x)) #  편의상 linr(x) 대신 x로 작성\n\n\nlinr(x)\n\ntensor([[ 0.6311],\n        [ 0.6304],\n        [ 0.6297],\n        ...,\n        [-0.6902],\n        [-0.6909],\n        [-0.6916]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\nyhat = sigmoid(linr(x))\nplt.plot(x, yhat.data) # 곡선 중 일부만 그려져 직선처럼 보임\n\n\n\n\n\n\n\n\n\nlinr(x)가 계산되는 과정\n\n\nlinr.weight, linr.bias\n\n(Parameter containing:\n tensor([[-0.6613]], requires_grad=True),\n Parameter containing:\n tensor([-0.0303], requires_grad=True))\n\n\n\n-0.6613*x + -0.0303\n\ntensor([[ 0.6310],\n        [ 0.6303],\n        [ 0.6297],\n        ...,\n        [-0.6903],\n        [-0.6909],\n        [-0.6916]])\n\n\n\n값을 아까처럼 지정해주면\n\n\nlinr.weight.data = torch.tensor([[10.0]])\nlinr.bias.data = torch.tensor([-4.0])\n\n❓ bias는 [[-4.0]]이 아니라 [-4.0]\n🔬(\n\nlinr.weight.data = torch.tensor([[10.0]])\nlinr.bias.data = torch.tensor([[-4.0]])\n\n\nlinr(x)\n\ntensor([[-14.0000],\n        [-13.9900],\n        [-13.9800],\n        ...,\n        [  5.9800],\n        [  5.9900],\n        [  6.0000]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n❓ 상관없는듯?\n\nlinr.weight.data = torch.tensor([10.0])\nlinr.bias.data = torch.tensor([[-4.0]])\n\n\n# linr(x) # error: RuntimeError: mat2 must be a matrix, got 1-D tensor\n\n)🔬\n🔬 참고) -4.0이 아니라 -4를 쓰면 error\n\nlinr.weight.data = torch.tensor([[10.0]])\nlinr.bias.data = torch.tensor([-4.0])\n\n\nlinr(x)\n\ntensor([[-14.0000],\n        [-13.9900],\n        [-13.9800],\n        ...,\n        [  5.9800],\n        [  5.9900],\n        [  6.0000]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\nw0hat + w1hat*x # 위와 동일\n\ntensor([[-14.0000],\n        [-13.9900],\n        [-13.9800],\n        ...,\n        [  5.9800],\n        [  5.9900],\n        [  6.0000]])\n\n\n\n-4*x + 10 # 이것도 동일\n\ntensor([[14.0000],\n        [13.9960],\n        [13.9920],\n        ...,\n        [ 6.0080],\n        [ 6.0040],\n        [ 6.0000]])\n\n\n\n다시 정리하면\n\n\ndef sigmoid(x):\n    return torch.exp(x) / (1+ torch.exp(x)) #  편의상 linr(x) 대신 x로 작성\n\n\nl1 = torch.nn.Linear(1,1)\nl1.weight.data = torch.tensor([[10.0]])\nl1.bias.data = torch.tensor([-4.0])\n#yhat = torch.exp(l1(x)) / (1+ torch.exp(l1(x)))\nyhat = sigmoid(l1(x))\n\n\nplt.plot(x,yhat.data)\n\n\n\n\n\n\n\n\n\n값을 바꾸고 싶으면\n\n\nl1 = torch.nn.Linear(1,1)\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\n#yhat = torch.exp(l1(x)) / (1+ torch.exp(l1(x)))\nyhat = sigmoid(l1(x))\n\n\nplt.plot(x,yhat.data)\n\n\n\n\n\n\n\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x, yhat.data, '--')\n\n\n\n\n\n\n\n\n)🗣️\n\nl1 = torch.nn.Linear(1,1)\nl1(x) # w0hat + w1hat*x \n\ntensor([[ 0.4735],\n        [ 0.4728],\n        [ 0.4721],\n        ...,\n        [-0.9890],\n        [-0.9897],\n        [-0.9905]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n🗣️ 실행할 때마다 달라지므로 아래와 같이 고정\n\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\n\n\ndef sigmoid(x):\n    return torch.exp(x)/(1+torch.exp(x))\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x[0],y[0],'o',label=r\"$(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--r',label=r\"prob (true, unknown) = $\\frac{exp(-1+5x)}{1+exp(-1+5x)}$\")\nplt.plot(x,sigmoid(l1(x)).data,'--b', label=r\"prob (estimated) = $(x_i,\\hat{y}_i)$ -- first curve\")\nplt.legend()\n\n\n\n\n\n\n\n\n#\n# 방법2 – l1, a1\n🗣️(\nx -&gt; w0hat + w1hat*x  # 최초의 곡선을 그리기 위한 선형 변환\nu = w0hat + w1hat*x  # 결과를 u로 저장\nfirst_curve = yhat = prob_hat = sigmoid(u)\nu = w0hat + w1hat*x = l1(x) # l1을 만든다면 이렇게도 쓸 수 있음\nl1 = torch.nn.Linear(1,1)\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\nu = l1(x)\nyhat = sigmoid(u)\n\nsigmoid는 직접 만들었음\n\n\nsigmoid?\n\n\nSignature: sigmoid(x)\nDocstring: &lt;no docstring&gt;\nFile:      /tmp/ipykernel_30452/3273882758.py\nType:      function\n\n\n\n\nsigmoid??\n\n\nSignature: sigmoid(x)\nDocstring: &lt;no docstring&gt;\nSource:   \ndef sigmoid(x):\n    return torch.exp(x)/(1+torch.exp(x))\nFile:      /tmp/ipykernel_30452/3273882758.py\nType:      function\n\n\n\n\n다음과 같이도 할 수 있음 (torch.nn의 클래스 이용)\n\n\nsig = torch.nn.Sigmoid()\nsig\n\nSigmoid()\n\n\n\nl1 = torch.nn.Linear(1,1)\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\nu = l1(x)\nyhat = sig(u)\n\n\nyhat\n\ntensor([[0.3775],\n        [0.3775],\n        [0.3774],\n        ...,\n        [0.2499],\n        [0.2498],\n        [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\nl1 = torch.nn.Linear(1,1)\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\nyhat = sig(l1(x)) # x --&gt; l1 --&gt; sig 로 이해\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x[0],y[0],'o',label=r\"$(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--r',label=r\"prob (true, unknown) = $\\frac{exp(-1+5x)}{1+exp(-1+5x)}$\")\nplt.plot(x,sigmoid(l1(x)).data,'--b', label=r\"prob (estimated) = $(x_i,\\hat{y}_i)$ -- first curve\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n방법1과 동일한 결과\n\n)🗣️\n\nl1 = torch.nn.Linear(1,1)\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\n\n\na1 = torch.nn.Sigmoid()\n\n\nsigmoid(l1(x)), a1(l1(x)) # 똑같아요\n\n(tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;DivBackward0&gt;),\n tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;))\n\n\n- 지금까지의 구현 확인\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x[0],y[0],'o',label=r\"$(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--r',label=r\"prob (true, unknown) = $\\frac{exp(-1+5x)}{1+exp(-1+5x)}$\")\nplt.plot(x,a1(l1(x)).data,'--b', label=r\"prob (estimated) = $(x_i,\\hat{y}_i)$ -- first curve with $(a_1 \\circ l_1)(x)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n#\n# 방법3 - l1, a1 만들고 \\(\\to\\) net\n🗣️(\n\nyhat\n\ntensor([[0.3775],\n        [0.3775],\n        [0.3774],\n        ...,\n        [0.2499],\n        [0.2498],\n        [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\na1(l1(x))\n\ntensor([[0.3775],\n        [0.3775],\n        [0.3774],\n        ...,\n        [0.2499],\n        [0.2498],\n        [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\nnet = al \\(\\circ\\) l1 을 정의하여 net(x)도 같은 결과를 나오게 하고 싶음\n\n\ntorch.nn.Sequential(l1,a1)\n\nSequential(\n  (0): Linear(in_features=1, out_features=1, bias=True)\n  (1): Sigmoid()\n)\n\n\n\nnet = torch.nn.Sequential(l1,a1)\nnet(x) # a1(l1(x))\n\ntensor([[0.3775],\n        [0.3775],\n        [0.3774],\n        ...,\n        [0.2499],\n        [0.2498],\n        [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\n이렇게 한 이유: parameters()를 이용하여 optimizer를 만들 수 있음\n\n\nnet.parameters()\n\n&lt;generator object Module.parameters at 0x7f34682a17b0&gt;\n\n\n)🗣️\n- 관찰: 지금 아래의 구조이다.\n\\[{\\bf x} \\overset{l_1}{\\to} {\\bf u} \\overset{a_1}{\\to} {\\bf v} = \\hat{\\bf y}\\]\n- 소망: 함수 \\(l_1, a_1\\) 의 합성을 하나로 묶어서\n\\[(a_1\\circ l_1)({\\bf x}) := net({\\bf x})\\]\n이러한 기능을 하는 하나의 함수 \\(net\\)을 만들 수 없을까?\n\nl1 = torch.nn.Linear(1,1)\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\na1 = torch.nn.Sigmoid()\n\n\nnet = torch.nn.Sequential(l1,a1) #l1을 취하고 그다음에 a1을 취하라는 의미\n\n\nnet(x), a1(l1(x)), sigmoid(l1(x))\n\n(tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;),\n tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;),\n tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;DivBackward0&gt;))\n\n\n* net 구조 잠깐 살펴보기\n🗣️(\n\nnet\n\nSequential(\n  (0): Linear(in_features=1, out_features=1, bias=True)\n  (1): Sigmoid()\n)\n\n\n\nnet[0]\n\nLinear(in_features=1, out_features=1, bias=True)\n\n\n\nl1\n\nLinear(in_features=1, out_features=1, bias=True)\n\n\n\nnet[1]\n\nSigmoid()\n\n\n\naaa = torch.nn.Sigmoid()\naaa\n\nSigmoid()\n\n\n\nnet가 리스트처럼 되어 있어 첫번째 원소 net[0]은 l1 이고 두번째 원소 net[1]은 aaa인듯\n확인 방법: 아래\n\n\nl1 is net[0]\n\nTrue\n\n\n\na1 is net[1]\n\nTrue\n\n\n\n다른 확인 방법\n\n오브젝트: 메모리에 저장\n저장되어 있는 주소가 동일하면 같은 오브젝트\n\n\n\nid(net[0]), id(l1)\n\n(139863062109248, 139863062109248)\n\n\n\nid(net[1]), id(a1)\n\n(139863062108960, 139863062108960)\n\n\n\nnet(x), a1(l1(x))\n\n(tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;),\n tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;))\n\n\n\nnet(x), net[1](net[0](x)) # 이것도 동일\n\n(tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;),\n tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;))\n\n\n)🗣️\n\nnet[0], net[1]\n\n(Linear(in_features=1, out_features=1, bias=True), Sigmoid())\n\n\n\nl1 is net[0]\n\nTrue\n\n\n\na1 is net[1]\n\nTrue\n\n\n#\n# 방법4 – net을 바로 만들기\n🗣️(\n# x --&gt; yhat: 회귀분석에서 최초의 직선 바로 만드는 방법\nnet = torch.nn.Linear(1,1)\nyhat - net(x)\n# x --&gt; yhat: 로지스틱에서 최초의 곡선 바로 만드는 방법\nnet = torch.nn.Sequential(\n    l1,\n    a1\n)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nyhat = net(x)\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nyhat = net(x)\n\n\nnet[0].weight # 아무 parameter가 들어가 있음\n\nParameter containing:\ntensor([[0.4945]], requires_grad=True)\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nnet[0].weight.data = torch.tensor([[-0.3]])\nnet[0].bias.data = torch.tensor([-0.8])\nyhat = net(x)\n\n\nnet(x)\n\ntensor([[0.3775],\n        [0.3775],\n        [0.3774],\n        ...,\n        [0.2499],\n        [0.2498],\n        [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n)🗣️\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nnet[0].weight.data = torch.tensor([[-0.3]])\nnet[0].bias.data = torch.tensor([-0.8])\nyhat = net(x)\n\n\nnet(x)\n\ntensor([[0.3775],\n        [0.3775],\n        [0.3774],\n        ...,\n        [0.2499],\n        [0.2498],\n        [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n🗣️ 결론: 위의 방법으로 사용하면 됨\n#"
  },
  {
    "objectID": "posts/03wk-2.html#d.-step14",
    "href": "posts/03wk-2.html#d.-step14",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "D. Step1~4",
    "text": "D. Step1~4\n🗣️(\n\n학습 시작\n\n\nplt.plot(x,y,'.',alpha=0.03) # given data\n\n\n\n\n\n\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nnet[0].weight.data = torch.tensor([[-0.3]])\nnet[0].bias.data = torch.tensor([-0.8])\nyhat = net(x)\n\n\nplt.plot(x,y,'.',alpha=0.03) # given data\nplt.plot(x,net(x).data, '--') # 최초의 곡선 그리기\n\n\n\n\n\n\n\n\n\n최초의 곡선보다 나은 곡선을 찾으며 update하면 됨\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nnet[0].weight.data = torch.tensor([[-0.3]])\nnet[0].bias.data = torch.tensor([-0.8])\nyhat = net(x)\nloss = torch.mean((y-yhat)**2) # loss 함수를 만들어 줌\nloss\n\ntensor(0.2747, grad_fn=&lt;MeanBackward0&gt;)\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nnet[0].weight.data = torch.tensor([[-0.3]])\nnet[0].bias.data = torch.tensor([-0.8])\noptimizr = torch.optim.SGD(net.parameters(), lr=0.25)\nfor epoc in range(200):\n    yhat = net(x)\n    loss = torch.mean((y-yhat)**2)\n    loss.backward() # 미분\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x,net(x).data, '--')\n\n\n\n\n\n\n\n\n\n최초의 곡선보다는 그럴듯해짐\n알고 있는 True 값과 비교해보면\n\n주황색 선: True\n200번 정도 반복하니 어느 정도 온 것 같지만 딱 맞다고 보기는 어려움\n\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x,prob,'--')\nplt.plot(x,net(x).data, '--')\n\n\n\n\n\n\n\n\n\n200번 더 (총 400번)\n\n\nfor epoc in range(200):\n    yhat = net(x)\n    loss = torch.mean((y-yhat)**2)\n    loss.backward() # 미분\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x,prob,'--')\nplt.plot(x,net(x).data, '--')\n\n\n\n\n\n\n\n\n\n200번 더 (총 600번)\n\n\nfor epoc in range(200):\n    yhat = net(x)\n    loss = torch.mean((y-yhat)**2)\n    loss.backward() # 미분\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x,prob,'--')\nplt.plot(x,net(x).data, '--')\n\n\n\n\n\n\n\n\n\n200번 더 (총 800번)\n\n\nfor epoc in range(200):\n    yhat = net(x)\n    loss = torch.mean((y-yhat)**2)\n    loss.backward() # 미분\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x,prob,'--')\nplt.plot(x,net(x).data, '--')\n\n\n\n\n\n\n\n\n\n돌릴수록 가까워질 것 같음\n\n)🗣️\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net \nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,prob,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')\n\n\n\n\n\n\n\n\n\n\nfor epoc in range(4900):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,prob,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 5000 epochs')\n\nText(0.5, 1.0, 'after 5000 epochs')\n\n\n\n\n\n\n\n\n\n🗣️ 로지스틱이 해결된 것처럼 보임\n🗣️(\n\n다음과 같이 해도 마찬가지 (초기값은 크게 중요하지 않으므로)\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\n# l1, a1 = net \n# l1.weight.data = torch.tensor([[-0.3]])\n# l1.bias.data = torch.tensor([-0.8])\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,prob,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')\n\n\n\n\n\n\n\n\n\n\nfor epoc in range(4900):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,prob,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 5000 epochs')\n\nText(0.5, 1.0, 'after 5000 epochs')\n\n\n\n\n\n\n\n\n\n\n성공한 것 같지만 실상은 그렇지 않음\n\nfor epoc in range(4900):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((y-yhat)**2) # 이 부분에 문제가 있어 설명할 예정\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n)🗣️"
  },
  {
    "objectID": "posts/03wk-2.html#a.-시각화를-위한-준비",
    "href": "posts/03wk-2.html#a.-시각화를-위한-준비",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "A. 시각화를 위한 준비",
    "text": "A. 시각화를 위한 준비\n\ndef plot_loss(loss_fn, ax=None, Wstar=[-1,5]):\n    w0hat,w1hat =torch.meshgrid(torch.arange(-10,3,0.1),torch.arange(-1,10,0.1),indexing='ij')\n    w0hat = w0hat.reshape(-1)\n    w1hat = w1hat.reshape(-1)\n    def l(w0hat,w1hat):\n        yhat = torch.exp(w0hat+w1hat*x)/(1+torch.exp(w0hat+w1hat*x))\n        return loss_fn(yhat,y) \n    loss = list(map(l,w0hat,w1hat))\n    #---#\n    if ax is None: \n        fig = plt.figure()\n        ax = fig.add_subplot(1,1,1,projection='3d')\n    ax.scatter(w0hat,w1hat,loss,s=0.001) \n    ax.scatter(w0hat[::20],w1hat[::20],loss[::20],s=0.1,color='C0') \n    w0star,w1star = np.array(Wstar).reshape(-1)\n    ax.scatter(w0star,w1star,l(w0star,w1star),s=200,marker='*',color='red',label=f\"W=[{w0star:.1f},{w1star:.1f}]\")\n    #---#\n    ax.elev = 15\n    ax.dist = -20\n    ax.azim = 75    \n    ax.legend()\n    ax.set_xlabel(r'$w_0$')  # x축 레이블 설정\n    ax.set_ylabel(r'$w_1$')  # y축 레이블 설정\n    ax.set_xticks([-10,-5,0])  # x축 틱 간격 설정\n    ax.set_yticks([-10,0,10])  # y축 틱 간격 설정\n\n\ndef _learn_and_record(net, loss_fn, optimizr):\n    yhat_history = [] \n    loss_history = []\n    What_history = []\n    Whatgrad_history = []\n    What_history.append([net[0].bias.data.item(), net[0].weight.data.item()])\n    for epoc in range(100): \n        ## step1 \n        yhat = net(x)\n        ## step2 \n        loss = loss_fn(yhat,y)\n        ## step3\n        loss.backward() \n        ## step4 \n        optimizr.step()\n        ## record \n        if epoc % 5 ==0: \n            yhat_history.append(yhat.reshape(-1).data.tolist())\n            loss_history.append(loss.item())\n            What_history.append([net[0].bias.data.item(), net[0].weight.data.item()])\n            Whatgrad_history.append([net[0].bias.grad.item(), net[0].weight.grad.item()])\n        optimizr.zero_grad() \n        \n    return yhat_history, loss_history, What_history, Whatgrad_history\n    \ndef show_animation(net, loss_fn, optimizr):\n    yhat_history,loss_history,What_history,Whatgrad_history = _learn_and_record(net,loss_fn,optimizr)\n    \n    fig = plt.figure(figsize=(7.5,3.5))\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n    ## ax1: 왼쪽그림 \n    ax1.scatter(x,y,alpha=0.01)\n    ax1.scatter(x[0],y[0],color='C0',label=r\"observed data = $(x_i,y_i)$\")\n    ax1.plot(x,prob,'--',label=r\"prob (true) = $(x_i,\\frac{exp(-1+5x_i)}{1+exp(-1+5x_i)})$\")    \n    line, = ax1.plot(x,yhat_history[0],'--',label=r\"prob (estimated) = $(x_i,\\hat{y}_i)$\") \n    ax1.legend()\n    ## ax2: 오른쪽그림 \n    plot_loss(loss_fn,ax2)\n    ax2.scatter(np.array(What_history)[0,0],np.array(What_history)[0,1],loss_history[0],color='blue',s=200,marker='*')    \n    def animate(epoc):\n        line.set_ydata(yhat_history[epoc])\n        w0hat = np.array(What_history)[epoc,0]\n        w1hat = np.array(What_history)[epoc,1]\n        w0hatgrad = np.array(Whatgrad_history)[epoc,0]\n        w1hatgrad = np.array(Whatgrad_history)[epoc,1]\n        ax2.scatter(w0hat,w1hat,loss_history[epoc],color='grey')\n        ax2.set_title(f\"What.grad=[{w0hatgrad:.4f},{w1hatgrad:.4f}]\",y=0.8)\n        fig.suptitle(f\"epoch={epoc*5} // What=[{w0hat:.2f},{w1hat:.2f}] // Loss={loss_fn.__class__.__name__} // Opt={optimizr.__class__.__name__}\")\n        return line\n    ani = animation.FuncAnimation(fig, animate, frames=20)    \n    plt.close()\n    return ani\n\n\nfrom matplotlib import animation\nplt.rcParams[\"animation.html\"] = \"jshtml\"\n\n함수사용법\n\nloss_fn = torch.nn.MSELoss()\nplot_loss(loss_fn)\n\n\n\n\n\n\n\n\n🗣️(\n\ndef loss_fn2(yhat,y):\n    return loss_fn(yhat,y)*2\n\n\nplot_loss(loss_fn2)\n\n\n\n\n\n\n\n\n\nz축만 2배 증가 (함수: 곡면을 그려주는 역할)\n\n\n# show_animation??\n\n\nSignature: show_animation(net, loss_fn, optimizr)\n\nnet: 초기 설정 값 (w0, w1)\nloss_fn: 그림\noptimizr: 학습 과정\n\n밑 코드: 어떠한 초기값을 받아 학습하는 과정을 그려줌\n\n실행할 때마다 초기값 달라짐\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n초기값 고정\n\n만약 학습률이 2.5면 더 빨리 떨어짐\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nnet[0].weight.data = torch.tensor([[-0.8]])\nnet[0].bias.data = torch.tensor([-0.3])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n)🗣️\n\ntorch.manual_seed(42)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n🗣️\n\n초기값에 따라 학습이 달라짐\n만약 초기 값이 우측 상단이라면 평평하기 때문에 update가 아주 조금씩 일어남"
  },
  {
    "objectID": "posts/03wk-2.html#b.-좋은-초기값",
    "href": "posts/03wk-2.html#b.-좋은-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "B. 좋은 초기값",
    "text": "B. 좋은 초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n🗣️\n\n이 경우는 기다리면 학습이 잘 될 거 같음"
  },
  {
    "objectID": "posts/03wk-2.html#c.-가능성-있는-초기값",
    "href": "posts/03wk-2.html#c.-가능성-있는-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "C. 가능성 있는 초기값",
    "text": "C. 가능성 있는 초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n🗣️\n\n마지막에 약간 희망이 보임\n마음 먹고 20,000번 정도 돌리면 될 거 같음"
  },
  {
    "objectID": "posts/03wk-2.html#d.-최악의-초기값",
    "href": "posts/03wk-2.html#d.-최악의-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "D. 최악의 초기값",
    "text": "D. 최악의 초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n🗣️\n\n이 경우는 희망이 없음\n곡선이 아래로 볼록한 2차 함수가 아니고 4차 함수라면 학습률과 초기 값에 따라 갖혀버릴 수도 있고 운에 따라 달라짐\n\n\n해결하는 접근법:\n\n컴공스타일: 에폭을 늘려볼까?\n산공스타일: 옵티마이저를 바꿔볼까?\n통계스타일: Loss를 바꿔볼까?\n🗣️\n\n초기 값을 바꿔가며 무수히 실행하며 찾음\n이 어려운 곡면에 대해 옵티마이저를 수정\n곡면 자체를 최적화가 잘 되게 바꿈 (loss 함수를 바꿈: MSE Loss 말고 다른 Loss?)"
  },
  {
    "objectID": "posts/03wk-2.html#a.-bce-loss를-사용하여-학습",
    "href": "posts/03wk-2.html#a.-bce-loss를-사용하여-학습",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "A. BCE Loss를 사용하여 학습",
    "text": "A. BCE Loss를 사용하여 학습\n- BCE loss라는게 있음.\n\n\\(loss= - \\sum_{i=1}^{n} \\big(y_i\\log(\\hat{y}_i)+(1-y_i)\\log(1-\\hat{y}_i)\\big)\\)\nhttps://en.wikipedia.org/wiki/Cross-entropy\n\n🗣️(\nyi = 0\nyi_hat = 0.001\nlog(1) = 0\nloss = 0\nyi = 0\nyi_hat = 0.9999\nlog(1-0.999) = log(0) = -무한대\nloss = 무한대\nyi = 1\nyi_hat = 1\nloss = 0\nyi = 1\nyi_hat = 0.0001\nloss = 무한대\n\n비슷할수록 0, 다를수록 무한대까지 감 -&gt; loss의 역할은 함\n원리: - log likelihoood\n\n)🗣️\n\n🗣️\n\nnet[0] = torch.nn.Linear(in_features=1, out_features=1)\nnet[1] = torch.nn.Sigmoid()\nnet = [net[0], net[1]] 느낌\nl1, a1 = [net[0], net[1]] 느낌\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net \nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    #loss = torch.mean((y-yhat)**2) # loss_fn(yhat,y)\n    loss = -torch.mean(y*torch.log(yhat) + (1-y)*torch.log(1-yhat))\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,prob,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')\n\n\n\n\n\n\n\n\n\n같은 100 에폭인데 훨씬 잘맞춤..\n🗣️ 동일한 초기 값\n- loss수식을 못외우겠다면?\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net \nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y) # yhat부터 써야함\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,prob,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')"
  },
  {
    "objectID": "posts/03wk-2.html#b.-loss-function-시각화",
    "href": "posts/03wk-2.html#b.-loss-function-시각화",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "B. Loss Function 시각화",
    "text": "B. Loss Function 시각화\n\nplot_loss(torch.nn.MSELoss())\n\n\n\n\n\n\n\n\n🗣️ MSELoss는 우측 상단에 있으면 안 될 것 같음\n\nplot_loss(torch.nn.BCELoss())\n\n\n\n\n\n\n\n\n- 비교해보자.\n\nfig = plt.figure()\nax1 = fig.add_subplot(1,2,1,projection='3d')\nax2 = fig.add_subplot(1,2,2,projection='3d')\nplot_loss(torch.nn.MSELoss(),ax1)\nplot_loss(torch.nn.BCELoss(),ax2)\n\n\n\n\n\n\n\n\n\n🗣️\n\n오른쪽과 같은 경우를 어려운 말로 convex function이라고 함\nloss 함수가 convex function이면 수렴시키기 쉬움"
  },
  {
    "objectID": "posts/03wk-2.html#c.-학습과정-시각화-좋은-초기값",
    "href": "posts/03wk-2.html#c.-학습과정-시각화-좋은-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "C. 학습과정 시각화 – 좋은 초기값",
    "text": "C. 학습과정 시각화 – 좋은 초기값\n- MSELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- BCELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n🗣️ 같은 초기값인데 BCELoss가 더 수렴을 잘 할 것 같음"
  },
  {
    "objectID": "posts/03wk-2.html#d.-학습과정-시각화-가능성-있는-초기값",
    "href": "posts/03wk-2.html#d.-학습과정-시각화-가능성-있는-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "D. 학습과정 시각화 – 가능성 있는 초기값",
    "text": "D. 학습과정 시각화 – 가능성 있는 초기값\n- MSELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- BCELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n🗣️ BCELoss는 처음부터 잘 떨어짐"
  },
  {
    "objectID": "posts/03wk-2.html#e.-학습과정-시각화-최악의-초기값",
    "href": "posts/03wk-2.html#e.-학습과정-시각화-최악의-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "E. 학습과정 시각화 – 최악의 초기값",
    "text": "E. 학습과정 시각화 – 최악의 초기값\n- MSELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- BCELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n🗣️ BCELoss는 처음부터 잘 떨어짐"
  },
  {
    "objectID": "posts/03wk-2.html#a.-학습과정-시각화-좋은-초기값",
    "href": "posts/03wk-2.html#a.-학습과정-시각화-좋은-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "A. 학습과정 시각화 – 좋은 초기값",
    "text": "A. 학습과정 시각화 – 좋은 초기값\n- MSELoss + SGD\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8470])\nnet[0].weight.data = torch.tensor([[-0.3467]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- MSELoss + Adam\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n🗣️ Adam을 사용하니 빨리 떨어지면서 잘 수렴함 (힘으로 미는 느낌)"
  },
  {
    "objectID": "posts/03wk-2.html#b.-학습과정-시각화-가능성-있는-초기값",
    "href": "posts/03wk-2.html#b.-학습과정-시각화-가능성-있는-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "B. 학습과정 시각화 – 가능성 있는 초기값",
    "text": "B. 학습과정 시각화 – 가능성 있는 초기값\n- MSELoss + SGD\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- MSELoss + Adam\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n🗣️ Adam을 사용하니 빨리 떨어지면서 잘 수렴함 (마지막은 살짝 돌아가는 느낌)"
  },
  {
    "objectID": "posts/03wk-2.html#c.-학습과정-시각화-최악의-초기값",
    "href": "posts/03wk-2.html#c.-학습과정-시각화-최악의-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "C. 학습과정 시각화 – 최악의 초기값",
    "text": "C. 학습과정 시각화 – 최악의 초기값\n- MSELoss + SGD\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.05) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- MSELoss + Adam\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n🗣️ Adam을 사용하니 빨리 떨어지면서 잘 수렴함 (내려오는 힘이 강해서 그런지 마지막은 살짝 돌다가 가는 느낌)\n🗣️ 현재 최적화를 잘하고 싶으면 Adam을 사용하면 됨"
  },
  {
    "objectID": "posts/03wk-2.html#d.-참고자료",
    "href": "posts/03wk-2.html#d.-참고자료",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "D. 참고자료",
    "text": "D. 참고자료\nhttps://www.youtube.com/watch?v=MD2fYip6QsQ\n\n11:50 – Momentum\n12:30 – RMSprop\n15:55 – Adam\n🗣️ local min과 global min이 따로 있을 때\n\n일반적인 경사하강법은 보통 local min에 빠짐\nAdam은 local min을 잘 탈출함 (항상은 X)"
  },
  {
    "objectID": "posts/03wk-2.html#a.-신문기사-데이터의-모티브",
    "href": "posts/03wk-2.html#a.-신문기사-데이터의-모티브",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "A. 신문기사 (데이터의 모티브)",
    "text": "A. 신문기사 (데이터의 모티브)\n- 스펙이 높아도 취업이 안된다고 합니다..\n중소·지방 기업 “뽑아봤자 그만두니까”\n중소기업 관계자들은 고스펙 지원자를 꺼리는 이유로 높은 퇴직률을 꼽는다. 여건이 좋은 대기업으로 이직하거나 회사를 관두는 경우가 많다는 하소연이다. 고용정보원이 지난 3일 공개한 자료에 따르면 중소기업 청년취업자 가운데 49.5%가 2년 내에 회사를 그만두는 것으로 나타났다.\n중소 IT업체 관계자는 “기업 입장에서 가장 뼈아픈 게 신입사원이 그만둬서 새로 뽑는 일”이라며 “명문대 나온 스펙 좋은 지원자를 뽑아놔도 1년을 채우지 않고 그만두는 사원이 대부분이라 우리도 눈을 낮춰 사람을 뽑는다”고 말했다."
  },
  {
    "objectID": "posts/03wk-2.html#b.-가짜데이터-스펙의-역설",
    "href": "posts/03wk-2.html#b.-가짜데이터-스펙의-역설",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "B. 가짜데이터 – 스펙의 역설",
    "text": "B. 가짜데이터 – 스펙의 역설\n🗣️ x: 스펙, prob: 합격할 확률\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2025/main/posts/ironyofspec.csv\")\ndf\n\n\n\n\n\n\n\n\nx\nprob\ny\n\n\n\n\n0\n-1.000000\n0.000045\n0.0\n\n\n1\n-0.998999\n0.000046\n0.0\n\n\n2\n-0.997999\n0.000047\n0.0\n\n\n3\n-0.996998\n0.000047\n0.0\n\n\n4\n-0.995998\n0.000048\n0.0\n\n\n...\n...\n...\n...\n\n\n1995\n0.995998\n0.505002\n0.0\n\n\n1996\n0.996998\n0.503752\n0.0\n\n\n1997\n0.997999\n0.502501\n0.0\n\n\n1998\n0.998999\n0.501251\n1.0\n\n\n1999\n1.000000\n0.500000\n1.0\n\n\n\n\n2000 rows × 3 columns\n\n\n\n\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.legend()\n\n\n\n\n\n\n\n\n🗣️ 스펙이 너무 높으면 오히려 떨어짐"
  },
  {
    "objectID": "posts/03wk-2.html#c.-로지스틱으로-적합",
    "href": "posts/03wk-2.html#c.-로지스틱으로-적합",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "C. 로지스틱으로 적합",
    "text": "C. 로지스틱으로 적합\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---# \nfor epoc in range(5000):\n    ## 1 \n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.plot(x,net(x).data, '--', label= r\"prob (estimated) = $(x_i,\\hat{y}_i)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n- Epoch을 10억번으로 설정해도 이건 못 맞출것 같음.\n\n🗣️\n\n주황색 선(model)이 올라가다가 내려오는 것은 최초의 곡선이 바뀔 수 있는 범위를 벗어남 (수식적으로)\n이런 경우 모형의 표현력이 낮다고 표현함"
  },
  {
    "objectID": "posts/03wk-2.html#d.-로지스틱-한계극복-아이디어만",
    "href": "posts/03wk-2.html#d.-로지스틱-한계극복-아이디어만",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "D. 로지스틱 한계극복 – 아이디어만",
    "text": "D. 로지스틱 한계극복 – 아이디어만\n🗣️ 반반 잘라서 하면 될 것 같음\n- sigmoid를 넣기 전의 상태가 직선이 아니라 꺽이는 직선이야 한다.\n\na = torch.nn.Sigmoid()\n\n\nfig,ax = plt.subplots(4,2,figsize=(8,8))\nu1 = torch.tensor([-6,-4,-2,0,2,4,6])\nu2 = torch.tensor([6,4,2,0,-2,-4,-6])\nu3 = torch.tensor([-6,-2,2,6,2,-2,-6])\nu4 = torch.tensor([-6,-2,2,6,4,2,0])\nax[0,0].plot(u1,'--o',color='C0',label = r\"$u_1$\")\nax[0,0].legend()\nax[0,1].plot(a(u1),'--o',color='C0',label = r\"$a(u_1)=\\frac{exp(u_1)}{exp(u_1)+1}$\")\nax[0,1].legend()\nax[1,0].plot(u2,'--o',color='C1',label = r\"$u_2$\")\nax[1,0].legend()\nax[1,1].plot(a(u2),'--o',color='C1',label = r\"$a(u_2)=\\frac{exp(u_2)}{exp(u_2)+1}$\")\nax[1,1].legend()\nax[2,0].plot(u3,'--o',color='C2', label = r\"$u_3$\")\nax[2,0].legend()\nax[2,1].plot(a(u3),'--o',color='C2', label = r\"$a(u_3)=\\frac{exp(u_3)}{exp(u_3)+1}$\")\nax[2,1].legend()\nax[3,0].plot(u4,'--o',color='C3', label = r\"$u_4$\")\nax[3,0].legend()\nax[3,1].plot(a(u4),'--o',color='C3', label = r\"$a(u_4)=\\frac{exp(u_4)}{exp(u_4)+1}$\")\nax[3,1].legend()"
  },
  {
    "objectID": "posts/03wk-2.html#footnotes",
    "href": "posts/03wk-2.html#footnotes",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n원래는 이렇게 썼었지.. \\(y_i = w_0 + w_1x_i + \\epsilon_i \\quad \\epsilon_i \\sim {\\cal N}(0,\\sigma^2)\\)↩︎"
  },
  {
    "objectID": "posts/05wk-2.html",
    "href": "posts/05wk-2.html",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "",
    "text": "📘 Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\n📝 🗣️ ✍️ 🔬 ❓"
  },
  {
    "objectID": "posts/05wk-2.html#a.-로지스틱",
    "href": "posts/05wk-2.html#a.-로지스틱",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "A. 로지스틱",
    "text": "A. 로지스틱\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(1)}} =\\underset{(n,1)}{\\hat{\\bf y}}\\]\n🗣️(\n\n위를 보고 다음과 같은 표현이 떠올라야 함\n\n다음은 관습적 표현\nu: 보통 X에 선형변환\nv: 보통 u에 비선형변환(Sigmoid, ReLU)\nv 결과에 선형변환을 하면 또 u라고 하기 때문에 우측상단에 숫자로 구분\n\n\nnet torch.nn.Sequential(\n    torch.nn.Linear(1,1), # l1(X) = u\n    torch.nn.Sigmoid() # sig(u) = v\n)\nyhat = net(X)\n)🗣️\n- 모든 observation과 가중치를 명시한 버전\n(표현1)\n\n\n단점: 똑같은 그림의 반복이 너무 많음\n\n- observation 반복을 생략한 버전들\n(표현2) 모든 \\(i\\)에 대하여 아래의 그림을 반복한다고 하면 (표현1)과 같다.\n\n(표현3) 그런데 (표현2)에서 아래와 같이 \\(x_i\\), \\(y_i\\) 대신에 간단히 \\(x\\), \\(y\\)로 쓰는 경우도 많음\n\n🗣️ x: vector\n- 1을 생략한 버전들\n(표현4) bais=False 대신에 bias=True를 주면 1을 생략할 수 있음\n\n(표현4의 수정) \\(\\hat{w}_1\\)대신에 \\(\\hat{w}\\)를 쓰는 것이 더 자연스러움\n\n(표현5) 선형변환의 결과는 아래와 같이 \\(u\\)로 표현하기도 한다.\n\n\n다이어그램은 그리는 사람의 취향에 따라 그리는 방법이 조금씩 다릅니다. 즉 교재마다 달라요."
  },
  {
    "objectID": "posts/05wk-2.html#b.-스펙의역설",
    "href": "posts/05wk-2.html#b.-스펙의역설",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "B. 스펙의역설",
    "text": "B. 스펙의역설\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}} =\\underset{(n,1)}{\\hat{\\bf y}}\\]\n참고: 코드로 표현\ntorch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=2),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=2,out_features=1),\n    torch.nn.Sigmoid()\n)\n- 이해를 위해서 예젠에 다루었던 아래의 상황을 고려하자.\n\n(강의노트의 표현)\n\n(좀 더 일반화된 표현) 상황을 일반화하면 아래와 같다.\n\n* Layer의 개념: \\({\\bf X}\\)에서 \\(\\hat{\\boldsymbol y}\\)로 가는 과정은 “선형변환+비선형변환”이 반복되는 구조이다. “선형변환+비선형변환”을 하나의 세트로 보면 아래와 같이 표현할 수 있다.\n\n\\(\\underset{(n,1)}{\\bf X}  \\overset{l_1}{\\to} \\left( \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\right) \\overset{l_2}{\\to} \\left(\\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}\\right), \\quad  \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{net({\\bf X})}=\\underset{(n,1)}{\\hat{\\bf y}}\\)\n\n🗣️ 선형변환 -&gt; 선형변환: 아무런 이점이 없음, 잘못 설계 (바로 가는 선형변환이 있기 때문)\n이것을 다이어그램으로 표현한다면 아래와 같다.\n(선형+비선형을 하나의 Layer로 묶은 표현)\n\n🗣️ Layer 0(Input Layer라고도 함)은 세지 X\nLayer를 세는 방법\n\n제 방식: 학습가능한 파라메터가 몇층으로 있는지… &lt;– 이것만 기억하세여\n일부 교재 설명: 입력층은 계산하지 않음, activation layer는 계산하지 않음. &lt;– 무시하세요.. 이러면 헷갈립니다..\n위의 예제의 경우 number of layer = 2 이다.\n\nHidden Layer의 수를 세는 방법\n\n제 방식: Hidden Layer의 수 = Layer의 수 -1 &lt;– 이걸 기억하세여..\n\n일부 교재 설명: Layer의 수 = Hidden Layer의 수 + 출력층의 수 = Hidden Layer의 수 + 1 &lt;– 기억하지 마세여\n위의 예제의 경우 number of hidden layer = 1 이다.\n\n🗣️ 이 경우 Hiden Layer: Layer 1 / 출력층: Layer 2 (yhat)\n\n\n\n\n\n\nImportant\n\n\n\n무조건 학습가능한 파라메터가 몇겹으로 있는지만 판단하세요. 딴거 아무것도 생각하지마세여\n## 예시1 -- 2층 (히든레이어는 1층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU(),\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n)\n## 예시2 -- 2층 (히든레이어는 1층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU(),\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid(),\n)\n## 예시3 -- 1층 (히든레이어는 없음!!)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n) \n## 예시4 -- 1층 (히든레이어는 없음!!)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n) \n## 예시5 -- 3층 (히든레이어는 2층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층    \n) \n## 예시6 -- 3층 (히든레이어는 2층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU()\n    torch.nn.Dropout(??)\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU()\n    torch.nn.Dropout(??)\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층  \n    torch.nn.Sigmoid()\n) \n\n\n\n\n\n\n\n\nImportant\n\n\n\n문헌에 따라서 레이어를 세는 개념이 제가 설명한 방식과 다른경우가 있습니다. 제가 설명한 방식보다 1씩 더해서 셉니다. 즉 아래의 경우 레이어를 3개로 카운트합니다.\n## 예시1 -- 문헌에 따라 3층으로 세는 경우가 있음 (히든레이어는 1층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU(),\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n)\n예를 들어 여기에서는 위의 경우 레이어는 3개라고 설명하고 있습니다. 이러한 카운팅은 “무시”하세요. 제가 설명한 방식이 맞아요. 이 링크 잘못(?) 나와있는 이유는 아래와 같습니다.\n- 진짜 예전에 MLP를 소개할 초창기에서는 위의 경우 Layer를 3개로 셌음. [@rosenblatt1962principles]\n- 그런데 요즘은 그렇게 안셈.. (그리고 애초에 MLP라는 용어도 잘 안쓰죠..)\n참고로 히든레이어의 수는 예전방식이나 지금방식이나 동일하게 카운트하므로 히든레이어만 세면 혼돈이 없습니다.\n\n\n\n🗣️\n\n요즘은 MLP보다는 DNN 용어 사용\n요즘은 Dropout보다 Batch Normalization을 사용\n\nBatch Normalization은 학습 parameter가 있음\n그러나 layer로 세지는 X\n\n요즘은 layer가 몇 층인지 굳이 따지지는 X\n\n\n* node의 개념: \\(u\\to v\\)로 가는 쌍을 간단히 노드라는 개념을 이용하여 나타낼 수 있음.\n(노드의 개념이 포함된 그림)\n\n여기에서 node의 숫자 = feature의 숫자와 같이 이해할 수 있다. 즉 아래와 같이 이해할 수 있다.\n(“number of nodes = number of features”로 이해한 그림)\n\n\n다이어그램의 표현방식은 교재마다 달라서 모든 예시를 달달 외울 필요는 없습니다. 다만 임의의 다이어그램을 보고 대응하는 네트워크를 pytorch로 구현하는 능력은 매우 중요합니다."
  },
  {
    "objectID": "posts/05wk-2.html#c.-mnist",
    "href": "posts/05wk-2.html#c.-mnist",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "C. MNIST",
    "text": "C. MNIST\n\\[\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n(다이어그램표현)\n\n🗣️ 학습 가능한 parameter 수: 784*32 (\\(X_{(n,784)}@w_{?} = (n,32)\\))\n\nLayer0,1,2 대신에 Input Layer, Hidden Layer, Output Layer로 표현함\n\n- 위의 다이어그램에 대응하는 코드\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=28*28*1,out_features=32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=32,out_features=1),\n    torch.nn.Sigmoid() \n)"
  },
  {
    "objectID": "posts/05wk-2.html#a.-gpu-사용방법",
    "href": "posts/05wk-2.html#a.-gpu-사용방법",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "A. GPU 사용방법",
    "text": "A. GPU 사용방법\n- cpu 연산이 가능한 메모리에 데이터 저장\n\ntorch.manual_seed(43052)\nx_cpu = torch.tensor([0.0,0.1,0.2]).reshape(-1,1) \ny_cpu = torch.tensor([0.0,0.2,0.4]).reshape(-1,1) \nnet_cpu = torch.nn.Linear(1,1) \n\n\nnet_cpu(x_cpu)\n\ntensor([[-0.8470],\n        [-0.8817],\n        [-0.9164]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\nx_cpu\n\ntensor([[0.0000],\n        [0.1000],\n        [0.2000]])\n\n\n- gpu 연산이 가능한 메모리에 데이터 저장\n\n!nvidia-smi # before\n\nMon Apr  7 09:48:42 2025       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.230.02             Driver Version: 535.230.02   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  NVIDIA GeForce RTX 3090        Off | 00000000:09:00.0 Off |                  N/A |\n|  0%   29C    P8              27W / 420W |     26MiB / 24576MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|    0   N/A  N/A      1152      G   /usr/lib/xorg/Xorg                            9MiB |\n|    0   N/A  N/A      1471      G   /usr/bin/gnome-shell                          8MiB |\n+---------------------------------------------------------------------------------------+\n\n\n🔬 ?\n\n!nvidia-smi # before\n\nTue May  6 15:07:19 2025       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.161.08             Driver Version: 535.161.08   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  NVIDIA A100-SXM4-80GB          On  | 00000000:47:00.0 Off |                   On |\n| N/A   67C    P0             197W / 275W |                  N/A |     N/A      Default |\n|                                         |                      |              Enabled |\n+-----------------------------------------+----------------------+----------------------+\n\n+---------------------------------------------------------------------------------------+\n| MIG devices:                                                                          |\n+------------------+--------------------------------+-----------+-----------------------+\n| GPU  GI  CI  MIG |                   Memory-Usage |        Vol|      Shared           |\n|      ID  ID  Dev |                     BAR1-Usage | SM     Unc| CE ENC DEC OFA JPG    |\n|                  |                                |        ECC|                       |\n|==================+================================+===========+=======================|\n|  0    0   0   0  |           49841MiB / 81050MiB  | 98      0 |  7   0    5    1    1 |\n|                  |              15MiB / 131072MiB |           |                       |\n+------------------+--------------------------------+-----------+-----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n+---------------------------------------------------------------------------------------+\n\n\n🗣️(\n\nx_cpu\n\ntensor([[0.0000],\n        [0.1000],\n        [0.2000]])\n\n\n\nx_cpu.to(\"cuda:0\")\n\ntensor([[0.0000],\n        [0.1000],\n        [0.2000]], device='cuda:0')\n\n\n\ndevice=‘cuda:0’\n\n)🗣️\n🗣️ :0 =&gt; GPU ID (여러개인 경우)\n\ntorch.manual_seed(43052)\nx_gpu = x_cpu.to(\"cuda:0\")\ny_gpu = y_cpu.to(\"cuda:0\")\nnet_gpu = torch.nn.Linear(1,1).to(\"cuda:0\") \n\n🗣️ 일반적으로는 메모리에 저장되지만, to(“cuda:0”)를 하면 GPU 메모리에 저장됨\n\n!nvidia-smi\n\nMon Apr  7 09:48:43 2025       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.230.02             Driver Version: 535.230.02   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  NVIDIA GeForce RTX 3090        Off | 00000000:09:00.0 Off |                  N/A |\n|  0%   34C    P2              65W / 420W |    287MiB / 24576MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|    0   N/A  N/A      1152      G   /usr/lib/xorg/Xorg                            9MiB |\n|    0   N/A  N/A      1471      G   /usr/bin/gnome-shell                          8MiB |\n|    0   N/A  N/A    140211      C   ...b3/anaconda3/envs/dl2025/bin/python      256MiB |\n+---------------------------------------------------------------------------------------+\n\n\n🔬 ?\n\n!nvidia-smi\n\nTue May  6 15:11:18 2025       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.161.08             Driver Version: 535.161.08   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  NVIDIA A100-SXM4-80GB          On  | 00000000:47:00.0 Off |                   On |\n| N/A   68C    P0             186W / 275W |                  N/A |     N/A      Default |\n|                                         |                      |              Enabled |\n+-----------------------------------------+----------------------+----------------------+\n\n+---------------------------------------------------------------------------------------+\n| MIG devices:                                                                          |\n+------------------+--------------------------------+-----------+-----------------------+\n| GPU  GI  CI  MIG |                   Memory-Usage |        Vol|      Shared           |\n|      ID  ID  Dev |                     BAR1-Usage | SM     Unc| CE ENC DEC OFA JPG    |\n|                  |                                |        ECC|                       |\n|==================+================================+===========+=======================|\n|  0    0   0   0  |           50298MiB / 81050MiB  | 98      0 |  7   0    5    1    1 |\n|                  |              17MiB / 131072MiB |           |                       |\n+------------------+--------------------------------+-----------+-----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n+---------------------------------------------------------------------------------------+\n\n\n\nGPU에 메모리를 올리면 GPU메모리가 점유된다! (26MiB -&gt; 287MiB)\n\n- cpu 혹은 gpu 연산이 가능한 메모리에 저장된 값들을 확인\n\nx_cpu, y_cpu, net_cpu.weight, net_cpu.bias\n\n(tensor([[0.0000],\n         [0.1000],\n         [0.2000]]),\n tensor([[0.0000],\n         [0.2000],\n         [0.4000]]),\n Parameter containing:\n tensor([[-0.3467]], requires_grad=True),\n Parameter containing:\n tensor([-0.8470], requires_grad=True))\n\n\n\nx_gpu, y_gpu, net_gpu.weight, net_gpu.bias\n\n(tensor([[0.0000],\n         [0.1000],\n         [0.2000]], device='cuda:0'),\n tensor([[0.0000],\n         [0.2000],\n         [0.4000]], device='cuda:0'),\n Parameter containing:\n tensor([[-0.3467]], device='cuda:0', requires_grad=True),\n Parameter containing:\n tensor([-0.8470], device='cuda:0', requires_grad=True))\n\n\n- gpu는 gpu끼리 연산가능하고 cpu는 cpu끼리 연산가능함\n(예시1)\n\nnet_cpu(x_cpu) \n\ntensor([[-0.8470],\n        [-0.8817],\n        [-0.9164]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n(예시2)\n\nnet_gpu(x_gpu) \n\ntensor([[-0.8470],\n        [-0.8817],\n        [-0.9164]], device='cuda:0', grad_fn=&lt;AddmmBackward0&gt;)\n\n\n(예시3)\n\nnet_cpu(x_gpu) \n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[15], line 1\n----&gt; 1 net_cpu(x_gpu) \n\nFile ~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/nn/modules/module.py:1739, in Module._wrapped_call_impl(self, *args, **kwargs)\n   1737     return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n   1738 else:\n-&gt; 1739     return self._call_impl(*args, **kwargs)\n\nFile ~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/nn/modules/module.py:1750, in Module._call_impl(self, *args, **kwargs)\n   1745 # If we don't have any hooks, we want to skip the rest of the logic in\n   1746 # this function, and just call forward.\n   1747 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n   1748         or _global_backward_pre_hooks or _global_backward_hooks\n   1749         or _global_forward_hooks or _global_forward_pre_hooks):\n-&gt; 1750     return forward_call(*args, **kwargs)\n   1752 result = None\n   1753 called_always_called_hooks = set()\n\nFile ~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/nn/modules/linear.py:125, in Linear.forward(self, input)\n    124 def forward(self, input: Tensor) -&gt; Tensor:\n--&gt; 125     return F.linear(input, self.weight, self.bias)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)\n\n\n\n(예시4)\n\nnet_gpu(x_cpu)\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[16], line 1\n----&gt; 1 net_gpu(x_cpu)\n\nFile ~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/nn/modules/module.py:1739, in Module._wrapped_call_impl(self, *args, **kwargs)\n   1737     return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n   1738 else:\n-&gt; 1739     return self._call_impl(*args, **kwargs)\n\nFile ~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/nn/modules/module.py:1750, in Module._call_impl(self, *args, **kwargs)\n   1745 # If we don't have any hooks, we want to skip the rest of the logic in\n   1746 # this function, and just call forward.\n   1747 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n   1748         or _global_backward_pre_hooks or _global_backward_hooks\n   1749         or _global_forward_hooks or _global_forward_pre_hooks):\n-&gt; 1750     return forward_call(*args, **kwargs)\n   1752 result = None\n   1753 called_always_called_hooks = set()\n\nFile ~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/nn/modules/linear.py:125, in Linear.forward(self, input)\n    124 def forward(self, input: Tensor) -&gt; Tensor:\n--&gt; 125     return F.linear(input, self.weight, self.bias)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)\n\n\n\n(예시5)\n\ntorch.mean((y_cpu-net_cpu(x_cpu))**2)\n\ntensor(1.2068, grad_fn=&lt;MeanBackward0&gt;)\n\n\n(예시6)\n\ntorch.mean((y_gpu-net_gpu(x_gpu))**2)\n\ntensor(1.2068, device='cuda:0', grad_fn=&lt;MeanBackward0&gt;)\n\n\n(예시7)\n\ntorch.mean((y_gpu-net_cpu(x_cpu))**2)\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[19], line 1\n----&gt; 1 torch.mean((y_gpu-net_cpu(x_cpu))**2)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n\n\n\n(예시8)\n\ntorch.mean((y_cpu-net_gpu(x_gpu))**2)\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[20], line 1\n----&gt; 1 torch.mean((y_cpu-net_gpu(x_gpu))**2)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
  },
  {
    "objectID": "posts/05wk-2.html#b.-시간측정-예비학습",
    "href": "posts/05wk-2.html#b.-시간측정-예비학습",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "B. 시간측정 (예비학습)",
    "text": "B. 시간측정 (예비학습)\n\nimport time \n\n\ntime.time()\n\n1746512391.3237932\n\n\n🗣️ 뭔지는 모르겠지만 차이는 알 수 있음\n\nt1 = time.time()\n\n\nt2 = time.time()\n\n\nt2-t1\n\n4.3513031005859375"
  },
  {
    "objectID": "posts/05wk-2.html#c.-cpu-vs-gpu-500-nodes",
    "href": "posts/05wk-2.html#c.-cpu-vs-gpu-500-nodes",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "C. CPU vs GPU (500 nodes)",
    "text": "C. CPU vs GPU (500 nodes)\n- CPU (500 nodes)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,500),\n    torch.nn.ReLU(),\n    torch.nn.Linear(500,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.36923766136169434\n\n\n🔬\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,500),\n    torch.nn.ReLU(),\n    torch.nn.Linear(500,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.8697936534881592\n\n\n- GPU (500 nodes)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,500),\n    torch.nn.ReLU(),\n    torch.nn.Linear(500,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.5803208351135254\n\n\n🔬\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,500),\n    torch.nn.ReLU(),\n    torch.nn.Linear(500,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.8882694244384766\n\n\n\nCPU가 더 빠르다??"
  },
  {
    "objectID": "posts/05wk-2.html#d.-cpu-vs-gpu-200000-nodes",
    "href": "posts/05wk-2.html#d.-cpu-vs-gpu-200000-nodes",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "D. CPU vs GPU (200,000 nodes)",
    "text": "D. CPU vs GPU (200,000 nodes)\n- CPU (200,000)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,200000),\n    torch.nn.ReLU(),\n    torch.nn.Linear(200000,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n84.05620455741882\n\n\n🔬\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,200000),\n    torch.nn.ReLU(),\n    torch.nn.Linear(200000,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n83.98482537269592\n\n\n- GPU (204,800)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,200000),\n    torch.nn.ReLU(),\n    torch.nn.Linear(200000,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n1.373826026916504\n\n\n🔬\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,200000),\n    torch.nn.ReLU(),\n    torch.nn.Linear(200000,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n2.6831233501434326\n\n\n\n🗣️\n\n항상 GPU가 빠른 것은 아님 (node가 커지면 GPU가 유리)\nCPU는 코어가 많아야 60여개, GPU는 코어가 만 개 단위\n\n왜 이런 차이가 나는가?\n연산을 하는 주체는 코어인데 CPU는 수는 적지만 일을 잘하는 코어들을 가지고 있고 GPU는 일은 못하지만 다수의 코어를 가지고 있기 때문"
  },
  {
    "objectID": "posts/05wk-2.html#e.-주의점",
    "href": "posts/05wk-2.html#e.-주의점",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "E. 주의점",
    "text": "E. 주의점\n- tensor 일 경우\n\nx = torch.tensor([1,2,3])\nx.to(\"cuda:0\"), x\n\n(tensor([1, 2, 3], device='cuda:0'), tensor([1, 2, 3]))\n\n\n- net일 경우\n\nnet = torch.nn.Linear(1,1).to(\"cuda:0\")\nnet.weight, net.bias\n\n(Parameter containing:\n tensor([[-0.0084]], device='cuda:0', requires_grad=True),\n Parameter containing:\n tensor([-0.6216], device='cuda:0', requires_grad=True))\n\n\n🗣️(\n\nnet은 값 자체가 통째로 cuda로 감\n\n\nnet_cpu = torch.nn.Linear(1,1)\nnet_cpu\n\nLinear(in_features=1, out_features=1, bias=True)\n\n\n\nnet_gpu = net_cpu.to(\"cuda:0\") # 이거를 실행하는 순간 cuda로 가기 때문에\n\n\nnet_cpu.weight # 더 이상 cpu로 부를 수 없음\n\nParameter containing:\ntensor([[0.1766]], device='cuda:0', requires_grad=True)\n\n\n\n비교\n\n\nx_cpu = torch.tensor([1,2,3])\nx_cpu\n\ntensor([1, 2, 3])\n\n\n\nx_gpu = x_cpu.to(\"cuda:0\")\n\n\nx_cpu\n\ntensor([1, 2, 3])\n\n\n\nx_gpu\n\ntensor([1, 2, 3], device='cuda:0')\n\n\n)🗣️"
  },
  {
    "objectID": "posts/05wk-2.html#a.-의문-좀-이상하지-않아요",
    "href": "posts/05wk-2.html#a.-의문-좀-이상하지-않아요",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "A. 의문: 좀 이상하지 않아요?",
    "text": "A. 의문: 좀 이상하지 않아요?\n- 국민상식: GPU 비싸요.. https://bbs.ruliweb.com/community/board/300143/read/61066881\n\nGPU 메모리 많아봐야 24GB, 그래도 비싸요.. http://shop.danawa.com/virtualestimate/?controller=estimateMain&methods=index&marketPlaceSeq=16\nGPU 메모리가 80GB일 경우 가격: https://prod.danawa.com/info/?pcode=21458333\n\n- 우리가 분석하는 데이터\n\nx = torch.linspace(-10,10,100000).reshape(-1,1)\neps = torch.randn(100000).reshape(-1,1)\ny = x*2 + eps \n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,2*x,'--')\n\n\n\n\n\n\n\n\n\nlen(x)\n\n100000\n\n\n- 데이터의 크기가 커지는 순간 x.to(\"cuda:0\"), y.to(\"cuda:0\") 쓰면 난리나겠는걸? \\(\\to\\) 이런식이면 GPU를 이용하여 아무런 분석도 못할것 같은데?? 뭔가 좀 이상한데??\n- 아이디어: 데이터를 100개중에 1개 꼴로만 쓰면 어떨까?\n\nx[::2].shape\n\ntorch.Size([50000, 1])\n\n\n\nx[::100].shape\n\ntorch.Size([1000, 1])\n\n\n\nplt.plot(x[::100],y[::100],'o',alpha=0.05)\nplt.plot(x,2*x,'--')\n\n\n\n\n\n\n\n\n\n대충 이거만 가지고 적합해도 충분히 정확할것 같은데?"
  },
  {
    "objectID": "posts/05wk-2.html#b.-xy-데이터를-굳이-모두-gpu에-넘겨야-하는가",
    "href": "posts/05wk-2.html#b.-xy-데이터를-굳이-모두-gpu에-넘겨야-하는가",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "B. X,y 데이터를 굳이 모두 GPU에 넘겨야 하는가?",
    "text": "B. X,y 데이터를 굳이 모두 GPU에 넘겨야 하는가?\n- 데이터셋을 짝홀로 나누어서 번갈아가면서 GPU에 올렸다 내렸다하면 안되나?\n- 아래의 알고리즘을 생각해보자.\n\n데이터를 반으로 나눈다.\n짝수obs의 x,y 그리고 net의 모든 파라메터를 GPU에 올린다.\nyhat, loss, grad, update 수행\n짝수obs의 x,y를 GPU메모리에서 내린다. 그리고 홀수obs의 x,y를 GPU메모리에 올린다.\nyhat, loss, grad, update 수행\n홀수obs의 x,y를 GPU메모리에서 내린다. 그리고 짝수obs의 x,y를 GPU메모리에 올린다.\n반복\n\n\n이러면 되는거아니야???? —&gt; 맞아요\n\n🗣️ =&gt; 확률적경사하강법"
  },
  {
    "objectID": "posts/05wk-2.html#c.-경사하강법-확률적경사하강법-미니배치-경사하강법",
    "href": "posts/05wk-2.html#c.-경사하강법-확률적경사하강법-미니배치-경사하강법",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "C. 경사하강법, 확률적경사하강법, 미니배치 경사하강법",
    "text": "C. 경사하강법, 확률적경사하강법, 미니배치 경사하강법\n🗣️ 임의의 묶음: 미니배치\n10개의 샘플이 있다고 가정. \\(\\{(x_i,y_i)\\}_{i=1}^{10}\\)\n# ver1 – 모든 샘플을 이용하여 slope 계산\n(epoch 1) \\(loss=\\sum_{i=1}^{10}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2 \\to slope  \\to update\\)\n(epoch 2) \\(loss=\\sum_{i=1}^{10}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2 \\to slope  \\to update\\)\n🗣️ loss가 SSE\n…\n\n우리가 항상 이렇게 했죠!\n\n# ver2 – 하나의 샘플만을 이용하여 slope 계산\n(epoch 1)\n\n\\(loss=(y_1-\\hat{w}_0-\\hat{w}_1x_1)^2 \\to slope \\to update\\)\n\\(loss=(y_2-\\hat{w}_0-\\hat{w}_1x_2)^2 \\to slope \\to update\\)\n…\n\\(loss=(y_{10}-\\hat{w}_0-\\hat{w}_1x_{10})^2  \\to  slope  \\to  update\\)\n\n(epoch 2)\n\n\\(loss=(y_1-\\hat{w}_0-\\hat{w}_1x_1)^2  \\to slope  \\to  update\\)\n\\(loss=(y_2-\\hat{w}_0-\\hat{w}_1x_2)^2  \\to slope  \\to  update\\)\n…\n\\(loss=(y_{10}-\\hat{w}_0-\\hat{w}_1x_{10})^2  \\to  slope  \\to  update\\)\n\n🗣️ epoch 2 후 20번 update\n…\n# ver3 – \\(m (\\leq n)\\) 개의 샘플을 이용하여 slope 계산\n🗣️ 미니배치 사이즈 = 3\n\\(m=3\\)이라고 하자.\n(epoch 1)\n\n\\(loss=\\sum_{i=1}^{3}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=\\sum_{i=4}^{6}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=\\sum_{i=7}^{9}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=(y_{10}-\\hat{w}_0-\\hat{w}_1x_{10})^2  \\to  slope  \\to  update\\)\n\n(epoch 2)\n\n\\(loss=\\sum_{i=1}^{3}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=\\sum_{i=4}^{6}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=\\sum_{i=7}^{9}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=(y_{10}-\\hat{w}_0-\\hat{w}_1x_{10})^2  \\to  slope  \\to  update\\)\n\n🗣️ 10은 단독으로 update\n…"
  },
  {
    "objectID": "posts/05wk-2.html#d.-용어의-정리",
    "href": "posts/05wk-2.html#d.-용어의-정리",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "D. 용어의 정리",
    "text": "D. 용어의 정리\n옛날\n- ver1(모든): gradient descent, batch gradient descent\n- ver2(하나만): stochastic gradient descent\n- ver3(몇개만): mini-batch gradient descent, mini-batch stochastic gradient descent\n🗣️ stochastic: 차례대로 하는 것이 아니라 랜덤으로 계속 뽑는 방식도 있어서 이것에 기원을 둠 / batch: 전체 data\n🗣️ ver3: 위 그림에서 y10의 경우 가중치가 계속 있는 것이 싫어서 랜덤으로 3개씩 뽑을 수도 있음 -&gt; stochastic\n요즘\n- ver1(모든): gradient descent\n- ver2(하나만): stochastic gradient descent with batch size = 1\n- ver3(몇개만): stochastic gradient descent - https://www.deeplearningbook.org/contents/optimization.html, 알고리즘 8-1 참고.\n🗣️ ver3을 제일 많이 씀"
  },
  {
    "objectID": "posts/05wk-2.html#e.-datasetds-dataloaderdl",
    "href": "posts/05wk-2.html#e.-datasetds-dataloaderdl",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "E. Dataset(ds), DataLoader(dl)",
    "text": "E. Dataset(ds), DataLoader(dl)\n\n취지는 알겠으나, C의 과정을 실제 구현하려면 진짜 어려움.. (입코딩과 손코딩의 차이) –&gt; 이걸 해결하기 위해서 파이토치에서는 DataLoader라는 오브젝트를 준비했음!\n\n- 데이터\n\nx=torch.tensor(range(10))\ny=torch.tensor([1.0]*5+[0.0]*5).reshape(-1,1)\n\n\nx, y\n\n(tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n tensor([[1.],\n         [1.],\n         [1.],\n         [1.],\n         [1.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.]]))\n\n\n\nx.shape, y.shape # 몇개씩 있는지가 중요\n\n(torch.Size([10]), torch.Size([10]))\n\n\n\nx=torch.tensor(range(10)).float().reshape(-1,1)\ny=torch.tensor([1.0]*5+[0.0]*5).reshape(-1,1)\ntorch.concat([x,y],axis=1)\n\ntensor([[0., 1.],\n        [1., 1.],\n        [2., 1.],\n        [3., 1.],\n        [4., 1.],\n        [5., 0.],\n        [6., 0.],\n        [7., 0.],\n        [8., 0.],\n        [9., 0.]])\n\n\n- ds오브젝트\n\nds = torch.utils.data.TensorDataset(x,y)\nds\n\n&lt;torch.utils.data.dataset.TensorDataset at 0x7f5c8eed5fa0&gt;\n\n\n🗣️ 뭔가 만들어짐 (ds: dataset)\n\nds.tensors \n# 생긴건 ds.tensors = (x,y) 임\n\n(tensor([[0.],\n         [1.],\n         [2.],\n         [3.],\n         [4.],\n         [5.],\n         [6.],\n         [7.],\n         [8.],\n         [9.]]),\n tensor([[1.],\n         [1.],\n         [1.],\n         [1.],\n         [1.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.]]))\n\n\n\nds[0],(x,y)[0] # (x,y) 튜플자체는 아님.. 인덱싱이 다르게 동작\n\n((tensor([0.]), tensor([1.])),\n tensor([[0.],\n         [1.],\n         [2.],\n         [3.],\n         [4.],\n         [5.],\n         [6.],\n         [7.],\n         [8.],\n         [9.]]))\n\n\n🗣️(\n\n(x,y)[1] # y\n\ntensor([[1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.]])\n\n\n\n(x,y)[2] # error\n\n\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\nCell In[60], line 1\n----&gt; 1 (x,y)[2] # error\n\nIndexError: tuple index out of range\n\n\n\n\nds[:3] # 인덱싱이 편함\n\n(tensor([[0.],\n         [1.],\n         [2.]]),\n tensor([[1.],\n         [1.],\n         [1.]]))\n\n\n)🗣️\n- dl 오브젝트\n\ndl = torch.utils.data.DataLoader(ds, batch_size=3)\n\n🗣️(\n\nbatch_size: 원하는 값으로 입력\n\n\ndl = torch.utils.data.DataLoader(ds, batch_size=5)\n\n\nfor _ in dl:\n    print(_)\n\n[tensor([[0.],\n        [1.],\n        [2.],\n        [3.],\n        [4.]]), tensor([[1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.]])]\n[tensor([[5.],\n        [6.],\n        [7.],\n        [8.],\n        [9.]]), tensor([[0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.]])]\n\n\n\nfor x,y in dl:\n    print(x)\n\ntensor([[0.],\n        [1.],\n        [2.],\n        [3.],\n        [4.]])\ntensor([[5.],\n        [6.],\n        [7.],\n        [8.],\n        [9.]])\n\n\n\ndl = torch.utils.data.DataLoader(ds, batch_size=3)\n\n\nfor x,y in dl:\n    print(x)\n\ntensor([[0.],\n        [1.],\n        [2.]])\ntensor([[3.],\n        [4.],\n        [5.]])\ntensor([[6.],\n        [7.],\n        [8.]])\ntensor([[9.]])\n\n\n)🗣️\n\nfor x_mbatch,y_mbatch in dl:\n    print(f\"x_mini_batch:{x_mbatch.tolist()} \\t y_mini_batch:{y_mbatch.tolist()}\")\n\nx_mini_batch:[[0.0], [1.0], [2.0]]   y_mini_batch:[[1.0], [1.0], [1.0]]\nx_mini_batch:[[3.0], [4.0], [5.0]]   y_mini_batch:[[1.0], [1.0], [0.0]]\nx_mini_batch:[[6.0], [7.0], [8.0]]   y_mini_batch:[[0.0], [0.0], [0.0]]\nx_mini_batch:[[9.0]]     y_mini_batch:[[0.0]]\n\n\n- 마지막관측치는 뭔데 단독으로 업데이트하냐?? –&gt; shuffle True 같이 자잘한 옵션도 있음..\n\ndl = torch.utils.data.DataLoader(ds,batch_size=3,shuffle=True)\nfor x_mbatch,y_mbatch in dl:\n    print(f\"x_mini_batch:{x_mbatch.tolist()} \\t y_mini_batch:{y_mbatch.tolist()}\")\n\nx_mini_batch:[[1.0], [5.0], [6.0]]   y_mini_batch:[[1.0], [0.0], [0.0]]\nx_mini_batch:[[7.0], [0.0], [9.0]]   y_mini_batch:[[0.0], [1.0], [0.0]]\nx_mini_batch:[[2.0], [8.0], [3.0]]   y_mini_batch:[[1.0], [0.0], [1.0]]\nx_mini_batch:[[4.0]]     y_mini_batch:[[1.0]]\n\n\n🗣️ 돌릴 때마다 달라짐"
  },
  {
    "objectID": "posts/05wk-2.html#f.-성능체크",
    "href": "posts/05wk-2.html#f.-성능체크",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "F. 성능체크",
    "text": "F. 성능체크\n- 목표: 확률적경사하강법과 그냥 경사하강법의 성능을 “동일 반복횟수”로 비교해보자.\n🗣️(\n10 4 -&gt; 10, 10, 10, 10\n10 4 -&gt; 3, 3, 3, 1\n\n위가 좋을 것 같지만 별 차이 없음\nbatch size를 잘 정하면 밑이 오히려 좋을 수도 있음\n\n)🗣️\n- MNIST자료를 그냥 경사하강법으로 적합해보자.\n\nimport torchvision\n\n\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\nto_tensor = torchvision.transforms.ToTensor()\nX0 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==0])\nX1 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==1])\nX = torch.concat([X0,X1],axis=0).reshape(-1,784)\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\n\n\nX.shape, y.shape\n\n(torch.Size([12665, 784]), torch.Size([12665, 1]))\n\n\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters())\n\n\nfor epoc in range(700):\n    # step1 \n    yhat = net(X)\n    # step2 \n    loss = loss_fn(yhat,y)\n    # step3     \n    loss.backward()\n    # step4 \n    optimizr.step()\n    optimizr.zero_grad()    \n\n\n((yhat &gt; 0.5) ==  y).float().mean()\n\ntensor(0.9953)\n\n\n- MNIST자료를 확률적 경사하강법으로 적합해보자. – 미니배치 쓰는 학습\n\n# train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n# to_tensor = torchvision.transforms.ToTensor()\n# X0 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==0])\n# X1 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==1])\n# X = torch.concat([X0,X1],axis=0).reshape(-1,784)\n# y = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\nds = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=2048)\n\n\nlen(X)/2048\n\n6.18408203125\n\n\n🗣️ 마지막 덩어리는 작음\n\n따라서 (mini) batchsize 가 2048 이라면 한 epoch당 7회 update\n\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters())\n\n\nfor epoc in range(100): \n    for xm,ym in dl:        \n        # step1 \n        ym_hat = net(xm)\n        # step2 \n        loss = loss_fn(ym_hat,ym)\n        # step3     \n        loss.backward()\n        # step4 \n        optimizr.step()\n        optimizr.zero_grad()\n\n\n🗣️\n\n총 update 반복 수는 동일 (7번 * 100번)\nxm = (2048,784), ym = (2048,1)\n\n\n\n((net(X) &gt; 0.5) ==  y).float().mean()\n\ntensor(0.9931)"
  }
]