[
  {
    "objectID": "posts/01wk-1.html",
    "href": "posts/01wk-1.html",
    "title": "01wk-1: (토치) – 강의소개, 파이토치 기본",
    "section": "",
    "text": "📘 Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\n📝 🗣️ ✍️ 🔬 ❓"
  },
  {
    "objectID": "posts/01wk-1.html#a.-torch",
    "href": "posts/01wk-1.html#a.-torch",
    "title": "01wk-1: (토치) – 강의소개, 파이토치 기본",
    "section": "A. torch",
    "text": "A. torch\n🗣️ torch는 numpy와 비슷 (벡터 만들기 등)\n- 벡터\n\ntorch.tensor([1,2,3])\n\ntensor([1, 2, 3])\n\n\n- 벡터의 덧셈\n\ntorch.tensor([1,2,3]) + torch.tensor([2,2,2])\n\ntensor([3, 4, 5])\n\n\n- 브로드캐스팅\n\ntorch.tensor([1,2,3]) + 2\n\ntensor([3, 4, 5])"
  },
  {
    "objectID": "posts/01wk-1.html#b.-벡터와-매트릭스",
    "href": "posts/01wk-1.html#b.-벡터와-매트릭스",
    "title": "01wk-1: (토치) – 강의소개, 파이토치 기본",
    "section": "B. 벡터와 매트릭스",
    "text": "B. 벡터와 매트릭스\n🗣️ torch.tensor는 np.array와 비슷\n- \\(3 \\times 2\\) matrix\n\ntorch.tensor([[1,2],[3,4],[5,6]]) \n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n- \\(3 \\times 1\\) matrix = \\(3 \\times 1\\) column vector\n\ntorch.tensor([[1],[3],[5]]) \n\ntensor([[1],\n        [3],\n        [5]])\n\n\n- \\(1 \\times 2\\) matrix = \\(1 \\times 2\\) row vector\n\ntorch.tensor([[1,2]]) \n\ntensor([[1, 2]])\n\n\n🗣️ torch.tensor([[1,2],[3,4],[5,6]])에서 [3,4],[5,6] 삭제라고 생각\n🗣️ column vector와 row vector는 구분되고 선언 방법이 다름\n- 더하기\n브로드캐스팅(편한거)\n\ntorch.tensor([[1,2],[3,4],[5,6]]) - 1\n\ntensor([[0, 1],\n        [2, 3],\n        [4, 5]])\n\n\n🗣️ “matrix - scalar”는 불가능하지만 알아서 원소별로 전부 뺌\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1],[-3],[-5]])\n\ntensor([[0, 1],\n        [0, 1],\n        [0, 1]])\n\n\n🗣️ (3, 2) - (3, 1)을 알아서 뺌\n✍️ torch.tensor([[-1,-1],[-3, 3],[-5,-5]])\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1,-2]])\n\ntensor([[0, 0],\n        [2, 2],\n        [4, 4]])\n\n\n🗣️ (3, 2) - (1, 2)을 알아서 뺌\n✍️ torch.tensor([[-1,-2],[-1,-2],[-1,-2]])\n잘못된 브로드캐스팅\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1,-3,-5]])\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[11], line 1\n----&gt; 1 torch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1,-3,-5]])\n\nRuntimeError: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1\n\n\n\n🗣️ 세로로 쓰거나 가로로 두 개의 원소만 썼으면 가능\n✍️ torch.tensor([[-1],[-3],[-5]]) 또는 torch.tensor([[-1,-3],[-1,-3],[-1,-3]]) 등\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1],[-2]])\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[12], line 1\n----&gt; 1 torch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1],[-2]])\n\nRuntimeError: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 0\n\n\n\n🗣️ (3, 2) - (2, 1) 는 알아서 채우기 어려우므로 error\n이상한 것\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([-1,-2])\n\ntensor([[0, 0],\n        [2, 2],\n        [4, 4]])\n\n\n🗣️ (3, 2) matrix - 길이가 2인 vector(2x1, 1x2 둘 다 아님)\n🗣️ “matrix - vector”를 row vector로 해석하고 늘려서 계산한 듯\n✍️ torch.tensor([[-1,-2],[-1,-2],[-1,-2]])\n🔬(\n\n차원 수만 알고 싶을 때 → tensor.dim() 또는 tensor.ndim\n각 차원의 크기까지 알고 싶을 때 → tensor.shape 또는 tensor.size()\n\n\nprint(torch.tensor([[1,2],[3,4],[5,6]]).dim())\nprint(torch.tensor([[1,2],[3,4],[5,6]]).shape)\nprint(torch.tensor([-1,-2]).dim())\nprint(torch.tensor([-1,-2]).shape)\nprint(torch.tensor([[1,2],[3,4],[5,6]]).ndim)\nprint(torch.tensor([[1,2],[3,4],[5,6]]).size())\nprint(torch.tensor([-1,-2]).ndim)\nprint(torch.tensor([-1,-2]).size())\n\n2\ntorch.Size([3, 2])\n1\ntorch.Size([2])\n2\ntorch.Size([3, 2])\n1\ntorch.Size([2])\n\n\n\n참고 (Chat GPT4o)\n\n\nNumPy와 PyTorch 차이 정리\n\n\n\n\n기능\nPyTorch\nNumPy\n\n\n\n\n차원 수\n.dim() 또는 .ndim\n.ndim\n\n\nshape 확인\n.shape 또는 .size()\n.shape\n\n\n크기 변경\n.view(), .reshape()\n.reshape()\n\n\n타입\ntorch.Tensor\nnp.ndarray\n\n\n\n\n실전 팁:\n\nPyTorch의 .dim()만 NumPy에서 안 먹힌다는 것만 기억하면 둘 다 거의 비슷하게 다룰 수 있음\n다차원 배열을 다룰 때 .ndim, .shape는 양쪽 모두 안전하게 쓸 수 있는 핵심 도구\ndim()은 PyTorch 고유 메서드\n\n\n)🔬\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([-1,-3,-5])\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[15], line 1\n----&gt; 1 torch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([-1,-3,-5])\n\nRuntimeError: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1\n\n\n\n🗣️ 길이가 3인 vector를 column vector로 해석하고 (3,2)로 채워서 계산할 것 같지만 X (이번에 발견)\n- 행렬곱\n정상적인 행렬곱\n\ntorch.tensor([[1,2],[3,4],[5,6]]) @ torch.tensor([[1],[2]])\n\ntensor([[ 5],\n        [11],\n        [17]])\n\n\n🗣️ (3,2) matirx @ (2,1) vector = (3,1) matrix\n\ntorch.tensor([[1,2,3]]) @ torch.tensor([[1,2],[3,4],[5,6]]) \n\ntensor([[22, 28]])\n\n\n🗣️ (1,3) @ (3,2) = (1,2)\n잘못된 행렬곱\n\ntorch.tensor([[1,2],[3,4],[5,6]]) @ torch.tensor([[1,2]])\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[18], line 1\n----&gt; 1 torch.tensor([[1,2],[3,4],[5,6]]) @ torch.tensor([[1,2]])\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (3x2 and 1x2)\n\n\n\n🗣️ (3,2) @ (1,2) 불가\n\ntorch.tensor([[1],[2],[3]]) @ torch.tensor([[1,2],[3,4],[5,6]]) \n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[19], line 1\n----&gt; 1 torch.tensor([[1],[2],[3]]) @ torch.tensor([[1,2],[3,4],[5,6]]) \n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (3x1 and 3x2)\n\n\n\n🗣️ (3,1) @ (3,2) 불가\n이상한 것\n\ntorch.tensor([[1,2],[3,4],[5,6]]) @ torch.tensor([1,2]) # 이게 왜 가능..\n\ntensor([ 5, 11, 17])\n\n\n🗣️ (3,2) @ (2) 길이가 2인 vector / 사람마다 해석 애매 (2,1)? (1,2)? / 곱하기를 위해 (2,1) column vector로 해석\n🗣️ (3,2) @ (2,1)로 해석 후 계산하여 (3) 길이가 3인 vector가 나옴\n\ntorch.tensor([1,2,3]) @ torch.tensor([[1,2],[3,4],[5,6]]) # 이건 왜 가능?\n\ntensor([22, 28])\n\n\n🗣️ (3) @ (3,2)에서 (3)을 (1,3) row vector로 해석\n🗣️( 엄밀하게 하려면\n\ntorch.tensor([[1,2,3]]) @ torch.tensor([[1,2],[3,4],[5,6]])\n\ntensor([[22, 28]])\n\n\n✍️ 당연히 결과의 차원도 다름\n)🗣️"
  },
  {
    "objectID": "posts/01wk-1.html#c.-transpose-reshape",
    "href": "posts/01wk-1.html#c.-transpose-reshape",
    "title": "01wk-1: (토치) – 강의소개, 파이토치 기본",
    "section": "C. transpose, reshape",
    "text": "C. transpose, reshape\n- transpose\n\ntorch.tensor([[1,2],[3,4]]).T \n\ntensor([[1, 3],\n        [2, 4]])\n\n\n\ntorch.tensor([[1],[3]]).T \n\ntensor([[1, 3]])\n\n\n🗣️ column vector -&gt; row vector\n\ntorch.tensor([[1,2]]).T \n\ntensor([[1],\n        [2]])\n\n\n🗣️ row vector -&gt; column vector\n🗣️ 차원을 바꾸는 효과 (1,2) -&gt; (2,1)\n- reshape\n🗣️( 차원 보기\n\ntorch.tensor([[1,2]]).shape\n\ntorch.Size([1, 2])\n\n\n을 column vector로 바꾸고 싶으면\n\ntorch.tensor([[1,2]]).reshape(2,1)\n\ntensor([[1],\n        [2]])\n\n\ntranspose와 동일\n)🗣️\n일반적인 사용\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(2,3)\n\ntensor([[1, 2, 3],\n        [4, 5, 6]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]])\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(1,6)\n\ntensor([[1, 2, 3, 4, 5, 6]])\n\n\n🗣️ (3,2) -&gt; (1,6)\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(6)\n\ntensor([1, 2, 3, 4, 5, 6])\n\n\n🗣️ (3,2)를 그냥 6으로 : 길이가 6인 vector로 바꿈\n편한 것\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(2,-1)\n\ntensor([[1, 2, 3],\n        [4, 5, 6]])\n\n\n🗣️ torch.tensor([[1,2],[3,4],[5,6]]).reshape(2,??)를 원할 때 ??를 알아서 맞춤 (불가능하면 error)\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(6,-1)\n\ntensor([[1],\n        [2],\n        [3],\n        [4],\n        [5],\n        [6]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(-1,6)\n\ntensor([[1, 2, 3, 4, 5, 6]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(-1)\n\ntensor([1, 2, 3, 4, 5, 6])\n\n\n🗣️ 전체를 vector로 바꾸고 싶을 때 (1차원)"
  },
  {
    "objectID": "posts/01wk-1.html#d.-concat-stack-starstarstar",
    "href": "posts/01wk-1.html#d.-concat-stack-starstarstar",
    "title": "01wk-1: (토치) – 강의소개, 파이토치 기본",
    "section": "D. concat, stack \\((\\star\\star\\star)\\)",
    "text": "D. concat, stack \\((\\star\\star\\star)\\)\n- concat\n\na = torch.tensor([[1],[3],[5]])\nb = torch.tensor([[2],[4],[6]])\ntorch.concat([a,b],axis=1)\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n🗣️(\n\na\n\ntensor([[1],\n        [3],\n        [5]])\n\n\n\nb\n\ntensor([[2],\n        [4],\n        [6]])\n\n\na와 b를 모두 vector로 갖고 있는데 [a b]처럼 놓고 싶을 때 사용\n\na, b\n\n(tensor([[1],\n         [3],\n         [5]]),\n tensor([[2],\n         [4],\n         [6]]))\n\n\n\ntorch.concat([a,b]) # 이렇게 하면 좌우가 아니라 위 아래로 합쳐짐\n\ntensor([[1],\n        [3],\n        [5],\n        [2],\n        [4],\n        [6]])\n\n\n(3,1)과 (3,1)을 (3,2)로 만들고 싶었는데 (6,1)이 됨 -&gt; axis=1 옵션 사용하면 (3,2) 가능 (모르겠으면 밑의 링크 참조)\n)🗣️\n\ntorch.concat([a,b],axis=1)\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n- stack\n\na = torch.tensor([1,3,5])\nb = torch.tensor([2,4,6])\ntorch.stack([a,b],axis=1)\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n🗣️(\n\na\n\ntensor([1, 3, 5])\n\n\n\nb\n\ntensor([2, 4, 6])\n\n\n\na.reshape(3,1) # 참고) concat 설명 예시와 동일\n\ntensor([[1],\n        [3],\n        [5]])\n\n\n\ntorch.concat([a.reshape(3,1), b.reshape(3,1)], axis=1) # 리스트로 만든 후 이렇게 하면 되긴하나 너무 힘듦\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n\ntorch.stack([a,b], axis=1) # 같은 결과\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n차이: concat은 바꾸려는 대상의 dimension을 바꾸지는 X (matrix는 matrix로, vector는 vector로) / stack은 dimension을 하나 늘려서 바꿔줌\nconcat과 stack 둘 다 알면 좋음\n)🗣️\n\ntorch.concat([a.reshape(3,1),b.reshape(3,1)],axis=1)\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n\n\n\n\n\n\nWarning\n\n\n\nconcat과 stack을 지금 처음본다면 아래를 복습하시는게 좋습니다.\nhttps://guebin.github.io/PP2024/posts/06wk-2.html#numpy와-축axis"
  },
  {
    "objectID": "posts/02wk-2.html",
    "href": "posts/02wk-2.html",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "",
    "text": "📘 Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\n📝 🗣️ ✍️ 🔬 ❓"
  },
  {
    "objectID": "posts/02wk-2.html#a.-print",
    "href": "posts/02wk-2.html#a.-print",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "A. print",
    "text": "A. print\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nalpha = 0.001\nprint(f\"시작값 = {What.data.reshape(-1)}\")\nfor epoc in range(30):\n    yhat = X @ What\n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - alpha * What.grad\n    print(f'loss = {loss:.2f} \\t 업데이트폭 = {-alpha * What.grad.reshape(-1)} \\t 업데이트결과: {What.data.reshape(-1)}')\n    What.grad = None\n\n시작값 = tensor([-5., 10.])\nloss = 8587.69   업데이트폭 = tensor([ 1.3423, -1.1889])      업데이트결과: tensor([-3.6577,  8.8111])\nloss = 5675.21   업데이트폭 = tensor([ 1.1029, -0.9499])      업데이트결과: tensor([-2.5548,  7.8612])\nloss = 3755.64   업데이트폭 = tensor([ 0.9056, -0.7596])      업데이트결과: tensor([-1.6492,  7.1016])\nloss = 2489.58   업데이트폭 = tensor([ 0.7431, -0.6081])      업데이트결과: tensor([-0.9061,  6.4935])\nloss = 1654.04   업데이트폭 = tensor([ 0.6094, -0.4872])      업데이트결과: tensor([-0.2967,  6.0063])\nloss = 1102.32   업데이트폭 = tensor([ 0.4995, -0.3907])      업데이트결과: tensor([0.2028, 5.6156])\nloss = 737.84    업데이트폭 = tensor([ 0.4091, -0.3136])      업데이트결과: tensor([0.6119, 5.3020])\nloss = 496.97    업데이트폭 = tensor([ 0.3350, -0.2519])      업데이트결과: tensor([0.9469, 5.0501])\nloss = 337.71    업데이트폭 = tensor([ 0.2742, -0.2025])      업데이트결과: tensor([1.2211, 4.8477])\nloss = 232.40    업데이트폭 = tensor([ 0.2243, -0.1629])      업데이트결과: tensor([1.4454, 4.6848])\nloss = 162.73    업데이트폭 = tensor([ 0.1834, -0.1311])      업데이트결과: tensor([1.6288, 4.5537])\nloss = 116.63    업데이트폭 = tensor([ 0.1500, -0.1056])      업데이트결과: tensor([1.7787, 4.4480])\nloss = 86.13     업데이트폭 = tensor([ 0.1226, -0.0851])      업데이트결과: tensor([1.9013, 4.3629])\nloss = 65.93     업데이트폭 = tensor([ 0.1001, -0.0687])      업데이트결과: tensor([2.0014, 4.2942])\nloss = 52.57     업데이트폭 = tensor([ 0.0818, -0.0554])      업데이트결과: tensor([2.0832, 4.2388])\nloss = 43.72     업데이트폭 = tensor([ 0.0668, -0.0447])      업데이트결과: tensor([2.1500, 4.1941])\nloss = 37.86     업데이트폭 = tensor([ 0.0545, -0.0361])      업데이트결과: tensor([2.2045, 4.1579])\nloss = 33.97     업데이트폭 = tensor([ 0.0445, -0.0292])      업데이트결과: tensor([2.2490, 4.1287])\nloss = 31.40     업데이트폭 = tensor([ 0.0363, -0.0236])      업데이트결과: tensor([2.2853, 4.1051])\nloss = 29.70     업데이트폭 = tensor([ 0.0296, -0.0191])      업데이트결과: tensor([2.3150, 4.0860])\nloss = 28.57     업데이트폭 = tensor([ 0.0242, -0.0155])      업데이트결과: tensor([2.3392, 4.0705])\nloss = 27.83     업데이트폭 = tensor([ 0.0197, -0.0125])      업데이트결과: tensor([2.3589, 4.0580])\nloss = 27.33     업데이트폭 = tensor([ 0.0161, -0.0101])      업데이트결과: tensor([2.3750, 4.0479])\nloss = 27.00     업데이트폭 = tensor([ 0.0131, -0.0082])      업데이트결과: tensor([2.3881, 4.0396])\nloss = 26.79     업데이트폭 = tensor([ 0.0107, -0.0067])      업데이트결과: tensor([2.3988, 4.0330])\nloss = 26.64     업데이트폭 = tensor([ 0.0087, -0.0054])      업데이트결과: tensor([2.4075, 4.0276])\nloss = 26.55     업데이트폭 = tensor([ 0.0071, -0.0044])      업데이트결과: tensor([2.4146, 4.0232])\nloss = 26.48     업데이트폭 = tensor([ 0.0058, -0.0035])      업데이트결과: tensor([2.4204, 4.0197])\nloss = 26.44     업데이트폭 = tensor([ 0.0047, -0.0029])      업데이트결과: tensor([2.4251, 4.0168])\nloss = 26.41     업데이트폭 = tensor([ 0.0038, -0.0023])      업데이트결과: tensor([2.4290, 4.0144])\n\n\n\n🗣️\n\nloss만 보면 점점 감소함, 갈수록 감소하는 폭도 작아지며 26 근처로 수렴\n업데이트 폭도 처음에는 컸다가 감소\n이에 따라 업데이트 결과도 갈수록 잘 안 바뀜"
  },
  {
    "objectID": "posts/02wk-2.html#b.-시각화-yhat의-관점에서",
    "href": "posts/02wk-2.html#b.-시각화-yhat의-관점에서",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "B. 시각화 – yhat의 관점에서!",
    "text": "B. 시각화 – yhat의 관점에서!\n🗣️(\n\nWhat = torch.tensor([[-5.0], [10.0]], requires_grad=True)\n\n\nyhat = X@What\nloss = torch.sum((yhat-y)**2)\nloss.backward()\nWhat.data = What.data - 0.001*What.grad\nWhat.grad = None\n\n\nplt.plot(x,y,'o')\nplt.plot(x, (X@What).data, '--', color=\"C1\") # 선 색깔 주황색 고정\n\n\n\n\n\n\n\n\n\n아래 코드를 반복하며 지켜보면 선이 변화하는 것을 볼 수 있음 (밑의 그래프는 여러번 반복한 최종 결과)\n\n\nyhat = X@What\nloss = torch.sum((yhat-y)**2)\nloss.backward()\nWhat.data = What.data - 0.001*What.grad\nWhat.grad = None\nplt.plot(x,y,'o')\nplt.plot(x, (X@What).data, '--', color=\"C1\")\n\n\n\n\n\n\n\n\n\n한 가지 아쉬운 점: 중간 과정의 그래프가 사라짐\n\n\nWhat = torch.tensor([[-5.0], [10.0]], requires_grad=True)\n\n\nplt.plot(x,y,'o')\nfig = plt.gcf() # 중간 그림을 저장 (호출 가능) get current figure\n\n\n\n\n\n\n\n\n\nax = fig.gca() # get current axes (axes: axis의 복수형, 여기서는 x축,y축 모두를 지칭)\nyhat = X@What\nloss = torch.sum((yhat-y)**2)\nloss.backward()\nWhat.data = What.data - 0.001*What.grad\nWhat.grad = None\nax.plot(x, (X@What).data, '--', color=\"C1\") # plt를 ax로 수정\n\n\nfig # 1번 실행\n\n\n\n\n\n\n\n\n\n1번 더 실행하면 겹쳐짐\n\n\nax = fig.gca() # get current axes (axes: axis의 복수형, 여기서는 x축,y축 모두를 지칭)\nyhat = X@What\nloss = torch.sum((yhat-y)**2)\nloss.backward()\nWhat.data = What.data - 0.001*What.grad\nWhat.grad = None\nax.plot(x, (X@What).data, '--', color=\"C1\") # plt를 ax로 수정\n\n\nfig # 1번 더 실행 (겹쳐짐)\n\n\n\n\n\n\n\n\n\n초기화 후 반복하면 업데이트된 폭을 볼 수 있음 (점점 줄어드는 것 같음)\n\n\nWhat = torch.tensor([[-5.0], [10.0]], requires_grad=True)\n\n\nplt.plot(x,y,'o')\nfig = plt.gcf()\n\n\n\n\n\n\n\n\n\nax = fig.gca()\nyhat = X@What\nloss = torch.sum((yhat-y)**2)\nloss.backward()\nWhat.data = What.data - 0.001*What.grad\nWhat.grad = None\nax.plot(x, (X@What).data, '--', color=\"C1\")\nfig\n\n\n\n\n\n\n\n\n\n제목을 넣을 수도 있음 (set_title, 단순 문자열 아니여도 가능)\n\n\nWhat = torch.tensor([[-5.0], [10.0]], requires_grad=True)\n\nplt.plot(x,y,'o')\nfig = plt.gcf()\n\n\n\n\n\n\n\n\n\nfor epoc in range(20):\n    ax = fig.gca()\n    yhat = X@What\n    loss = torch.sum((yhat-y)**2)\n    loss.backward()\n    What.data = What.data - 0.001*What.grad\n    What.grad = None\n    ax.plot(x, (X@What).data, '--', color=\"C1\")\n    ax.set_title(What.data.reshape(-1))\n    fig\n\n\nfig\n\n\n\n\n\n\n\n\n)🗣️\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nalpha = 0.001\nplt.plot(x,y,'o',label = \"observed\")\nfig = plt.gcf()\nax = fig.gca()\nax.plot(x,X@What.data,'--',color=\"C1\")\nfor epoc in range(30):\n    yhat = X @ What\n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - alpha * What.grad\n    ax.plot(x,X@What.data,'--',color=\"C1\",alpha=0.1)\n    What.grad = None\n\n\n\n\n\n\n\n\n🗣️ alpha: 겹쳐지면 진해짐"
  },
  {
    "objectID": "posts/02wk-2.html#c.-시각화-loss의-관점에서",
    "href": "posts/02wk-2.html#c.-시각화-loss의-관점에서",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "C. 시각화 – loss의 관점에서!!",
    "text": "C. 시각화 – loss의 관점에서!!\n🗣️(\n\ndef plot_loss():\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='3d')\n    w0 = np.arange(-6, 11, 0.5) \n    w1 = np.arange(-6, 11, 0.5)\n    W1,W0 = np.meshgrid(w1,w0)\n    LOSS=W0*0\n    for i in range(len(w0)):\n        for j in range(len(w1)):\n            LOSS[i,j]=torch.sum((y-w0[i]-w1[j]*x)**2)\n    ax.plot_surface(W0, W1, LOSS, rstride=1, cstride=1, color='b',alpha=0.1)\n    ax.azim = 30  ## 3d plot의 view 조절 \n    ax.dist = 8   ## 3d plot의 view 조절 \n    ax.elev = 5   ## 3d plot의 view 조절 \n    ax.set_xlabel(r'$w_0$')  # x축 레이블 설정\n    ax.set_ylabel(r'$w_1$')  # y축 레이블 설정\n    ax.set_xticks([-5,0,5,10])  # x축 틱 간격 설정\n    ax.set_yticks([-5,0,5,10])  # y축 틱 간격 설정\n    plt.close(fig)  # 자동 출력 방지\n    return fig\n\n\nfig = plot_loss()\nfig # loss_fn(w0hat, w1hat)을 z에 찍음\n\n\n\n\n\n\n\n\n\n# 손실 8587.6875 를 계산하는 또 다른 방식\ndef l(w0hat,w1hat):\n    yhat = w0hat + w1hat*x\n    return torch.sum((y-yhat)**2)\n\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nWhat\n\ntensor([[-5.],\n        [10.]], requires_grad=True)\n\n\n\nl(-5,10) # 손실 계산\n\ntensor(8587.6875)\n\n\n\ntorch.sum((y-X@What)**2) # 다른 방법\n\ntensor(8587.6875, grad_fn=&lt;SumBackward0&gt;)\n\n\n\nyhat = -5 + 10*x\ntorch.sum((y-yhat)**2) # 다른 방법 2\n\ntensor(8587.6875)\n\n\n\nfig\nax = fig.gca()\nax.scatter(-5, 10, l(-5,10)) # 점 찍기\n\n&lt;mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7fc9261c2bb0&gt;\n\n\n\nfig\n\n\n\n\n\n\n\n\n\nfig\nax = fig.gca()\nax.scatter(-1, 3, l(-1,3)) # 다른 점 찍기\n\n&lt;mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7fc925df1eb0&gt;\n\n\n\nfig\n\n\n\n\n\n\n\n\n\n위 과정을 반복하면 곡면을 그릴 수 있음\n밑은 True 값 찍기\n\n\nfig\nax = fig.gca()\nax.scatter(2.5, 4.0, l(2.5,4.0)) # True 값\n\n&lt;mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7fc925f14670&gt;\n\n\n\nfig\n\n\n\n\n\n\n\n\n\n밑에 정리된 코드 과정\n\n\nfig = plot_loss()\nfig # loss_fn(w0hat,w1hat)\nax = fig.gca()\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nw0hat, w1hat = What.data.reshape(-1) # 언패킹\nax.scatter(w0hat, w1hat, l(w0hat, w1hat)) # x, y, z\nfig # 최초의 직선에 대응하는 What 값\n\n\n\n\n\n\n\n\n\nyhat = X@What\nloss = torch.sum((y-yhat)**2)\nloss.backward()\nWhat.data = What.data - 0.001*What.grad\nWhat.grad = None\nw0hat, w1hat = What.data.reshape(-1)\nax.scatter(w0hat, w1hat, l(w0hat, w1hat))\nfig # 반복 실행할수록 update됨\n\n\n\n\n\n\n\n\n\nyhat = X@What\nloss = torch.sum((y-yhat)**2)\nloss.backward()\nWhat.data = What.data - 0.001*What.grad\nWhat.grad = None\nw0hat, w1hat = What.data.reshape(-1)\nax.scatter(w0hat, w1hat, l(w0hat, w1hat), color=\"C1\") # 앞으로는 주황색으로 색깔 고정\nfig # 반복 실행할수록 점점 최소가 되는 쪽으로 진행됨\n\n\n\n\n\n\n\n\n)🗣️\n\ndef plot_loss():\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='3d')\n    w0 = np.arange(-6, 11, 0.5) \n    w1 = np.arange(-6, 11, 0.5)\n    W1,W0 = np.meshgrid(w1,w0)\n    LOSS=W0*0\n    for i in range(len(w0)):\n        for j in range(len(w1)):\n            LOSS[i,j]=torch.sum((y-w0[i]-w1[j]*x)**2)\n    ax.plot_surface(W0, W1, LOSS, rstride=1, cstride=1, color='b',alpha=0.1)\n    ax.azim = 30  ## 3d plot의 view 조절 \n    ax.dist = 8   ## 3d plot의 view 조절 \n    ax.elev = 5   ## 3d plot의 view 조절 \n    ax.set_xlabel(r'$w_0$')  # x축 레이블 설정\n    ax.set_ylabel(r'$w_1$')  # y축 레이블 설정\n    ax.set_xticks([-5,0,5,10])  # x축 틱 간격 설정\n    ax.set_yticks([-5,0,5,10])  # y축 틱 간격 설정\n    plt.close(fig)  # 자동 출력 방지\n    return fig\n\n\n# 손실 8587.6875 를 계산하는 또 다른 방식\ndef l(w0hat,w1hat):\n    yhat = w0hat + w1hat*x\n    return torch.sum((y-yhat)**2)\n\n\nfig = plot_loss()\nax = fig.gca()\nax.scatter(2.5, 4, l(2.5,4), s=200, marker='*', color='red', label=r\"${\\bf W}=[2.5, 4]'$\")\nax.scatter(-5, 10, l(-5,10), s=200, marker='*', color='blue', label=r\"initial $\\hat{\\bf W}=[-5, 10]'$\")\nax.legend()\nfig\n\n\n\n\n\n\n\n\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nalpha = 0.001\nfor epoc in range(30):\n    yhat = X @ What\n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - 0.001 * What.grad\n    w0,w1 = What.data.reshape(-1) \n    ax.scatter(w0,w1,l(w0,w1),s=5,marker='o',color='blue')\n    What.grad = None\n\n\nfig\n\n\n\n\n\n\n\n\n\n🗣️\n\nB의 시각화에서 최초의 직선에 대응하는 점이 파란색 점\n점들이 빨간색 점으로 이동하는 과정은 직선이 올라가는 과정에 대응"
  },
  {
    "objectID": "posts/02wk-2.html#d.-애니메이션",
    "href": "posts/02wk-2.html#d.-애니메이션",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "D. 애니메이션",
    "text": "D. 애니메이션\n\nfrom matplotlib import animation\n\n\nplt.rcParams['figure.figsize'] = (7.5,2.5)\nplt.rcParams[\"animation.html\"] = \"jshtml\" \n\n\ndef show_animation(alpha=0.001):\n    ## 1. 히스토리 기록을 위한 list 초기화\n    loss_history = [] \n    yhat_history = [] \n    What_history = [] \n\n    ## 2. 학습 + 학습과정기록\n    What= torch.tensor([[-5.0],[10.0]],requires_grad=True)\n    What_history.append(What.data.tolist())\n    for epoc in range(30): \n        yhat=X@What ; yhat_history.append(yhat.data.tolist())\n        loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n        loss.backward() \n        What.data = What.data - alpha * What.grad; What_history.append(What.data.tolist())\n        What.grad = None    \n\n    ## 3. 시각화 \n    fig = plt.figure()\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n\n    #### ax1: yhat의 관점에서.. \n    ax1.plot(x,y,'o',label=r\"$(x_i,y_i)$\")\n    line, = ax1.plot(x,yhat_history[0],label=r\"$(x_i,\\hat{y}_i)$\") \n    ax1.legend()\n    #### ax2: loss의 관점에서.. \n    w0 = np.arange(-6, 11, 0.5) \n    w1 = np.arange(-6, 11, 0.5)\n    W1,W0 = np.meshgrid(w1,w0)\n    LOSS=W0*0\n    for i in range(len(w0)):\n        for j in range(len(w1)):\n            LOSS[i,j]=torch.sum((y-w0[i]-w1[j]*x)**2)\n    ax2.plot_surface(W0, W1, LOSS, rstride=1, cstride=1, color='b',alpha=0.1)\n    ax2.azim = 30  ## 3d plot의 view 조절 \n    ax2.dist = 8   ## 3d plot의 view 조절 \n    ax2.elev = 5   ## 3d plot의 view 조절 \n    ax2.set_xlabel(r'$w_0$')  # x축 레이블 설정\n    ax2.set_ylabel(r'$w_1$')  # y축 레이블 설정\n    ax2.set_xticks([-5,0,5,10])  # x축 틱 간격 설정\n    ax2.set_yticks([-5,0,5,10])  # y축 틱 간격 설정\n    ax2.scatter(2.5, 4, l(2.5,4), s=200, marker='*', color='red', label=r\"${\\bf W}=[2.5, 4]'$\")\n    ax2.scatter(-5, 10, l(-5,10), s=200, marker='*', color='blue')\n    ax2.legend()\n    def animate(epoc):\n        line.set_ydata(yhat_history[epoc])\n        ax2.scatter(np.array(What_history)[epoc,0],np.array(What_history)[epoc,1],loss_history[epoc],color='grey')\n        fig.suptitle(f\"alpha = {alpha} / epoch = {epoc}\")\n        return line\n\n    ani = animation.FuncAnimation(fig, animate, frames=30)\n    plt.close()\n    return ani\n\n\n🗣️ alpha:\n\n학습률: update되는 폭 (ML 관점)\nstep size: 오른쪽 그림 함수 관점 (산업 공학 관점)\n\n\n\nani = show_animation(alpha=0.001)\nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/02wk-2.html#e.-학습률에-따른-시각화",
    "href": "posts/02wk-2.html#e.-학습률에-따른-시각화",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "E. 학습률에 따른 시각화",
    "text": "E. 학습률에 따른 시각화\n- \\(\\alpha\\)가 너무 작다면 비효율적임\n\nshow_animation(alpha=0.0001)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n🗣️ 0.001 -&gt; 0.0001\n\n아까보다 가는 둥 마는 둥 함\n\n\n- \\(\\alpha\\)가 크다고 무조건 좋은건 또 아님\n\nshow_animation(alpha=0.0083)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n🗣️ 0.001 -&gt; 0.0083 (직접 찾은 숫자)\n\n처음부터 최소점을 지나버림 (직선이 점들 위로 바로 올라감) -&gt; 바람직하지 않음\n이후 직선이 다시 점들 아래로 내려옴\n왔다갔다하면서 내려오는 것 같기는 하나 효율적인 느낌은 아님\n\n\n- 수틀리면 수렴안할수도??\n\nshow_animation(alpha=0.0085)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n🗣️ 0.001 -&gt; 0.0085\n\n직전의 0.0083과 얼마 차이가 나지도 않는데\n이번에는 왔다갔다하면서 수렴하지도 않음\n오히려 갈수록 포물선 모양으로 점점 올라감\n\n\n- 그냥 망할수도??\n\nshow_animation(alpha=0.01)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n🗣️ 0.001 -&gt; 0.01\n\n기울기가 무한대가 됨\n교훈: alpha를 잘 선택해야 수렴함\n\n\n\n\nplt.rcdefaults()\nplt.rcParams['figure.figsize'] = 4.5,3.0"
  },
  {
    "objectID": "posts/02wk-2.html#a.-기본패턴",
    "href": "posts/02wk-2.html#a.-기본패턴",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "A. 기본패턴",
    "text": "A. 기본패턴\n🗣️ SSE 말고 MSE로\n\n## -- 외우세요!!! -- ##\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = X@What \n    # step2: loss\n    loss = torch.sum((y-yhat)**2)/100\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    What.data = What.data - 0.1 * What.grad\n    What.grad = None\n\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What.data,'--')\nplt.title(f'What={What.data.reshape(-1)}');"
  },
  {
    "objectID": "posts/02wk-2.html#b.-step2의-수정-loss_fn-이용",
    "href": "posts/02wk-2.html#b.-step2의-수정-loss_fn-이용",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "B. Step2의 수정 – loss_fn 이용",
    "text": "B. Step2의 수정 – loss_fn 이용\n🗣️(\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\n\n\nyhat=X@What\n\n\ntorch.sum((y-yhat)**2)/100 # MSE\n\ntensor(85.8769, grad_fn=&lt;DivBackward0&gt;)\n\n\n\ntorch.mean((y-yhat)**2) # MSE\n\ntensor(85.8769, grad_fn=&lt;MeanBackward0&gt;)\n\n\n\ndef loss_fn(yhat, y):\n    return torch.mean((y-yhat)**2)\n\n\nloss_fn(yhat,y)\n\ntensor(85.8769, grad_fn=&lt;MeanBackward0&gt;)\n\n\n\nloss_fn 원리를 잘 모른다면 pytorch 함수 이용\n\n\nloss_fn = torch.nn.MSELoss()\nloss_fn(yhat,y) # 결과는 동일\n\ntensor(85.8769, grad_fn=&lt;MseLossBackward0&gt;)\n\n\n\n틀린 설명\n\ntorch.nn.MSELoss는 함수인데, “None -&gt; MSE를 계산해주는 함수”인 함수\n\n맞는 설명\n\ntorch.nn.MSELoss는 callable object를 생성하는 클래스\n\n\n)🗣️\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\nloss_fn = torch.nn.MSELoss()\nfor epoc in range(30):\n    # step1: yhat \n    yhat = X@What \n    # step2: loss\n    #loss = torch.sum((y-yhat)**2)/100\n    loss = loss_fn(yhat,y) # 여기서는 큰 상관없지만 습관적으로 yhat을 먼저넣는 연습을 하자!!\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    What.data = What.data - 0.1 * What.grad\n    What.grad = None\n\n🗣️ loss_fn은 무조건 yhat 먼저\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What.data,'--')\nplt.title(f'What={What.data.reshape(-1)}');"
  },
  {
    "objectID": "posts/02wk-2.html#c.-step1의-수정-net-이용",
    "href": "posts/02wk-2.html#c.-step1의-수정-net-이용",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "C. Step1의 수정 – net 이용",
    "text": "C. Step1의 수정 – net 이용\n🗣️ yhat = X@What도 알고 싶지 않다면 (네트워크 이용)\n# net – net 오브젝트란?\n원래 yhat을 이런식으로 구했는데 ~\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\nyhat= X@What\nyhat[:5]\n\ntensor([[-29.8211],\n        [-28.6215],\n        [-24.9730],\n        [-21.2394],\n        [-19.7919]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n아래와 같은 방식으로 코드를 짜고 싶음..\nyhat = net(X) # \n🗣️ X를 입력으로 받아 yhat을 출력하고 싶음\n위와 같은 코드를 가능하게 하는 net은 torch에서 지원하고 아래와 같이 사용할 수 있음.\n🗣️(\n\n# torch.nn.Linear?\n\nnet = torch.nn.Linear(\n    in_features= ??,\n    out_features= ??,\n    bias= False # default는 True\n)\n\nin_features: 입력(X)에 대한 차원 (features를 dimension으로 생각)\n\n\nX.shape # 100은 관측값 개수에 따라 바뀔 수 있고, 2는 모형이 정해지면 안 바뀜\n\ntorch.Size([100, 2])\n\n\n\nout_features: 출력(y)에 대한 차원\n\n\ny.shape # 마찬가지로 1\n\ntorch.Size([100, 1])\n\n\n\nnet = torch.nn.Linear(\n    in_features= 2,\n    out_features= 1,\n    bias= False\n)\n\n\nyhat = net(X)\nyhat[:5]\n\ntensor([[-0.1600],\n        [-0.1362],\n        [-0.0639],\n        [ 0.0101],\n        [ 0.0388]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\n원래 구한 yhat과 비교하면 What을 설정하지 않았으므로 당연히 다름\n\n\nnet.weight # What과 같다고 생각하면 됨\n\nParameter containing:\ntensor([[0.3320, 0.1982]], requires_grad=True)\n\n\n\n엄밀히 말하면 net.weight는 2x1 matrix가 아니라 1x2 martix\n\n컴퓨터 공학적 이유로 이렇게 되어 있음 (column vector보다 row vector 연산이 쉽다고 함)\n\n\n\nnet.weight.T # 이게 진짜 What과 동일\n\ntensor([[0.3320],\n        [0.1982]], grad_fn=&lt;PermuteBackward0&gt;)\n\n\n\nnet.weight.data = torch.tensor([[-5.0],[10.0]]).T\nnet.weight.data\n\ntensor([[-5., 10.]])\n\n\n\nyhat= net(X)\nyhat[:5]\n\ntensor([[-29.8211],\n        [-28.6215],\n        [-24.9730],\n        [-21.2394],\n        [-19.7919]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\n원래 구한 yhat과 동일\n\n)🗣️\n\n# yhat = net(X) \nnet = torch.nn.Linear(\n    in_features=2, # X:(n,2) --&gt; 2 \n    out_features=1, # yhat:(n,1) --&gt; 1 \n    bias=False \n)\n\n\nnet.weight.data = torch.tensor([[-5.0], [10.0]]).T # .T 를 해야함. 외우세요 \nnet.weight\n\nParameter containing:\ntensor([[-5., 10.]], requires_grad=True)\n\n\n\nnet(X)[:5]\n\ntensor([[-29.8211],\n        [-28.6215],\n        [-24.9730],\n        [-21.2394],\n        [-19.7919]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\n(X@What)[:5]\n\ntensor([[-29.8211],\n        [-28.6215],\n        [-24.9730],\n        [-21.2394],\n        [-19.7919]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\n(X@net.weight.T)[:5]\n\ntensor([[-29.8211],\n        [-28.6215],\n        [-24.9730],\n        [-21.2394],\n        [-19.7919]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n#\n- 수정된코드\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\nfor epoc in range(30):\n    # step1: yhat\n    # yhat = X@What \n    yhat = net(X)\n    # step2: loss\n    loss = loss_fn(yhat,y)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    net.weight.data = net.weight.data - 0.1 * net.weight.grad\n    net.weight.grad = None\n\n🗣️ What.data -&gt; net.weight.data, What.grad -&gt; net.weight.grad\n\nplt.plot(x,y,'o')\nplt.plot(x,net(X).data,'--')\nplt.title(f'net.weight={net.weight.data.reshape(-1)}');"
  },
  {
    "objectID": "posts/02wk-2.html#d.-step4의-수정-optimizer의-이용",
    "href": "posts/02wk-2.html#d.-step4의-수정-optimizer의-이용",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "D. Step4의 수정 – optimizer의 이용",
    "text": "D. Step4의 수정 – optimizer의 이용\n- 소망: 아래의 과정을 좀 더 편하게 했으면..\nnet.weight.data = net.weight.data - 0.1 * net.weight.grad\nnet.weight.data = None \n# optimizer – 이걸 이용하면 update 과정을 손쉽게 할 수 있음\n기존코드\n\n## -- 준비과정 -- ## \n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n\n\n## -- 1에폭진행 -- ## \n# step1: \nyhat = net(X)\n# step2: loss\nloss = loss_fn(yhat,y)\n# step3: 미분\nloss.backward()\n# step4: update\nprint(net.weight.data)\nnet.weight.data = net.weight.data - 0.1 * net.weight.grad\nprint(net.weight.data)\nnet.weight.grad = None\n\ntensor([[-5., 10.]])\ntensor([[-3.6577,  8.8111]])\n\n\n\n## -- 2에폭진행 -- ## \n# step1: 2에폭진행\nyhat = net(X)\n# step2: loss\nloss = loss_fn(yhat,y)\n# step3: 미분\nloss.backward()\n# step4: update\nprint(net.weight.data)\nnet.weight.data = net.weight.data - 0.1 * net.weight.grad\nprint(net.weight.data)\nnet.weight.grad = None\n\ntensor([[-3.6577,  8.8111]])\ntensor([[-2.5548,  7.8612]])\n\n\n새로운코드 – optimizer 이용\n🗣️(\n\ntorch.optim.SGD : optimizer를 만들어줌\ntorch.optim.SGD는 net.weight를 갖고 있어야 함(What)\n\nnet.weight는 net.parameters()로 볼 수 있음\nnet.parameters()는 generator: iterable object -&gt; list화 가능\n\ntorch.optim.SGD는 학습률 lr도 갖고 있어야 함\n\n\nnet.weight\n\nParameter containing:\ntensor([[-2.5548,  7.8612]], requires_grad=True)\n\n\n\nnet.parameters()\n\n&lt;generator object Module.parameters at 0x7fc922ade820&gt;\n\n\n\nlist(net.parameters()) # 값을 보려면\n\n[Parameter containing:\n tensor([[-2.5548,  7.8612]], requires_grad=True)]\n\n\n\n# optimizr = torch.optim.SGD(net.parameters(), lr=0.1) # net.parameters(): generator\n\n\nnet.weight.data = net.weight.data - 0.1 * net.weight.grad\n\n=&gt; optimizr.step()\n\nnet.weight.grad = None\n\n=&gt; optimizr.zero_grad()\n\n\n)🗣️\n\n## -- 준비과정 -- ## \n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n# step4를 위한 사전준비\noptimizr = torch.optim.SGD(net.parameters(),lr=0.1)\n\n\n## -- 1에폭진행 -- ## \nyhat = net(X)\n# step2: loss\nloss = loss_fn(yhat,y)\n# step3: 미분\nloss.backward()\n# step4: update\nprint(net.weight.data)\n#net.weight.data = net.weight.data - 0.1 * net.weight.grad\noptimizr.step()\nprint(net.weight.data)\n#net.weight.grad = None\noptimizr.zero_grad()\n\ntensor([[-5., 10.]])\ntensor([[-3.6577,  8.8111]])\n\n\n\n## -- 2에폭진행 -- ## \nyhat = net(X)\n# step2: loss\nloss = loss_fn(yhat,y)\n# step3: 미분\nloss.backward()\n# step4: update\nprint(net.weight.data)\n#net.weight.data = net.weight.data - 0.1 * net.weight.grad\noptimizr.step()\nprint(net.weight.data)\n#net.weight.grad = None\noptimizr.zero_grad()\n\ntensor([[-3.6577,  8.8111]])\ntensor([[-2.5548,  7.8612]])\n\n\n#\n- 수정된코드\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n# step4를 위한 사전준비 \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = net(X)\n    # step2: loss\n    loss = loss_fn(yhat,y)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.data,'--')\nplt.title(f'net.weight={net.weight.data.reshape(-1)}');"
  },
  {
    "objectID": "posts/01wk-2.html",
    "href": "posts/01wk-2.html",
    "title": "01wk-2, 02wk-1: (회귀) – 회귀모형, 손실함수, 파이토치를 이용한 추정",
    "section": "",
    "text": "📘 Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\n📝 🗣️ ✍️ 🔬 ❓"
  },
  {
    "objectID": "posts/01wk-2.html#a.-아이스-아메리카노-가짜자료",
    "href": "posts/01wk-2.html#a.-아이스-아메리카노-가짜자료",
    "title": "01wk-2, 02wk-1: (회귀) – 회귀모형, 손실함수, 파이토치를 이용한 추정",
    "section": "A. 아이스 아메리카노 (가짜자료)",
    "text": "A. 아이스 아메리카노 (가짜자료)\n- 카페주인인 박혜원씨는 온도와 아이스아메리카노 판매량이 관계가 있다는 것을 알았다. 구체적으로는\n\n“온도가 높아질 수록 (=날씨가 더울수록) 아이스아메리카노의 판매량이 증가”\n\n한다는 사실을 알게 되었다. 이를 확인하기 위해서 아래와 같이 100개의 데이터를 모았다.\n\ntemp = [-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n        -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n        -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n        -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n        -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n        -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n        -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n         0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n         0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n         0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n         1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n         1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n         2.3935,  2.6056,  2.6057,  2.6632]\n\n\nsales= [-8.5420, -6.5767, -5.9496, -4.4794, -4.2516, -3.1326, -4.0239, -4.1862,\n        -3.3403, -2.2027, -2.0262, -2.5619, -1.3353, -2.0466, -0.4664, -1.3513,\n        -1.6472, -0.1089, -0.3071, -0.6299, -0.0438,  0.4163,  0.4166, -0.0943,\n         0.2662,  0.4591,  0.8905,  0.8998,  0.6314,  1.3845,  0.8085,  1.2594,\n         1.1211,  1.9232,  1.0619,  1.3552,  2.1161,  1.1437,  1.6245,  1.7639,\n         1.6022,  1.7465,  0.9830,  1.7824,  2.1116,  2.8621,  2.1165,  1.5226,\n         2.5572,  2.8361,  3.3956,  2.0679,  2.8140,  3.4852,  3.6059,  2.5966,\n         2.8854,  3.9173,  3.6527,  4.1029,  4.3125,  3.4026,  3.2180,  4.5686,\n         4.3772,  4.3075,  4.4895,  4.4827,  5.3170,  5.4987,  5.4632,  6.0328,\n         5.2842,  5.0539,  5.4538,  6.0337,  5.7250,  5.7587,  6.2020,  6.5992,\n         6.4621,  6.5140,  6.6846,  7.3497,  8.0909,  7.0794,  6.8667,  7.4229,\n         7.2544,  7.1967,  9.5006,  9.0339,  7.4887,  9.0759, 11.0946, 10.3260,\n        12.2665, 13.0983, 12.5468, 13.8340]\n\n🗣️ 음수 판매량은 일단 무시\n여기에서 temp는 평균기온이고, sales는 아이스아메리카노 판매량이다. 평균기온과 판매량의 그래프를 그려보면 아래와 같다.\n\nplt.plot(temp,sales,'o')\n\n\n\n\n\n\n\n\n🗣️ 약간의 오차는 있지만 선으로 보임\n오늘 바깥의 온도는 0.5도 이다. 아이스 아메라카노를 몇잔정도 만들어 두면 좋을까?\n🗣️ 이 그래프를 보고 4.5잔 정도로 짐작 가능"
  },
  {
    "objectID": "posts/01wk-2.html#b.-가짜자료를-만든-방법",
    "href": "posts/01wk-2.html#b.-가짜자료를-만든-방법",
    "title": "01wk-2, 02wk-1: (회귀) – 회귀모형, 손실함수, 파이토치를 이용한 추정",
    "section": "B. 가짜자료를 만든 방법",
    "text": "B. 가짜자료를 만든 방법\n- 방법1: \\(y_i= w_0+w_1 x_i +\\epsilon_i = 2.5 + 4x_i +\\epsilon_i, \\quad i=1,2,\\dots,n\\)\n🗣️(\nxi = 온도 = temp\nyi = 판매량 = sales\n판매량 = 2.5 + 4*온도 + 오차\n\ntorch.randn(10) # 표준정규분포에서 10개 값 추출, 길이가 10인 vector (column vector인지 row vector인지는 모름)\n\ntensor([-0.4351, -0.4066,  1.2577, -1.1443,  0.3941, -0.2229, -0.4337,  0.8736,\n         0.6216,  1.0963])\n\n\n\ntorch.randn(100).sort() # 100개 값을 정렬 / 앞은 정렬된 값, 뒤는 인덱스\n\ntorch.return_types.sort(\nvalues=tensor([-3.3450e+00, -2.3363e+00, -1.7533e+00, -1.6534e+00, -1.4996e+00,\n        -1.4218e+00, -1.3757e+00, -1.3314e+00, -1.1898e+00, -1.1594e+00,\n        -1.1386e+00, -1.0975e+00, -1.0961e+00, -1.0899e+00, -1.0250e+00,\n        -9.7851e-01, -9.1254e-01, -8.8307e-01, -8.7845e-01, -8.4915e-01,\n        -7.4344e-01, -7.0972e-01, -7.0845e-01, -6.8746e-01, -6.7488e-01,\n        -6.6512e-01, -6.0503e-01, -5.8921e-01, -5.4838e-01, -5.1363e-01,\n        -5.0996e-01, -4.7537e-01, -4.3955e-01, -3.5707e-01, -3.4237e-01,\n        -3.4013e-01, -3.2890e-01, -3.2078e-01, -3.0216e-01, -2.9112e-01,\n        -2.8083e-01, -2.4387e-01, -2.4171e-01, -2.0109e-01, -1.9779e-01,\n        -1.9549e-01, -5.8397e-02, -2.5842e-02, -2.2056e-02,  2.0055e-03,\n         1.0348e-02,  2.2201e-02,  2.5445e-02,  2.6868e-02,  6.2116e-02,\n         1.3408e-01,  1.5172e-01,  2.0091e-01,  2.3218e-01,  2.5000e-01,\n         2.7442e-01,  2.8144e-01,  3.4857e-01,  3.7494e-01,  4.4520e-01,\n         4.8013e-01,  4.9466e-01,  5.0311e-01,  5.7595e-01,  6.2995e-01,\n         6.3221e-01,  6.5666e-01,  6.5788e-01,  6.6027e-01,  6.7909e-01,\n         7.1635e-01,  7.1752e-01,  7.2141e-01,  8.0059e-01,  8.0419e-01,\n         8.0801e-01,  8.1830e-01,  8.9444e-01,  9.6222e-01,  9.9973e-01,\n         1.1303e+00,  1.1527e+00,  1.2046e+00,  1.2086e+00,  1.2469e+00,\n         1.2752e+00,  1.2872e+00,  1.3125e+00,  1.4296e+00,  1.4390e+00,\n         1.5448e+00,  1.6129e+00,  1.6454e+00,  1.6769e+00,  1.7580e+00]),\nindices=tensor([81, 19, 56, 18, 89, 54, 27, 31, 65, 85, 94, 47,  0,  7,  8, 57, 14, 92,\n         3, 12, 86, 48,  9, 82, 62, 78,  1, 28, 32, 67, 21, 53, 10, 30, 23,  5,\n        88, 24, 63, 40, 20, 77, 34, 87, 99, 80, 41,  4, 69, 90, 35, 72, 58, 11,\n        22, 42, 76, 95, 74, 38, 46, 59, 91, 68, 43, 44, 50, 96, 51,  6, 29, 13,\n        66, 49, 73,  2, 70, 93, 97, 16, 15, 98, 55, 33, 39, 84, 25, 61, 17, 64,\n        45, 26, 75, 71, 79, 37, 60, 83, 36, 52]))\n\n\n\na = torch.randn(100).sort()\ntype(a)\n\ntorch.return_types.sort\n\n\n\na[0]\n\ntensor([-2.8188e+00, -2.7746e+00, -2.5355e+00, -2.4374e+00, -2.2716e+00,\n        -2.1492e+00, -1.8555e+00, -1.8281e+00, -1.6228e+00, -1.6164e+00,\n        -1.5151e+00, -1.5046e+00, -1.4989e+00, -1.4708e+00, -1.4605e+00,\n        -1.3748e+00, -1.3521e+00, -1.3183e+00, -1.2710e+00, -1.2416e+00,\n        -1.1459e+00, -1.0949e+00, -1.0907e+00, -1.0903e+00, -1.0481e+00,\n        -1.0313e+00, -1.0079e+00, -1.0003e+00, -9.9874e-01, -9.9081e-01,\n        -9.8943e-01, -9.7448e-01, -9.4772e-01, -9.4282e-01, -9.1282e-01,\n        -8.8605e-01, -8.6893e-01, -8.5283e-01, -7.8566e-01, -7.7867e-01,\n        -7.6961e-01, -7.4827e-01, -6.6928e-01, -6.3990e-01, -5.9842e-01,\n        -5.8057e-01, -5.5388e-01, -5.1941e-01, -5.1005e-01, -4.9040e-01,\n        -4.7796e-01, -3.9862e-01, -3.9854e-01, -3.8835e-01, -3.7719e-01,\n        -3.6587e-01, -3.0923e-01, -3.0278e-01, -2.5337e-01, -2.1358e-01,\n        -1.7441e-01, -1.4875e-01, -5.6163e-02, -3.3250e-02, -2.6646e-02,\n         2.1082e-03,  1.3442e-02,  9.5665e-02,  1.0434e-01,  1.2852e-01,\n         1.8255e-01,  2.2326e-01,  2.3160e-01,  2.5853e-01,  2.6803e-01,\n         3.3640e-01,  3.6288e-01,  3.7120e-01,  3.8451e-01,  4.0117e-01,\n         4.3763e-01,  4.5193e-01,  5.2404e-01,  6.1333e-01,  6.7461e-01,\n         6.8081e-01,  8.0477e-01,  9.1538e-01,  9.5395e-01,  1.0907e+00,\n         1.1139e+00,  1.1281e+00,  1.2559e+00,  1.2686e+00,  1.3258e+00,\n         1.3563e+00,  1.3864e+00,  1.5558e+00,  1.6258e+00,  2.1654e+00])\n\n\n\nx,_ = torch.randn(100).sort() # 언패킹\nx\n\ntensor([-2.8984, -2.6607, -2.2449, -2.2072, -2.1918, -2.1538, -1.9428, -1.9416,\n        -1.8612, -1.6956, -1.6357, -1.4785, -1.4322, -1.2127, -1.1737, -0.9456,\n        -0.9244, -0.8456, -0.8190, -0.7925, -0.7609, -0.7305, -0.7011, -0.6806,\n        -0.6442, -0.6117, -0.6059, -0.5994, -0.4920, -0.4066, -0.3879, -0.3867,\n        -0.3612, -0.3604, -0.3142, -0.3112, -0.2940, -0.2812, -0.2753, -0.2665,\n        -0.2145, -0.2106, -0.1864, -0.1633, -0.1470, -0.1331, -0.1316, -0.0994,\n        -0.0954, -0.0717, -0.0586, -0.0329,  0.0095,  0.0182,  0.0214,  0.0915,\n         0.0952,  0.1077,  0.1124,  0.1612,  0.1614,  0.1969,  0.2003,  0.3242,\n         0.3424,  0.3925,  0.4078,  0.4468,  0.4536,  0.5199,  0.5238,  0.5563,\n         0.5595,  0.6236,  0.6372,  0.6451,  0.6630,  0.7122,  0.7335,  0.7569,\n         0.7589,  0.8969,  0.9318,  0.9552,  1.0023,  1.0198,  1.1083,  1.1978,\n         1.2752,  1.2928,  1.3265,  1.3825,  1.4325,  1.5292,  1.6095,  1.6239,\n         1.7316,  2.0886,  2.3070,  3.2682])\n\n\n\ntorch.manual_seed(43052) # 값 고정\nx,_ = torch.randn(100).sort()\nx\n\ntensor([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n        -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n        -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n        -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n        -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n        -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n        -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n         0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n         0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n         0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n         1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n         1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n         2.3935,  2.6056,  2.6057,  2.6632])\n\n\n\n# temp # 위의 temp와 x는 동일\n\n\nsales[0] # -2.4821 * 4 + 2.5 + 오차\n\n-8.542\n\n\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\neps = torch.randn(100)*0.5 # 오차 만들기 (분산 작게하려고 0.5를 곱함)\n\n\n-2.4821 * 4 + 2.5 + eps[0] # sales[0]과 동일\n\ntensor(-8.5420)\n\n\n\nx[1] * 4 + 2.5 + eps[1] # 두 번째 값\n\ntensor(-6.5767)\n\n\n\nsales[1]\n\n-6.5767\n\n\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\neps = torch.randn(100)*0.5\ny = x * 4 + 2.5 + eps # 브로드캐스팅 이용\n\n\ntemp[:5],sales[:5]\n\n([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792],\n [-8.542, -6.5767, -5.9496, -4.4794, -4.2516])\n\n\n\nx[:5], y[:5] # 위와 동일\n\n(tensor([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792]),\n tensor([-8.5420, -6.5767, -5.9496, -4.4794, -4.2516]))\n\n\n)🗣️\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\neps = torch.randn(100)*0.5\ny = x * 4 + 2.5 + eps\n\n\nx[:5], y[:5]\n\n(tensor([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792]),\n tensor([-8.5420, -6.5767, -5.9496, -4.4794, -4.2516]))\n\n\n- 방법2: \\({\\bf y}={\\bf X}{\\bf W} +\\boldsymbol{\\epsilon}\\)\n\n\\({\\bf y}=\\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\dots \\\\ y_n\\end{bmatrix}, \\quad {\\bf X}=\\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\dots \\\\ 1 & x_n\\end{bmatrix}, \\quad {\\bf W}=\\begin{bmatrix} 2.5 \\\\ 4 \\end{bmatrix}, \\quad \\boldsymbol{\\epsilon}= \\begin{bmatrix} \\epsilon_1 \\\\ \\dots \\\\ \\epsilon_n\\end{bmatrix}\\)\n\n🗣️(\n\\(y_1 = 2.5 + 4x_1 + \\epsilon_1\\)\n\\(y_2 = 2.5 + 4x_2 + \\epsilon_2\\)\n\\(y_3 = 2.5 + 4x_3 + \\epsilon_3\\) … 을 위와 같이 표현할 수 있음\n방법1은 scalar로 표현, 방법2는 matrix로 표현\n\ny # 길이가 100인 vector (방법1) / 방법2는 (100,1) matrix로 표현되어야 함\n\ntensor([-8.5420, -6.5767, -5.9496, -4.4794, -4.2516, -3.1326, -4.0239, -4.1862,\n        -3.3403, -2.2027, -2.0262, -2.5619, -1.3353, -2.0466, -0.4664, -1.3513,\n        -1.6472, -0.1089, -0.3071, -0.6299, -0.0438,  0.4163,  0.4166, -0.0943,\n         0.2662,  0.4591,  0.8905,  0.8998,  0.6314,  1.3845,  0.8085,  1.2594,\n         1.1211,  1.9232,  1.0619,  1.3552,  2.1161,  1.1437,  1.6245,  1.7639,\n         1.6022,  1.7465,  0.9830,  1.7824,  2.1116,  2.8621,  2.1165,  1.5226,\n         2.5572,  2.8361,  3.3956,  2.0679,  2.8140,  3.4852,  3.6059,  2.5966,\n         2.8854,  3.9173,  3.6527,  4.1029,  4.3125,  3.4026,  3.2180,  4.5686,\n         4.3772,  4.3075,  4.4895,  4.4827,  5.3170,  5.4987,  5.4632,  6.0328,\n         5.2842,  5.0539,  5.4538,  6.0337,  5.7250,  5.7587,  6.2020,  6.5992,\n         6.4621,  6.5140,  6.6846,  7.3497,  8.0909,  7.0794,  6.8667,  7.4229,\n         7.2544,  7.1967,  9.5006,  9.0339,  7.4887,  9.0759, 11.0946, 10.3260,\n        12.2665, 13.0983, 12.5468, 13.8340])\n\n\n\nx # 길이가 100인 vector (방법1) / 방법2는 [1 x] 이런식으로 표현되어야 함\n\ntensor([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n        -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n        -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n        -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n        -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n        -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n        -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n         0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n         0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n         0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n         1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n         1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n         2.3935,  2.6056,  2.6057,  2.6632])\n\n\n[1 x] 만들기\n\ntorch.ones(100) , x # 길이가 100인 vector\n\n(tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n tensor([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n         -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n         -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n         -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n         -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n         -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n         -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n          0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n          0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n          0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n          1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n          1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n          2.3935,  2.6056,  2.6057,  2.6632]))\n\n\n\n# torch.stack([torch.ones(100) , x]) # 좌우로 합치기 위해 stack 사용\nprint(torch.stack([torch.ones(100) , x]).shape)\n# torch.stack([torch.ones(100) , x], axis=1) # 원했던 결과\nprint(torch.stack([torch.ones(100) , x], axis=1).shape)\n\n# torch.stack([torch.ones(100) , x]).T # 다른 방법\nprint(torch.stack([torch.ones(100) , x]).T.shape)\n\ntorch.Size([2, 100])\ntorch.Size([100, 2])\ntorch.Size([100, 2])\n\n\n\nX = torch.stack([torch.ones(100) , x], axis=1)\nW = torch.tensor([[2.5],[4.0]])\ny = X@W + eps.reshape(100,1)\ny.shape\n\ntorch.Size([100, 1])\n\n\n\nsales[:5]\n\n[-8.542, -6.5767, -5.9496, -4.4794, -4.2516]\n\n\n\ny[:5,0]\n\ntensor([-8.5420, -6.5767, -5.9496, -4.4794, -4.2516])\n\n\nsales와 y 동일\n🔬🗣️(\n\n(참고) 인덱싱 관련 설명\n\n\ny[:5]\n\ntensor([[-8.5420],\n        [-6.5767],\n        [-5.9496],\n        [-4.4794],\n        [-4.2516]])\n\n\ny는 matrix 이므로\n\ny[:5,[0]] # column vector처럼 됨\n\ntensor([[-8.5420],\n        [-6.5767],\n        [-5.9496],\n        [-4.4794],\n        [-4.2516]])\n\n\n\n# y[:,:] # y가 그대로 나옴\n\n\ny[:5,:] # 그 중 5개만\n\ntensor([[-8.5420],\n        [-6.5767],\n        [-5.9496],\n        [-4.4794],\n        [-4.2516]])\n\n\n나열 방식만 다르고 값은 sales와 똑같음\n)🔬🗣️\n\nX = torch.stack([torch.ones(100) , x], axis=1) # (100, 2)\nW = torch.tensor([[2.5],[4.0]]) # (2, 1)\ny = X@W + eps.reshape(100,1) # (100, 1)\nx # 아마도 (100,) \n\ntensor([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n        -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n        -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n        -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n        -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n        -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n        -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n         0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n         0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n         0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n         1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n         1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n         2.3935,  2.6056,  2.6057,  2.6632])\n\n\n(100,)을 (100,1)로 바꾸고 싶음\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\neps = torch.randn(100)*0.5\ny = x * 4 + 2.5 + eps\n\nX = torch.stack([torch.ones(100) , x], axis=1) # (100, 2)\nW = torch.tensor([[2.5],[4.0]]) # (2, 1)\ny = X@W + eps.reshape(100,1) # (100, 1)\nx = X[:,[1]]\n\n\nx[:5], y[:5]\n\n(tensor([[-2.4821],\n         [-2.3621],\n         [-1.9973],\n         [-1.6239],\n         [-1.4792]]),\n tensor([[-8.5420],\n         [-6.5767],\n         [-5.9496],\n         [-4.4794],\n         [-4.2516]]))\n\n\n\ntemp[:5], sales[:5]\n\n([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792],\n [-8.542, -6.5767, -5.9496, -4.4794, -4.2516])\n\n\n방법 2처럼 matrix로도 가능하다는 것을 확인\n)🗣️\n📝(\nX = torch.stack([torch.ones(100),x],axis=1)\nW = torch.tensor([[2.5],[4.0]])\ny = X@W + eps.reshape(100,1)\nx = X[:,[1]]\n✍️ 편의상 위의 코드는 실행시키지 않음\n\nX[:5,:], y[:5,:]\n\n(tensor([[ 1.0000, -2.4821],\n         [ 1.0000, -2.3621],\n         [ 1.0000, -1.9973],\n         [ 1.0000, -1.6239],\n         [ 1.0000, -1.4792]]),\n tensor([[-8.5420],\n         [-6.5767],\n         [-5.9496],\n         [-4.4794],\n         [-4.2516]]))\n\n\n)📝\n- ture와 observed data를 동시에 시각화\n🗣️(\n\nplt.plot(temp, sales) # 이러한 데이터를 관측했다고 생각\n\n\n\n\n\n\n\n\n\nplt.plot(temp, sales, 'o') # scatter plot\n\n\n\n\n\n\n\n\n\nplt.plot(x, y, 'o') # 위와 동일\n\n\n\n\n\n\n\n\nx에서 y로 가는 패턴을 찾고 싶음\n\nplt.plot(x, y, 'o', label=\"observed data\") # 관측한 값\nplt.legend()\n\n\n\n\n\n\n\n\n\nplt.plot(x, y, 'o', label=\"observed data\") # 점선 + epsilon(통계적으로 설명할 수 없는 현상, random)\nplt.plot(x, 2.5 + 4*x, '--', label=\"true\") # 원래 관측되어야 했던 값\nplt.legend()\n\n\n\n\n\n\n\n\n\n하고 싶은 것\n\n카페 주인: 온도가 0.5일 때 얼마나 팔릴지 알고 싶음\n가장 간단: 0.5를 점선 위에 올린 후 y 값을 예측 (0.5 * 4 + 2.5 = 4.5)\n하지만 실제로는 파란색만 알고 있으므로 위의 방법은 cheating\n\n\n\nplt.plot(x,y,'o',label=r\"observed data: $(x_i,y_i)$\")\n#plt.plot(x,2.5+4*x,'--',label=r\"true: $(x_i, 4x_i+2.5)$ // $y=4x+2.5$ \")\nplt.legend()\n\n\n\n\n\n\n\n\n\n하고 싶은 것\n\n위의 상태에서 적당한 추세선을 그려서 추정\n\n\n)🗣️\n\nplt.plot(x,y,'o',label=r\"observed data: $(x_i,y_i)$\")\n#plt.plot(x,2.5+4*x,'--',label=r\"true: $(x_i, 4x_i+2.5)$ // $y=4x+2.5$ \")\nplt.legend()"
  },
  {
    "objectID": "posts/01wk-2.html#c.-회귀분석이란",
    "href": "posts/01wk-2.html#c.-회귀분석이란",
    "title": "01wk-2, 02wk-1: (회귀) – 회귀모형, 손실함수, 파이토치를 이용한 추정",
    "section": "C. 회귀분석이란?",
    "text": "C. 회귀분석이란?\n- 클리셰: 관측한 자료 \\((x_i,y_i)\\) 가 있음 \\(\\to\\) 우리는 \\((x_i,y_i)\\)의 관계를 파악하여 새로운 \\(x\\)가 왔을때 그것에 대한 예측값(predicted value) \\(\\hat{y}\\)을 알아내는 법칙을 알고 싶음 \\(\\to\\) 관계를 파악하기 위해서 \\((x_i, y_i)\\)의 산점도를 그려보니 \\(x_i\\)와 \\(y_i\\)는 선형성을 가지고 있다는 것이 파악됨 \\(\\to\\) 오차항이 등분산성을 가지고 어쩌고 저쩌고… \\(\\to\\) 하여튼 \\((x_i,y_i)\\) 를 “적당히 잘 관통하는” 어떠한 하나의 추세선을 잘 추정하면 된다.\n- 회귀분석이란 산점도를 보고 적당한 추세선을 찾는 것이다. 좀 더 정확하게 말하면 \\((x_1,y_1) \\dots (x_n,y_n)\\) 으로 \\(\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\) 를 최대한 \\(\\begin{bmatrix} 2.5 \\\\ 4 \\end{bmatrix}\\)와 비슷하게 찾는 것.\n\ngiven data : \\(\\big\\{(x_i,y_i) \\big\\}_{i=1}^{n}\\)\nparameter: \\({\\bf W}=\\begin{bmatrix} w_0 \\\\ w_1 \\end{bmatrix}\\)\nestimated parameter: \\({\\bf \\hat{W}}=\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\)\n\n🗣️ y = ax + b 꼴에서 a, b를 정함\n- 더 쉽게 말하면 아래의 그림을 보고 “적당한” 추세선을 찾는 것이다.\n\nplt.plot(x,y,'o',label=r\"observed data: $(x_i,y_i)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n- 추세선을 그리는 행위 = \\((w_0,w_1)\\)을 선택하는일"
  },
  {
    "objectID": "posts/01wk-2.html#a.-1단계-최초의-점선",
    "href": "posts/01wk-2.html#a.-1단계-최초의-점선",
    "title": "01wk-2, 02wk-1: (회귀) – 회귀모형, 손실함수, 파이토치를 이용한 추정",
    "section": "A. 1단계 – 최초의 점선",
    "text": "A. 1단계 – 최초의 점선\n🗣️(\n\nWhat = torch.tensor([[-5.0],[10.0]], requires_grad=True)\nWhat\n\ntensor([[-5.],\n        [10.]], requires_grad=True)\n\n\n\nyhat = X@What\n\n\n# plt.plot(x, y, 'o')\n# plt.plot(x, yhat, '--')\n\n\n실행시키면 error\nrequires_grad=True를 없애면 error 발생 X\nrequires_grad=True\n\n미분이 필요함을 나타내는 옵션\n지금은 의미를 정확하게 알 수 없지만 편의상 이름을 미분꼬리표라고 부르겠음\n\n\n\nWhat+1\n\ntensor([[-4.],\n        [11.]], grad_fn=&lt;AddBackward0&gt;)\n\n\n\n꼬리표가 바뀌긴 하나 큰 지장은 없음\n\n\n# yhat\n\n\nyhat을 실행시켜도 계산을 잘 되나 꼬리표가 있음\n꼬리표 때문에 그래프를 그리면 error가 발생\n해결책 (꼬리표를 제거한다고 생각, 꼬리표가 있으면 계산은 가능하나 그래프 그리기 불가능)\n\nRuntimeError: Can’t call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n.data\n\n\n\n# yhat.detach()\n\n\n# yhat.data\n\n\nplt.plot(x, y, 'o')\nplt.plot(x, yhat.detach(), '--') # 그림을 그리기 위해서 yhat의 미분꼬리표를 제거\n\n\n\n\n\n\n\n\n)🗣️\n🗣️ 그냥 아무 직선을 그음 (2단계만 잘 되면 상관 X)\n\nWhat = torch.tensor([[-5.0],[10.0]])\nWhat\n\ntensor([[-5.],\n        [10.]])\n\n\n\nyhat = X@What \n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.data,'--')"
  },
  {
    "objectID": "posts/01wk-2.html#b.-2단계-update",
    "href": "posts/01wk-2.html#b.-2단계-update",
    "title": "01wk-2, 02wk-1: (회귀) – 회귀모형, 손실함수, 파이토치를 이용한 추정",
    "section": "B. 2단계 – update",
    "text": "B. 2단계 – update\n- ’적당한 정도’를 판단하기 위한 장치: loss function 도입!\n\\[loss=\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2=\\sum_{i=1}^{n}(y_i-(\\hat{w}_0+\\hat{w}_1x_i))^2=({\\bf y}-{\\bf\\hat{y}})^\\top({\\bf y}-{\\bf\\hat{y}})=({\\bf y}-{\\bf X}{\\bf \\hat{W}})^\\top({\\bf y}-{\\bf X}{\\bf \\hat{W}})\\]\n🗣️ loss는 \\((\\hat{w}_0, \\hat{w}_1)\\)을 입력으로 받음. loss 값을 최소로 만드는 \\((\\hat{w}_0, \\hat{w}_1)\\)을 찾으면 됨.\n- loss 함수의 특징: 위 그림의 주황색 점선이 ‘적당할 수록’ loss값이 작다.\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat)\n\n\n\n\n\n\n\n\n\nloss = torch.sum((y-yhat)**2)\nloss\n\ntensor(8587.6875)\n\n\n- 우리의 목표: 이 loss(=8587.6275)을 더 줄이자.\n\n궁극적으로는 아예 모든 조합 \\((\\hat{w}_0,\\hat{w}_1)\\)에 대하여 가장 작은 loss를 찾으면 좋겠다.\n\n- 문제의 치환: 생각해보니까 우리의 문제는 아래와 같이 수학적으로 단순화 되었다.\n\n가장 적당한 주황색 선을 찾자 \\(\\to\\) \\(loss(\\hat{w}_0,\\hat{w}_1)\\)를 최소로하는 \\((\\hat{w}_0,\\hat{w}_1)\\)의 값을 찾자.\n\n- 수정된 목표: \\(loss(\\hat{w}_0,\\hat{w}_1)\\)를 최소로 하는 \\((\\hat{w}_0,\\hat{w}_1)\\)을 구하라.\n\n단순한 수학문제가 되었다. 이것은 마치 \\(f(x,y)\\)를 최소화하는 \\((x,y)\\)를 찾으라는 것임.\n함수의 최대값 혹은 최소값을 컴퓨터를 이용하여 찾는것을 “최적화”라고 하며 이는 산공교수님들이 가장 잘하는 분야임. (산공교수님들에게 부탁하면 잘해줌, 산공교수님들은 보통 최적화해서 어디에 쓸지보다 최적화 자체에 더 관심을 가지고 연구하심)\n최적화를 하는 방법? 경사하강법\n\n# 경사하강법 아이디어 (1차원)\n\n임의의 점을 찍는다.\n그 점에서 순간기울기를 구한다. (접선) &lt;– 미분\n순간기울기(=미분계수)의 부호를 살펴보고 부호와 반대방향으로 움직인다.\n\n\n팁: 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 조절한다. \\(\\to\\) \\(\\alpha\\)를 도입\n\n\n최종수식: \\(\\hat{w} \\leftarrow \\hat{w} - \\alpha \\times \\frac{\\partial}{\\partial w}loss(w)\\)\n\n#\n🗣️(\n\n보폭: step size\n함수를 최고차항이 양수인 2차 함수로 생각하면 이해하기 쉬움\n\nx에서 a만큼 오른쪽으로 이동: x + a\nx에서 a만큼 왼쪽으로 이동: x - a\n미분계수가 0인쪽으로 움직일 때\n\nx가 오른쪽에 있으면 미분계수 &gt; 0\nx가 왼쪽에 있으면 미분계수 &lt; 0\n\n미분계수가 0인쪽과 가까울수록 접선 기울기의 절대값이 작아짐 -&gt; \\(\\alpha\\)로 조절\n\n\\(\\alpha\\)가 너무 작으면 수렴 속도가 느릴 수 있고, 너무 크면 수렴을 안할 수 있음\n\n예시) \\(f(x) = x^2\\) 에서 \\(x=2\\)일 때 \\(\\alpha = 1\\)이면 \\(x\\)는 \\(-2\\)와 \\(2\\)만 왔다갔다 함\n\n\n)🗣️\n# 경사하강법 아이디어 (2차원)\n\n\n임의의 점을 찍는다.\n그 점에서 순간기울기를 구한다. (접평면) &lt;– 편미분\n순간기울기(=미분계수)의 부호를 살펴보고 부호와 반대방향으로 각각 움직인다.\n\n\n팁: 여기서도 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 각각 조절한다. \\(\\to\\) \\(\\alpha\\)를 도입.\n\n#\n🗣️(\n\n여기서 임의의 점은 2차원\n편미분: 하나만 변수로 보고 나머지 고정\n\n이후 1차원 방식과 동일\n어떤 방향(왼쪽, 오른쪽)으로 얼마나 갈 지(\\(\\alpha\\))\n\n\n)🗣️\n- 경사하강법 = loss를 줄이도록 \\({\\bf \\hat{W}}\\)를 개선하는 방법\n\n업데이트 공식: 수정값 = 원래값 - \\(\\alpha\\) \\(\\times\\) 기울어진크기(=미분계수)\n여기에서 \\(\\alpha\\)는 전체적인 보폭의 크기를 결정한다. 즉 \\(\\alpha\\)값이 클수록 한번의 update에 움직이는 양이 크다.\n\n🗣️ \\(\\alpha\\)를 ML에서는 학습률이라고 함\n- loss는 \\(\\hat{\\bf W} =\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\) 에 따라서 값이 바뀌는 함수로 해석가능하고 구체적인 형태는 아래와 같음.\n\\[ loss(\\hat{w}_0,\\hat{w}_1) := loss(\\hat{\\bf W})=\\sum_{i=1}^{n}(y_i-(\\hat{w}_0+\\hat{w}_1x_i))^2=({\\bf y}-{\\bf X}{\\bf \\hat{W}})^\\top({\\bf y}-{\\bf X}{\\bf \\hat{W}})\\]\n따라서 구하고 싶은것은 아래와 같음\n\\[\\hat{\\bf W}^{LSE} = \\underset{\\bf \\hat{W}}{\\operatorname{argmin}} ~ loss(\\hat{\\bf W})\\]\n\n\n\n\n\n\nWarning\n\n\n\n아래의 수식\n\\[\\hat{\\bf W}^{LSE} = \\underset{\\bf \\hat{W}}{\\operatorname{argmin}} ~ loss(\\hat{\\bf W})\\]\n은 아래와 같이 표현해도 무방합니다.\n\\[\\hat{\\bf W} = \\underset{\\bf W}{\\operatorname{argmin}} ~ loss({\\bf W})\\]\n마치 함수 \\(f(\\hat{x})=({\\hat x}-1)^2\\) 을 \\(f(x)=(x-1)^2\\) 이라고 표현할 수 있는 것 처럼요..\n\n\n여기까지 01wk-2에서 수업했습니다~\n\n여기부터는 02wk-1에서..\n# 지난시간 복습\n\n# x,X,W,y // X = [1 x], W = [w0, w1]' # 회귀분석에서는 W=β\n# 회귀모형: y=X@W+ϵ = X@β+ϵ\n# true: E(y)=X@W\n# observed: (x,y)\n# estimated W = What = [w0hat, w1hat]' &lt;-- 아무값이나넣었음.. \n# estimated y = yhat = X@What = X@β̂ \n# loss = yhat이랑 y랑 얼마나 비슷한지 = sum((y-yhat)^2)\n# (x,y) 보고 최적의 선분을 그리는것 = loss를 가장 작게 만드는 What = [w0hat, w1hat] 를 찾는것\n# 전략: (1) 아무 What나 찍는다 (2) 그거보다 더 나은 What을 찾는다. (3) 1-2를 반복한다. \n# 전략2가 어려운데, 이를 수행하는 방법이 경사하강법 \n# 경사하강법 알고리즘: 더나은What = 원래What - 0.1*미분값\n\n\nWhat = torch.tensor([[-5.0],[10.0]])\nWhat\n\ntensor([[-5.],\n        [10.]])\n\n\n\nyhat = X@What \nplt.plot(x,y,'o')\nplt.plot(x,yhat,'--')\n\n\n\n\n\n\n\n\n\nloss = torch.sum((y-yhat)**2)\nloss\n\ntensor(8587.6875)\n\n\n복습끝~\n#\n- 더 나은 선으로 업데이트하기 위해서는 공식 “더나은What = 원래What - 0.1*미분값” 를 적용해야하고 이를 위해서는 미분값을 계산할 수 있어야 함.\n\n\n\n\n\n\nImportant\n\n\n\n경사하강법을 좀 더 엄밀하게 써보자. 경사하강법은 \\(loss(\\hat{\\bf W})\\)를 최소로 만드는 \\(\\hat{\\bf W}\\)를 컴퓨터로 구하는 방법인데, 구체적으로는 아래와 같다.\n1. 임의의 점 \\(\\hat{\\bf W}\\)를 찍는다.\n2. 그 점에서 순간기울기를 구한다. 즉 \\(\\left.\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})\\right|_{{\\bf W}=\\hat{\\bf W}}\\) 를 계산한다.\n3. \\(\\hat{\\bf W}\\)에서의 순간기울기의 부호를 살펴보고 부호와 반대방향으로 움직인다. 이때 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 각각 조절한다. 즉 아래의 수식에 따라 업데이트 한다.\n\\[\\hat{\\bf W} \\leftarrow \\hat{\\bf W} - \\alpha \\times \\left.\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})\\right|_{{\\bf W}=\\hat{\\bf W}}\\]\n여기에서 맨 마지막 수식을 간단하게 쓴 것이 더나은What = 원래What - 0.1*미분값 이다.\n\n\n- 미분값을 계산하는 방법1\n\n# 손실 8587.6875 를 계산하는 또 다른 방식\ndef l(w0,w1):\n    yhat = w0 + w1*x\n    return torch.sum((y-yhat)**2)\n\n\nl(-5,10)\n\ntensor(8587.6875)\n\n\n🗣️(\n\n굳이 함수를 만든 이유: 미분하려고\n편미분 구현\n\nl(-5,10)\n(l(w0+h,w1) - l(w0,w1))/h: 도함수\n\n\n)🗣️\n\nh=0.001\nprint((l(-5+h,10) - l(-5,10))/h)\nprint((l(-5,10+h) - l(-5,10))/h)\n\ntensor(-1341.7968)\ntensor(1190.4297)\n\n\n일단 이거로 업데이트해볼까?\n\n# 더나은What = 원래What - 0.1*미분값\n# [-5,10] - 0.001 * [-1341.7968,1190.4297]\n\n\nsssss = What - 0.001 * torch.tensor([[-1341.7968],[1190.4297]])\nsssss\n\ntensor([[-3.6582],\n        [ 8.8096]])\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What,'-') # 원래What: 주황색\nplt.plot(x,X@sssss,'-') # 더나은What: 초록색\n\n\n\n\n\n\n\n\n\n잘 된 것 같긴한데..\n미분구하는게 너무 어려워..\n다른 방법 없을까?\n\n\n\n\n\n\n\nImportant\n\n\n\n사실 이 방법은\n\n\\(\\frac{\\partial}{\\partial w_0}loss(w_0,w_1) \\approx \\frac{loss(w_0+h,w_1)-loss(w_0,w_1)}{h}\\)\n\\(\\frac{\\partial}{\\partial w_1}loss(w_0,w_1) \\approx \\frac{loss(w_0,w_1+h)-loss(w_0,w_1)}{h}\\)\n\n이 계산을 이용하여\n\\[\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W}):= \\begin{bmatrix} \\frac{\\partial}{\\partial w_0} \\\\ \\frac{\\partial}{\\partial w_1}\\end{bmatrix}loss({\\bf W}) =  \\begin{bmatrix} \\frac{\\partial}{\\partial w_0}loss({\\bf W}) \\\\ \\frac{\\partial}{\\partial w_1}loss({\\bf W})\\end{bmatrix}  =  \\begin{bmatrix} \\frac{\\partial}{\\partial w_0}loss(w_0,w_1) \\\\ \\frac{\\partial}{\\partial w_1}loss(w_0,w_1)\\end{bmatrix}\\]\n를 계산한 것이라 볼 수 있죠\n\n\n- 미분값을 계산하는 방법2\n\n## 약간의 지식이 필요함. \n# loss = (y-XWhat)'(y-XWhat)\n# = (y'-What'X')(y-XWhat)\n# = y'y-y'XWhat -What'X'y + What'X'XWhat \n# loss를 What으로 미분\n# loss' = -X'y - X'y + 2X'XWhat\n\n❓ 행렬 미분 복습 필요\n\n-2*X.T@y + 2*X.T@X@What\n\ntensor([[-1342.2524],\n        [ 1188.9302]])\n\n\n🗣️ 약간의 오차는 있지만 위와 비슷 (그러나 방법1, 방법2 말고 다른 방법을 쓰고 싶음)\n\n\n\n\n\n\nImportant\n\n\n\n이 방법은 \\(loss({\\bf W})\\)의 미분을 구할수 있어야 사용가능합니다. 즉\n\\[\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})= -2{\\bf X}^\\top {\\bf y} + 2{\\bf X}^\\top {\\bf X}{\\bf W}\\]\n를 계산할 수 있어야 합니다.\n\n\n- 미분값을 계산하는 방법3 – 이 패턴을 외우세여\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nWhat\n\ntensor([[-5.],\n        [10.]], requires_grad=True)\n\n\n\nyhat = X@What\nloss = torch.sum((y-yhat)**2)\nloss\n\ntensor(8587.6875, grad_fn=&lt;SumBackward0&gt;)\n\n\n🗣️ 꼬리표가 있긴하지만 결과는 위와 동일\n\nloss.backward() # loss를 미분하라.. 꼬리표가 있게 한 What으로.. \n\n🗣️(\n\nloss를 What으로 미분\n일반적으로 미분을 하면 도함수가 나오지만, 이 경우는 도함수에서 현재 What값을 대입한 결과가 나옴\n정확히 말하면 What에 해당하는 접선의 기울기\n실행해도 실행결과는 나오지 않음. 결과는 What.grad에 저장되어 있음\n\n)🗣️\n\nWhat.grad\n\ntensor([[-1342.2524],\n        [ 1188.9305]])\n\n\n- 위의 코드를 다시 복습해보자.\n– loss.backward()실행전 –\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nyhat = X@What\nloss = torch.sum((y-yhat)**2)\n\n\nWhat.data, What.grad\n\n(tensor([[-5.],\n         [10.]]),\n None)\n\n\n🗣️ .backward()를 실행하지 않아서 .grad에 아무 값도 없음(None으로 초기화 됨)\n– loss.backward()실행후 –\n\nloss.backward()\n\n\nWhat.data, What.grad\n\n(tensor([[-5.],\n         [10.]]),\n tensor([[-1342.2524],\n         [ 1188.9305]]))\n\n\n🗣️(\n\n.backward()를 실행하니 .grad에 기울기 값이 계산되어 업데이트 됨\nloss.backward(): What.grad &lt;- What에서 미분값 인줄 알았으나 사실은\nloss.backward(): What.grad &lt;- What.grad + What에서 미분값 (즉, 누적을 시켜서 더함)\n\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\n\n\nyhat = X@What\nloss = torch.sum((y-yhat)**2)\nloss.backward()\n\n\nWhat.data, What.grad\n\n(tensor([[-5.],\n         [10.]]),\n tensor([[-1342.2524],\n         [ 1188.9305]]))\n\n\n\nyhat = X@What\nloss = torch.sum((y-yhat)**2)\nloss.backward()\n\n\nWhat.data, What.grad\n\n(tensor([[-5.],\n         [10.]]),\n tensor([[-2684.5049],\n         [ 2377.8611]]))\n\n\n\n두 배가 됨\n왜?\n\n산공: 알고리즘 상에서는 What.grad의 값은 loss.backward()를 할때마다 초기화가 맞음 (이론적으로는 이게 맞음)\n컴공: 그러면 나중에 계산 효율이 안 좋아짐 (웬만하면 계산한 미분값을 갖고 있고 싶음, 필요 없으면 따로 초기화하면 됨)\n통계: 최적화와 미분 빨리하는 것에 관심 X\n\n\n)🗣️\n✍️ 이후 원활한 코드 실행을 위한 코드 (의미X)\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nyhat = X@What\nloss = torch.sum((y-yhat)**2)\n\nWhat.data, What.grad\n\nloss.backward()\n\nWhat.data, What.grad\n\n(tensor([[-5.],\n         [10.]]),\n tensor([[-1342.2524],\n         [ 1188.9305]]))\n\n\n# 1회 업데이트 과정을 차근차근 시각화하며 정리해보자.\n\nalpha = 0.001 \nprint(f\"{What.data} -- 수정전\")\nprint(f\"{-alpha*What.grad} -- 수정하는폭\")\nprint(f\"{What.data-alpha*What.grad} -- 수정후\")\nprint(f\"{torch.tensor([[2.5],[4]])} -- 참값(이건 비밀~~)\")\n\ntensor([[-5.],\n        [10.]]) -- 수정전\ntensor([[ 1.3423],\n        [-1.1889]]) -- 수정하는폭\ntensor([[-3.6577],\n        [ 8.8111]]) -- 수정후\ntensor([[2.5000],\n        [4.0000]]) -- 참값(이건 비밀~~)\n\n\n🗣️(\n\n\\(\\alpha\\)를 0.001로 잡은 이유: 미분값이 1000 단위로 나와서 그대로 넣으면 원하는 결과가 안 나올 것 같음\n\n잘 수렴될때까지 시행착오를 겪으며 해봐야 함\n\n수정하는 폭: 위 그래프에서 주황색 선\n수정 후: 위 그래프에서 초록색 선\n수정 전보다 수정 후가 참값에 가까우므로 올바른 방향을 진행되고 있음을 알 수 있음\n\n)🗣️\n\nWbefore = What.data\nWafter = What.data - alpha * What.grad \nWbefore, Wafter\n\n(tensor([[-5.],\n         [10.]]),\n tensor([[-3.6577],\n         [ 8.8111]]))\n\n\n\nplt.plot(x,y,'o',label=r'observed data')\nplt.plot(x,X@Wbefore,'--', label=r\"$\\hat{\\bf y}_{before}={\\bf X}@\\hat{\\bf W}_{before}$\")\nplt.plot(x,X@Wafter,'--', label=r\"$\\hat{\\bf y}_{after}={\\bf X}@\\hat{\\bf W}_{after}$\")\nplt.legend()\n\n\n\n\n\n\n\n\n#"
  },
  {
    "objectID": "posts/01wk-2.html#c.-3단계-iteration-learn-estimate-bfhat-w",
    "href": "posts/01wk-2.html#c.-3단계-iteration-learn-estimate-bfhat-w",
    "title": "01wk-2, 02wk-1: (회귀) – 회귀모형, 손실함수, 파이토치를 이용한 추정",
    "section": "C. 3단계 – iteration (=learn = estimate \\(\\bf{\\hat W}\\))",
    "text": "C. 3단계 – iteration (=learn = estimate \\(\\bf{\\hat W}\\))\n- 이제 1단계와 2단계를 반복만하면된다. 그래서 아래와 같은 코드를 작성하면 될 것 같은데…\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True) # 최초의 직선을 만드는 값\nfor epoc in range(30):\n    yhat = X@What \n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - 0.001 * What.grad\n돌려보면 잘 안된다.\n🗣️ 원래 철자는 epoch이지만 편의상 epoc으로 작성, 잘 되기 위해서는 마지막에 초기화를 해줘야 함\n- 아래와 같이 해야한다.\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True) # 최초의 직선을 만드는 값\nfor epoc in range(30):\n    yhat = X@What \n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - 0.001 * What.grad\n    What.grad = None \n\n\nplt.plot(x,y,'o',label=r\"observed: $(x_i,y_i)$\")\nplt.plot(x,X@What.data,'--o', label=r\"estimated: $(x_i,\\hat{y}_i)$ -- after 30 iterations (=epochs)\", alpha=0.4 )\nplt.legend()\n\n\n\n\n\n\n\n\n- 왜? loss.backward() 는 아래의 역할을 하는것 처럼 이해되었지만\n\nWhat.grad \\(\\leftarrow\\) What에서미분값\n\n실제로는 아래의 역할을 수행하기 때문이다. (컴퓨터공학적인 이유로..)\n\nWhat.grad \\(\\leftarrow\\) What.grad + What에서미분값\n\n\n\n\n\n\n\nNote\n\n\n\nWhat.grad \\(\\leftarrow\\) What.grad + What에서미분값 임을 확인하기 위해서.. 약간의 테스트를 했습니다.\n먼저\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True) # 최초의 직선을 만드는 값\nprint(What.data)\nprint(What.grad)\n를 확인한뒤 아래를 반복실행해봤을때\nyhat = X@What \nloss = torch.sum((y-yhat)**2)\nloss.backward() # \nprint(What.data)\nprint(What.grad)\nWhat.data와 What.grad 값이 계속 일정하게 나온다면\n\nWhat.grad \\(\\leftarrow\\) What에서미분값\n\n이와 같은 계산이 진행되는 것이겠고, What.grad의 값이 자꾸 커진다면\n\nWhat.grad \\(\\leftarrow\\) What.grad + What에서미분값\n\n이와 같은 계산이 진행되는 것이겠죠?"
  },
  {
    "objectID": "posts/04wk-1.html",
    "href": "posts/04wk-1.html",
    "title": "04wk-1: (신경망) – 로지스틱의 한계 극복",
    "section": "",
    "text": "📘 Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\n\n\n\n\n\n\n\n\nType\nWhat It Means\nWhen I Use It\n\n\n\n\n📝 Lecture\nOriginal material from the professor’s notes\nWhen I’m referencing core concepts or provided code\n\n\n🗣️ In-Class Note\nVerbal explanations shared during the lecture\nWhen I want to record something the professor said in class but didn’t include in the official notes\n\n\n✍️ My Note\nMy thoughts, interpretations, or additional explanations\nWhen I reflect on or explain something in my own words\n\n\n🔬 Experiment\nCode I tried out or changed to explore further\nWhen I test variations or go beyond the original example\n\n\n❓ Question\nQuestions I had while studying\nWhen I want to revisit or research something more deeply\n\n\n\n📝 🗣️ ✍️ 🔬 ❓\n\n1. 강의노트 원본 및 영상 링크\nhttps://guebin.github.io/DL2025/posts/04wk-1.html\n\n\n2. Imports 📝\n\nimport torch\nimport matplotlib.pyplot as plt \nimport pandas as pd\n\n\nplt.rcParams['figure.figsize'] = (4.5, 3.0)\n\n\n\n3. 꺽인직선을 만드는 방법 📝\n지난시간복습\n\n# 오늘의 잔소리.. \n## 회귀(카페예제): yhat=직선=linr(x), 정규분포, MSEloss\n## 로지스틱(스펙과취업): yhat=곡선=sig(직선)=sig(linr(x)), 베르누이, BCELoss\n## 이름없음(스펙의역설): yhat=꺽인곡선=sig(꺽인직선)=sig(??), 베르누이, BCELOss\n\n- 로지스틱의 한계를 극복하기 위해서는 시그모이드를 취하기 전에 꺽인 그래프 모양을 만드는 기술이 있어야겠음.\n- 아래와 같은 벡터 \\({\\bf x}\\)를 가정하자.\n\nx = torch.linspace(-1,1,1001).reshape(-1,1)\nx\n\ntensor([[-1.0000],\n        [-0.9980],\n        [-0.9960],\n        ...,\n        [ 0.9960],\n        [ 0.9980],\n        [ 1.0000]])\n\n\n- 목표: 아래와 같은 벡터 \\({\\bf y}\\)를 만들어보자.\n\\[{\\bf y} = [y_1,y_2,\\dots,y_{n}]^\\top, \\quad y_i = \\begin{cases} 9x_i +4.5& x_i &lt;0 \\\\ -4.5x_i + 4.5& x_i &gt;0 \\end{cases}\\]\n\n\n\n\n\n\nCaution\n\n\n\n일반적으로 제 강의노트에서\n\n독립변수 = 설명변수 = \\({\\bf x}\\), \\({\\bf X}\\)\n종속변수 = 반응변수 = \\({\\bf y}\\)\n\n를 의미하는데요, 여기에서 \\(({\\bf x},{\\bf y})\\) 는 (독립변수,종속변수) 혹은 (설명변수,반응변수) 를 의미하는게 아닙니다.\n\n\n# 방법1 – 수식 그대로 구현\n🗣️(\n\nplt.plot(x,x,color=\"red\")\nplt.plot(x,9*x+4.5,color=\"blue\")\nplt.plot(x,-4.5*x+4.5,color=\"orange\")\n\n\n\n\n\n\n\n\n\n# (9*x+4.5)[x&lt;0]\n\n\nlen(9*x+4.5)\n\n1001\n\n\n\nlen((9*x+4.5)[x&lt;0])\n\n501\n\n\n)🗣️\n\nplt.plot(x,9*x+4.5,color=\"blue\",alpha=0.1)\nplt.plot(x[x&lt;0], (9*x+4.5)[x&lt;0],color=\"blue\")\nplt.plot(x,-4.5*x+4.5,color=\"orange\",alpha=0.1)\nplt.plot(x[x&gt;0], (-4.5*x+4.5)[x&gt;0],color=\"orange\")\n\n\n\n\n\n\n\n\n\ny = x*0\ny[x&lt;0] = (9*x+4.5)[x&lt;0]\ny[x&gt;0] = (-4.5*x+4.5)[x&gt;0]\nplt.plot(x,y)\n\n\n\n\n\n\n\n\n#\n# 방법2 – 렐루이용\n🗣️(\n\nrelu = torch.nn.ReLU()\nplt.plot(x,x,color=\"red\")\nplt.plot(x,relu(x),color=\"blue\")\n\n\n\n\n\n\n\n\n\nx가 0보다 작으면 y를 0으로 만듦\n\n\nrelu = torch.nn.ReLU()\nplt.plot(x,x,color=\"red\")\nplt.plot(x,relu(-x),color=\"blue\")\n\n\n\n\n\n\n\n\n\ny축 대칭\n\n\nrelu = torch.nn.ReLU()\nplt.plot(x,relu(x),color=\"red\")\nplt.plot(x,relu(-x),color=\"blue\")\n\n\n\n\n\n\n\n\n\nrelu = torch.nn.ReLU()\nplt.plot(x,-relu(x),color=\"red\")\nplt.plot(x,relu(-x),color=\"blue\")\n\n\n\n\n\n\n\n\n\nrelu = torch.nn.ReLU()\nplt.plot(x,-relu(x),color=\"red\")\nplt.plot(x,-relu(-x),color=\"blue\")\n\n\n\n\n\n\n\n\n\n파란색의 기울기를 9, 빨간색의 기울기를 4.5로 만들면\n\n\nrelu = torch.nn.ReLU()\nplt.plot(x,-4.5*relu(x),color=\"red\")\nplt.plot(x,-9*relu(-x),color=\"blue\")\n\n\n\n\n\n\n\n\n\ny절편이 4.5이므로\n\n\nrelu = torch.nn.ReLU()\n# plt.plot(x,-4.5*relu(x),color=\"red\")\n# plt.plot(x,-9*relu(-x),color=\"blue\")\ny = -4.5*relu(x) + -9*relu(-x)\nplt.plot(x,y)\n\n\n\n\n\n\n\n\n\nrelu = torch.nn.ReLU()\n# plt.plot(x,-4.5*relu(x),color=\"red\")\n# plt.plot(x,-9*relu(-x),color=\"blue\")\ny = -4.5*relu(x) + -9*relu(-x) + 4.5\nplt.plot(x,y)\n\n\n\n\n\n\n\n\n)🗣️\n\nrelu = torch.nn.ReLU()\n#plt.plot(x,-4.5*relu(x),color=\"red\")\n#plt.plot(x,-9*relu(-x),color=\"blue\")\ny = -4.5*relu(x) + -9*relu(-x) + 4.5\nplt.plot(x,y)\n\n\n\n\n\n\n\n\n- 좀 더 중간과정을 시각화 – (강의때 설명안했음)\n\nfig = plt.figure(figsize=(6, 4))\nspec = fig.add_gridspec(4, 3)\nax1 = fig.add_subplot(spec[:2,0]); ax1.set_title(r'$x$'); ax1.set_ylim(-1,1)\nax2 = fig.add_subplot(spec[2:,0]); ax2.set_title(r'$-x$'); ax2.set_ylim(-1,1)\nax3 = fig.add_subplot(spec[:2,1]); ax3.set_title(r'$relu(x)$'); ax3.set_ylim(-1,1)\nax4 = fig.add_subplot(spec[2:,1]); ax4.set_title(r'$relu(-x)$'); ax4.set_ylim(-1,1)\nax5 = fig.add_subplot(spec[1:3,2]); ax5.set_title(r'$-4.5 relu(x)-9 relu(-x)+4.5$')\n#---#\nax1.plot(x,'--',color='C0')\nax2.plot(-x,'--',color='C1')\nax3.plot(relu(x),'--',color='C0')\nax4.plot(relu(-x),'--',color='C1')\nax5.plot(-4.5*relu(x)-9*relu(-x)+4.5,'--',color='C2')\nfig.tight_layout()\n\n\n\n\n\n\n\n\n#\n# 방법3 – relu의 브로드캐스팅 활용\n🗣️(\n\ntorch.tensor([[1,2],[2,3],[4,-4]]) \n\ntensor([[ 1,  2],\n        [ 2,  3],\n        [ 4, -4]])\n\n\n\nplt.plot(torch.tensor([[1,2],[2,3],[4,-4]]), '--o') \n\n\n\n\n\n\n\n\n\ncolumn별로 plot이 됨\n\n\ntorch.concat([x,-x], axis=1)\n\ntensor([[-1.0000,  1.0000],\n        [-0.9980,  0.9980],\n        [-0.9960,  0.9960],\n        ...,\n        [ 0.9960, -0.9960],\n        [ 0.9980, -0.9980],\n        [ 1.0000, -1.0000]])\n\n\n\nplt.plot(torch.concat([x,-x], axis=1))\n\n\n\n\n\n\n\n\n\n여기서 relu를 하면? relu는 column wise하게 브로드캐스팅 됨\n\n\nplt.plot(relu(torch.concat([x,-x], axis=1)))\n\n\n\n\n\n\n\n\n\nu = torch.concat([x,-x], axis=1)\nv = relu(u)\nplt.plot(v)\n\n\n\n\n\n\n\n\n\nu = torch.concat([x,-x], axis=1)\nv = relu(u)\nv[:,[0]] # 첫번째 열\n\ntensor([[0.0000],\n        [0.0000],\n        [0.0000],\n        ...,\n        [0.9960],\n        [0.9980],\n        [1.0000]])\n\n\n)🗣️\n- 우리가 하고 싶은 것\n\n# y = -4.5*relu(x) + -9*relu(-x) + 4.5\n\n- 아래와 같은 아이디어로 y를 계산해도 된다.\n\nx, relu 준비\nu = [x -x]\nv = relu(u) = [relu(x), relu(-x)] = [v1 v2]\ny = -4.5*v1 + -9*v2 + 4.5\n\n\nu = torch.concat([x,-x],axis=1)\nv = relu(u)\nv1 = v[:,[0]]\nv2 = v[:,[1]]\ny = -4.5*v1 -9*v2 + 4.5 \nplt.plot(x,y)\n\n\n\n\n\n\n\n\n🗣️(\n\nBonus\n\n\nv # nx2\n\ntensor([[0.0000, 1.0000],\n        [0.0000, 0.9980],\n        [0.0000, 0.9960],\n        ...,\n        [0.9960, 0.0000],\n        [0.9980, 0.0000],\n        [1.0000, 0.0000]])\n\n\n\nv.T # 2xn, 중첩 리스트로 해석 가능\n\ntensor([[0.0000, 0.0000, 0.0000,  ..., 0.9960, 0.9980, 1.0000],\n        [1.0000, 0.9980, 0.9960,  ..., 0.0000, 0.0000, 0.0000]])\n\n\n\nv1, v2 = v.T # 언패킹, v1과 v2는 length n인 vector\ny = -4.5*v1 -9*v2 + 4.5 \ny # y 역시 vector\n\ntensor([-4.5000, -4.4820, -4.4640,  ...,  0.0180,  0.0090,  0.0000])\n\n\n\ny가 nx1이 되어야하므로\n\n\nv1, v2 = v.T\ny = -4.5*v1 -9*v2 + 4.5 \ny = y.reshape(-1,1)\nplt.plot(x,y)\n\n\n\n\n\n\n\n\n)🗣️\n#\n# 방법4 – y = linr(v)\n🗣️(\n\nv\n\ntensor([[0.0000, 1.0000],\n        [0.0000, 0.9980],\n        [0.0000, 0.9960],\n        ...,\n        [0.9960, 0.0000],\n        [0.9980, 0.0000],\n        [1.0000, 0.0000]])\n\n\n\nv @ torch.tensor([[-4.5],[-9]])\n\ntensor([[-9.0000],\n        [-8.9820],\n        [-8.9640],\n        ...,\n        [-4.4820],\n        [-4.4910],\n        [-4.5000]])\n\n\n\ny = v @ torch.tensor([[-4.5],[-9]]) + 4.5\nplt.plot(x,y)\n\n\n\n\n\n\n\n\n)🗣️\n\n# 4. y = -4.5*v1 + -9*v2 + 4.5 = [v1 v2] @ [[-4.5],[-9]] + 4.5 \n# y = -4 + 3*x = [1 x] @ [[-4],[3]]\n\n\nx \nu = torch.concat([x,-x],axis=1)\nv = relu(u) \ny = v @ torch.tensor([[-4.5],[-9]]) + 4.5 \n\n\nplt.plot(x,y)\n\n\n\n\n\n\n\n\n#\n# 방법5 – u = linr(x)\n🗣️(\n\n#u = [x -x] = x @ [[1 -1]]\n\n)🗣️\n\n# x \n# u = torch.concat([x,-x],axis=1)\n# v = relu(u) \n# y = v @ torch.tensor([[-4.5],[-9]]) + 4.5 \n\n\nx \nu = x @ torch.tensor([[1.0, -1.0]])\nv = relu(u) \ny = v @ torch.tensor([[-4.5],[-9]]) + 4.5 \n\n\nplt.plot(x,y)\n\n\n\n\n\n\n\n\n#\n# 방법6 – torch.nn.Linear()를 이용\n🗣️(\n\n# x \n# u = x @ torch.tensor([[1.0, -1.0]]) = linr(x) =&gt; l1(x) \n# v = relu(u) = a1(u)\n# y = v @ torch.tensor([[-4.5],[-9]]) + 4.5 = linr(x) =&gt; l2(v) \n\n\nl은 linear의 약자, a는 activation function의 약자\n\n\n# u = l1(x) # l1은 x-&gt;u인 선형변환: (n,1) -&gt; (n,2) 인 선형변환\nl1 = torch.nn.Linear(1,2,bias=False)\nl1.weight.data = torch.tensor([[1.0, -1.0]]).T \nl1(x)\n\ntensor([[-1.0000,  1.0000],\n        [-0.9980,  0.9980],\n        [-0.9960,  0.9960],\n        ...,\n        [ 0.9960, -0.9960],\n        [ 0.9980, -0.9980],\n        [ 1.0000, -1.0000]], grad_fn=&lt;MmBackward0&gt;)\n\n\n\nu\n\ntensor([[-1.0000,  1.0000],\n        [-0.9980,  0.9980],\n        [-0.9960,  0.9960],\n        ...,\n        [ 0.9960, -0.9960],\n        [ 0.9980, -0.9980],\n        [ 1.0000, -1.0000]])\n\n\n\n# u = l1(x) # l1은 x-&gt;u인 선형변환: (n,1) -&gt; (n,2) 인 선형변환\nl1 = torch.nn.Linear(1,2,bias=False)\nl1.weight.data = torch.tensor([[1.0, -1.0]]).T \na1 = relu \nl2 = torch.nn.Linear(2,1,bias=True) # + 4.5 =&gt; bias\nl2.weight.data = torch.tensor([[-4.5],[-9]]).T \nl2.bias.data = torch.tensor([4.5])\nu = l1(x)\nv = a1(u) \ny = l2(v) \n\n\ny\n\ntensor([[-4.5000],\n        [-4.4820],\n        [-4.4640],\n        ...,\n        [ 0.0180],\n        [ 0.0090],\n        [ 0.0000]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\nplt.plot(x,y.data)\n\n\n\n\n\n\n\n\n\npiecewise linear function 정의 (x -&gt; l1 -&gt; a1 -&gt; l2) =&gt; 한 번에 그래프 그리기 가능\n\n\npwlinr = torch.nn.Sequential(l1,a1,l2)\nplt.plot(x,pwlinr(x).data)\n\n\n\n\n\n\n\n\n)🗣️\n\n# x \n# u = x @ torch.tensor([[1.0, -1.0]]) = l1(x) \n# v = relu(u) = a1(u)\n# y = v @ torch.tensor([[-4.5],[-9]]) + 4.5 = l2(v) \n\n\n# u = l1(x) # l1은 x-&gt;u인 선형변환: (n,1) -&gt; (n,2) 인 선형변환\nl1 = torch.nn.Linear(1,2,bias=False)\nl1.weight.data = torch.tensor([[1.0, -1.0]]).T \na1 = relu \nl2 = torch.nn.Linear(2,1,bias=True)\nl2.weight.data = torch.tensor([[-4.5],[-9]]).T \nl2.bias.data = torch.tensor([4.5])\n#---#\nx\nu = l1(x)\nv = a1(u) \ny = l2(v) \n\n\nplt.plot(x,y.data)\n\n\n\n\n\n\n\n\n\npwlinr = torch.nn.Sequential(l1,a1,l2)\nplt.plot(x,pwlinr(x).data)\n\n\n\n\n\n\n\n\n#\n\n\n\n\n\n\nNote\n\n\n\n수식표현\n(1) \\({\\bf X}=\\begin{bmatrix} x_1 \\\\ \\dots \\\\ x_n \\end{bmatrix}\\)\n(2) \\(l_1({\\bf X})={\\bf X}{\\bf W}^{(1)}\\overset{bc}{+} {\\boldsymbol b}^{(1)}=\\begin{bmatrix} x_1 & -x_1 \\\\ x_2 & -x_2 \\\\ \\dots & \\dots \\\\ x_n & -x_n\\end{bmatrix}\\)\n\n\\({\\bf W}^{(1)}=\\begin{bmatrix} 1 & -1 \\end{bmatrix}\\)\n\\({\\boldsymbol b}^{(1)}=\\begin{bmatrix} 0 & 0 \\end{bmatrix}\\)\n\n(3) \\((a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big)=\\begin{bmatrix} \\text{relu}(x_1) & \\text{relu}(-x_1) \\\\ \\text{relu}(x_2) & \\text{relu}(-x_2) \\\\ \\dots & \\dots \\\\ \\text{relu}(x_n) & \\text{relu}(-x_n)\\end{bmatrix}\\)\n(4) \\((l_2 \\circ a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big){\\bf W}^{(2)}\\overset{bc}{+}b^{(2)}\\)\n\\(\\quad=\\begin{bmatrix} -4.5\\times\\text{relu}(x_1) -9.0 \\times \\text{relu}(-x_1) +4.5 \\\\ -4.5\\times\\text{relu}(x_2) -9.0 \\times\\text{relu}(-x_2) + 4.5 \\\\ \\dots \\\\ -4.5\\times \\text{relu}(x_n) -9.0 \\times\\text{relu}(-x_n)+4.5 \\end{bmatrix}\\)\n\n\\({\\bf W}^{(2)}=\\begin{bmatrix} -4.5 \\\\ -9 \\end{bmatrix}\\)\n\\(b^{(2)}=4.5\\)\n\n(5) \\(\\textup{pwlinr}({\\bf X})=(l_2 \\circ a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big){\\bf W}^{(2)}\\overset{bc}{+}b^{(2)}\\)\n\\(\\quad =\\begin{bmatrix} -4.5\\times\\text{relu}(x_1) -9.0 \\times \\text{relu}(-x_1) +4.5 \\\\ -4.5\\times\\text{relu}(x_2) -9.0 \\times\\text{relu}(-x_2) + 4.5 \\\\ \\dots \\\\ -4.5\\times \\text{relu}(x_n) -9.0 \\times\\text{relu}(-x_n)+4.5 \\end{bmatrix}\\)\n\n\n\n\n4. 스펙의역설 적합 📝\n- 다시한번 데이터 정리\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2025/main/posts/ironyofspec.csv\")\n\n🗣️(\n\ntorch.tensor(df.x)\n\ntensor([-1.0000, -0.9990, -0.9980,  ...,  0.9980,  0.9990,  1.0000],\n       dtype=torch.float64)\n\n\n\ndtype=torch.float64을 보기 싫으면 다음과 같이 하면 됨 (pytorch는 기본적으로 32형으로 저장되는 것을 원함)\n\n\ntorch.tensor(df.x).float() # vector\n\ntensor([-1.0000, -0.9990, -0.9980,  ...,  0.9980,  0.9990,  1.0000])\n\n\n\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\n\n\nplt.plot(x,y,'.',alpha=0.03)\n\n\n\n\n\n\n\n\n\nprob: 참값, 관측 불가\n\n)🗣️\n\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x,prob,'--')\n\n\n\n\n\n\n\n\n- Step1에 대한 생각: 네트워크를 어떻게 만들까? = 아키텍처를 어떻게 만들까? = 모델링\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n\n\\(l_1\\): torch.nn.Linear(1,2,bias=False)\n\\(a_1\\): torch.nn.ReLU()\n\\(l_2\\): torch.nn.Linear(2,1,bias=True)\n\\(a_2\\): torch.nn.Sigmoid()\n\n🗣️ l2까지는 꺾인 선\n- Step1-4\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2,bias=False),\n    torch.nn.ReLU(),\n    torch.nn.Linear(2,1,bias=True),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss() \noptimizr = torch.optim.Adam(net.parameters())\n\n🗣️ lr 따로 설정 안하면 default로 들어감\n\nfor epoc in range(5000):\n    ## step1\n    yhat = net(x)\n    ## step2\n    loss = loss_fn(yhat,y)\n    ## step3\n    loss.backward()\n    ## step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x,prob,'--')\nplt.plot(x,yhat.data,'--')\n\n\n\n\n\n\n\n\n한번더~\n\nfor epoc in range(5000):\n    ## step1\n    yhat = net(x)\n    ## step2\n    loss = loss_fn(yhat,y)\n    ## step3\n    loss.backward()\n    ## step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x,prob,'--')\nplt.plot(x,yhat.data,'--')\n\n\n\n\n\n\n\n\n🗣️(\n\n???\n\n\nnet\n\nSequential(\n  (0): Linear(in_features=1, out_features=2, bias=False)\n  (1): ReLU()\n  (2): Linear(in_features=2, out_features=1, bias=True)\n  (3): Sigmoid()\n)\n\n\n\nnet[0](x) # 처음 linear transform 통과\n\ntensor([[-2.8167,  3.9404],\n        [-2.8139,  3.9364],\n        [-2.8111,  3.9325],\n        ...,\n        [ 2.8111, -3.9325],\n        [ 2.8139, -3.9364],\n        [ 2.8167, -3.9404]], grad_fn=&lt;MmBackward0&gt;)\n\n\n\nplt.plot(x,net[0](x).data)\n\n\n\n\n\n\n\n\n\n기울기 튜닝이 이미 되어 있음 (생각대로라면 나중에 되어야 함)\n\n\nplt.plot(x,net[1](net[0](x)).data) # 랠루\n\n\n\n\n\n\n\n\n\nplt.plot(x,net[2](net[1](net[0](x))).data) # 2번째 linear transform\n\n\n\n\n\n\n\n\n\nplt.plot(x,net[3](net[2](net[1](net[0](x)))).data) # sigmoid\n\n\n\n\n\n\n\n\n\n원래라면 u = x @ [1 -1] 처럼 그래프 틀을 맞춰놓고 기울기를 미세조정하였지만\n기울기를 처음부터 미세조정하면서 해도 잘 맞을 수 있음\n\n이 말은 global min을 하나만 갖는 것이 아님 (여러 개의 최저값이 있을 수 있음)\n\n\n)🗣️"
  },
  {
    "objectID": "posts/03wk-1.html",
    "href": "posts/03wk-1.html",
    "title": "03wk-1: (회귀, 로지스틱) – 파이토치식 코딩패턴 (2), 로지스틱 모형",
    "section": "",
    "text": "📘 Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\n📝 🗣️ ✍️ 🔬 ❓"
  },
  {
    "objectID": "posts/03wk-1.html#a.-bias의-사용",
    "href": "posts/03wk-1.html#a.-bias의-사용",
    "title": "03wk-1: (회귀, 로지스틱) – 파이토치식 코딩패턴 (2), 로지스틱 모형",
    "section": "A. bias의 사용",
    "text": "A. bias의 사용\n🗣️(\n\n저번 시간 코드\n\n\nnet = torch.nn.Linear(2, 1, bias=False)\nnet.weight.data = torch.tensor([[-5.0, 10.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(), lr=0.1) # lr: learning rate\n\n# step 1~4\nfor epoc in range(30):\n    # 1\n    yhat = net(X)\n    # 2\n    loss = loss_fn(yhat,y)\n    # 3\n    loss.backward()\n    # 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nnet.weight # 지난 시간 결과와 동일\n\nParameter containing:\ntensor([[2.4290, 4.0144]], requires_grad=True)\n\n\n\n이제 bias=True\n\n\n# net(X) = X@net.weight.T # 현재 이렇게 알고 있으나 사실은 아님\n\n\nnet.weight\n\nParameter containing:\ntensor([[2.4290, 4.0144]], requires_grad=True)\n\n\n\nprint(net.bias) # 현재는 bias=False\n\nNone\n\n\n\n# net(X) = X@net.weight.T + net.bias # 사실은 이게 맞음\n\n\n둘은 동일\n\ny = X@W + ϵ # y = net(X) + ϵ\ny = w0hat + x*w1hat + ϵ # y = net(x) + ϵ\n\nnet(X) = X@net.weight.T + net.bias 에서 X가 x로 바뀌면\n\nnet(x) = x@net.weight.T + net.bias\nnet(x) = w0hat + x*w1hat 이므로\nnet.bias에 해당하는 것은 w0hat\nnet.weight.T에 해당하는 것은 w1hat 으로 생각 가능\n\n위를 기반으로 net(x)를 만들면\n\nx는 (n,1)이므로 input 차원은 1\n\n\n\nnet = torch.nn.Linear(1,1,bias=True)\nnet\n\nLinear(in_features=1, out_features=1, bias=True)\n\n\n\nnet.weight # 1x1 matrix\n\nParameter containing:\ntensor([[0.3480]], requires_grad=True)\n\n\n\nnet.bias # length 1인 vector\n\nParameter containing:\ntensor([0.7757], requires_grad=True)\n\n\n\nnet.weight.T # net(x) = x@net.weight.T + net.bias 에서 net.weight.T는 w1hat\n\ntensor([[0.3480]], grad_fn=&lt;PermuteBackward0&gt;)\n\n\n\nnet.weight.data = torch.tensor([[10.0]])\nnet.weight.data\n\ntensor([[10.]])\n\n\n\nnet.bias.data = torch.tensor([[-5.0]]) # net(x) = x@net.weight.T + net.bias 에서 net.bias는 w0hat\nnet.bias.data\n\ntensor([[-5.]])\n\n\n\n위의 내용을 저번 시간 코드에 반영하면\n\nnet 수정, weight 및 bias 값 수정\nnet(X) -&gt; net(x)\n\n\n\nnet = torch.nn.Linear(1, 1, bias=True)\nnet.weight.data = torch.tensor([[10.0]])\nnet.bias.data = torch.tensor([[-5.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(), lr=0.1) # lr: learning rate\n\n# step 1~4\nfor epoc in range(30):\n    # 1\n    yhat = net(x)\n    # 2\n    loss = loss_fn(yhat,y)\n    # 3\n    loss.backward()\n    # 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nnet.weight\n\nParameter containing:\ntensor([[4.0144]], requires_grad=True)\n\n\n\nnet.bias\n\nParameter containing:\ntensor([[2.4290]], requires_grad=True)\n\n\n\n저번 시간 결과와 동일\n\n)🗣️\nnet에서 bias를 사용\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=1,\n    out_features=1,\n    bias=True\n) # net(x) = x@net.weight.T + net.bias \nnet.bias.data = torch.tensor([-5.0])\nnet.weight.data = torch.tensor([[10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n# step4를 위한 사전준비 \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = net(x)\n    # step2: loss\n    loss = loss_fn(yhat,y)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nnet.bias.data, net.weight.data\n\n(tensor([2.4290]), tensor([[4.0144]]))\n\n\n#"
  },
  {
    "objectID": "posts/03wk-1.html#b.-잘못된-코드",
    "href": "posts/03wk-1.html#b.-잘못된-코드",
    "title": "03wk-1: (회귀, 로지스틱) – 파이토치식 코딩패턴 (2), 로지스틱 모형",
    "section": "B. 잘못된(?) 코드",
    "text": "B. 잘못된(?) 코드\n🗣️ bias의 default는 True이므로 저번 시간 코드에서 bias를 지우면 bias=True가 됨\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n# step4를 위한 사전준비 \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = net(X)\n    # step2: loss\n    loss = loss_fn(yhat,y)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    optimizr.step()\n    optimizr.zero_grad()\n\n🗣️(\n\nnet.weight # 결과가 많이 달라짐\n\nParameter containing:\ntensor([[-1.1114,  4.0080]], requires_grad=True)\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(X).data, '--')\n\n\n\n\n\n\n\n\n\n그런데 결과를 시각화해보면 나쁘지 않음\n\n)🗣️\n- 결과시각화\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.data,'--')\nplt.title(f'net.weight={net.weight.data.reshape(-1)}');\n\n\n\n\n\n\n\n\n- 나쁘지 않은 이유?\n✍️ 바로 밑의 코드는 편의상 실행 X\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n)\nyhat = net(X) = X@net.weight.T + net.bias\n\nnet.weight\n\nParameter containing:\ntensor([[-1.1114,  4.0080]], requires_grad=True)\n\n\n\nnet.bias\n\nParameter containing:\ntensor([3.5562], requires_grad=True)\n\n\n🗣️(\n\n원래대로라면 절편, 기울기 총 2개의 parameter만 학습해야하는데 위의 결과는 3개를 학습함\nyhat 계산 과정을 살펴보면\n\n\nX[[0],:] # nx2 martix에서 첫 번째 observation만 뽑음\n\ntensor([[ 1.0000, -2.4821]])\n\n\n\nyhat[:1] # 이 yhat이 어떻게 나왔는지 보면\n\ntensor([[-7.5063]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\nX[[0],:] @ net.weight.T + net.bias\n\n\n-1.1114 * 1.0000 + 4.0080 * (-2.4821) + 3.5562 # 약간의 차이는 소수점 차이\n\n-7.503456799999999\n\n\n\n-2.4821은 x, 다음과 같이 정리하면\n\n\n-1.1114 * 1.0000 + 3.5562\n\n2.4448\n\n\n\n절편에 대한 True 값: 2.5, 기울기에 대한 True 값: 4\n\n즉, 절편을 2개로 나눠서 학습함 (비효율적)\n\n그러면 이게 틀린 것인가?\n\n회귀분석에서 이렇게 모델링하면 틀림 (통계학적 관점)\n하지만 학습 결과 자체는 맞음 (비효율적일뿐)\nAI나 DL 관점에서는 최적의 parameter 개수가 정해지지 않은 경우가 많아서\n비효율적이긴해도 잘못으로 까지는 생각 X\n\n\n)🗣️"
  },
  {
    "objectID": "posts/03wk-1.html#a.-hatbf-y",
    "href": "posts/03wk-1.html#a.-hatbf-y",
    "title": "03wk-1: (회귀, 로지스틱) – 파이토치식 코딩패턴 (2), 로지스틱 모형",
    "section": "A. \\(\\hat{\\bf y} = ??\\)",
    "text": "A. \\(\\hat{\\bf y} = ??\\)\n🗣️(\n\n일반적으로 회귀분석에서 설명 변수, 반응 변수 모두 연속형 변수이지만,\ny가 상태를 의미할 때가 있음 (ex. X = 점수, y = 합격/불합격)\n\n합격을 1, 불합격을 0으로 숫자화하면\ny는 0 또는 1만 가짐\n\n이러한 자료는 매우 많음\n\n)🗣️\n- \\({\\bf X}\\)를 가지고 \\({\\bf y}\\)를 맞추는 아래와 같은 문제\n\nx = torch.tensor([-6,-5,-4,-3,-2,-1, 0, 1, 2, 3, 4, 5, 6.0]).reshape(-1,1)\ny = torch.tensor([ 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1]).reshape(-1,1)\nplt.plot(x,y,'o')\n\n\n\n\n\n\n\n\n🗣️(\n\nx가 증가함에 따라 y가 1이 될 것 같고, x가 감소함에 따라 y가 0될 것 같음\n모델링을 어떻게?\n모델링: observed data를 보고 error-free한 structure를 찾는 것\n여기서 error-free한 structure는?\n\nerror-free: 운적인 요소가 없음\n\n운적인 요소?\n\n이 경우 0점인데 합격, 1점인데 불합격\n도저히 받아들이지 못할 수 있음\n(이렇게 경계에 있는데 운적인 요소로 결정되는 경우)\n\n이것을 일반적인 회귀분석처럼 underlying(error-free)이 있고 오차항을 정규분포에서 error를 뽑은 것으로 설명하면 X\n\n이전의 cafe 데이터는 이렇게 설명 가능\n\n차라리 underlying에서 x값에 대응하는 y값을 성공 확률로 하는 베르누이 시행으로 설명하면 그럴듯 함\n\nunderlying: 여기서는 관측값이 아니고 확률을 의미하는 곡선으로 해석\n성공 확률이 0.9인 베르누이 시행을 했는데 0.1인 확률의 결과가 나와도 어쩔 수 없음 (운적인 요소)\n오차: 베르누이 시행에 의해 생성되는 랜덤성\n\n통계학과식 모델링\n\nstructure(error-free)뿐만 아니라 (이것도 어려움, 여기까지는 비통계학과식)\n관측치를 error term을 이용해 설명 (운적인 요소가 어떻게 작용하는지)\n\nyhat\n\nunderlying\ny가 0 또는 1만 가지므로 yhat도 그래야하나 싶지만 X (회귀분석에서 오차항이 포함된 관측치를 따라가는 것과 동일)\nyhat은 0과 1사이의 숫자 (모델링 대상: 관측치가 아니라 추세선)\n\n\n다음과 같이 모델링을 해보면\n\n\nprob = torch.exp(x) / (torch.exp(x) + 1)\nplt.plot(x,y,'o')\nplt.plot(x,prob,'--')\n\n\n\n\n\n\n\n\n\n\\(\\frac{e^x}{e^x + 1}\\)\n\n\\(x\\)가 커지면 1에 가까워지고\n\\(x=0\\)이면 1/2\n\\(x\\)가 작아지면 0에 가까워짐\n\n하지만 이 수식은 이 경우에만 맞고 확장성이 떨어짐\n\n)🗣️\n- 아래와 같이 모형화 하면?\n\nplt.plot(x,y,'o', label=r\"observed data (with error) = $(x_i,y_i)$\")\nplt.plot(x,torch.exp(x)/(1+torch.exp(x)),'o--', label = \"underlying (without error)\")\nplt.legend()"
  },
  {
    "objectID": "posts/03wk-1.html#b.-hatbf-y-fracexptextlinrbf-x1exptextlinrbf-x",
    "href": "posts/03wk-1.html#b.-hatbf-y-fracexptextlinrbf-x1exptextlinrbf-x",
    "title": "03wk-1: (회귀, 로지스틱) – 파이토치식 코딩패턴 (2), 로지스틱 모형",
    "section": "B. \\(\\hat{\\bf y} = \\frac{\\exp(\\text{linr}({\\bf X}))}{1+\\exp(\\text{linr}({\\bf X}))}\\)",
    "text": "B. \\(\\hat{\\bf y} = \\frac{\\exp(\\text{linr}({\\bf X}))}{1+\\exp(\\text{linr}({\\bf X}))}\\)\n- 걱정: 산점도가 꼭 아래와 같은 방식이 아니라면 어쩌지?\n\nplt.plot(x,y,'o')\n\n\n\n\n\n\n\n\n\n\\(x\\)가 증가할수록 \\(y\\)가 0이 된다면?\n0근처에서 변화가 일어나지 않고 2근처에서 변화가 일어난다면?\n변화가 좀 더 급하게 (혹은 완만하게 일어난다면?)\n\n🗣️(\n\n\\(\\frac{e^{-x}}{e^{-x} + 1}\\)\n합격률이 낮은 경우\nstrict하게 결과가 나뉘는 경우(ex. 장학금)\n\n\nplt.plot(x,y,'o', label=r\"observed data (with error) = $(x_i,y_i)$\")\nplt.plot(x,torch.exp(-x)/(1+torch.exp(-x)),'o--', label = \"underlying (without error)\")\nplt.legend()\n\n\n\n\n\n\n\n\n\nplt.plot(x,y,'o', label=r\"observed data (with error) = $(x_i,y_i)$\")\nplt.plot(x,torch.exp(-x+3)/(1+torch.exp(-x+3)),'o--', label = \"underlying (without error)\")\nplt.legend()\n\n\n\n\n\n\n\n\n\nplt.plot(x,y,'o', label=r\"observed data (with error) = $(x_i,y_i)$\")\nplt.plot(x,torch.exp(5*x+3)/(1+torch.exp(5*x+3)),'o--', label = \"underlying (without error)\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n이러한 5*x+3 등을 일반화하면\n\n5x+3 = w0hat + w1hat  x : 회귀분석 선형 모형\n= w0hat + w1hat * x = linr(x) # x를 linear transform시킴\n\n\n🔬 0근처에서 변화가 일어나지 않고 2근처에서 변화가 일어난다면?\n\nplt.plot(x,y,'o', label=r\"observed data (with error) = $(x_i,y_i)$\")\nplt.plot(x,torch.exp(x-2)/(1+torch.exp(x-2)),'o--', label = \"underlying (without error)\")\nplt.legend()\n\n\n\n\n\n\n\n\n🔬 변화가 좀 더 급하게 일어난다면?\n\nplt.plot(x,y,'o', label=r\"observed data (with error) = $(x_i,y_i)$\")\nplt.plot(x,torch.exp(3*x)/(1+torch.exp(3*x)),'o--', label = \"underlying (without error)\")\nplt.legend()\n\n\n\n\n\n\n\n\n🔬 변화가 좀 더 완만하게 일어난다면?\n\nplt.plot(x,y,'o', label=r\"observed data (with error) = $(x_i,y_i)$\")\nplt.plot(x,torch.exp(x/3)/(1+torch.exp(x/3)),'o--', label = \"underlying (without error)\")\nplt.legend()\n\n\n\n\n\n\n\n\n)🗣️\n\nplt.plot(x,y,'o', label=r\"observed data (with error) = $(x_i,y_i)$\")\nplt.plot(x,torch.exp(5*x+3)/(1+torch.exp(5*x+3)),'o--', label = \"underlying (without error)\")\nplt.legend()\n\n\n\n\n\n\n\n\n- 걱정해결\n\n#plt.plot(x,y,'o', label=r\"observed data (with error) = $(x_i,y_i)$\")\nplt.plot(x,torch.exp(x)/(1+torch.exp(x)),'o--', label = \"underlying type1 (without error)\", color=\"C1\")\nplt.plot(x,torch.exp(5*x)/(1+torch.exp(5*x)),'o--', label = \"underlying type2 (without error)\", color=\"C2\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n회귀 vs 로지스틱\n\n\\({\\bf X} \\to {\\bf y}\\) 에 대한 패턴이 \\(\\text{linr}({\\bf X}) \\approx {\\bf y}\\) 이라면 회귀!\n\\({\\bf X} \\to {\\bf y}\\) 에 대한 패턴이 \\(\\frac{\\exp(\\text{linr}({\\bf X}))}{1+\\exp(\\text{linr}({\\bf X}))} \\approx {\\bf y}\\) 이라면 로지스틱!\n\n\n\n🗣️(\n\nX를 linear transform했더니 선 자체가 y와 비슷 =&gt; 회귀\n위의 그래프를 그리는 식으로 했더니 y와 비슷 =&gt; 로지스틱\n\n정확히는 확률이 y와 비슷하다면 (y 자체는 0 또는 1)\n\n\n)🗣️"
  },
  {
    "objectID": "posts/03wk-1.html#c.-로지스틱-모형",
    "href": "posts/03wk-1.html#c.-로지스틱-모형",
    "title": "03wk-1: (회귀, 로지스틱) – 파이토치식 코딩패턴 (2), 로지스틱 모형",
    "section": "C. 로지스틱 모형",
    "text": "C. 로지스틱 모형\n- \\(x\\)가 커질수록 (혹은 작아질수록) \\(y=1\\)이 잘나오는 모형은 아래와 같이 설계할 수 있음 &lt;— 외우세요!!!\n\n\\(y_i \\sim {\\cal B}(\\pi_i),\\quad\\) where \\(\\pi_i = \\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)} = \\frac{1}{1+\\exp(-w_0-w_1x_i)}\\)\n\\(\\hat{y}_i= \\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\frac{1}{1+\\exp(-\\hat{w}_0-\\hat{w}_1x_i)}\\)\n🗣️\n\n\\(\\pi_i\\)는 확률을 의미\n\\(\\frac{e^{x}}{1 + e^{x}}\\) = \\(\\frac{1}{e^{-x} + 1}\\) 에서 \\(x\\) 대신 \\(w_0+w_1x_i\\)\n책 마다 다르지만 오른쪽처럼 많이 씀\n\n\n- 회귀모형과 로지스틱 모형의 비교\n\n회귀모형: \\(y_i \\sim {\\cal N}(w_0+w_1x_i, \\sigma^2)\\)1\n로지스틱: \\(y_i \\sim {\\cal B}\\big(\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\big)\\)\n🗣️\n\n회귀모형: 오차항의 관점에서 해석\n로지스틱(y가 0 또는 1): 위의 곡선을 나타내는 일반적인 수식\n\n=&gt; 이 수식값을 토대로 베르누이 시행을 하면 오차항까지 설명 가능한 모델이 됨\n\n\n\n- 우리가 예측하고 싶은것\n\n회귀모형: 정규분포의 평균을 예측하고 싶음. 즉 \\(w_0+w_1x_i\\)를 예측하고 싶음. 예측값으로는 \\(\\hat{w}_0 + \\hat{w}_1x_i\\)를 사용!\n로지스틱: 베르누이의 평균을 예측하고 싶음. 즉 \\(\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\)를 예측하고 싶음. 예측값으로는 \\(\\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}\\)를 사용!\n🗣️\n\n둘 다 \\(\\hat{w}_0\\), \\(\\hat{w}_1\\)를 추정하면 각각 직선과 곡선이 결정됨\n베르누이의 평균은 \\(p\\)\n\n즉, 확률을 예측하고 싶음"
  },
  {
    "objectID": "posts/03wk-1.html#footnotes",
    "href": "posts/03wk-1.html#footnotes",
    "title": "03wk-1: (회귀, 로지스틱) – 파이토치식 코딩패턴 (2), 로지스틱 모형",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n원래는 이렇게 썼었지.. \\(y_i = w_0 + w_1x_i + \\epsilon_i \\quad \\epsilon_i \\sim {\\cal N}(0,\\sigma^2)\\)↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Deep Learning",
    "section": "",
    "text": "Based on: https://guebin.github.io/DL2025/\n\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nApr 9, 2025\n\n\n06wk-1: (신경망) – 데이터분석 코딩패턴\n\n\nsw1kwon \n\n\n\n\nApr 7, 2025\n\n\n05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법\n\n\nsw1kwon \n\n\n\n\nApr 2, 2025\n\n\n05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃\n\n\nsw1kwon \n\n\n\n\nMar 31, 2025\n\n\n04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST\n\n\nsw1kwon \n\n\n\n\nMar 26, 2025\n\n\n04wk-1: (신경망) – 로지스틱의 한계 극복\n\n\nsw1kwon \n\n\n\n\nMar 24, 2025\n\n\n03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계\n\n\nsw1kwon \n\n\n\n\nMar 19, 2025\n\n\n03wk-1: (회귀, 로지스틱) – 파이토치식 코딩패턴 (2), 로지스틱 모형\n\n\nsw1kwon \n\n\n\n\nMar 17, 2025\n\n\n02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)\n\n\nsw1kwon \n\n\n\n\nMar 10, 2025\n\n\n01wk-2, 02wk-1: (회귀) – 회귀모형, 손실함수, 파이토치를 이용한 추정\n\n\nsw1kwon \n\n\n\n\nMar 5, 2025\n\n\n01wk-1: (토치) – 강의소개, 파이토치 기본\n\n\nsw1kwon \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/06wk-1.html",
    "href": "posts/06wk-1.html",
    "title": "06wk-1: (신경망) – 데이터분석 코딩패턴",
    "section": "",
    "text": "📘 Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\n📝 🗣️ ✍️ 🔬 ❓"
  },
  {
    "objectID": "posts/06wk-1.html#a.-일반적인-traintest-셋팅",
    "href": "posts/06wk-1.html#a.-일반적인-traintest-셋팅",
    "title": "06wk-1: (신경망) – 데이터분석 코딩패턴",
    "section": "A. 일반적인 train/test 셋팅",
    "text": "A. 일반적인 train/test 셋팅\n- Step1: 데이터정리\n\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\ntest_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True)\nto_tensor = torchvision.transforms.ToTensor()\nX0 = torch.stack([to_tensor(img) for img, lbl in train_dataset if lbl==0])\nX1 = torch.stack([to_tensor(img) for img, lbl in train_dataset if lbl==1])\nX = torch.concat([X0,X1],axis=0).reshape(-1,784)\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\nXX0 = torch.stack([to_tensor(img) for img, lbl in test_dataset if lbl==0])\nXX1 = torch.stack([to_tensor(img) for img, lbl in test_dataset if lbl==1])\nXX = torch.concat([XX0,XX1],axis=0).reshape(-1,784)\nyy = torch.tensor([0.0]*len(XX0) + [1.0]*len(XX1)).reshape(-1,1)\n\n🗣️(\n\nX[0].shape\n\ntorch.Size([784])\n\n\n\nplt.imshow(X[0].reshape(28,28), cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nprint(y[0]) # label이 tensor 형태로 저장되어 있음\n\ntensor([0.])\n\n\n\nX만 가지고 학습을 한 뒤 XX를 가지고 확인\n\n\nX.shape, y.shape\n\n(torch.Size([12665, 784]), torch.Size([12665, 1]))\n\n\n\nXX.shape, yy.shape\n\n(torch.Size([2115, 784]), torch.Size([2115, 1]))\n\n\n)🗣️\n- Step2: 학습가능한 오브젝트들의 설정 (모델링과정 포함)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(), # (n,32)\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid() # y는 0 또는 1\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters()) # Adam은 너무 잘 맞춰서 SGD\n\n- Step3: 학습 (=적합)\n\nfor epoc in range(1,501):\n    #---에폭시작---# \n    # 1 \n    yhat = net(X) \n    # 2 \n    loss = loss_fn(yhat,y) \n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\n    #---에폭끝---# \n    #에폭마다 내가 보고싶은것들을 보여주는 코드\n    if (epoc % 50) ==0: # 50으로 나눈 나머지 = 0 =&gt; 50의 배수\n        acc = ((net(X).data &gt; 0.5) == y).float().mean().item() # item: tensor -&gt; float\n        print(f\"# of epochs={epoc}   \\t train_acc = {acc:.4f}\")\n\n# of epochs=50       train_acc = 0.4677\n# of epochs=100      train_acc = 0.4677\n# of epochs=150      train_acc = 0.4757\n# of epochs=200      train_acc = 0.5295\n# of epochs=250      train_acc = 0.6632\n# of epochs=300      train_acc = 0.7929\n# of epochs=350      train_acc = 0.8731\n# of epochs=400      train_acc = 0.9206\n# of epochs=450      train_acc = 0.9465\n# of epochs=500      train_acc = 0.9634\n\n\n🗣️ 오버피팅 비판 가능성 존재\n- Step4: 예측 & 결과분석\ntrain acc\n\n((net(X).data &gt; 0.5) == y).float().mean()\n\ntensor(0.9634)\n\n\ntest acc\n\n((net(XX).data&gt;0.5) == yy).float().mean()\n\ntensor(0.9749)\n\n\n🗣️ 실전에서 더 괜찮음\n🗣️ Step4: acc, recall, F1 score, 시각화 등\n#에폭마다 내가 보고싶은것들을 보여주는 코드\n    if (epoc % 50) ==0: # 50으로 나눈 나머지 = 0 =&gt; 50의 배수\n        acc = ((net(X).data &gt; 0.5) == y).float().mean().item() # item: tensor -&gt; float\n        Xval --&gt; # train data 자체에서 test 데이터를 나누고 정확도를 비교하며 early stopping 할 수도 있음 (오버피팅 방지)\n        print(f\"# of epochs={epoc}   \\t train_acc = {acc:.4f}\")"
  },
  {
    "objectID": "posts/06wk-1.html#b.-dropout-사용",
    "href": "posts/06wk-1.html#b.-dropout-사용",
    "title": "06wk-1: (신경망) – 데이터분석 코딩패턴",
    "section": "B. Dropout 사용",
    "text": "B. Dropout 사용\n- Step1: 데이터정리\n\npass\n\n- Step2: 학습가능한 오브젝트들의 설정 (모델링과정 포함)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.Dropout(0.9),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters())\n\n🗣️ 원래는 활성화 함수 다음이지만 ReLU 한정 전에도 사용 가능\n- Step3: 학습 (=적합)\n\nfor epoc in range(1,501):\n    net.train()\n    #---에폭시작---# \n    # 1 \n    yhat = net(X) \n    # 2 \n    loss = loss_fn(yhat,y) \n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\n    #---에폭끝---# \n    net.eval()\n    #에폭마다 내가 보고싶은것들을 보여주는 코드\n    if (epoc % 50) ==0:\n        acc = ((net(X).data &gt; 0.5) == y).float().mean().item()\n        print(f\"# of epochs={epoc}   \\t train_acc = {acc:.4f}\")\n\n# of epochs=50       train_acc = 0.4677\n# of epochs=100      train_acc = 0.4677\n# of epochs=150      train_acc = 0.4744\n# of epochs=200      train_acc = 0.5215\n# of epochs=250      train_acc = 0.6435\n# of epochs=300      train_acc = 0.7675\n# of epochs=350      train_acc = 0.8468\n# of epochs=400      train_acc = 0.8978\n# of epochs=450      train_acc = 0.9301\n# of epochs=500      train_acc = 0.9492\n\n\n\n# of epochs=50       train_acc = 0.4677\n# of epochs=100      train_acc = 0.4677\n# of epochs=150      train_acc = 0.4757 # 위의 결과와 살짝 다름\n# of epochs=200      train_acc = 0.5295\n# of epochs=250      train_acc = 0.6632\n# of epochs=300      train_acc = 0.7929\n# of epochs=350      train_acc = 0.8731\n# of epochs=400      train_acc = 0.9206\n# of epochs=450      train_acc = 0.9465\n# of epochs=500      train_acc = 0.9634\n\n- Step4: 예측 & 결과분석\ntrain acc\n\n((net(X).data &gt; 0.5) == y).float().mean()\n\ntensor(0.9492)\n\n\ntest acc\n\n((net(XX).data&gt;0.5) == yy).float().mean()\n\ntensor(0.9626)\n\n\n🗣️ 실전에서 더 괜찮음"
  },
  {
    "objectID": "posts/06wk-1.html#c.-gpu도-사용",
    "href": "posts/06wk-1.html#c.-gpu도-사용",
    "title": "06wk-1: (신경망) – 데이터분석 코딩패턴",
    "section": "C. GPU도 사용",
    "text": "C. GPU도 사용\n- Step1: 데이터정리\n\npass\n\n- Step2: 학습가능한 오브젝트들의 설정 (모델링과정 포함)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.Dropout(0.9),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters())\n\n- Step3: 학습 (=적합)\n\nfor epoc in range(1,501):\n    net.train()\n    #---에폭시작---# \n    X = X.to(\"cuda:0\")\n    y = y.to(\"cuda:0\")\n    # 1 \n    yhat = net(X) \n    # 2 \n    loss = loss_fn(yhat,y) \n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\n    #---에폭끝---# \n    net.eval()\n    #에폭마다 내가 보고싶은것들을 보여주는 코드\n    if (epoc % 50) ==0:\n        acc = ((net(X).data &gt; 0.5) == y).float().mean().item()\n        print(f\"# of epochs={epoc}   \\t train_acc = {acc:.4f}\")\n\n# of epochs=50       train_acc = 0.4677\n# of epochs=100      train_acc = 0.4677\n# of epochs=150      train_acc = 0.4745\n# of epochs=200      train_acc = 0.5223\n# of epochs=250      train_acc = 0.6441\n# of epochs=300      train_acc = 0.7686\n# of epochs=350      train_acc = 0.8469\n# of epochs=400      train_acc = 0.8979\n# of epochs=450      train_acc = 0.9302\n# of epochs=500      train_acc = 0.9492\n\n\n🗣️ 빠름\n- Step4: 예측 & 결과분석\ntrain acc\n\n((net(X).data &gt; 0.5) == y).float().mean()\n\ntensor(0.9492, device='cuda:0')\n\n\ntest acc\n\n# ((net(XX).data&gt;0.5) == yy).float().mean() # net(XX)가 문제\n\n🗣️ XX를 GPU에 올리든가, net를 CPU에 내리든가\n\nXX = XX.to(\"cuda:0\")\nyy = yy.to(\"cuda:0\") \n\n\n((net(XX).data&gt;0.5) == yy).float().mean()\n\ntensor(0.9626, device='cuda:0')"
  },
  {
    "objectID": "posts/06wk-1.html#d.-미니배치도-사용",
    "href": "posts/06wk-1.html#d.-미니배치도-사용",
    "title": "06wk-1: (신경망) – 데이터분석 코딩패턴",
    "section": "D. 미니배치도 사용",
    "text": "D. 미니배치도 사용\n- Step1: 데이터정리\n🗣️ 다시 CPU로 내림\n\nX = X.to(\"cpu\")\ny = y.to(\"cpu\")\nXX = XX.to(\"cpu\")\nyy = yy.to(\"cpu\")\n\n🗣️(\n\nX.shape\n\ntorch.Size([12665, 784])\n\n\n\nds  = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size = 16) \n\n\n# for Xm, ym in dl: # m: 미니 배치\n#     print(Xm) # 하나하나가 미니배치\n\n\n# for Xm, ym in dl: # m: 미니 배치\n#     print(Xm.shape) # 결과: torch.Size([16, 784])\n\n\nds  = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size = 16, shuffle=True) \n\n\n# for Xm, ym in dl: # m: 미니 배치\n#     print(ym) # 섞여 있음\n\n\n# for Xm, ym in dl: # m: 미니 배치\n#     print(ym.shape) # 결과: torch.Size([16, 1])\n\n)🗣️\n\nds  = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size = 16, shuffle=True) \n\n- Step2: 학습가능한 오브젝트들의 설정 (모델링과정 포함)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.Dropout(0.9),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters())\n\n- Step3: 학습 (=적합)\n\n🗣️\n\nX=X.to(“cuda:0”), y=y.to(“cuda:0”)를 할 수는 없으므로 미니배치 별로 GPU에 올림\nepoch을 500번씩 돌릴 필요는 없으므로 2번만 돌림\n\n\n\nfor epoc in range(1,3):\n    net.train()\n    #---에폭시작---# \n    for Xm,ym in dl:         \n        Xm = Xm.to(\"cuda:0\")\n        ym = ym.to(\"cuda:0\")\n        # 1 \n        ym_hat = net(Xm) \n        # 2 \n        loss = loss_fn(ym_hat,ym) \n        # 3 \n        loss.backward()\n        # 4 \n        optimizr.step()\n        optimizr.zero_grad()\n    #---에폭끝---# \n    net.eval()\n    #에폭마다 내가 보고싶은것들을 보여주는 코드\n    s = 0 \n    for Xm, ym in dl:\n        Xm = Xm.to(\"cuda:0\")\n        ym = ym.to(\"cuda:0\")\n        s = s + ((net(Xm) &gt; 0.5) == ym).float().sum()\n    acc = s/12665        \n    print(f\"# of epochs={epoc}   \\t train_acc = {acc:.4f}\")\n\n# of epochs=1        train_acc = 0.9860\n# of epochs=2        train_acc = 0.9931\n\n\n🗣️ 다른 방법 (이렇게 하면 쉬움)\nfor epoc in range(1,3):\n    net.train()\n    net.gpu()\n    #---에폭시작---# \n    for Xm,ym in dl:         \n        Xm = Xm.to(\"cuda:0\")\n        ym = ym.to(\"cuda:0\")\n        # 1 \n        ym_hat = net(Xm) \n        # 2 \n        loss = loss_fn(ym_hat,ym) \n        # 3 \n        loss.backward()\n        # 4 \n        optimizr.step()\n        optimizr.zero_grad()\n    #---에폭끝---# \n    net.eval()\n    net.to(\"cpu\")\n    #에폭마다 내가 보고싶은것들을 보여주는 코드\n    acc = ((net(X).data &gt; 0.5) == y).float().mean().item()\n    print(f\"# of epochs={epoc}   \\t train_acc = {acc:.4f}\")\n\n🗣️ 다른 방법 (net를 GPU로 유지하고 싶으면) =&gt; 강의안 코드\n\nmean 대신 sum\n하나의 미니배치에서 맞은 것의 개수를 s에 계속 누적 시킴 (for문)\nfor 문이 종료되고 s를 총 개수(X.shape)로 나누면 accuracy가 계산됨\n\n\n- Step4: 예측 & 결과분석\n🗣️(\n\n# net(X) # error\n\n\nnet은 cuda에 있고 X는 cpu에 있음\n\nnet을 cpu로 내릴 것인지, X를 cuda로 올릴 것인지 선택\n\nX를 cuda로 올리기 싫어서 미니배치를 사용하였으므로 net을 cpu로 내림\n\n)🗣️\n\nnet.to(\"cpu\")\n\nSequential(\n  (0): Linear(in_features=784, out_features=32, bias=True)\n  (1): Dropout(p=0.9, inplace=False)\n  (2): ReLU()\n  (3): Linear(in_features=32, out_features=1, bias=True)\n  (4): Sigmoid()\n)\n\n\ntrain acc\n\n((net(X) &gt; 0.5) == y).float().mean()\n\ntensor(0.9931)\n\n\ntest acc\n\n((net(XX) &gt; 0.5) == yy).float().mean()\n\ntensor(0.9967)\n\n\n🗣️ test도 잘 나오므로 오버피팅 X\n\n점점 비본질적인 코드가 늘어남 (=코드가 드럽다는 소리에요) –&gt; Trainer의 개념 등장\n\n\n🗣️\n\n딥러닝 가지고 분석하면 –&gt; 트레이너가 있는 다른 패키지를 써야함 (학부 수준)\n\n파이토치 라이트닝\n허깅페이스\n\n연구할때는 파이토치 이해해야 함"
  },
  {
    "objectID": "posts/04wk-2.html",
    "href": "posts/04wk-2.html",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "",
    "text": "📘 Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\n📝 🗣️ ✍️ 🔬 ❓"
  },
  {
    "objectID": "posts/04wk-2.html#a.-step은-표현-불가능하지-않나",
    "href": "posts/04wk-2.html#a.-step은-표현-불가능하지-않나",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "A. Step은 표현 불가능하지 않나?",
    "text": "A. Step은 표현 불가능하지 않나?\n# 예제1 – 일부러 이상하게 만든 취업합격률 곡선\n\ntorch.manual_seed(43052)\nx = torch.linspace(-1,1,2000).reshape(-1,1)\nu = 0*x-3\nu[x&lt;-0.2] = (15*x+6)[x&lt;-0.2]\nu[(-0.2&lt;x)&(x&lt;0.4)] = (0*x-1)[(-0.2&lt;x)&(x&lt;0.4)]\nsig = torch.nn.Sigmoid()\nv = π = sig(u)\ny = torch.bernoulli(v)\n\n\nplt.plot(x,y,'.',alpha=0.03, label=\"observed\")\nplt.plot(x,v,'--', label=\"unobserved\")\nplt.legend()\n\n\n\n\n\n\n\n\n🗣️ 뚝 떨어지는 부분은 어떻게 해야하지? 기울기를 급하게 근사하는 식으로 접근\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(512,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n🗣️ bias 여부가 직선의 개수에 영향을 주지는 X, (1,2)가 아니라 (1,512)로 하면 여러 번 꺾일 것임\n\nplt.plot(x,y,'.',alpha=0.03, label=\"observed\")\nplt.plot(x,v, label=\"true\")\nplt.plot(x,net(x).data,'--', label=\"estimated\")\nplt.legend()\n\n\n\n\n\n\n\n\n🗣️ true는 관측할 수 없음, estimated는 true와 차이가 있어도 쓸만 함\n🗣️(\n\n과정 살펴보기\n\n\nnet\n\nSequential(\n  (0): Linear(in_features=1, out_features=512, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=512, out_features=1, bias=True)\n  (3): Sigmoid()\n)\n\n\n\nnet[:1]\n\nSequential(\n  (0): Linear(in_features=1, out_features=512, bias=True)\n)\n\n\n\nnet[:3]\n\nSequential(\n  (0): Linear(in_features=1, out_features=512, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=512, out_features=1, bias=True)\n)\n\n\n\nplt.plot(net[:3](x).data) # 꺾인 선\n\n\n\n\n\n\n\n\n\n정답은 아니지만 적당히 근사적으로 쓸 수 있을 것 같음\n\n\nplt.plot(net[:4](x).data) # sigmoid 결과\n\n\n\n\n\n\n\n\n)🗣️\n#"
  },
  {
    "objectID": "posts/04wk-2.html#b.-곡선은-표현-불가능하지-않나",
    "href": "posts/04wk-2.html#b.-곡선은-표현-불가능하지-않나",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "B. 곡선은 표현 불가능하지 않나?",
    "text": "B. 곡선은 표현 불가능하지 않나?\n# 예제2 – 2024년 수능 미적30번 문제에 나온 곡선\n\\[y_i = e^{-x_i} \\times  |\\cos(5x_i)| \\times \\sin(5x) + \\epsilon_i, \\quad \\epsilon_i \\sim N(0,\\sigma^2)\\]\n\ntorch.manual_seed(43052)\nx = torch.linspace(0,2,2000).reshape(-1,1)\neps = torch.randn(2000).reshape(-1,1)*0.05\nfx = torch.exp(-1*x)* torch.abs(torch.cos(3*x))*(torch.sin(3*x))\ny = fx + eps\n\n\nplt.plot(x,y,label=\"observed\",alpha=0.5)\nplt.plot(x,fx,label=\"true\")\n\n\n\n\n\n\n\n\n🗣️ 되게 세밀하게 많이 꺾으면 곡선은 아니지만 곡선처럼 보일 수 있을 것 같음 (이 상황에서 bias 여부는 의미 X)\n🗣️(\n\n굳이 0과 1 사이로 누를 필요도 없고 - 값도 갖고 있으므로 sigmoid 취할 필요는 없을듯\ny가 0 또는 1이 아니고 연속적인 어떤 값을 계속 가질 수 있음\n\n회귀랑 비슷하므로 MSELoss 사용\nBCELoss를 여기서 사용한다면 이 경우 log에 음수가 들어갈 수도 있으므로 X\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1024), # 꺽이지않은 1024개의 직선\n    torch.nn.ReLU(), # 꺽인(렐루된) 1024개의 직선 \n    torch.nn.Linear(1024,1), # 합쳐진 하나의 꺽인 직선 \n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n## \nfor epoc in range(1000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,label=\"observed\",alpha=0.5)\nplt.plot(x,fx,label=\"true\")\nplt.plot(x,net(x).data,'--',label=\"estimated\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n잘 보면 직선 느낌이 있기는 하나 이 정도면 그럭저럭 괜찮음\n\n)🗣️\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2048), # 꺽이지않은 1024개의 직선\n    torch.nn.ReLU(), # 꺽인(렐루된) 1024개의 직선 \n    torch.nn.Linear(2048,1), # 합쳐진 하나의 꺽인 직선 \n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n## \nfor epoc in range(1000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,label=\"observed\",alpha=0.5)\nplt.plot(x,fx,label=\"true\")\nplt.plot(x,net(x).data,'--',label=\"estimated\")\nplt.legend()\n\n\n\n\n\n\n\n\n#"
  },
  {
    "objectID": "posts/04wk-2.html#a.-시벤코정리-소개",
    "href": "posts/04wk-2.html#a.-시벤코정리-소개",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "A. 시벤코정리 소개",
    "text": "A. 시벤코정리 소개\n\n\n\n\n\n\nUniversal Approximation Thm [@cybenko1989approximation]\n\n\n\n하나의 은닉층을 가지는 아래와 같은 꼴의 네트워크 \\(net: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\)는\nnet = torch.nn.Sequential(\n    torch.nn.Linear(p,???),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(???,q)\n)\n모든 보렐 가측함수 (Borel measurable function)\n\\[f: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\]\n를 원하는 정확도로 “근사”시킬 수 있다. 쉽게 말하면 \\({\\bf X} \\to {\\bf y}\\) 인 어떠한 복잡한 규칙라도 하나의 은닉층을 가진 신경망이 원하는 정확도로 근사시킨다는 의미이다. 예를들면 아래와 같은 문제를 해결할 수 있다.\n\n\\({\\bf X}_{n\\times 2}\\)는 토익점수, GPA 이고 \\({\\bf y}_{n\\times 1}\\)는 취업여부일 경우 \\({\\bf X} \\to {\\bf y}\\)인 규칙을 신경망은 항상 찾을 수 있다.\n\\({\\bf X}_{n \\times p}\\)는 주택이미지, 지역정보, 주택면적, 주택에 대한 설명 이고 \\({\\bf y}_{n\\times 1}\\)는 주택가격일 경우 \\({\\bf X} \\to {\\bf y}\\)인 규칙을 신경망은 항상 찾을 수 있다.\n\n즉 하나의 은닉층을 가진 신경망의 표현력은 거의 무한대라 볼 수 있다.\n\n\n\n🗣️\n\n시벤코가 Sigmoid로 증명했으나 ReLU를 넣어도 상관 X\nx는 p의 차원을 갖고 y는 q의 차원을 가져도 됨 (같을 필요 X)\n???: 아무 숫자를 넣어도 상관없으나 2^n 으로 쓰는게 메모리에 효율적이라고 알려져 있음\n보렐가측함수: 일반인들이 상상할 수 있는 거의 모든 함수\n이미지와 텍스트도 숫자로 바꿀 수 있음 =&gt; X를 nxp로 정리 가능\n\n\n\n보렐가측함수에 대한 정의는 측도론에 대한 이해가 있어야 가능함. 측도론에 대한 내용이 궁금하다면 https://guebin.github.io/SS2024/ 을 공부해보세요"
  },
  {
    "objectID": "posts/04wk-2.html#b.-왜-가능한가",
    "href": "posts/04wk-2.html#b.-왜-가능한가",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "B. 왜 가능한가??",
    "text": "B. 왜 가능한가??\n- 준비\n\nx = torch.linspace(-10,10,200).reshape(-1,1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=2),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(in_features=2,out_features=1)\n)\nl1,a1,l2 = net\n\n🗣️ 2개의 직선 -&gt; 2개의 곡선(Sigmoid) -&gt; 1개로 합침\n\nnet\n\nSequential(\n  (0): Linear(in_features=1, out_features=2, bias=True)\n  (1): Sigmoid()\n  (2): Linear(in_features=2, out_features=1, bias=True)\n)\n\n\n🗣️(\n\nplt.plot(x, net[0](x).data)\n\n\n\n\n\n\n\n\n\nplt.plot(x, net[:2](x).data) # Sigmoid 까지\n\n\n\n\n\n\n\n\n\nplt.plot(x, net[:3](x).data) # 합쳐서 하나의 Sigmoid\n\n\n\n\n\n\n\n\n)🗣️\n# 생각1 – 2개의 시그모이드를 우연히 잘 조합하면 하나의 계단함수를 만들 수 있다.\n🗣️ 숫자를 잘 때려맞추다보면..\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+10.00,+10.00])\n\n\nl2.weight.data = torch.tensor([[1.00,1.00]])\nl2.bias.data = torch.tensor([-1.00])\n\n\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x)[:,[0]].data,label=r\"$-5x+10$\")\nax[0].plot(x,l1(x)[:,[1]].data,label=r\"$5x+10$\")\nax[0].set_title('$l_1(x)$')\nax[0].legend()\nax[1].plot(x,a1(l1(x))[:,[0]].data,label=r\"$v_1=sig(-5x+10)$\")\nax[1].plot(x,a1(l1(x))[:,[1]].data,label=r\"$v_2=sig(5x+10)$\")\nax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[1].legend()\nax[2].plot(x,l2(a1(l1(x))).data,color='C2',label=r\"$v_1+v_2-1$\")\nax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$')\nax[2].legend()\n\n\n\n\n\n\n\n\n#\n# 생각2 – 계단함수의 모양이 꼭 생각1과 같을 필요는 없다. 중심은 이동가능하고, 높이도 조절가능하다.\n가능한 예시1\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+0.00,+20.00])\nl2.weight.data = torch.tensor([[1.00,1.00]])\nl2.bias.data = torch.tensor([-1.00])\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x).data.numpy(),'--',color='C0'); ax[0].set_title('$l_1(x)$')\nax[1].plot(x,a1(l1(x)).data.numpy(),'--',color='C0'); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[2].plot(x,l2(a1(l1(x))).data,'--',color='C0'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$');\nax[2].set_ylim(-0.1,2.6)\n\n\n\n\n\n\n\n\n가능한 예시2\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+20.00,+00.00])\nl2.weight.data = torch.tensor([[2.50,2.50]])\nl2.bias.data = torch.tensor([-2.50])\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x).data.numpy(),'--',color='C1'); ax[0].set_title('$l_1(x)$')\nax[1].plot(x,a1(l1(x)).data.numpy(),'--',color='C1'); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[2].plot(x,l2(a1(l1(x))).data,'--',color='C1'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$');\nax[2].set_ylim(-0.1,2.6)\n\n\n\n\n\n\n\n\n#\n# 생각3: 첫번째 선형변환(=\\(l_1\\))에서 out_features=4로 하고 적당한 가중치를 조정하면 \\((l_2\\circ a_1 \\circ l_1)(x)\\)의 결과로 생각2의 예시1,2를 조합한 형태도 가능할 것 같다. 즉 4개의 시그모이드를 잘 조합하면 2단계 계단함수를 만들 수 있다.\n\nl1 = torch.nn.Linear(in_features=1,out_features=4)\na1 = torch.nn.Sigmoid()\nl2 = torch.nn.Linear(in_features=4,out_features=1)\n\n\nl1.weight.data = torch.tensor([[-5.00],[5.00],[-5.00],[5.00]])\nl1.bias.data = torch.tensor([0.00, 20.00, 20.00, 0])\nl2.weight.data = torch.tensor([[1.00,  1.00, 2.50,  2.50]])\nl2.bias.data = torch.tensor([-1.0-2.5])\n\n🗣️ 숫자를 바꾸면 모양이 달라짐\n\nplt.plot(l2(a1(l1(x))).data,'--')\nplt.title(r\"$(l_2 \\circ a_1 \\circ l_1)(x)$\")\n\nText(0.5, 1.0, '$(l_2 \\\\circ a_1 \\\\circ l_1)(x)$')\n\n\n\n\n\n\n\n\n\n\n이러한 함수는 계단모양이며, 0을 제외한 서로다른 계단의 높이는 2개가 된다. 이를 간단히 “2단계-계단함수”라고 칭하자.\n\n#\n# 생각4 – \\(2m\\)개의 시그모이드를 우연히 잘 조합하면 \\(m\\)단계 계단함수를 만들 수 있다.\n- 정리1: 2개의 시그모이드를 우연히 잘 결합하면 아래와 같은 “1단계-계단함수” 함수 \\(h\\)를 만들 수 있다.\n🗣️(\n\nsig = torch.nn.Sigmoid()\n\n\n곱하는 숫자가 커질수록 급하게 올라감\n\n\nplt.plot(x, sig(0.5*(x-0.5)))\n\n\n\n\n\n\n\n\n\nplt.plot(x, sig(3*(x-0.5)))\n\n\n\n\n\n\n\n\n\nplt.plot(x, sig(200*(x-0.5)))\n\n\n\n\n\n\n\n\n\nplt.plot(x, sig(200*(x-0.5)))\nplt.plot(x, -sig(200*(x+0.5)))\n\n\n\n\n\n\n\n\n\nv1 = sig(200*(x-0.5))\nv2 = -sig(200*(x+0.5))\nplt.plot(x,v1+v2)\n\n\n\n\n\n\n\n\n\nplt.plot(x, -sig(200*(x-0.5)))\nplt.plot(x, sig(200*(x+0.5)))\n\n\n\n\n\n\n\n\n)🗣️\n\ndef h(x):\n    sig = torch.nn.Sigmoid()\n    v1 = -sig(200*(x-0.5))\n    v2 = sig(200*(x+0.5))\n    return v1+v2 \n\n\nplt.plot(x,h(x))\nplt.title(\"$h(x)$\")\n\nText(0.5, 1.0, '$h(x)$')\n\n\n\n\n\n\n\n\n\n- 정리2: 위와 같은 함수 \\(h\\)를 이용한 아래의 네트워크를 고려하자. 이는 “m단계-계단함수”를 만든다.\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{h}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n그리고 위의 네트워크와 동일한 효과를 주는 아래의 네트워크가 항상 존재함.\n🗣️ 2개의 Sigmoid를 각각 취함\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2m)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,2m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n#\n# 생각5 – 그런데 어지간한 함수형태는 구불구불한 “m단계-계단함수”로 다 근사할 수 있지 않나?\n그렇다면 아래의 네트워크에서 (1) ?? 를 충분히 키우고 (2) 적절하게 학습만 잘 된다면\nnet = torch.nn.Sequential(\n    torch.nn.Linear(p,???),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(???,q)\n)\n위의 네트워크는 거의 무한한 표현력을 가진다. –&gt; 이런식으로 증명하면 됩니당\n#"
  },
  {
    "objectID": "posts/04wk-2.html#c.-h의-위력",
    "href": "posts/04wk-2.html#c.-h의-위력",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "C. \\(h\\)의 위력",
    "text": "C. \\(h\\)의 위력\n🗣️ Sigmoid 대신 h를 하고 싶음\n- 소망: 아래와 같이 net을 설계해서, 그 위력을 체감해보고 싶은데..\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,??),\n    torch.nn.H(),\n    torch.nn.Linear(??,1)\n)\n- \\(h(x)\\)를 생성하는 클래스를 만들어보자.\n🗣️ Module: 상속 / 잘 모르겠으면 다음을 templete으로 생각하고 외우기\nclass H(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self,x):\n        # out = h(x)\n        return out\n🗣️(\n\nclass H(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self,x):\n        def h(x):\n            sig = torch.nn.Sigmoid()\n            v1 = -sig(200*(x-0.5))\n            v2 = sig(200*(x+0.5))\n            return v1+v2 \n        out = h(x)\n        return out \n\n\nmy_h = H()\n\n\nplt.plot(x, my_h(x))\n\n\n\n\n\n\n\n\n)🗣️\n\nclass H(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self,x):\n        def h(x):\n            sig = torch.nn.Sigmoid()\n            v1 = -sig(200*(x-0.5))\n            v2 = sig(200*(x+0.5))\n            return v1+v2 \n        out = h(x)\n        return out \n\n\nh = H()\n\n- \\(h\\)의 위력을 체감해보자.\n# 예제1 – 스펙의 역설\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2025/main/posts/ironyofspec.csv\")\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\n\n🗣️(\n\n다음을 적합시키려고 함\n\n\nplt.plot(x,prob)\n\n\n\n\n\n\n\n\n\nnetwork 만든 이전 방식\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2,bias=False),\n    torch.nn.ReLu(),\n    torch.nn.Linear(2,1),\n    torch.Sigmoid()\n)\n\n이제 이렇게 하지 않고 다음과 같이 하려고 함\n\n)🗣️\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2048),\n    H(),\n    torch.nn.Linear(2048,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(200):\n    ## 1 \n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,prob)\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n\n\n🗣️ 적합된 것을 보면 안 맞기는 하나 따라가고는 있음\n#\n# 예제2 – 수능곡선\n\ntorch.manual_seed(43052)\nx = torch.linspace(0,2,2000).reshape(-1,1)\neps = torch.randn(2000).reshape(-1,1)*0.05\nfx = torch.exp(-1*x)* torch.abs(torch.cos(3*x))*(torch.sin(3*x))\ny = fx + eps\n\n\nplt.plot(x,y,alpha=0.5)\nplt.plot(x,fx)\n\n\n\n\n\n\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2048),\n    H(),\n    torch.nn.Linear(2048,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(200):\n    ## 1 \n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n🗣️ Sigmoid를 할 필요는 X\n\nplt.plot(x,y,alpha=0.5)\nplt.plot(x,fx)\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n\n\n#"
  },
  {
    "objectID": "posts/04wk-2.html#d.-의문점",
    "href": "posts/04wk-2.html#d.-의문점",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "D. 의문점",
    "text": "D. 의문점\n🗣️ 반박은 다음 시간\n- 이 수업을 잘 이해한 사람: 그냥 활성화함수를 \\(h\\)로 쓰면 끝 아니야? 뭐하러 relu 를 쓰는거지?\n- 딥러닝을 좀 공부해본사람1: 왜 딥러닝이 2010년이 지나서야 떳지? 1989년에 세상의 모든 문제가 풀려야 하는것 아닌가?\n- 딥러닝을 좀 공부해본사람2: 하나의 은닉층을 가진 네크워크는 잘 안쓰지 않나? 은닉층이 깊을수록 좋다고 들었는데?\n- 약간의 의구심이 있지만 아무튼 우리는 아래의 무기를 가진 꼴이 되었다.\n\n\n\n\n\n\n우리의 무기\n\n\n\n하나의 은닉층을 가지는 아래와 같은 꼴의 네트워크로,\nnet = torch.nn.Sequential(\n    torch.nn.Linear(p,???),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(???,q)\n)\n\\(f: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\) 인 모든 보렐 가측 함수 \\(f\\) 을 원하는 정확도로 “근사”시킬 수 있다."
  },
  {
    "objectID": "posts/04wk-2.html#a.-예비학습-plt.imshow",
    "href": "posts/04wk-2.html#a.-예비학습-plt.imshow",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "A. 예비학습 – plt.imshow()",
    "text": "A. 예비학습 – plt.imshow()\n- plt.imshow(..., cmap=\"gray\") 에서 ...이 shape이 (??,??)이면 흑백이미지를 출력\n🗣️(\n\nimg = torch.tensor([[255,100],\n                    [255,0]])\nplt.imshow(img)\n\n\n\n\n\n\n\n\n\nimg.shape # 2x2 픽셀\n\ntorch.Size([2, 2])\n\n\n)🗣️\n\nimg = torch.tensor([[255,100],\n                    [255,0]])\nplt.imshow(img,cmap=\"gray\")\n\n\n\n\n\n\n\n\n🗣️ 숫자가 클수록 흰색, 작을수록 검정색\n- plt.imshow(...) 에서 ...의 shape이 (??,??,3)이면 칼라이미지를 출력\n🗣️(\n\nr = torch.tensor([[255,0],\n                  [255,0]])\ng = r*0\nb = r*0\ng\n\ntensor([[0, 0],\n        [0, 0]])\n\n\n\nr.shape\n\ntorch.Size([2, 2])\n\n\n\ntorch.stack([r,g,b],axis=-1)\n\ntensor([[[255,   0,   0],\n         [  0,   0,   0]],\n\n        [[255,   0,   0],\n         [  0,   0,   0]]])\n\n\n\ntorch.stack([r,g,b],axis=-1).shape\n\ntorch.Size([2, 2, 3])\n\n\n)🗣️\n\nr = torch.tensor([[255,0],\n                  [255,0]])\ng = torch.tensor([[0,255],\n                  [0,0]])\nb = torch.tensor([[0,0],\n                  [0,255]])\nimg = torch.stack([r,g,b],axis=-1)\nplt.imshow(img)\n\n\n\n\n\n\n\n\n🔬\n\nimg\n\ntensor([[[255,   0,   0],\n         [  0, 255,   0]],\n\n        [[255,   0,   0],\n         [  0,   0, 255]]])\n\n\n- plt.imshow(...) 에서 ...의 자료형이 int인지 float인지에 따라서 인식이 다름\n🗣️ int: max를 255로 그림, float: max를 1로 그림\n\nr = torch.tensor([[1,0],\n                  [1,0]])\ng = torch.tensor([[0,1],\n                  [0,0]])\nb = torch.tensor([[0,0],\n                  [0,1]])\nimg = torch.stack([r,g,b],axis=-1)\nplt.imshow(img)\n\n\n\n\n\n\n\n\n\nimg[0]\n\ntensor([[1, 0, 0],\n        [0, 1, 0]])\n\n\n\nr = torch.tensor([[255,0],\n                  [255,0]])/255\ng = torch.tensor([[0,255],\n                  [0,0]])/255\nb = torch.tensor([[0,0],\n                  [0,255]])/255\nimg = torch.stack([r,g,b],axis=-1)\nplt.imshow(img)\n\n\n\n\n\n\n\n\n\nimg[0]\n\ntensor([[1., 0., 0.],\n        [0., 1., 0.]])"
  },
  {
    "objectID": "posts/04wk-2.html#b.-데이터",
    "href": "posts/04wk-2.html#b.-데이터",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "B. 데이터",
    "text": "B. 데이터\n- 데이터 정리코드\n\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\nto_tensor = torchvision.transforms.ToTensor()\nX3 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==3])\nX7 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==7])\nX = torch.concat([X3,X7],axis=0)\ny = torch.tensor([0.0]*len(X3) + [1.0]*len(X7))\n\n100.0%\n100.0%\n100.0%\n100.0%\n\n\n🗣️(\n\nX.shape # 4차원\n\ntorch.Size([12396, 1, 28, 28])\n\n\n\nX[0].shape\n\ntorch.Size([1, 28, 28])\n\n\n\nX[0][0].shape\n\ntorch.Size([28, 28])\n\n\n\nplt.imshow(X[0][0],cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nplt.imshow(X[0].reshape(28,28),cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nplt.imshow(X[1].reshape(28,28),cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nplt.imshow(X[-1].reshape(28,28),cmap=\"gray\") # 끝에 있는 관측치\n\n\n\n\n\n\n\n\n\nplt.imshow(X[-2].reshape(28,28),cmap=\"gray\") # 끝에 있는 관측치\n\n\n\n\n\n\n\n\n\ny\n\ntensor([0., 0., 0.,  ..., 1., 1., 1.])\n\n\n\n0은 3의 이미지, 1은 7의 이미지\n\n\nlen(y)\n\n12396\n\n\n)🗣️\n\nplt.plot(y,'.')\n\n\n\n\n\n\n\n\n- 우리는 \\({\\bf X}: (n,1,28,28)\\) 에서 \\({\\bf y}: (n,1)\\)으로 가는 맵핑을 배우고 싶음. \\(\\to\\) 이런건 배운적이 없는데?.. \\(\\to\\) 그렇다면 \\({\\bf X}:(n,784) \\to {\\bf y}:(n,1)\\) 으로 가는 맵핑을 학습하자.\n)🗣️\n\n28*28\n\n784\n\n\n[img for img in X] = [X[0], X[1], ..., X[-1]]\n\nX[0].shape\n\ntorch.Size([1, 28, 28])\n\n\n\ntorch.stack([img.reshape(-1) for img in X])\n\ntensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]])\n\n\n\ntorch.stack([img.reshape(-1) for img in X]).shape\n\ntorch.Size([12396, 784])\n\n\n\ny.shape # vector\n\ntorch.Size([12396])\n\n\n)🗣️\n\nX = torch.stack([img.reshape(-1) for img in X])\ny = y.reshape(-1,1)\n\n\nX.shape,y.shape\n\n(torch.Size([12396, 784]), torch.Size([12396, 1]))"
  },
  {
    "objectID": "posts/04wk-2.html#c.-학습",
    "href": "posts/04wk-2.html#c.-학습",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "C. 학습",
    "text": "C. 학습\n🗣️ H가 더 좋은 것을 알고 있지만 사람들이 많이 쓰는 ReLU로\n🗣️(\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\n\n\nnet(X)\n\ntensor([[0.5066],\n        [0.5152],\n        [0.4821],\n        ...,\n        [0.5168],\n        [0.5087],\n        [0.5066]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\ny와 비슷한 형태로 출력되는 것이 중요\n\n)🗣️\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(200):\n    ## 1 \n    yhat = net(X) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y,'.')\nplt.plot(net(X).data,'.',alpha=0.2)\n\n\n\n\n\n\n\n\n🗣️ 틀린 것도 있지만 맞은 것이 더 많음 (2,000번하면 더 많이 맞춤)\n🗣️(Accuracy\n\nRule 정하기\n\n\nnet(X).data &gt; 0.5\n\ntensor([[False],\n        [False],\n        [False],\n        ...,\n        [ True],\n        [ True],\n        [ True]])\n\n\n\n(net(X).data &gt; 0.5)*1.0\n\ntensor([[0.],\n        [0.],\n        [0.],\n        ...,\n        [1.],\n        [1.],\n        [1.]])\n\n\n\ny\n\ntensor([[0.],\n        [0.],\n        [0.],\n        ...,\n        [1.],\n        [1.],\n        [1.]])\n\n\n\n(y == (net(X).data &gt; 0.5)*1.0)\n\ntensor([[True],\n        [True],\n        [True],\n        ...,\n        [True],\n        [True],\n        [True]])\n\n\n\n(y == (net(X).data &gt; 0.5)*1.0).sum()\n\ntensor(12264)\n\n\n\nlen(y)\n\n12396\n\n\n\n12264/12396\n\n0.989351403678606\n\n\n\n((y == (net(X).data &gt; 0.5))*1.0).mean()\n\ntensor(0.9894)\n\n\n)🗣️\n\n((y == (net(X).data &gt; 0.5))*1.0).mean()\n\ntensor(0.9894)\n\n\n\n\n\n\n\n\nNote\n\n\n\n이미지자료의 차원\n\n칼라이미지데이터 \\({\\bf X}\\)는 (n,3,h,w) 의 차원을 가지거나 (n,h,w,3)의 차원을 가진다.\n흑백이미지데이터 \\({\\bf X}\\)는 (n,h,w) 의 차원을 가지거나 (n,1,h,w)의 차원을 가지거나 (n,h,w,1)의 차원을 가진다."
  },
  {
    "objectID": "posts/05wk-1.html",
    "href": "posts/05wk-1.html",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "",
    "text": "📘 Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\n📝 🗣️ ✍️ 🔬 ❓"
  },
  {
    "objectID": "posts/05wk-1.html#a.-데이터",
    "href": "posts/05wk-1.html#a.-데이터",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "A. 데이터",
    "text": "A. 데이터\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\neps = torch.randn(100)*0.5\ny = x * 4 + 2.5 + eps\nx,y = x.reshape(-1,1), y.reshape(-1,1)\n\n\nplt.plot(x,y,'o')"
  },
  {
    "objectID": "posts/05wk-1.html#b.-학습",
    "href": "posts/05wk-1.html#b.-학습",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "B. 학습",
    "text": "B. 학습\n\n🗣️ 현재 수준에서는 다음처럼 생각\n\ny가 연속: MSELoss\ny가 0 또는 1만: BCELoss\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.1)\n## \nfor epoc in range(200):\n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = loss_fn(yhat,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n\n\n\nnet[0].weight, net[0].bias\n\n(Parameter containing:\n tensor([[4.0042]], requires_grad=True),\n Parameter containing:\n tensor([2.4459], requires_grad=True))"
  },
  {
    "objectID": "posts/05wk-1.html#c.-예측",
    "href": "posts/05wk-1.html#c.-예측",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "C. 예측",
    "text": "C. 예측\n온도가 0.1 도일때, 커피를 얼마나 팔까?\n\n0.1 * 4.0042 + 2.4459 \n\n2.84632\n\n\n\nxx = torch.tensor([[0.1]])\nnet(xx)\n\ntensor([[2.8463]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n온도가 0.2도일때 커피를 얼마나 팔까?\n\n0.2 * 4.0042 + 2.4459 \n\n3.24674\n\n\n\nxx = torch.tensor([[0.2]])\nnet(xx)\n\ntensor([[3.2467]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n온도가 [0.1, 0.2] 일때의 예측값을 한번에 보고 싶다면?\n\nxx = torch.tensor([[0.1],\n                   [0.2]])\nnet(xx)\n\ntensor([[2.8463],\n        [3.2467]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\n\n\n\n\n\nNote\n\n\n\n이거 질문이 와서 좀 더 자세히 설명하겠습니다. (아직 net(x)의 계산 과정을 선형 변환 관점에서 수식으로 정리하는 데 익숙하지 않으셔서 그럴 수 있습니다. 이건 단순 산수라서 하나씩 차근차근 따라가다 보면 충분히 이해하실 수 있어요. 처음부터 바로 이해되지 않더라도 전혀 걱정하실 필요 없습니다.)\n하나의 값 \\(x\\)에 대하여 \\(net(x)\\)는 아래를 의미하는 연산을 합니다.\nnet(x) = 4.0042 * x + 2.4459  = net[0].weight * x + net[0].bias\n사실 위의 과정을 수식으로 엄밀하게 쓰면 아래와 같습니다.\n\\[net(\\begin{bmatrix} x \\end{bmatrix}) = 2.4459 + \\begin{bmatrix} x \\end{bmatrix} \\begin{bmatrix} 4.0042 \\end{bmatrix}\\]\n여기에서 \\(\\begin{bmatrix} x \\end{bmatrix}\\) 와 \\(\\begin{bmatrix} 4.0042  \\end{bmatrix}\\) 는 모두 \\(1\\times 1\\) matrix를 의미합니다. 만약에 \\(2 \\times 1\\) matrix \\({\\bf x} = \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix}\\)를 네트워크의 입력으로 고려한다면 아래와 같이 됩니다.\n\\[net({\\bf x})=net\\left(\\begin{bmatrix}x_1 \\\\ x_2 \\end{bmatrix}\\right) = 2.4459 + \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} \\begin{bmatrix} 4.0042 \\end{bmatrix} = \\begin{bmatrix} 2.4459 + 4.0042 x_1 \\\\ 2.4459 + 4.0042 x_2\\end{bmatrix} \\]\n따라서 \\({\\bf xx} = \\begin{bmatrix} 0.1 \\\\ 0.2 \\end{bmatrix}\\) 를 네트워크의 입력으로 넣으면\n\\[net({\\bf xx})= \\begin{bmatrix} 2.4459 + 4.0042 \\times 0.1 \\\\ 2.4459 + 4.0042 \\times 0.2\\end{bmatrix}= \\begin{bmatrix} 2.8463 \\\\ 3.2467 \\end{bmatrix}\\]\n와 같이 계산되겠죠."
  },
  {
    "objectID": "posts/05wk-1.html#a.-오버피팅",
    "href": "posts/05wk-1.html#a.-오버피팅",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "A. 오버피팅",
    "text": "A. 오버피팅\n- 오버피팅이란?\n\n위키: In mathematical modeling, overfitting is “the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit to additional data or predict future observations reliably”. (수학적 모델링에서 과적합이란 “어떤 모델이 주어진 데이터에 너무 꼭 맞춰져 있어서, 새로운 데이터나 미래의 결과를 잘 예측하지 못할 수 있는 상태”를 의미한다.)\n제 개념: 데이터를 “데이터 = 언더라잉 + 오차”라고 생각할때 우리가 데이터로부터 적합할 것은 언더라잉인데 오차항을 적합하고 있는 현상."
  },
  {
    "objectID": "posts/05wk-1.html#b.-오버피팅-예시",
    "href": "posts/05wk-1.html#b.-오버피팅-예시",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "B. 오버피팅 예시",
    "text": "B. 오버피팅 예시\n🗣️ 네트워크의 표현력이 너무 좋을 때\n- \\(m\\)이 매우 클때 아래의 네트워크 거의 무엇이든 맞출 수 있다고 보면 된다.\n\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{h}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n- 그런데 종종 맞추지 말아야 할 것들도 맞춘다.\n\\[\\text{model:} \\quad y_i = (0\\times x_i) + \\epsilon_i,~~ \\text{where}~ \\epsilon_i \\sim N(0,0.01^2)\\]\n🗣️ y는 x에 대한 식 X / underlying = 0 / structure: 허구, 오차항이 만들어낸 우연\n\ntorch.manual_seed(5) \nx = torch.linspace(0,1,100).reshape(100,1)\ny = torch.randn(100).reshape(100,1)*0.01\nplt.plot(x,y,'--o',alpha=0.5)\n\n\n\n\n\n\n\n\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(512,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(1000):\n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = loss_fn(yhat,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'--o',alpha=0.5)\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n\n\n🗣️ 0으로 적합하지 않은 것은 다 틀림"
  },
  {
    "objectID": "posts/05wk-1.html#c.-오버피팅이라는-뚜렷한-증거-train-test",
    "href": "posts/05wk-1.html#c.-오버피팅이라는-뚜렷한-증거-train-test",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "C. 오버피팅이라는 뚜렷한 증거! (train / test)",
    "text": "C. 오버피팅이라는 뚜렷한 증거! (train / test)\n🗣️ 0보다 주황색 선이 더 좋은 것 같다는 주장에 대한 반박 (예측)\n- 데이터의 분리하여 보자.\n\ntorch.manual_seed(5) \nx_all = torch.linspace(0,1,100).reshape(100,1)\ny_all = torch.randn(100).reshape(100,1)*0.01\nx,xx = x_all[:80], x_all[80:]\ny,yy = y_all[:80], y_all[80:]\nplt.plot(x,y,'--o',alpha=0.5,label=\"training\")\nplt.plot(xx,yy,'--o',alpha=0.5,label=\"test\")\nplt.legend()\n\n\n\n\n\n\n\n\n- train만 학습\n🗣️ B와 똑같은 조건\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(512,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(1000):\n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = loss_fn(yhat,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- training data로 학습한 net를 training data 에 적용\n\nplt.plot(x_all,y_all,'--o',alpha=0.5,color=\"gray\")\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n\n\n\ntraining에서는 그럭저럭 잘 맞춤\n\n- training data로 학습한 net를 test data 에 적용\n\nplt.plot(x_all,y_all,'--o',alpha=0.5,color=\"gray\")\nplt.plot(x,net(x).data,'--')\nplt.plot(xx,net(xx).data,'--')\n\n\n\n\n\n\n\n\n\ntrain에서는 그럭저럭 잘 맞추는데 test에서는 엉망이다 = overfit\n\n🗣️ random이기 때문에 trend는 없음"
  },
  {
    "objectID": "posts/05wk-1.html#d.-시벤코정리의-올바른-이해",
    "href": "posts/05wk-1.html#d.-시벤코정리의-올바른-이해",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "D. 시벤코정리의 올바른 이해",
    "text": "D. 시벤코정리의 올바른 이해\n\n\n\n\n\n\nNote\n\n\n\n시벤코의 항변(?) [@cybenko1989approximation]\n하나의 은닉층을 가지는 아래와 같은 꼴의 네트워크 \\(net: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\)는\nnet = torch.nn.Sequential(\n    torch.nn.Linear(p,???),\n    torch.nn.Sigmoid(), ## &lt;-- 여기에 렐루를 써도 된다. \n    torch.nn.Linear(???,q)\n)\n모든 보렐가측함수\n\\[f: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\]\n를 원하는 정확도로 “근사”시킬 수 있다. 쉽게 말하면 \\({\\bf X} \\to {\\bf y}\\) 인 어떠한 복잡한 규칙라도 하나의 은닉층을 가진 신경망이 원하는 정확도로 근사시킨다는 의미이다. 그렇지만 이러한 규칙이 네크워크가 학습하지 못했던 자료 (처음 보는 자료, unseen data) \\({\\bf XX}_{m \\times p}\\), \\({\\bf yy}_{m \\times q}\\) 에 대하여서도 올바르게 적용된다라는 보장은 없다. 시벤코는 단지 net가 가지는 표현력의 한계를 수학적으로 밝혔을 뿐이다."
  },
  {
    "objectID": "posts/05wk-1.html#a.-오버피팅의-해결",
    "href": "posts/05wk-1.html#a.-오버피팅의-해결",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "A. 오버피팅의 해결",
    "text": "A. 오버피팅의 해결\n- 오버피팅의 해결책: 드랍아웃\n- 데이터\n\ntorch.manual_seed(5) \nx_all = torch.linspace(0,1,100).reshape(100,1)\ny_all = torch.randn(100).reshape(100,1)*0.01\n#plt.plot(x_all,y_all,'--o',alpha=0.5)\nx,y = x_all[:80], y_all[:80]\nxx,yy = x_all[80:], y_all[80:]\nplt.plot(x,y,'--o',color=\"C0\")\nplt.plot(xx,yy,'--o',color=\"C1\")\n\n\n\n\n\n\n\n\n- 학습\n🗣️ torch.nn.Dropout(0.8) 추가 (학습 시 일부만 사용)\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(0.8),\n    torch.nn.Linear(512,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(1000):\n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = loss_fn(yhat,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과시각화 (잘못된 사용)\n\nplt.plot(x_all,y_all,'--o',alpha=0.5,color=\"gray\")\nplt.plot(x,net(x).data,'--')\nplt.plot(xx,net(xx).data,'--')\n\n\n\n\n\n\n\n\n- 결과시각화 (올바른 사용)\n\nnet.training \n\nTrue\n\n\n🗣️ 평가 모드로 바꾸기\n\nnet.eval()\n\nSequential(\n  (0): Linear(in_features=1, out_features=512, bias=True)\n  (1): ReLU()\n  (2): Dropout(p=0.8, inplace=False)\n  (3): Linear(in_features=512, out_features=1, bias=True)\n)\n\n\n\nnet.training\n\nFalse\n\n\n\nplt.plot(x_all,y_all,'--o',alpha=0.5,color=\"gray\")\nplt.plot(x,net(x).data,'--')\nplt.plot(xx,net(xx).data,'--')\n\n\n\n\n\n\n\n\n🗣️ 어느 정도 0으로 떨어짐, 오버피팅 문제가 완전히 해결되지는 않았지만 어느정도 완화"
  },
  {
    "objectID": "posts/05wk-1.html#b.-드랍아웃-레이어",
    "href": "posts/05wk-1.html#b.-드랍아웃-레이어",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "B. 드랍아웃 레이어",
    "text": "B. 드랍아웃 레이어\n- 드랍아웃의 성질1: 드랍아웃의 계산방식을 이해해보자.\n🗣️ default= 0.5\n\nu = torch.randn(10,2)\nd = torch.nn.Dropout(0.9)\nu\n\ntensor([[ 0.5951,  0.2245],\n        [ 0.8238,  0.5230],\n        [ 0.4772, -1.0465],\n        [-0.6826,  0.4257],\n        [ 0.5113,  0.4130],\n        [-0.3946,  0.0827],\n        [ 1.4149, -1.7569],\n        [ 0.3142, -0.9964],\n        [-0.4613,  0.3530],\n        [-0.2743, -0.5558]])\n\n\n\nd(u)\n\ntensor([[0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, -0.0000],\n        [-0.0000, 0.0000],\n        [5.1128, 4.1303],\n        [-0.0000, 0.0000],\n        [0.0000, -0.0000],\n        [0.0000, -0.0000],\n        [-0.0000, 3.5305],\n        [-0.0000, -0.0000]])\n\n\n\n90%의 드랍아웃: 드랍아웃층의 입력 중 임의로 90%를 골라서 결과를 0으로 만든다. + 그리고 0이 되지않고 살아남은 값들은 10배 만큼 값이 커진다.\n남은값을 10배 키우는 이유? 출력의 평균값을 보정하기 위해서\n\n- 드랍아웃의 성질2: 드랍아웃을 on/off 하는 방법을 이해해보자.\n\nu = torch.randn(10,2)\nu\n\ntensor([[ 0.8395,  1.8825],\n        [-0.0415, -2.3987],\n        [-0.3658, -1.3403],\n        [-1.4066,  0.7178],\n        [-1.0465,  0.9663],\n        [-1.2350,  1.3424],\n        [-1.1903,  0.3955],\n        [ 0.4236, -0.7882],\n        [-0.4348,  0.2669],\n        [-0.9102, -0.3219]])\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Dropout(0.9)\n)\nnet\n\nSequential(\n  (0): Dropout(p=0.9, inplace=False)\n)\n\n\n\nu,net(u)\n\n(tensor([[ 0.8395,  1.8825],\n         [-0.0415, -2.3987],\n         [-0.3658, -1.3403],\n         [-1.4066,  0.7178],\n         [-1.0465,  0.9663],\n         [-1.2350,  1.3424],\n         [-1.1903,  0.3955],\n         [ 0.4236, -0.7882],\n         [-0.4348,  0.2669],\n         [-0.9102, -0.3219]]),\n tensor([[  0.0000,   0.0000],\n         [ -0.0000,  -0.0000],\n         [ -0.0000,  -0.0000],\n         [-14.0662,   0.0000],\n         [ -0.0000,   0.0000],\n         [-12.3497,   0.0000],\n         [ -0.0000,   0.0000],\n         [  4.2361,  -0.0000],\n         [ -0.0000,   0.0000],\n         [ -0.0000,  -3.2190]]))\n\n\n🗣️ 매번 어떤 노드가 죽을지 모름 (다 0이 되기도 함)\n❓ 비율? 확률?\n\nnet.training\n\nTrue\n\n\n\nnet.eval() # 드랍아웃이 무력화\n\nSequential(\n  (0): Dropout(p=0.9, inplace=False)\n)\n\n\n\nu,net(u)\n\n(tensor([[ 0.8395,  1.8825],\n         [-0.0415, -2.3987],\n         [-0.3658, -1.3403],\n         [-1.4066,  0.7178],\n         [-1.0465,  0.9663],\n         [-1.2350,  1.3424],\n         [-1.1903,  0.3955],\n         [ 0.4236, -0.7882],\n         [-0.4348,  0.2669],\n         [-0.9102, -0.3219]]),\n tensor([[ 0.8395,  1.8825],\n         [-0.0415, -2.3987],\n         [-0.3658, -1.3403],\n         [-1.4066,  0.7178],\n         [-1.0465,  0.9663],\n         [-1.2350,  1.3424],\n         [-1.1903,  0.3955],\n         [ 0.4236, -0.7882],\n         [-0.4348,  0.2669],\n         [-0.9102, -0.3219]]))\n\n\n- 드랍아웃레이어 정리\n\n계산: (1) 입력의 일부를 임의로 0으로 만드는 역할 (2) 0이 안된것들은 스칼라배하여 드랍아웃을 통과한 모든 숫자들의 총합이 대체로 일정하게 되도록 조정\non/off: 학습시에는 dropout on / 학습을 하지 않을 경우는 dropout off\n느낌: 일부러 패널티를 안고 학습하는 느낌..\n효과: 오버피팅을 억제하는 효과가 있음\n\n🗣️ 랜덤 포레스트와 동일\n\n참고: 오버피팅을 잡는 방법은 드랍아웃만 있는게 아니다..\n\n🗣️ 근본: 시각화 후 데이터에 맞춘 모델을 찾음 (어려움) / 실제: 시벤코 정리로 적합을 한 후 드랍아웃을 걸어 오버피팅 방지"
  },
  {
    "objectID": "posts/05wk-1.html#c.-드랍아웃-레이어의-위치",
    "href": "posts/05wk-1.html#c.-드랍아웃-레이어의-위치",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "C. 드랍아웃 레이어의 위치",
    "text": "C. 드랍아웃 레이어의 위치\n- ReLU,dropout의 특이한 성질: \\(\\text{dropout}(\\text{relu}({\\bf x}))=\\text{relu}(\\text{dropout}({\\bf x}))\\)\n🗣️ 둘 다 x를 그대로 내보내거나 0으로 만듦 (순서 상관 없이 결과 동일)\n\nu = torch.randn(10,2)\nr = torch.nn.ReLU()\nd = torch.nn.Dropout()\n\n\ntorch.manual_seed(0)\nd(r(u))\n\ntensor([[0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.5372],\n        [2.6658, 2.1870],\n        [0.3798, 0.0000],\n        [0.0000, 1.6593],\n        [0.9300, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.0000]])\n\n\n\ntorch.manual_seed(0)\nr(d(u))\n\ntensor([[0.0000, 0.0000],\n        [-0.0000, 0.0000],\n        [0.0000, 0.0000],\n        [0.0000, 0.5372],\n        [2.6658, 2.1870],\n        [0.3798, -0.0000],\n        [0.0000, 1.6593],\n        [0.9300, 0.0000],\n        [0.0000, 0.0000],\n        [-0.0000, 0.0000]])\n\n\n- 다른 활성화함수는 성립안함\n🗣️ 활성화 함수: 비선형 함수, activation 함수\n\nu = torch.randn(10,2)\ns = torch.nn.Sigmoid()\nd = torch.nn.Dropout()\n\n\ntorch.manual_seed(0)\nd(s(u))\n\ntensor([[0.4801, 0.0000],\n        [0.0000, 1.4006],\n        [0.3487, 0.0000],\n        [0.0000, 1.2299],\n        [0.9213, 1.6180],\n        [1.1322, 0.0000],\n        [0.0000, 1.4407],\n        [0.6015, 1.4349],\n        [0.0000, 1.7626],\n        [0.0000, 0.0000]])\n\n\n\ntorch.manual_seed(0)\ns(d(u))\n\ntensor([[0.0907, 0.5000],\n        [0.5000, 0.8452],\n        [0.0427, 0.5000],\n        [0.5000, 0.7183],\n        [0.4218, 0.9472],\n        [0.6300, 0.5000],\n        [0.5000, 0.8691],\n        [0.1561, 0.8657],\n        [0.5000, 0.9822],\n        [0.5000, 0.5000]])\n\n\n- 결론: 드랍아웃은 활성화 함수 바로 뒤에 오는게 맞음. (그렇지 않다면 0을 만들 수 없는걸?) 그렇지만 ReLU의 경우 활성화 함수 직전에 취하기도 함.\n🗣️ ReLU는 순서를 바꾸는 것이 계산 상에 효율이 있다고 함"
  },
  {
    "objectID": "posts/05wk-1.html#d.-평균보정의-필요성-선택학습",
    "href": "posts/05wk-1.html#d.-평균보정의-필요성-선택학습",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "D. 평균보정의 필요성 (선택학습)",
    "text": "D. 평균보정의 필요성 (선택학습)\n\n\n\n\n\n\nNote\n\n\n\n90%의 드랍아웃에서 출력결과에 왜 x10하는지 좀 더 자세히 설명한 챕터입니다. 궁금하시다면 읽어보시고 아니라면 넘어가셔도 무방합니다.\n\n\n- 아래의 데이터를 관찰하자.\n\nx,_ = torch.randn(300).sort()\ny = relu(20*x) + torch.randn(300)\nx,y = x.reshape(-1,1), y.reshape(-1,1)\n\n\nplt.plot(x,y,'o')\n\n\n\n\n\n\n\n\n- 적합해보자.\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1000),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(0.1),\n    torch.nn.Linear(1000,1,bias=False),\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(5000):\n    ## 1 \n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nnet.eval()\n\nSequential(\n  (0): Linear(in_features=1, out_features=1000, bias=True)\n  (1): ReLU()\n  (2): Dropout(p=0.1, inplace=False)\n  (3): Linear(in_features=1000, out_features=1, bias=False)\n)\n\n\n\nnet.training\n\nFalse\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n\n\n- 주황색선이나오는 이유 설명해보자.\n\nU = net[:-1](x).data \nW = net[-1].weight.T \n\n아래3개는 동일한코드임\n\nnet(x).reshape(-1)[:10] # 코드1\n\ntensor([-0.9858, -0.5127, -0.4687,  0.0514,  0.0558,  0.2089,  0.2213,  0.2619,\n         0.2691,  0.2823], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\n(U@W).reshape(-1)[:10] # 코드2\n\ntensor([-0.9858, -0.5127, -0.4687,  0.0514,  0.0558,  0.2089,  0.2213,  0.2619,\n         0.2691,  0.2823], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\n((U*W.reshape(-1)).sum(axis=1))[:10] # 코드3\n\ntensor([-0.9858, -0.5127, -0.4687,  0.0514,  0.0558,  0.2089,  0.2213,  0.2619,\n         0.2691,  0.2823], grad_fn=&lt;SliceBackward0&gt;)\n\n\n따라서 아래의 주황색선들의 .sum(axis=1) 하기만 하면 net(x)의 결과가 된다.\n\nplt.plot(x,U*W.reshape(-1).data,color=\"C1\",alpha=0.02);\n\n\n\n\n\n\n\n\n- 즉 왼쪽의 주황색선1이 모두 합쳐져서 오른쪽의 점선이된다.\n\nfig,ax = plt.subplots(1,2,figsize=(9,3))\nax[0].plot(x,U*W.reshape(-1).data,color=\"C1\",alpha=0.02);\nax[0].set_title(\"1,000 ReLUs\")\nax[1].plot(x,net(x).data,'--',color=\"C1\")\nax[1].set_title(r\"$net({\\bf x})$=sum(1,000 ReLUs)\");\n\n\n\n\n\n\n\n\n\n만약에 왼쪽의 주황색선이 10%만 사용되어서 100개의 렐루만 사용되었다면? 대충 x10을 해줘야 net(x) 가 나오지 않겠어요?"
  },
  {
    "objectID": "posts/05wk-1.html#footnotes",
    "href": "posts/05wk-1.html#footnotes",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n1000개가 있음↩︎"
  },
  {
    "objectID": "posts/03wk-2.html",
    "href": "posts/03wk-2.html",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "",
    "text": "📘 Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\n📝 🗣️ ✍️ 🔬 ❓"
  },
  {
    "objectID": "posts/03wk-2.html#a.-로지스틱-모형",
    "href": "posts/03wk-2.html#a.-로지스틱-모형",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "A. 로지스틱 모형",
    "text": "A. 로지스틱 모형\n- \\(x\\)가 커질수록 (혹은 작아질수록) \\(y=1\\)이 잘나오는 모형은 아래와 같이 설계할 수 있음 &lt;— 외우세요!!!\n\n\\(y_i \\sim {\\cal B}(\\pi_i),\\quad\\) where \\(\\pi_i = \\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)} = \\frac{1}{1+\\exp(-w_0-w_1x_i)}\\)\n\\(\\hat{y}_i= \\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\frac{1}{1+\\exp(-\\hat{w}_0-\\hat{w}_1x_i)}\\)\n\n- 회귀모형과 로지스틱 모형의 비교\n\n회귀모형: \\(y_i \\sim {\\cal N}(w_0+w_1x_i, \\sigma^2)\\)1\n로지스틱: \\(y_i \\sim {\\cal B}\\big(\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\big)\\)\n\n- 우리가 예측하고 싶은것\n\n회귀모형: 정규분포의 평균을 예측하고 싶음. 즉 \\(w_0+w_1x_i\\)를 예측하고 싶음. 예측값으로는 \\(\\hat{w}_0 + \\hat{w}_1x_i\\)를 사용!\n로지스틱: 베르누이의 평균을 예측하고 싶음. 즉 \\(\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\)를 예측하고 싶음. 예측값으로는 \\(\\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}\\)를 사용!"
  },
  {
    "objectID": "posts/03wk-2.html#b.-데이터-스펙과-취업",
    "href": "posts/03wk-2.html#b.-데이터-스펙과-취업",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "B. 데이터 – 스펙과 취업",
    "text": "B. 데이터 – 스펙과 취업\n🗣️(\n\n데이터 만들기\n\n\ntorch.linspace(-1,1,2000)\n\ntensor([-1.0000, -0.9990, -0.9980,  ...,  0.9980,  0.9990,  1.0000])\n\n\n\nlen(torch.linspace(-1,1,2000))\n\n2000\n\n\n\nx = torch.linspace(-1,1,2000).reshape(2000,1)\nx\n\ntensor([[-1.0000],\n        [-0.9990],\n        [-0.9980],\n        ...,\n        [ 0.9980],\n        [ 0.9990],\n        [ 1.0000]])\n\n\n\n이 상태에서 선형 변환을 한다면\n\n-1 + x*5 : 선형 모델\n로지스틱 모형은\n\n\n\nx = torch.linspace(-1,1,2000).reshape(2000,1)\nprob = torch.exp(-1 + x*5) / (1+ torch.exp(-1 + x*5))\nplt.plot(x,prob)\n\n\n\n\n\n\n\n\n\n다른 방법 (보기 좋게)\n\n\nx = torch.linspace(-1,1,2000).reshape(2000,1)\nw0, w1 = -1, 5\nprob = torch.exp(w0 + x*w1) / (1+ torch.exp(w0 + x*w1))\nplt.plot(x,prob)\n\n\n\n\n\n\n\n\n\nprob\n\ntensor([[0.0025],\n        [0.0025],\n        [0.0025],\n        ...,\n        [0.9818],\n        [0.9819],\n        [0.9820]])\n\n\n\nprob.shape\n\ntorch.Size([2000, 1])\n\n\n\ny 만들기 (prob로 베르누이 시행)\n\n\ntorch.bernoulli(prob)\n\ntensor([[0.],\n        [0.],\n        [0.],\n        ...,\n        [1.],\n        [1.],\n        [1.]])\n\n\n\ntorch.bernoulli(prob).shape\n\ntorch.Size([2000, 1])\n\n\n\nseed 고정 후 시각화\n\n\ntorch.manual_seed(43052)\nx = torch.linspace(-1,1,2000).reshape(2000,1)\nw0, w1 = -1, 5\nprob = torch.exp(w0 + x*w1) / (1+ torch.exp(w0 + x*w1))\ny = torch.bernoulli(prob)\n\n\nplt.plot(x,y) # 보기 쉽지는 않음 \n\n\n\n\n\n\n\n\n\nplt.plot(x,y, 'o') # 점들이 너무 많이 겹침\n\n\n\n\n\n\n\n\n\nplt.plot(x,y,'.',alpha=0.03) # 투명도 조절\n\n\n\n\n\n\n\n\n\nx가 증가할수록 y는 1이 나올 가능성이 높아지고\nx가 감소할수록 y는 0이 나올 가능성이 높아짐\n\n\nplt.plot(x,y,'.',alpha=0.03) # 관측(error 포함)\nplt.plot(x,prob,'--') # 실체 데이터에서는 관측 불가능 (error-free structure)\n\n\n\n\n\n\n\n\n)🗣️\n\ntorch.manual_seed(43052)\nx = torch.linspace(-1,1,2000).reshape(2000,1)\nw0,w1 = -1, 5\nprob = torch.exp(w0+w1*x) / (1+torch.exp(w0+w1*x)) \ny = torch.bernoulli(prob)\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x[0],y[0],'.',label=r\"$(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--r',label=r\"prob (true, unknown) = $\\frac{exp(-1+5x)}{1+exp(-1+5x)}$\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n🗣️\n\nprob: 확률\n파란색 점: 관측값\n목표: 빨간색 선 잘 맞추기\n\n방법: 최초의 곡선을 그리고 update"
  },
  {
    "objectID": "posts/03wk-2.html#c.-step1-net-설계-모델링",
    "href": "posts/03wk-2.html#c.-step1-net-설계-모델링",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "C. Step1: net 설계 (모델링)",
    "text": "C. Step1: net 설계 (모델링)\n- 최초의 곡선을 그려보자.\n\n최초의직선: \\(\\hat{y}_i= \\hat{w}_0+\\hat{w}_1x_i\\) 에서 아무 \\(\\hat{w}_0\\), \\(\\hat{w}_1\\) 을 설정하면 된다.\n최초의곡선: \\(\\hat{y}_i= \\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\frac{1}{1+\\exp(-\\hat{w}_0-\\hat{w}_1x_i)}\\) 에서 아무 \\(\\hat{w}_0\\), \\(\\hat{w}_1\\) 을 설정하면 된다.\n\n\n\n\n\n\n\nNote\n\n\n\n일단은 초기 설정값을 \\(\\hat{w}_0 = -0.8\\), \\(\\hat{w}_1 = -0.3\\) 으로 하자. (실제값은 \\(w_0=-1\\), \\(w_1=5\\) 이다)\n\n\n# 방법1 – l1, sigmoid\n🗣️(\n\nw0hat = -4\nw1hat = 10\nyhat = torch.exp(w0hat + w1hat*x) / (1+ torch.exp(w0hat + w1hat*x))\n\n\nyhat\n\ntensor([[8.3153e-07],\n        [8.3989e-07],\n        [8.4833e-07],\n        ...,\n        [9.9748e-01],\n        [9.9750e-01],\n        [9.9753e-01]])\n\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x, yhat, '--')\n\n\n\n\n\n\n\n\n\nyhat을 다음과 같이 할 수도 있음\n\n\nlinr = torch.nn.Linear(1,1)\n# linr(x)\n\n\ndef sigmoid(x):\n    return torch.exp(x) / (1+ torch.exp(x)) #  편의상 linr(x) 대신 x로 작성\n\n\nlinr(x)\n\ntensor([[ 0.6311],\n        [ 0.6304],\n        [ 0.6297],\n        ...,\n        [-0.6902],\n        [-0.6909],\n        [-0.6916]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\nyhat = sigmoid(linr(x))\nplt.plot(x, yhat.data) # 곡선 중 일부만 그려져 직선처럼 보임\n\n\n\n\n\n\n\n\n\nlinr(x)가 계산되는 과정\n\n\nlinr.weight, linr.bias\n\n(Parameter containing:\n tensor([[-0.6613]], requires_grad=True),\n Parameter containing:\n tensor([-0.0303], requires_grad=True))\n\n\n\n-0.6613*x + -0.0303\n\ntensor([[ 0.6310],\n        [ 0.6303],\n        [ 0.6297],\n        ...,\n        [-0.6903],\n        [-0.6909],\n        [-0.6916]])\n\n\n\n값을 아까처럼 지정해주면\n\n\nlinr.weight.data = torch.tensor([[10.0]])\nlinr.bias.data = torch.tensor([-4.0])\n\n❓ bias는 [[-4.0]]이 아니라 [-4.0]\n🔬(\n\nlinr.weight.data = torch.tensor([[10.0]])\nlinr.bias.data = torch.tensor([[-4.0]])\n\n\nlinr(x)\n\ntensor([[-14.0000],\n        [-13.9900],\n        [-13.9800],\n        ...,\n        [  5.9800],\n        [  5.9900],\n        [  6.0000]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n❓ 상관없는듯?\n\nlinr.weight.data = torch.tensor([10.0])\nlinr.bias.data = torch.tensor([[-4.0]])\n\n\n# linr(x) # error: RuntimeError: mat2 must be a matrix, got 1-D tensor\n\n)🔬\n🔬 참고) -4.0이 아니라 -4를 쓰면 error\n\nlinr.weight.data = torch.tensor([[10.0]])\nlinr.bias.data = torch.tensor([-4.0])\n\n\nlinr(x)\n\ntensor([[-14.0000],\n        [-13.9900],\n        [-13.9800],\n        ...,\n        [  5.9800],\n        [  5.9900],\n        [  6.0000]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\nw0hat + w1hat*x # 위와 동일\n\ntensor([[-14.0000],\n        [-13.9900],\n        [-13.9800],\n        ...,\n        [  5.9800],\n        [  5.9900],\n        [  6.0000]])\n\n\n\n-4*x + 10 # 이것도 동일\n\ntensor([[14.0000],\n        [13.9960],\n        [13.9920],\n        ...,\n        [ 6.0080],\n        [ 6.0040],\n        [ 6.0000]])\n\n\n\n다시 정리하면\n\n\ndef sigmoid(x):\n    return torch.exp(x) / (1+ torch.exp(x)) #  편의상 linr(x) 대신 x로 작성\n\n\nl1 = torch.nn.Linear(1,1)\nl1.weight.data = torch.tensor([[10.0]])\nl1.bias.data = torch.tensor([-4.0])\n#yhat = torch.exp(l1(x)) / (1+ torch.exp(l1(x)))\nyhat = sigmoid(l1(x))\n\n\nplt.plot(x,yhat.data)\n\n\n\n\n\n\n\n\n\n값을 바꾸고 싶으면\n\n\nl1 = torch.nn.Linear(1,1)\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\n#yhat = torch.exp(l1(x)) / (1+ torch.exp(l1(x)))\nyhat = sigmoid(l1(x))\n\n\nplt.plot(x,yhat.data)\n\n\n\n\n\n\n\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x, yhat.data, '--')\n\n\n\n\n\n\n\n\n)🗣️\n\nl1 = torch.nn.Linear(1,1)\nl1(x) # w0hat + w1hat*x \n\ntensor([[ 0.4735],\n        [ 0.4728],\n        [ 0.4721],\n        ...,\n        [-0.9890],\n        [-0.9897],\n        [-0.9905]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n🗣️ 실행할 때마다 달라지므로 아래와 같이 고정\n\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\n\n\ndef sigmoid(x):\n    return torch.exp(x)/(1+torch.exp(x))\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x[0],y[0],'o',label=r\"$(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--r',label=r\"prob (true, unknown) = $\\frac{exp(-1+5x)}{1+exp(-1+5x)}$\")\nplt.plot(x,sigmoid(l1(x)).data,'--b', label=r\"prob (estimated) = $(x_i,\\hat{y}_i)$ -- first curve\")\nplt.legend()\n\n\n\n\n\n\n\n\n#\n# 방법2 – l1, a1\n🗣️(\nx -&gt; w0hat + w1hat*x  # 최초의 곡선을 그리기 위한 선형 변환\nu = w0hat + w1hat*x  # 결과를 u로 저장\nfirst_curve = yhat = prob_hat = sigmoid(u)\nu = w0hat + w1hat*x = l1(x) # l1을 만든다면 이렇게도 쓸 수 있음\nl1 = torch.nn.Linear(1,1)\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\nu = l1(x)\nyhat = sigmoid(u)\n\nsigmoid는 직접 만들었음\n\n\nsigmoid?\n\n\nSignature: sigmoid(x)\nDocstring: &lt;no docstring&gt;\nFile:      /tmp/ipykernel_30452/3273882758.py\nType:      function\n\n\n\n\nsigmoid??\n\n\nSignature: sigmoid(x)\nDocstring: &lt;no docstring&gt;\nSource:   \ndef sigmoid(x):\n    return torch.exp(x)/(1+torch.exp(x))\nFile:      /tmp/ipykernel_30452/3273882758.py\nType:      function\n\n\n\n\n다음과 같이도 할 수 있음 (torch.nn의 클래스 이용)\n\n\nsig = torch.nn.Sigmoid()\nsig\n\nSigmoid()\n\n\n\nl1 = torch.nn.Linear(1,1)\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\nu = l1(x)\nyhat = sig(u)\n\n\nyhat\n\ntensor([[0.3775],\n        [0.3775],\n        [0.3774],\n        ...,\n        [0.2499],\n        [0.2498],\n        [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\nl1 = torch.nn.Linear(1,1)\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\nyhat = sig(l1(x)) # x --&gt; l1 --&gt; sig 로 이해\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x[0],y[0],'o',label=r\"$(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--r',label=r\"prob (true, unknown) = $\\frac{exp(-1+5x)}{1+exp(-1+5x)}$\")\nplt.plot(x,sigmoid(l1(x)).data,'--b', label=r\"prob (estimated) = $(x_i,\\hat{y}_i)$ -- first curve\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n방법1과 동일한 결과\n\n)🗣️\n\nl1 = torch.nn.Linear(1,1)\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\n\n\na1 = torch.nn.Sigmoid()\n\n\nsigmoid(l1(x)), a1(l1(x)) # 똑같아요\n\n(tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;DivBackward0&gt;),\n tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;))\n\n\n- 지금까지의 구현 확인\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x[0],y[0],'o',label=r\"$(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--r',label=r\"prob (true, unknown) = $\\frac{exp(-1+5x)}{1+exp(-1+5x)}$\")\nplt.plot(x,a1(l1(x)).data,'--b', label=r\"prob (estimated) = $(x_i,\\hat{y}_i)$ -- first curve with $(a_1 \\circ l_1)(x)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n#\n# 방법3 - l1, a1 만들고 \\(\\to\\) net\n🗣️(\n\nyhat\n\ntensor([[0.3775],\n        [0.3775],\n        [0.3774],\n        ...,\n        [0.2499],\n        [0.2498],\n        [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\na1(l1(x))\n\ntensor([[0.3775],\n        [0.3775],\n        [0.3774],\n        ...,\n        [0.2499],\n        [0.2498],\n        [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\nnet = al \\(\\circ\\) l1 을 정의하여 net(x)도 같은 결과를 나오게 하고 싶음\n\n\ntorch.nn.Sequential(l1,a1)\n\nSequential(\n  (0): Linear(in_features=1, out_features=1, bias=True)\n  (1): Sigmoid()\n)\n\n\n\nnet = torch.nn.Sequential(l1,a1)\nnet(x) # a1(l1(x))\n\ntensor([[0.3775],\n        [0.3775],\n        [0.3774],\n        ...,\n        [0.2499],\n        [0.2498],\n        [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\n이렇게 한 이유: parameters()를 이용하여 optimizer를 만들 수 있음\n\n\nnet.parameters()\n\n&lt;generator object Module.parameters at 0x7f34682a17b0&gt;\n\n\n)🗣️\n- 관찰: 지금 아래의 구조이다.\n\\[{\\bf x} \\overset{l_1}{\\to} {\\bf u} \\overset{a_1}{\\to} {\\bf v} = \\hat{\\bf y}\\]\n- 소망: 함수 \\(l_1, a_1\\) 의 합성을 하나로 묶어서\n\\[(a_1\\circ l_1)({\\bf x}) := net({\\bf x})\\]\n이러한 기능을 하는 하나의 함수 \\(net\\)을 만들 수 없을까?\n\nl1 = torch.nn.Linear(1,1)\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\na1 = torch.nn.Sigmoid()\n\n\nnet = torch.nn.Sequential(l1,a1) #l1을 취하고 그다음에 a1을 취하라는 의미\n\n\nnet(x), a1(l1(x)), sigmoid(l1(x))\n\n(tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;),\n tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;),\n tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;DivBackward0&gt;))\n\n\n* net 구조 잠깐 살펴보기\n🗣️(\n\nnet\n\nSequential(\n  (0): Linear(in_features=1, out_features=1, bias=True)\n  (1): Sigmoid()\n)\n\n\n\nnet[0]\n\nLinear(in_features=1, out_features=1, bias=True)\n\n\n\nl1\n\nLinear(in_features=1, out_features=1, bias=True)\n\n\n\nnet[1]\n\nSigmoid()\n\n\n\naaa = torch.nn.Sigmoid()\naaa\n\nSigmoid()\n\n\n\nnet가 리스트처럼 되어 있어 첫번째 원소 net[0]은 l1 이고 두번째 원소 net[1]은 aaa인듯\n확인 방법: 아래\n\n\nl1 is net[0]\n\nTrue\n\n\n\na1 is net[1]\n\nTrue\n\n\n\n다른 확인 방법\n\n오브젝트: 메모리에 저장\n저장되어 있는 주소가 동일하면 같은 오브젝트\n\n\n\nid(net[0]), id(l1)\n\n(139863062109248, 139863062109248)\n\n\n\nid(net[1]), id(a1)\n\n(139863062108960, 139863062108960)\n\n\n\nnet(x), a1(l1(x))\n\n(tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;),\n tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;))\n\n\n\nnet(x), net[1](net[0](x)) # 이것도 동일\n\n(tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;),\n tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;))\n\n\n)🗣️\n\nnet[0], net[1]\n\n(Linear(in_features=1, out_features=1, bias=True), Sigmoid())\n\n\n\nl1 is net[0]\n\nTrue\n\n\n\na1 is net[1]\n\nTrue\n\n\n#\n# 방법4 – net을 바로 만들기\n🗣️(\n# x --&gt; yhat: 회귀분석에서 최초의 직선 바로 만드는 방법\nnet = torch.nn.Linear(1,1)\nyhat - net(x)\n# x --&gt; yhat: 로지스틱에서 최초의 곡선 바로 만드는 방법\nnet = torch.nn.Sequential(\n    l1,\n    a1\n)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nyhat = net(x)\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nyhat = net(x)\n\n\nnet[0].weight # 아무 parameter가 들어가 있음\n\nParameter containing:\ntensor([[0.4945]], requires_grad=True)\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nnet[0].weight.data = torch.tensor([[-0.3]])\nnet[0].bias.data = torch.tensor([-0.8])\nyhat = net(x)\n\n\nnet(x)\n\ntensor([[0.3775],\n        [0.3775],\n        [0.3774],\n        ...,\n        [0.2499],\n        [0.2498],\n        [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n)🗣️\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nnet[0].weight.data = torch.tensor([[-0.3]])\nnet[0].bias.data = torch.tensor([-0.8])\nyhat = net(x)\n\n\nnet(x)\n\ntensor([[0.3775],\n        [0.3775],\n        [0.3774],\n        ...,\n        [0.2499],\n        [0.2498],\n        [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n🗣️ 결론: 위의 방법으로 사용하면 됨\n#"
  },
  {
    "objectID": "posts/03wk-2.html#d.-step14",
    "href": "posts/03wk-2.html#d.-step14",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "D. Step1~4",
    "text": "D. Step1~4\n🗣️(\n\n학습 시작\n\n\nplt.plot(x,y,'.',alpha=0.03) # given data\n\n\n\n\n\n\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nnet[0].weight.data = torch.tensor([[-0.3]])\nnet[0].bias.data = torch.tensor([-0.8])\nyhat = net(x)\n\n\nplt.plot(x,y,'.',alpha=0.03) # given data\nplt.plot(x,net(x).data, '--') # 최초의 곡선 그리기\n\n\n\n\n\n\n\n\n\n최초의 곡선보다 나은 곡선을 찾으며 update하면 됨\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nnet[0].weight.data = torch.tensor([[-0.3]])\nnet[0].bias.data = torch.tensor([-0.8])\nyhat = net(x)\nloss = torch.mean((y-yhat)**2) # loss 함수를 만들어 줌\nloss\n\ntensor(0.2747, grad_fn=&lt;MeanBackward0&gt;)\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nnet[0].weight.data = torch.tensor([[-0.3]])\nnet[0].bias.data = torch.tensor([-0.8])\noptimizr = torch.optim.SGD(net.parameters(), lr=0.25)\nfor epoc in range(200):\n    yhat = net(x)\n    loss = torch.mean((y-yhat)**2)\n    loss.backward() # 미분\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x,net(x).data, '--')\n\n\n\n\n\n\n\n\n\n최초의 곡선보다는 그럴듯해짐\n알고 있는 True 값과 비교해보면\n\n주황색 선: True\n200번 정도 반복하니 어느 정도 온 것 같지만 딱 맞다고 보기는 어려움\n\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x,prob,'--')\nplt.plot(x,net(x).data, '--')\n\n\n\n\n\n\n\n\n\n200번 더 (총 400번)\n\n\nfor epoc in range(200):\n    yhat = net(x)\n    loss = torch.mean((y-yhat)**2)\n    loss.backward() # 미분\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x,prob,'--')\nplt.plot(x,net(x).data, '--')\n\n\n\n\n\n\n\n\n\n200번 더 (총 600번)\n\n\nfor epoc in range(200):\n    yhat = net(x)\n    loss = torch.mean((y-yhat)**2)\n    loss.backward() # 미분\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x,prob,'--')\nplt.plot(x,net(x).data, '--')\n\n\n\n\n\n\n\n\n\n200번 더 (총 800번)\n\n\nfor epoc in range(200):\n    yhat = net(x)\n    loss = torch.mean((y-yhat)**2)\n    loss.backward() # 미분\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x,prob,'--')\nplt.plot(x,net(x).data, '--')\n\n\n\n\n\n\n\n\n\n돌릴수록 가까워질 것 같음\n\n)🗣️\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net \nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,prob,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')\n\n\n\n\n\n\n\n\n\n\nfor epoc in range(4900):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,prob,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 5000 epochs')\n\nText(0.5, 1.0, 'after 5000 epochs')\n\n\n\n\n\n\n\n\n\n🗣️ 로지스틱이 해결된 것처럼 보임\n🗣️(\n\n다음과 같이 해도 마찬가지 (초기값은 크게 중요하지 않으므로)\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\n# l1, a1 = net \n# l1.weight.data = torch.tensor([[-0.3]])\n# l1.bias.data = torch.tensor([-0.8])\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,prob,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')\n\n\n\n\n\n\n\n\n\n\nfor epoc in range(4900):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,prob,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 5000 epochs')\n\nText(0.5, 1.0, 'after 5000 epochs')\n\n\n\n\n\n\n\n\n\n\n성공한 것 같지만 실상은 그렇지 않음\n\nfor epoc in range(4900):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((y-yhat)**2) # 이 부분에 문제가 있어 설명할 예정\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n)🗣️"
  },
  {
    "objectID": "posts/03wk-2.html#a.-시각화를-위한-준비",
    "href": "posts/03wk-2.html#a.-시각화를-위한-준비",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "A. 시각화를 위한 준비",
    "text": "A. 시각화를 위한 준비\n\ndef plot_loss(loss_fn, ax=None, Wstar=[-1,5]):\n    w0hat,w1hat =torch.meshgrid(torch.arange(-10,3,0.1),torch.arange(-1,10,0.1),indexing='ij')\n    w0hat = w0hat.reshape(-1)\n    w1hat = w1hat.reshape(-1)\n    def l(w0hat,w1hat):\n        yhat = torch.exp(w0hat+w1hat*x)/(1+torch.exp(w0hat+w1hat*x))\n        return loss_fn(yhat,y) \n    loss = list(map(l,w0hat,w1hat))\n    #---#\n    if ax is None: \n        fig = plt.figure()\n        ax = fig.add_subplot(1,1,1,projection='3d')\n    ax.scatter(w0hat,w1hat,loss,s=0.001) \n    ax.scatter(w0hat[::20],w1hat[::20],loss[::20],s=0.1,color='C0') \n    w0star,w1star = np.array(Wstar).reshape(-1)\n    ax.scatter(w0star,w1star,l(w0star,w1star),s=200,marker='*',color='red',label=f\"W=[{w0star:.1f},{w1star:.1f}]\")\n    #---#\n    ax.elev = 15\n    ax.dist = -20\n    ax.azim = 75    \n    ax.legend()\n    ax.set_xlabel(r'$w_0$')  # x축 레이블 설정\n    ax.set_ylabel(r'$w_1$')  # y축 레이블 설정\n    ax.set_xticks([-10,-5,0])  # x축 틱 간격 설정\n    ax.set_yticks([-10,0,10])  # y축 틱 간격 설정\n\n\ndef _learn_and_record(net, loss_fn, optimizr):\n    yhat_history = [] \n    loss_history = []\n    What_history = []\n    Whatgrad_history = []\n    What_history.append([net[0].bias.data.item(), net[0].weight.data.item()])\n    for epoc in range(100): \n        ## step1 \n        yhat = net(x)\n        ## step2 \n        loss = loss_fn(yhat,y)\n        ## step3\n        loss.backward() \n        ## step4 \n        optimizr.step()\n        ## record \n        if epoc % 5 ==0: \n            yhat_history.append(yhat.reshape(-1).data.tolist())\n            loss_history.append(loss.item())\n            What_history.append([net[0].bias.data.item(), net[0].weight.data.item()])\n            Whatgrad_history.append([net[0].bias.grad.item(), net[0].weight.grad.item()])\n        optimizr.zero_grad() \n        \n    return yhat_history, loss_history, What_history, Whatgrad_history\n    \ndef show_animation(net, loss_fn, optimizr):\n    yhat_history,loss_history,What_history,Whatgrad_history = _learn_and_record(net,loss_fn,optimizr)\n    \n    fig = plt.figure(figsize=(7.5,3.5))\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n    ## ax1: 왼쪽그림 \n    ax1.scatter(x,y,alpha=0.01)\n    ax1.scatter(x[0],y[0],color='C0',label=r\"observed data = $(x_i,y_i)$\")\n    ax1.plot(x,prob,'--',label=r\"prob (true) = $(x_i,\\frac{exp(-1+5x_i)}{1+exp(-1+5x_i)})$\")    \n    line, = ax1.plot(x,yhat_history[0],'--',label=r\"prob (estimated) = $(x_i,\\hat{y}_i)$\") \n    ax1.legend()\n    ## ax2: 오른쪽그림 \n    plot_loss(loss_fn,ax2)\n    ax2.scatter(np.array(What_history)[0,0],np.array(What_history)[0,1],loss_history[0],color='blue',s=200,marker='*')    \n    def animate(epoc):\n        line.set_ydata(yhat_history[epoc])\n        w0hat = np.array(What_history)[epoc,0]\n        w1hat = np.array(What_history)[epoc,1]\n        w0hatgrad = np.array(Whatgrad_history)[epoc,0]\n        w1hatgrad = np.array(Whatgrad_history)[epoc,1]\n        ax2.scatter(w0hat,w1hat,loss_history[epoc],color='grey')\n        ax2.set_title(f\"What.grad=[{w0hatgrad:.4f},{w1hatgrad:.4f}]\",y=0.8)\n        fig.suptitle(f\"epoch={epoc*5} // What=[{w0hat:.2f},{w1hat:.2f}] // Loss={loss_fn.__class__.__name__} // Opt={optimizr.__class__.__name__}\")\n        return line\n    ani = animation.FuncAnimation(fig, animate, frames=20)    \n    plt.close()\n    return ani\n\n\nfrom matplotlib import animation\nplt.rcParams[\"animation.html\"] = \"jshtml\"\n\n함수사용법\n\nloss_fn = torch.nn.MSELoss()\nplot_loss(loss_fn)\n\n\n\n\n\n\n\n\n🗣️(\n\ndef loss_fn2(yhat,y):\n    return loss_fn(yhat,y)*2\n\n\nplot_loss(loss_fn2)\n\n\n\n\n\n\n\n\n\nz축만 2배 증가 (함수: 곡면을 그려주는 역할)\n\n\n# show_animation??\n\n\nSignature: show_animation(net, loss_fn, optimizr)\n\nnet: 초기 설정 값 (w0, w1)\nloss_fn: 그림\noptimizr: 학습 과정\n\n밑 코드: 어떠한 초기값을 받아 학습하는 과정을 그려줌\n\n실행할 때마다 초기값 달라짐\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n초기값 고정\n\n만약 학습률이 2.5면 더 빨리 떨어짐\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nnet[0].weight.data = torch.tensor([[-0.8]])\nnet[0].bias.data = torch.tensor([-0.3])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n)🗣️\n\ntorch.manual_seed(42)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n🗣️\n\n초기값에 따라 학습이 달라짐\n만약 초기 값이 우측 상단이라면 평평하기 때문에 update가 아주 조금씩 일어남"
  },
  {
    "objectID": "posts/03wk-2.html#b.-좋은-초기값",
    "href": "posts/03wk-2.html#b.-좋은-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "B. 좋은 초기값",
    "text": "B. 좋은 초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n🗣️\n\n이 경우는 기다리면 학습이 잘 될 거 같음"
  },
  {
    "objectID": "posts/03wk-2.html#c.-가능성-있는-초기값",
    "href": "posts/03wk-2.html#c.-가능성-있는-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "C. 가능성 있는 초기값",
    "text": "C. 가능성 있는 초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n🗣️\n\n마지막에 약간 희망이 보임\n마음 먹고 20,000번 정도 돌리면 될 거 같음"
  },
  {
    "objectID": "posts/03wk-2.html#d.-최악의-초기값",
    "href": "posts/03wk-2.html#d.-최악의-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "D. 최악의 초기값",
    "text": "D. 최악의 초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n🗣️\n\n이 경우는 희망이 없음\n곡선이 아래로 볼록한 2차 함수가 아니고 4차 함수라면 학습률과 초기 값에 따라 갖혀버릴 수도 있고 운에 따라 달라짐\n\n\n해결하는 접근법:\n\n컴공스타일: 에폭을 늘려볼까?\n산공스타일: 옵티마이저를 바꿔볼까?\n통계스타일: Loss를 바꿔볼까?\n🗣️\n\n초기 값을 바꿔가며 무수히 실행하며 찾음\n이 어려운 곡면에 대해 옵티마이저를 수정\n곡면 자체를 최적화가 잘 되게 바꿈 (loss 함수를 바꿈: MSE Loss 말고 다른 Loss?)"
  },
  {
    "objectID": "posts/03wk-2.html#a.-bce-loss를-사용하여-학습",
    "href": "posts/03wk-2.html#a.-bce-loss를-사용하여-학습",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "A. BCE Loss를 사용하여 학습",
    "text": "A. BCE Loss를 사용하여 학습\n- BCE loss라는게 있음.\n\n\\(loss= - \\sum_{i=1}^{n} \\big(y_i\\log(\\hat{y}_i)+(1-y_i)\\log(1-\\hat{y}_i)\\big)\\)\nhttps://en.wikipedia.org/wiki/Cross-entropy\n\n🗣️(\nyi = 0\nyi_hat = 0.001\nlog(1) = 0\nloss = 0\nyi = 0\nyi_hat = 0.9999\nlog(1-0.999) = log(0) = -무한대\nloss = 무한대\nyi = 1\nyi_hat = 1\nloss = 0\nyi = 1\nyi_hat = 0.0001\nloss = 무한대\n\n비슷할수록 0, 다를수록 무한대까지 감 -&gt; loss의 역할은 함\n원리: - log likelihoood\n\n)🗣️\n\n🗣️\n\nnet[0] = torch.nn.Linear(in_features=1, out_features=1)\nnet[1] = torch.nn.Sigmoid()\nnet = [net[0], net[1]] 느낌\nl1, a1 = [net[0], net[1]] 느낌\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net \nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    #loss = torch.mean((y-yhat)**2) # loss_fn(yhat,y)\n    loss = -torch.mean(y*torch.log(yhat) + (1-y)*torch.log(1-yhat))\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,prob,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')\n\n\n\n\n\n\n\n\n\n같은 100 에폭인데 훨씬 잘맞춤..\n🗣️ 동일한 초기 값\n- loss수식을 못외우겠다면?\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net \nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y) # yhat부터 써야함\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,prob,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')"
  },
  {
    "objectID": "posts/03wk-2.html#b.-loss-function-시각화",
    "href": "posts/03wk-2.html#b.-loss-function-시각화",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "B. Loss Function 시각화",
    "text": "B. Loss Function 시각화\n\nplot_loss(torch.nn.MSELoss())\n\n\n\n\n\n\n\n\n🗣️ MSELoss는 우측 상단에 있으면 안 될 것 같음\n\nplot_loss(torch.nn.BCELoss())\n\n\n\n\n\n\n\n\n- 비교해보자.\n\nfig = plt.figure()\nax1 = fig.add_subplot(1,2,1,projection='3d')\nax2 = fig.add_subplot(1,2,2,projection='3d')\nplot_loss(torch.nn.MSELoss(),ax1)\nplot_loss(torch.nn.BCELoss(),ax2)\n\n\n\n\n\n\n\n\n\n🗣️\n\n오른쪽과 같은 경우를 어려운 말로 convex function이라고 함\nloss 함수가 convex function이면 수렴시키기 쉬움"
  },
  {
    "objectID": "posts/03wk-2.html#c.-학습과정-시각화-좋은-초기값",
    "href": "posts/03wk-2.html#c.-학습과정-시각화-좋은-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "C. 학습과정 시각화 – 좋은 초기값",
    "text": "C. 학습과정 시각화 – 좋은 초기값\n- MSELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- BCELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n🗣️ 같은 초기값인데 BCELoss가 더 수렴을 잘 할 것 같음"
  },
  {
    "objectID": "posts/03wk-2.html#d.-학습과정-시각화-가능성-있는-초기값",
    "href": "posts/03wk-2.html#d.-학습과정-시각화-가능성-있는-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "D. 학습과정 시각화 – 가능성 있는 초기값",
    "text": "D. 학습과정 시각화 – 가능성 있는 초기값\n- MSELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- BCELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n🗣️ BCELoss는 처음부터 잘 떨어짐"
  },
  {
    "objectID": "posts/03wk-2.html#e.-학습과정-시각화-최악의-초기값",
    "href": "posts/03wk-2.html#e.-학습과정-시각화-최악의-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "E. 학습과정 시각화 – 최악의 초기값",
    "text": "E. 학습과정 시각화 – 최악의 초기값\n- MSELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- BCELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n🗣️ BCELoss는 처음부터 잘 떨어짐"
  },
  {
    "objectID": "posts/03wk-2.html#a.-학습과정-시각화-좋은-초기값",
    "href": "posts/03wk-2.html#a.-학습과정-시각화-좋은-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "A. 학습과정 시각화 – 좋은 초기값",
    "text": "A. 학습과정 시각화 – 좋은 초기값\n- MSELoss + SGD\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8470])\nnet[0].weight.data = torch.tensor([[-0.3467]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- MSELoss + Adam\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n🗣️ Adam을 사용하니 빨리 떨어지면서 잘 수렴함 (힘으로 미는 느낌)"
  },
  {
    "objectID": "posts/03wk-2.html#b.-학습과정-시각화-가능성-있는-초기값",
    "href": "posts/03wk-2.html#b.-학습과정-시각화-가능성-있는-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "B. 학습과정 시각화 – 가능성 있는 초기값",
    "text": "B. 학습과정 시각화 – 가능성 있는 초기값\n- MSELoss + SGD\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- MSELoss + Adam\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n🗣️ Adam을 사용하니 빨리 떨어지면서 잘 수렴함 (마지막은 살짝 돌아가는 느낌)"
  },
  {
    "objectID": "posts/03wk-2.html#c.-학습과정-시각화-최악의-초기값",
    "href": "posts/03wk-2.html#c.-학습과정-시각화-최악의-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "C. 학습과정 시각화 – 최악의 초기값",
    "text": "C. 학습과정 시각화 – 최악의 초기값\n- MSELoss + SGD\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.05) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- MSELoss + Adam\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n🗣️ Adam을 사용하니 빨리 떨어지면서 잘 수렴함 (내려오는 힘이 강해서 그런지 마지막은 살짝 돌다가 가는 느낌)\n🗣️ 현재 최적화를 잘하고 싶으면 Adam을 사용하면 됨"
  },
  {
    "objectID": "posts/03wk-2.html#d.-참고자료",
    "href": "posts/03wk-2.html#d.-참고자료",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "D. 참고자료",
    "text": "D. 참고자료\nhttps://www.youtube.com/watch?v=MD2fYip6QsQ\n\n11:50 – Momentum\n12:30 – RMSprop\n15:55 – Adam\n🗣️ local min과 global min이 따로 있을 때\n\n일반적인 경사하강법은 보통 local min에 빠짐\nAdam은 local min을 잘 탈출함 (항상은 X)"
  },
  {
    "objectID": "posts/03wk-2.html#a.-신문기사-데이터의-모티브",
    "href": "posts/03wk-2.html#a.-신문기사-데이터의-모티브",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "A. 신문기사 (데이터의 모티브)",
    "text": "A. 신문기사 (데이터의 모티브)\n- 스펙이 높아도 취업이 안된다고 합니다..\n중소·지방 기업 “뽑아봤자 그만두니까”\n중소기업 관계자들은 고스펙 지원자를 꺼리는 이유로 높은 퇴직률을 꼽는다. 여건이 좋은 대기업으로 이직하거나 회사를 관두는 경우가 많다는 하소연이다. 고용정보원이 지난 3일 공개한 자료에 따르면 중소기업 청년취업자 가운데 49.5%가 2년 내에 회사를 그만두는 것으로 나타났다.\n중소 IT업체 관계자는 “기업 입장에서 가장 뼈아픈 게 신입사원이 그만둬서 새로 뽑는 일”이라며 “명문대 나온 스펙 좋은 지원자를 뽑아놔도 1년을 채우지 않고 그만두는 사원이 대부분이라 우리도 눈을 낮춰 사람을 뽑는다”고 말했다."
  },
  {
    "objectID": "posts/03wk-2.html#b.-가짜데이터-스펙의-역설",
    "href": "posts/03wk-2.html#b.-가짜데이터-스펙의-역설",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "B. 가짜데이터 – 스펙의 역설",
    "text": "B. 가짜데이터 – 스펙의 역설\n🗣️ x: 스펙, prob: 합격할 확률\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2025/main/posts/ironyofspec.csv\")\ndf\n\n\n\n\n\n\n\n\nx\nprob\ny\n\n\n\n\n0\n-1.000000\n0.000045\n0.0\n\n\n1\n-0.998999\n0.000046\n0.0\n\n\n2\n-0.997999\n0.000047\n0.0\n\n\n3\n-0.996998\n0.000047\n0.0\n\n\n4\n-0.995998\n0.000048\n0.0\n\n\n...\n...\n...\n...\n\n\n1995\n0.995998\n0.505002\n0.0\n\n\n1996\n0.996998\n0.503752\n0.0\n\n\n1997\n0.997999\n0.502501\n0.0\n\n\n1998\n0.998999\n0.501251\n1.0\n\n\n1999\n1.000000\n0.500000\n1.0\n\n\n\n\n2000 rows × 3 columns\n\n\n\n\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.legend()\n\n\n\n\n\n\n\n\n🗣️ 스펙이 너무 높으면 오히려 떨어짐"
  },
  {
    "objectID": "posts/03wk-2.html#c.-로지스틱으로-적합",
    "href": "posts/03wk-2.html#c.-로지스틱으로-적합",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "C. 로지스틱으로 적합",
    "text": "C. 로지스틱으로 적합\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---# \nfor epoc in range(5000):\n    ## 1 \n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.plot(x,net(x).data, '--', label= r\"prob (estimated) = $(x_i,\\hat{y}_i)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n- Epoch을 10억번으로 설정해도 이건 못 맞출것 같음.\n\n🗣️\n\n주황색 선(model)이 올라가다가 내려오는 것은 최초의 곡선이 바뀔 수 있는 범위를 벗어남 (수식적으로)\n이런 경우 모형의 표현력이 낮다고 표현함"
  },
  {
    "objectID": "posts/03wk-2.html#d.-로지스틱-한계극복-아이디어만",
    "href": "posts/03wk-2.html#d.-로지스틱-한계극복-아이디어만",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "D. 로지스틱 한계극복 – 아이디어만",
    "text": "D. 로지스틱 한계극복 – 아이디어만\n🗣️ 반반 잘라서 하면 될 것 같음\n- sigmoid를 넣기 전의 상태가 직선이 아니라 꺽이는 직선이야 한다.\n\na = torch.nn.Sigmoid()\n\n\nfig,ax = plt.subplots(4,2,figsize=(8,8))\nu1 = torch.tensor([-6,-4,-2,0,2,4,6])\nu2 = torch.tensor([6,4,2,0,-2,-4,-6])\nu3 = torch.tensor([-6,-2,2,6,2,-2,-6])\nu4 = torch.tensor([-6,-2,2,6,4,2,0])\nax[0,0].plot(u1,'--o',color='C0',label = r\"$u_1$\")\nax[0,0].legend()\nax[0,1].plot(a(u1),'--o',color='C0',label = r\"$a(u_1)=\\frac{exp(u_1)}{exp(u_1)+1}$\")\nax[0,1].legend()\nax[1,0].plot(u2,'--o',color='C1',label = r\"$u_2$\")\nax[1,0].legend()\nax[1,1].plot(a(u2),'--o',color='C1',label = r\"$a(u_2)=\\frac{exp(u_2)}{exp(u_2)+1}$\")\nax[1,1].legend()\nax[2,0].plot(u3,'--o',color='C2', label = r\"$u_3$\")\nax[2,0].legend()\nax[2,1].plot(a(u3),'--o',color='C2', label = r\"$a(u_3)=\\frac{exp(u_3)}{exp(u_3)+1}$\")\nax[2,1].legend()\nax[3,0].plot(u4,'--o',color='C3', label = r\"$u_4$\")\nax[3,0].legend()\nax[3,1].plot(a(u4),'--o',color='C3', label = r\"$a(u_4)=\\frac{exp(u_4)}{exp(u_4)+1}$\")\nax[3,1].legend()"
  },
  {
    "objectID": "posts/03wk-2.html#footnotes",
    "href": "posts/03wk-2.html#footnotes",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n원래는 이렇게 썼었지.. \\(y_i = w_0 + w_1x_i + \\epsilon_i \\quad \\epsilon_i \\sim {\\cal N}(0,\\sigma^2)\\)↩︎"
  },
  {
    "objectID": "posts/05wk-2.html",
    "href": "posts/05wk-2.html",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "",
    "text": "📘 Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\n📝 🗣️ ✍️ 🔬 ❓"
  },
  {
    "objectID": "posts/05wk-2.html#a.-로지스틱",
    "href": "posts/05wk-2.html#a.-로지스틱",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "A. 로지스틱",
    "text": "A. 로지스틱\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(1)}} =\\underset{(n,1)}{\\hat{\\bf y}}\\]\n🗣️(\n\n위를 보고 다음과 같은 표현이 떠올라야 함\n\n다음은 관습적 표현\nu: 보통 X에 선형변환\nv: 보통 u에 비선형변환(Sigmoid, ReLU)\nv 결과에 선형변환을 하면 또 u라고 하기 때문에 우측상단에 숫자로 구분\n\n\nnet torch.nn.Sequential(\n    torch.nn.Linear(1,1), # l1(X) = u\n    torch.nn.Sigmoid() # sig(u) = v\n)\nyhat = net(X)\n)🗣️\n- 모든 observation과 가중치를 명시한 버전\n(표현1)\n\n\n단점: 똑같은 그림의 반복이 너무 많음\n\n- observation 반복을 생략한 버전들\n(표현2) 모든 \\(i\\)에 대하여 아래의 그림을 반복한다고 하면 (표현1)과 같다.\n\n(표현3) 그런데 (표현2)에서 아래와 같이 \\(x_i\\), \\(y_i\\) 대신에 간단히 \\(x\\), \\(y\\)로 쓰는 경우도 많음\n\n🗣️ x: vector\n- 1을 생략한 버전들\n(표현4) bais=False 대신에 bias=True를 주면 1을 생략할 수 있음\n\n(표현4의 수정) \\(\\hat{w}_1\\)대신에 \\(\\hat{w}\\)를 쓰는 것이 더 자연스러움\n\n(표현5) 선형변환의 결과는 아래와 같이 \\(u\\)로 표현하기도 한다.\n\n\n다이어그램은 그리는 사람의 취향에 따라 그리는 방법이 조금씩 다릅니다. 즉 교재마다 달라요."
  },
  {
    "objectID": "posts/05wk-2.html#b.-스펙의역설",
    "href": "posts/05wk-2.html#b.-스펙의역설",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "B. 스펙의역설",
    "text": "B. 스펙의역설\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}} =\\underset{(n,1)}{\\hat{\\bf y}}\\]\n참고: 코드로 표현\ntorch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=2),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=2,out_features=1),\n    torch.nn.Sigmoid()\n)\n- 이해를 위해서 예젠에 다루었던 아래의 상황을 고려하자.\n\n(강의노트의 표현)\n\n(좀 더 일반화된 표현) 상황을 일반화하면 아래와 같다.\n\n* Layer의 개념: \\({\\bf X}\\)에서 \\(\\hat{\\boldsymbol y}\\)로 가는 과정은 “선형변환+비선형변환”이 반복되는 구조이다. “선형변환+비선형변환”을 하나의 세트로 보면 아래와 같이 표현할 수 있다.\n\n\\(\\underset{(n,1)}{\\bf X}  \\overset{l_1}{\\to} \\left( \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\right) \\overset{l_2}{\\to} \\left(\\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}\\right), \\quad  \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{net({\\bf X})}=\\underset{(n,1)}{\\hat{\\bf y}}\\)\n\n🗣️ 선형변환 -&gt; 선형변환: 아무런 이점이 없음, 잘못 설계 (바로 가는 선형변환이 있기 때문)\n이것을 다이어그램으로 표현한다면 아래와 같다.\n(선형+비선형을 하나의 Layer로 묶은 표현)\n\n🗣️ Layer 0(Input Layer라고도 함)은 세지 X\nLayer를 세는 방법\n\n제 방식: 학습가능한 파라메터가 몇층으로 있는지… &lt;– 이것만 기억하세여\n일부 교재 설명: 입력층은 계산하지 않음, activation layer는 계산하지 않음. &lt;– 무시하세요.. 이러면 헷갈립니다..\n위의 예제의 경우 number of layer = 2 이다.\n\nHidden Layer의 수를 세는 방법\n\n제 방식: Hidden Layer의 수 = Layer의 수 -1 &lt;– 이걸 기억하세여..\n\n일부 교재 설명: Layer의 수 = Hidden Layer의 수 + 출력층의 수 = Hidden Layer의 수 + 1 &lt;– 기억하지 마세여\n위의 예제의 경우 number of hidden layer = 1 이다.\n\n🗣️ 이 경우 Hiden Layer: Layer 1 / 출력층: Layer 2 (yhat)\n\n\n\n\n\n\nImportant\n\n\n\n무조건 학습가능한 파라메터가 몇겹으로 있는지만 판단하세요. 딴거 아무것도 생각하지마세여\n## 예시1 -- 2층 (히든레이어는 1층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU(),\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n)\n## 예시2 -- 2층 (히든레이어는 1층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU(),\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid(),\n)\n## 예시3 -- 1층 (히든레이어는 없음!!)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n) \n## 예시4 -- 1층 (히든레이어는 없음!!)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n) \n## 예시5 -- 3층 (히든레이어는 2층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층    \n) \n## 예시6 -- 3층 (히든레이어는 2층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU()\n    torch.nn.Dropout(??)\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU()\n    torch.nn.Dropout(??)\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층  \n    torch.nn.Sigmoid()\n) \n\n\n\n\n\n\n\n\nImportant\n\n\n\n문헌에 따라서 레이어를 세는 개념이 제가 설명한 방식과 다른경우가 있습니다. 제가 설명한 방식보다 1씩 더해서 셉니다. 즉 아래의 경우 레이어를 3개로 카운트합니다.\n## 예시1 -- 문헌에 따라 3층으로 세는 경우가 있음 (히든레이어는 1층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU(),\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n)\n예를 들어 여기에서는 위의 경우 레이어는 3개라고 설명하고 있습니다. 이러한 카운팅은 “무시”하세요. 제가 설명한 방식이 맞아요. 이 링크 잘못(?) 나와있는 이유는 아래와 같습니다.\n- 진짜 예전에 MLP를 소개할 초창기에서는 위의 경우 Layer를 3개로 셌음. [@rosenblatt1962principles]\n- 그런데 요즘은 그렇게 안셈.. (그리고 애초에 MLP라는 용어도 잘 안쓰죠..)\n참고로 히든레이어의 수는 예전방식이나 지금방식이나 동일하게 카운트하므로 히든레이어만 세면 혼돈이 없습니다.\n\n\n\n🗣️\n\n요즘은 MLP보다는 DNN 용어 사용\n요즘은 Dropout보다 Batch Normalization을 사용\n\nBatch Normalization은 학습 parameter가 있음\n그러나 layer로 세지는 X\n\n요즘은 layer가 몇 층인지 굳이 따지지는 X\n\n\n* node의 개념: \\(u\\to v\\)로 가는 쌍을 간단히 노드라는 개념을 이용하여 나타낼 수 있음.\n(노드의 개념이 포함된 그림)\n\n여기에서 node의 숫자 = feature의 숫자와 같이 이해할 수 있다. 즉 아래와 같이 이해할 수 있다.\n(“number of nodes = number of features”로 이해한 그림)\n\n\n다이어그램의 표현방식은 교재마다 달라서 모든 예시를 달달 외울 필요는 없습니다. 다만 임의의 다이어그램을 보고 대응하는 네트워크를 pytorch로 구현하는 능력은 매우 중요합니다."
  },
  {
    "objectID": "posts/05wk-2.html#c.-mnist",
    "href": "posts/05wk-2.html#c.-mnist",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "C. MNIST",
    "text": "C. MNIST\n\\[\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n(다이어그램표현)\n\n🗣️ 학습 가능한 parameter 수: 784*32 (\\(X_{(n,784)}@w_{?} = (n,32)\\))\n\nLayer0,1,2 대신에 Input Layer, Hidden Layer, Output Layer로 표현함\n\n- 위의 다이어그램에 대응하는 코드\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=28*28*1,out_features=32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=32,out_features=1),\n    torch.nn.Sigmoid() \n)"
  },
  {
    "objectID": "posts/05wk-2.html#a.-gpu-사용방법",
    "href": "posts/05wk-2.html#a.-gpu-사용방법",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "A. GPU 사용방법",
    "text": "A. GPU 사용방법\n- cpu 연산이 가능한 메모리에 데이터 저장\n\ntorch.manual_seed(43052)\nx_cpu = torch.tensor([0.0,0.1,0.2]).reshape(-1,1) \ny_cpu = torch.tensor([0.0,0.2,0.4]).reshape(-1,1) \nnet_cpu = torch.nn.Linear(1,1) \n\n\nnet_cpu(x_cpu)\n\ntensor([[-0.8470],\n        [-0.8817],\n        [-0.9164]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\nx_cpu\n\ntensor([[0.0000],\n        [0.1000],\n        [0.2000]])\n\n\n- gpu 연산이 가능한 메모리에 데이터 저장\n\n!nvidia-smi # before\n\nMon Apr  7 09:48:42 2025       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.230.02             Driver Version: 535.230.02   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  NVIDIA GeForce RTX 3090        Off | 00000000:09:00.0 Off |                  N/A |\n|  0%   29C    P8              27W / 420W |     26MiB / 24576MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|    0   N/A  N/A      1152      G   /usr/lib/xorg/Xorg                            9MiB |\n|    0   N/A  N/A      1471      G   /usr/bin/gnome-shell                          8MiB |\n+---------------------------------------------------------------------------------------+\n\n\n🔬 ?\n\n!nvidia-smi # before\n\nTue May  6 15:07:19 2025       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.161.08             Driver Version: 535.161.08   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  NVIDIA A100-SXM4-80GB          On  | 00000000:47:00.0 Off |                   On |\n| N/A   67C    P0             197W / 275W |                  N/A |     N/A      Default |\n|                                         |                      |              Enabled |\n+-----------------------------------------+----------------------+----------------------+\n\n+---------------------------------------------------------------------------------------+\n| MIG devices:                                                                          |\n+------------------+--------------------------------+-----------+-----------------------+\n| GPU  GI  CI  MIG |                   Memory-Usage |        Vol|      Shared           |\n|      ID  ID  Dev |                     BAR1-Usage | SM     Unc| CE ENC DEC OFA JPG    |\n|                  |                                |        ECC|                       |\n|==================+================================+===========+=======================|\n|  0    0   0   0  |           49841MiB / 81050MiB  | 98      0 |  7   0    5    1    1 |\n|                  |              15MiB / 131072MiB |           |                       |\n+------------------+--------------------------------+-----------+-----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n+---------------------------------------------------------------------------------------+\n\n\n🗣️(\n\nx_cpu\n\ntensor([[0.0000],\n        [0.1000],\n        [0.2000]])\n\n\n\nx_cpu.to(\"cuda:0\")\n\ntensor([[0.0000],\n        [0.1000],\n        [0.2000]], device='cuda:0')\n\n\n\ndevice=‘cuda:0’\n\n)🗣️\n🗣️ :0 =&gt; GPU ID (여러개인 경우)\n\ntorch.manual_seed(43052)\nx_gpu = x_cpu.to(\"cuda:0\")\ny_gpu = y_cpu.to(\"cuda:0\")\nnet_gpu = torch.nn.Linear(1,1).to(\"cuda:0\") \n\n🗣️ 일반적으로는 메모리에 저장되지만, to(“cuda:0”)를 하면 GPU 메모리에 저장됨\n\n!nvidia-smi\n\nMon Apr  7 09:48:43 2025       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.230.02             Driver Version: 535.230.02   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  NVIDIA GeForce RTX 3090        Off | 00000000:09:00.0 Off |                  N/A |\n|  0%   34C    P2              65W / 420W |    287MiB / 24576MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|    0   N/A  N/A      1152      G   /usr/lib/xorg/Xorg                            9MiB |\n|    0   N/A  N/A      1471      G   /usr/bin/gnome-shell                          8MiB |\n|    0   N/A  N/A    140211      C   ...b3/anaconda3/envs/dl2025/bin/python      256MiB |\n+---------------------------------------------------------------------------------------+\n\n\n🔬 ?\n\n!nvidia-smi\n\nTue May  6 15:11:18 2025       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.161.08             Driver Version: 535.161.08   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  NVIDIA A100-SXM4-80GB          On  | 00000000:47:00.0 Off |                   On |\n| N/A   68C    P0             186W / 275W |                  N/A |     N/A      Default |\n|                                         |                      |              Enabled |\n+-----------------------------------------+----------------------+----------------------+\n\n+---------------------------------------------------------------------------------------+\n| MIG devices:                                                                          |\n+------------------+--------------------------------+-----------+-----------------------+\n| GPU  GI  CI  MIG |                   Memory-Usage |        Vol|      Shared           |\n|      ID  ID  Dev |                     BAR1-Usage | SM     Unc| CE ENC DEC OFA JPG    |\n|                  |                                |        ECC|                       |\n|==================+================================+===========+=======================|\n|  0    0   0   0  |           50298MiB / 81050MiB  | 98      0 |  7   0    5    1    1 |\n|                  |              17MiB / 131072MiB |           |                       |\n+------------------+--------------------------------+-----------+-----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n+---------------------------------------------------------------------------------------+\n\n\n\nGPU에 메모리를 올리면 GPU메모리가 점유된다! (26MiB -&gt; 287MiB)\n\n- cpu 혹은 gpu 연산이 가능한 메모리에 저장된 값들을 확인\n\nx_cpu, y_cpu, net_cpu.weight, net_cpu.bias\n\n(tensor([[0.0000],\n         [0.1000],\n         [0.2000]]),\n tensor([[0.0000],\n         [0.2000],\n         [0.4000]]),\n Parameter containing:\n tensor([[-0.3467]], requires_grad=True),\n Parameter containing:\n tensor([-0.8470], requires_grad=True))\n\n\n\nx_gpu, y_gpu, net_gpu.weight, net_gpu.bias\n\n(tensor([[0.0000],\n         [0.1000],\n         [0.2000]], device='cuda:0'),\n tensor([[0.0000],\n         [0.2000],\n         [0.4000]], device='cuda:0'),\n Parameter containing:\n tensor([[-0.3467]], device='cuda:0', requires_grad=True),\n Parameter containing:\n tensor([-0.8470], device='cuda:0', requires_grad=True))\n\n\n- gpu는 gpu끼리 연산가능하고 cpu는 cpu끼리 연산가능함\n(예시1)\n\nnet_cpu(x_cpu) \n\ntensor([[-0.8470],\n        [-0.8817],\n        [-0.9164]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n(예시2)\n\nnet_gpu(x_gpu) \n\ntensor([[-0.8470],\n        [-0.8817],\n        [-0.9164]], device='cuda:0', grad_fn=&lt;AddmmBackward0&gt;)\n\n\n(예시3)\n\nnet_cpu(x_gpu) \n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[15], line 1\n----&gt; 1 net_cpu(x_gpu) \n\nFile ~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/nn/modules/module.py:1739, in Module._wrapped_call_impl(self, *args, **kwargs)\n   1737     return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n   1738 else:\n-&gt; 1739     return self._call_impl(*args, **kwargs)\n\nFile ~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/nn/modules/module.py:1750, in Module._call_impl(self, *args, **kwargs)\n   1745 # If we don't have any hooks, we want to skip the rest of the logic in\n   1746 # this function, and just call forward.\n   1747 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n   1748         or _global_backward_pre_hooks or _global_backward_hooks\n   1749         or _global_forward_hooks or _global_forward_pre_hooks):\n-&gt; 1750     return forward_call(*args, **kwargs)\n   1752 result = None\n   1753 called_always_called_hooks = set()\n\nFile ~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/nn/modules/linear.py:125, in Linear.forward(self, input)\n    124 def forward(self, input: Tensor) -&gt; Tensor:\n--&gt; 125     return F.linear(input, self.weight, self.bias)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)\n\n\n\n(예시4)\n\nnet_gpu(x_cpu)\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[16], line 1\n----&gt; 1 net_gpu(x_cpu)\n\nFile ~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/nn/modules/module.py:1739, in Module._wrapped_call_impl(self, *args, **kwargs)\n   1737     return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n   1738 else:\n-&gt; 1739     return self._call_impl(*args, **kwargs)\n\nFile ~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/nn/modules/module.py:1750, in Module._call_impl(self, *args, **kwargs)\n   1745 # If we don't have any hooks, we want to skip the rest of the logic in\n   1746 # this function, and just call forward.\n   1747 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n   1748         or _global_backward_pre_hooks or _global_backward_hooks\n   1749         or _global_forward_hooks or _global_forward_pre_hooks):\n-&gt; 1750     return forward_call(*args, **kwargs)\n   1752 result = None\n   1753 called_always_called_hooks = set()\n\nFile ~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/nn/modules/linear.py:125, in Linear.forward(self, input)\n    124 def forward(self, input: Tensor) -&gt; Tensor:\n--&gt; 125     return F.linear(input, self.weight, self.bias)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)\n\n\n\n(예시5)\n\ntorch.mean((y_cpu-net_cpu(x_cpu))**2)\n\ntensor(1.2068, grad_fn=&lt;MeanBackward0&gt;)\n\n\n(예시6)\n\ntorch.mean((y_gpu-net_gpu(x_gpu))**2)\n\ntensor(1.2068, device='cuda:0', grad_fn=&lt;MeanBackward0&gt;)\n\n\n(예시7)\n\ntorch.mean((y_gpu-net_cpu(x_cpu))**2)\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[19], line 1\n----&gt; 1 torch.mean((y_gpu-net_cpu(x_cpu))**2)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n\n\n\n(예시8)\n\ntorch.mean((y_cpu-net_gpu(x_gpu))**2)\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[20], line 1\n----&gt; 1 torch.mean((y_cpu-net_gpu(x_gpu))**2)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
  },
  {
    "objectID": "posts/05wk-2.html#b.-시간측정-예비학습",
    "href": "posts/05wk-2.html#b.-시간측정-예비학습",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "B. 시간측정 (예비학습)",
    "text": "B. 시간측정 (예비학습)\n\nimport time \n\n\ntime.time()\n\n1746512391.3237932\n\n\n🗣️ 뭔지는 모르겠지만 차이는 알 수 있음\n\nt1 = time.time()\n\n\nt2 = time.time()\n\n\nt2-t1\n\n4.3513031005859375"
  },
  {
    "objectID": "posts/05wk-2.html#c.-cpu-vs-gpu-500-nodes",
    "href": "posts/05wk-2.html#c.-cpu-vs-gpu-500-nodes",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "C. CPU vs GPU (500 nodes)",
    "text": "C. CPU vs GPU (500 nodes)\n- CPU (500 nodes)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,500),\n    torch.nn.ReLU(),\n    torch.nn.Linear(500,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.36923766136169434\n\n\n🔬\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,500),\n    torch.nn.ReLU(),\n    torch.nn.Linear(500,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.8697936534881592\n\n\n- GPU (500 nodes)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,500),\n    torch.nn.ReLU(),\n    torch.nn.Linear(500,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.5803208351135254\n\n\n🔬\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,500),\n    torch.nn.ReLU(),\n    torch.nn.Linear(500,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.8882694244384766\n\n\n\nCPU가 더 빠르다??"
  },
  {
    "objectID": "posts/05wk-2.html#d.-cpu-vs-gpu-200000-nodes",
    "href": "posts/05wk-2.html#d.-cpu-vs-gpu-200000-nodes",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "D. CPU vs GPU (200,000 nodes)",
    "text": "D. CPU vs GPU (200,000 nodes)\n- CPU (200,000)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,200000),\n    torch.nn.ReLU(),\n    torch.nn.Linear(200000,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n84.05620455741882\n\n\n🔬\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,200000),\n    torch.nn.ReLU(),\n    torch.nn.Linear(200000,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n83.98482537269592\n\n\n- GPU (204,800)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,200000),\n    torch.nn.ReLU(),\n    torch.nn.Linear(200000,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n1.373826026916504\n\n\n🔬\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,200000),\n    torch.nn.ReLU(),\n    torch.nn.Linear(200000,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n2.6831233501434326\n\n\n\n🗣️\n\n항상 GPU가 빠른 것은 아님 (node가 커지면 GPU가 유리)\nCPU는 코어가 많아야 60여개, GPU는 코어가 만 개 단위\n\n왜 이런 차이가 나는가?\n연산을 하는 주체는 코어인데 CPU는 수는 적지만 일을 잘하는 코어들을 가지고 있고 GPU는 일은 못하지만 다수의 코어를 가지고 있기 때문"
  },
  {
    "objectID": "posts/05wk-2.html#e.-주의점",
    "href": "posts/05wk-2.html#e.-주의점",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "E. 주의점",
    "text": "E. 주의점\n- tensor 일 경우\n\nx = torch.tensor([1,2,3])\nx.to(\"cuda:0\"), x\n\n(tensor([1, 2, 3], device='cuda:0'), tensor([1, 2, 3]))\n\n\n- net일 경우\n\nnet = torch.nn.Linear(1,1).to(\"cuda:0\")\nnet.weight, net.bias\n\n(Parameter containing:\n tensor([[-0.0084]], device='cuda:0', requires_grad=True),\n Parameter containing:\n tensor([-0.6216], device='cuda:0', requires_grad=True))\n\n\n🗣️(\n\nnet은 값 자체가 통째로 cuda로 감\n\n\nnet_cpu = torch.nn.Linear(1,1)\nnet_cpu\n\nLinear(in_features=1, out_features=1, bias=True)\n\n\n\nnet_gpu = net_cpu.to(\"cuda:0\") # 이거를 실행하는 순간 cuda로 가기 때문에\n\n\nnet_cpu.weight # 더 이상 cpu로 부를 수 없음\n\nParameter containing:\ntensor([[0.1766]], device='cuda:0', requires_grad=True)\n\n\n\n비교\n\n\nx_cpu = torch.tensor([1,2,3])\nx_cpu\n\ntensor([1, 2, 3])\n\n\n\nx_gpu = x_cpu.to(\"cuda:0\")\n\n\nx_cpu\n\ntensor([1, 2, 3])\n\n\n\nx_gpu\n\ntensor([1, 2, 3], device='cuda:0')\n\n\n)🗣️"
  },
  {
    "objectID": "posts/05wk-2.html#a.-의문-좀-이상하지-않아요",
    "href": "posts/05wk-2.html#a.-의문-좀-이상하지-않아요",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "A. 의문: 좀 이상하지 않아요?",
    "text": "A. 의문: 좀 이상하지 않아요?\n- 국민상식: GPU 비싸요.. https://bbs.ruliweb.com/community/board/300143/read/61066881\n\nGPU 메모리 많아봐야 24GB, 그래도 비싸요.. http://shop.danawa.com/virtualestimate/?controller=estimateMain&methods=index&marketPlaceSeq=16\nGPU 메모리가 80GB일 경우 가격: https://prod.danawa.com/info/?pcode=21458333\n\n- 우리가 분석하는 데이터\n\nx = torch.linspace(-10,10,100000).reshape(-1,1)\neps = torch.randn(100000).reshape(-1,1)\ny = x*2 + eps \n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,2*x,'--')\n\n\n\n\n\n\n\n\n\nlen(x)\n\n100000\n\n\n- 데이터의 크기가 커지는 순간 x.to(\"cuda:0\"), y.to(\"cuda:0\") 쓰면 난리나겠는걸? \\(\\to\\) 이런식이면 GPU를 이용하여 아무런 분석도 못할것 같은데?? 뭔가 좀 이상한데??\n- 아이디어: 데이터를 100개중에 1개 꼴로만 쓰면 어떨까?\n\nx[::2].shape\n\ntorch.Size([50000, 1])\n\n\n\nx[::100].shape\n\ntorch.Size([1000, 1])\n\n\n\nplt.plot(x[::100],y[::100],'o',alpha=0.05)\nplt.plot(x,2*x,'--')\n\n\n\n\n\n\n\n\n\n대충 이거만 가지고 적합해도 충분히 정확할것 같은데?"
  },
  {
    "objectID": "posts/05wk-2.html#b.-xy-데이터를-굳이-모두-gpu에-넘겨야-하는가",
    "href": "posts/05wk-2.html#b.-xy-데이터를-굳이-모두-gpu에-넘겨야-하는가",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "B. X,y 데이터를 굳이 모두 GPU에 넘겨야 하는가?",
    "text": "B. X,y 데이터를 굳이 모두 GPU에 넘겨야 하는가?\n- 데이터셋을 짝홀로 나누어서 번갈아가면서 GPU에 올렸다 내렸다하면 안되나?\n- 아래의 알고리즘을 생각해보자.\n\n데이터를 반으로 나눈다.\n짝수obs의 x,y 그리고 net의 모든 파라메터를 GPU에 올린다.\nyhat, loss, grad, update 수행\n짝수obs의 x,y를 GPU메모리에서 내린다. 그리고 홀수obs의 x,y를 GPU메모리에 올린다.\nyhat, loss, grad, update 수행\n홀수obs의 x,y를 GPU메모리에서 내린다. 그리고 짝수obs의 x,y를 GPU메모리에 올린다.\n반복\n\n\n이러면 되는거아니야???? —&gt; 맞아요\n\n🗣️ =&gt; 확률적경사하강법"
  },
  {
    "objectID": "posts/05wk-2.html#c.-경사하강법-확률적경사하강법-미니배치-경사하강법",
    "href": "posts/05wk-2.html#c.-경사하강법-확률적경사하강법-미니배치-경사하강법",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "C. 경사하강법, 확률적경사하강법, 미니배치 경사하강법",
    "text": "C. 경사하강법, 확률적경사하강법, 미니배치 경사하강법\n🗣️ 임의의 묶음: 미니배치\n10개의 샘플이 있다고 가정. \\(\\{(x_i,y_i)\\}_{i=1}^{10}\\)\n# ver1 – 모든 샘플을 이용하여 slope 계산\n(epoch 1) \\(loss=\\sum_{i=1}^{10}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2 \\to slope  \\to update\\)\n(epoch 2) \\(loss=\\sum_{i=1}^{10}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2 \\to slope  \\to update\\)\n🗣️ loss가 SSE\n…\n\n우리가 항상 이렇게 했죠!\n\n# ver2 – 하나의 샘플만을 이용하여 slope 계산\n(epoch 1)\n\n\\(loss=(y_1-\\hat{w}_0-\\hat{w}_1x_1)^2 \\to slope \\to update\\)\n\\(loss=(y_2-\\hat{w}_0-\\hat{w}_1x_2)^2 \\to slope \\to update\\)\n…\n\\(loss=(y_{10}-\\hat{w}_0-\\hat{w}_1x_{10})^2  \\to  slope  \\to  update\\)\n\n(epoch 2)\n\n\\(loss=(y_1-\\hat{w}_0-\\hat{w}_1x_1)^2  \\to slope  \\to  update\\)\n\\(loss=(y_2-\\hat{w}_0-\\hat{w}_1x_2)^2  \\to slope  \\to  update\\)\n…\n\\(loss=(y_{10}-\\hat{w}_0-\\hat{w}_1x_{10})^2  \\to  slope  \\to  update\\)\n\n🗣️ epoch 2 후 20번 update\n…\n# ver3 – \\(m (\\leq n)\\) 개의 샘플을 이용하여 slope 계산\n🗣️ 미니배치 사이즈 = 3\n\\(m=3\\)이라고 하자.\n(epoch 1)\n\n\\(loss=\\sum_{i=1}^{3}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=\\sum_{i=4}^{6}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=\\sum_{i=7}^{9}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=(y_{10}-\\hat{w}_0-\\hat{w}_1x_{10})^2  \\to  slope  \\to  update\\)\n\n(epoch 2)\n\n\\(loss=\\sum_{i=1}^{3}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=\\sum_{i=4}^{6}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=\\sum_{i=7}^{9}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=(y_{10}-\\hat{w}_0-\\hat{w}_1x_{10})^2  \\to  slope  \\to  update\\)\n\n🗣️ 10은 단독으로 update\n…"
  },
  {
    "objectID": "posts/05wk-2.html#d.-용어의-정리",
    "href": "posts/05wk-2.html#d.-용어의-정리",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "D. 용어의 정리",
    "text": "D. 용어의 정리\n옛날\n- ver1(모든): gradient descent, batch gradient descent\n- ver2(하나만): stochastic gradient descent\n- ver3(몇개만): mini-batch gradient descent, mini-batch stochastic gradient descent\n🗣️ stochastic: 차례대로 하는 것이 아니라 랜덤으로 계속 뽑는 방식도 있어서 이것에 기원을 둠 / batch: 전체 data\n🗣️ ver3: 위 그림에서 y10의 경우 가중치가 계속 있는 것이 싫어서 랜덤으로 3개씩 뽑을 수도 있음 -&gt; stochastic\n요즘\n- ver1(모든): gradient descent\n- ver2(하나만): stochastic gradient descent with batch size = 1\n- ver3(몇개만): stochastic gradient descent - https://www.deeplearningbook.org/contents/optimization.html, 알고리즘 8-1 참고.\n🗣️ ver3을 제일 많이 씀"
  },
  {
    "objectID": "posts/05wk-2.html#e.-datasetds-dataloaderdl",
    "href": "posts/05wk-2.html#e.-datasetds-dataloaderdl",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "E. Dataset(ds), DataLoader(dl)",
    "text": "E. Dataset(ds), DataLoader(dl)\n\n취지는 알겠으나, C의 과정을 실제 구현하려면 진짜 어려움.. (입코딩과 손코딩의 차이) –&gt; 이걸 해결하기 위해서 파이토치에서는 DataLoader라는 오브젝트를 준비했음!\n\n- 데이터\n\nx=torch.tensor(range(10))\ny=torch.tensor([1.0]*5+[0.0]*5).reshape(-1,1)\n\n\nx, y\n\n(tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n tensor([[1.],\n         [1.],\n         [1.],\n         [1.],\n         [1.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.]]))\n\n\n\nx.shape, y.shape # 몇개씩 있는지가 중요\n\n(torch.Size([10]), torch.Size([10]))\n\n\n\nx=torch.tensor(range(10)).float().reshape(-1,1)\ny=torch.tensor([1.0]*5+[0.0]*5).reshape(-1,1)\ntorch.concat([x,y],axis=1)\n\ntensor([[0., 1.],\n        [1., 1.],\n        [2., 1.],\n        [3., 1.],\n        [4., 1.],\n        [5., 0.],\n        [6., 0.],\n        [7., 0.],\n        [8., 0.],\n        [9., 0.]])\n\n\n- ds오브젝트\n\nds = torch.utils.data.TensorDataset(x,y)\nds\n\n&lt;torch.utils.data.dataset.TensorDataset at 0x7f5c8eed5fa0&gt;\n\n\n🗣️ 뭔가 만들어짐 (ds: dataset)\n\nds.tensors \n# 생긴건 ds.tensors = (x,y) 임\n\n(tensor([[0.],\n         [1.],\n         [2.],\n         [3.],\n         [4.],\n         [5.],\n         [6.],\n         [7.],\n         [8.],\n         [9.]]),\n tensor([[1.],\n         [1.],\n         [1.],\n         [1.],\n         [1.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.]]))\n\n\n\nds[0],(x,y)[0] # (x,y) 튜플자체는 아님.. 인덱싱이 다르게 동작\n\n((tensor([0.]), tensor([1.])),\n tensor([[0.],\n         [1.],\n         [2.],\n         [3.],\n         [4.],\n         [5.],\n         [6.],\n         [7.],\n         [8.],\n         [9.]]))\n\n\n🗣️(\n\n(x,y)[1] # y\n\ntensor([[1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.]])\n\n\n\n(x,y)[2] # error\n\n\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\nCell In[60], line 1\n----&gt; 1 (x,y)[2] # error\n\nIndexError: tuple index out of range\n\n\n\n\nds[:3] # 인덱싱이 편함\n\n(tensor([[0.],\n         [1.],\n         [2.]]),\n tensor([[1.],\n         [1.],\n         [1.]]))\n\n\n)🗣️\n- dl 오브젝트\n\ndl = torch.utils.data.DataLoader(ds, batch_size=3)\n\n🗣️(\n\nbatch_size: 원하는 값으로 입력\n\n\ndl = torch.utils.data.DataLoader(ds, batch_size=5)\n\n\nfor _ in dl:\n    print(_)\n\n[tensor([[0.],\n        [1.],\n        [2.],\n        [3.],\n        [4.]]), tensor([[1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.]])]\n[tensor([[5.],\n        [6.],\n        [7.],\n        [8.],\n        [9.]]), tensor([[0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.]])]\n\n\n\nfor x,y in dl:\n    print(x)\n\ntensor([[0.],\n        [1.],\n        [2.],\n        [3.],\n        [4.]])\ntensor([[5.],\n        [6.],\n        [7.],\n        [8.],\n        [9.]])\n\n\n\ndl = torch.utils.data.DataLoader(ds, batch_size=3)\n\n\nfor x,y in dl:\n    print(x)\n\ntensor([[0.],\n        [1.],\n        [2.]])\ntensor([[3.],\n        [4.],\n        [5.]])\ntensor([[6.],\n        [7.],\n        [8.]])\ntensor([[9.]])\n\n\n)🗣️\n\nfor x_mbatch,y_mbatch in dl:\n    print(f\"x_mini_batch:{x_mbatch.tolist()} \\t y_mini_batch:{y_mbatch.tolist()}\")\n\nx_mini_batch:[[0.0], [1.0], [2.0]]   y_mini_batch:[[1.0], [1.0], [1.0]]\nx_mini_batch:[[3.0], [4.0], [5.0]]   y_mini_batch:[[1.0], [1.0], [0.0]]\nx_mini_batch:[[6.0], [7.0], [8.0]]   y_mini_batch:[[0.0], [0.0], [0.0]]\nx_mini_batch:[[9.0]]     y_mini_batch:[[0.0]]\n\n\n- 마지막관측치는 뭔데 단독으로 업데이트하냐?? –&gt; shuffle True 같이 자잘한 옵션도 있음..\n\ndl = torch.utils.data.DataLoader(ds,batch_size=3,shuffle=True)\nfor x_mbatch,y_mbatch in dl:\n    print(f\"x_mini_batch:{x_mbatch.tolist()} \\t y_mini_batch:{y_mbatch.tolist()}\")\n\nx_mini_batch:[[1.0], [5.0], [6.0]]   y_mini_batch:[[1.0], [0.0], [0.0]]\nx_mini_batch:[[7.0], [0.0], [9.0]]   y_mini_batch:[[0.0], [1.0], [0.0]]\nx_mini_batch:[[2.0], [8.0], [3.0]]   y_mini_batch:[[1.0], [0.0], [1.0]]\nx_mini_batch:[[4.0]]     y_mini_batch:[[1.0]]\n\n\n🗣️ 돌릴 때마다 달라짐"
  },
  {
    "objectID": "posts/05wk-2.html#f.-성능체크",
    "href": "posts/05wk-2.html#f.-성능체크",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "F. 성능체크",
    "text": "F. 성능체크\n- 목표: 확률적경사하강법과 그냥 경사하강법의 성능을 “동일 반복횟수”로 비교해보자.\n🗣️(\n10 4 -&gt; 10, 10, 10, 10\n10 4 -&gt; 3, 3, 3, 1\n\n위가 좋을 것 같지만 별 차이 없음\nbatch size를 잘 정하면 밑이 오히려 좋을 수도 있음\n\n)🗣️\n- MNIST자료를 그냥 경사하강법으로 적합해보자.\n\nimport torchvision\n\n\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\nto_tensor = torchvision.transforms.ToTensor()\nX0 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==0])\nX1 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==1])\nX = torch.concat([X0,X1],axis=0).reshape(-1,784)\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\n\n\nX.shape, y.shape\n\n(torch.Size([12665, 784]), torch.Size([12665, 1]))\n\n\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters())\n\n\nfor epoc in range(700):\n    # step1 \n    yhat = net(X)\n    # step2 \n    loss = loss_fn(yhat,y)\n    # step3     \n    loss.backward()\n    # step4 \n    optimizr.step()\n    optimizr.zero_grad()    \n\n\n((yhat &gt; 0.5) ==  y).float().mean()\n\ntensor(0.9953)\n\n\n- MNIST자료를 확률적 경사하강법으로 적합해보자. – 미니배치 쓰는 학습\n\n# train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n# to_tensor = torchvision.transforms.ToTensor()\n# X0 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==0])\n# X1 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==1])\n# X = torch.concat([X0,X1],axis=0).reshape(-1,784)\n# y = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\nds = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=2048)\n\n\nlen(X)/2048\n\n6.18408203125\n\n\n🗣️ 마지막 덩어리는 작음\n\n따라서 (mini) batchsize 가 2048 이라면 한 epoch당 7회 update\n\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters())\n\n\nfor epoc in range(100): \n    for xm,ym in dl:        \n        # step1 \n        ym_hat = net(xm)\n        # step2 \n        loss = loss_fn(ym_hat,ym)\n        # step3     \n        loss.backward()\n        # step4 \n        optimizr.step()\n        optimizr.zero_grad()\n\n\n🗣️\n\n총 update 반복 수는 동일 (7번 * 100번)\nxm = (2048,784), ym = (2048,1)\n\n\n\n((net(X) &gt; 0.5) ==  y).float().mean()\n\ntensor(0.9931)"
  }
]