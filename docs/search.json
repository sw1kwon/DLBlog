[
  {
    "objectID": "posts/01wk-1.html",
    "href": "posts/01wk-1.html",
    "title": "01wk-1: (í† ì¹˜) â€“ ê°•ì˜ì†Œê°œ, íŒŒì´í† ì¹˜ ê¸°ë³¸",
    "section": "",
    "text": "ğŸ“˜ Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\nğŸ“ ğŸ—£ï¸ âœï¸ ğŸ”¬ â“"
  },
  {
    "objectID": "posts/01wk-1.html#a.-torch",
    "href": "posts/01wk-1.html#a.-torch",
    "title": "01wk-1: (í† ì¹˜) â€“ ê°•ì˜ì†Œê°œ, íŒŒì´í† ì¹˜ ê¸°ë³¸",
    "section": "A. torch",
    "text": "A. torch\nğŸ—£ï¸ torchëŠ” numpyì™€ ë¹„ìŠ· (ë²¡í„° ë§Œë“¤ê¸° ë“±)\n- ë²¡í„°\n\ntorch.tensor([1,2,3])\n\ntensor([1, 2, 3])\n\n\n- ë²¡í„°ì˜ ë§ì…ˆ\n\ntorch.tensor([1,2,3]) + torch.tensor([2,2,2])\n\ntensor([3, 4, 5])\n\n\n- ë¸Œë¡œë“œìºìŠ¤íŒ…\n\ntorch.tensor([1,2,3]) + 2\n\ntensor([3, 4, 5])"
  },
  {
    "objectID": "posts/01wk-1.html#b.-ë²¡í„°ì™€-ë§¤íŠ¸ë¦­ìŠ¤",
    "href": "posts/01wk-1.html#b.-ë²¡í„°ì™€-ë§¤íŠ¸ë¦­ìŠ¤",
    "title": "01wk-1: (í† ì¹˜) â€“ ê°•ì˜ì†Œê°œ, íŒŒì´í† ì¹˜ ê¸°ë³¸",
    "section": "B. ë²¡í„°ì™€ ë§¤íŠ¸ë¦­ìŠ¤",
    "text": "B. ë²¡í„°ì™€ ë§¤íŠ¸ë¦­ìŠ¤\nğŸ—£ï¸ torch.tensorëŠ” np.arrayì™€ ë¹„ìŠ·\n- \\(3 \\times 2\\) matrix\n\ntorch.tensor([[1,2],[3,4],[5,6]]) \n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n- \\(3 \\times 1\\) matrix = \\(3 \\times 1\\) column vector\n\ntorch.tensor([[1],[3],[5]]) \n\ntensor([[1],\n        [3],\n        [5]])\n\n\n- \\(1 \\times 2\\) matrix = \\(1 \\times 2\\) row vector\n\ntorch.tensor([[1,2]]) \n\ntensor([[1, 2]])\n\n\nğŸ—£ï¸ torch.tensor([[1,2],[3,4],[5,6]])ì—ì„œ [3,4],[5,6] ì‚­ì œë¼ê³  ìƒê°\nğŸ—£ï¸ column vectorì™€ row vectorëŠ” êµ¬ë¶„ë˜ê³  ì„ ì–¸ ë°©ë²•ì´ ë‹¤ë¦„\n- ë”í•˜ê¸°\në¸Œë¡œë“œìºìŠ¤íŒ…(í¸í•œê±°)\n\ntorch.tensor([[1,2],[3,4],[5,6]]) - 1\n\ntensor([[0, 1],\n        [2, 3],\n        [4, 5]])\n\n\nğŸ—£ï¸ â€œmatrix - scalarâ€ëŠ” ë¶ˆê°€ëŠ¥í•˜ì§€ë§Œ ì•Œì•„ì„œ ì›ì†Œë³„ë¡œ ì „ë¶€ ëºŒ\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1],[-3],[-5]])\n\ntensor([[0, 1],\n        [0, 1],\n        [0, 1]])\n\n\nğŸ—£ï¸ (3, 2) - (3, 1)ì„ ì•Œì•„ì„œ ëºŒ\nâœï¸ torch.tensor([[-1,-1],[-3, 3],[-5,-5]])\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1,-2]])\n\ntensor([[0, 0],\n        [2, 2],\n        [4, 4]])\n\n\nğŸ—£ï¸ (3, 2) - (1, 2)ì„ ì•Œì•„ì„œ ëºŒ\nâœï¸ torch.tensor([[-1,-2],[-1,-2],[-1,-2]])\nì˜ëª»ëœ ë¸Œë¡œë“œìºìŠ¤íŒ…\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1,-3,-5]])\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[11], line 1\n----&gt; 1 torch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1,-3,-5]])\n\nRuntimeError: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1\n\n\n\nğŸ—£ï¸ ì„¸ë¡œë¡œ ì“°ê±°ë‚˜ ê°€ë¡œë¡œ ë‘ ê°œì˜ ì›ì†Œë§Œ ì¼ìœ¼ë©´ ê°€ëŠ¥\nâœï¸ torch.tensor([[-1],[-3],[-5]]) ë˜ëŠ” torch.tensor([[-1,-3],[-1,-3],[-1,-3]]) ë“±\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1],[-2]])\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[12], line 1\n----&gt; 1 torch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1],[-2]])\n\nRuntimeError: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 0\n\n\n\nğŸ—£ï¸ (3, 2) - (2, 1) ëŠ” ì•Œì•„ì„œ ì±„ìš°ê¸° ì–´ë ¤ìš°ë¯€ë¡œ ì—ëŸ¬\nì´ìƒí•œ ê²ƒ\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([-1,-2])\n\ntensor([[0, 0],\n        [2, 2],\n        [4, 4]])\n\n\nğŸ—£ï¸ (3, 2) matrix - ê¸¸ì´ê°€ 2ì¸ vector(2x1, 1x2 ë‘˜ ë‹¤ ì•„ë‹˜)\nğŸ—£ï¸ matrix - vectorë¥¼ row vectorë¡œ í•´ì„í•˜ê³  ëŠ˜ë ¤ì„œ ê³„ì‚°í•œ ë“¯\nâœï¸ torch.tensor([[-1,-2],[-1,-2],[-1,-2]])\nğŸ”¬(\n\nì°¨ì› ìˆ˜ë§Œ ì•Œê³  ì‹¶ì„ ë•Œ â†’ tensor.dim() ë˜ëŠ” tensor.ndim\nê° ì°¨ì›ì˜ í¬ê¸°ê¹Œì§€ ì•Œê³  ì‹¶ì„ ë•Œ â†’ tensor.shape ë˜ëŠ” tensor.size()\n\n\nprint(torch.tensor([[1,2],[3,4],[5,6]]).dim())\nprint(torch.tensor([[1,2],[3,4],[5,6]]).shape)\nprint(torch.tensor([-1,-2]).dim())\nprint(torch.tensor([-1,-2]).shape)\nprint(torch.tensor([[1,2],[3,4],[5,6]]).ndim)\nprint(torch.tensor([[1,2],[3,4],[5,6]]).size())\nprint(torch.tensor([-1,-2]).ndim)\nprint(torch.tensor([-1,-2]).size())\n\n2\ntorch.Size([3, 2])\n1\ntorch.Size([2])\n2\ntorch.Size([3, 2])\n1\ntorch.Size([2])\n\n\n\nì°¸ê³  (Chat GPT4o)\n\n\nNumPyì™€ PyTorch ì°¨ì´ ì •ë¦¬\n\n\n\n\nê¸°ëŠ¥\nPyTorch\nNumPy\n\n\n\n\nì°¨ì› ìˆ˜\n.dim() ë˜ëŠ” .ndim\n.ndim\n\n\nshape í™•ì¸\n.shape ë˜ëŠ” .size()\n.shape\n\n\ní¬ê¸° ë³€ê²½\n.view(), .reshape()\n.reshape()\n\n\níƒ€ì…\ntorch.Tensor\nnp.ndarray\n\n\n\n\nì‹¤ì „ íŒ:\n\nPyTorchì˜ .dim()ë§Œ NumPyì—ì„œ ì•ˆ ë¨¹íŒë‹¤ëŠ” ê²ƒë§Œ ê¸°ì–µí•˜ë©´ ë‘˜ ë‹¤ ê±°ì˜ ë¹„ìŠ·í•˜ê²Œ ë‹¤ë£° ìˆ˜ ìˆìŒ\në‹¤ì°¨ì› ë°°ì—´ì„ ë‹¤ë£° ë•Œ .ndim, .shapeëŠ” ì–‘ìª½ ëª¨ë‘ ì•ˆì „í•˜ê²Œ ì“¸ ìˆ˜ ìˆëŠ” í•µì‹¬ ë„êµ¬\ndim()ì€ PyTorch ê³ ìœ  ë©”ì„œë“œ\n\n\n)ğŸ”¬\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([-1,-3,-5])\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[15], line 1\n----&gt; 1 torch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([-1,-3,-5])\n\nRuntimeError: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1\n\n\n\nğŸ—£ï¸ ê¸¸ì´ê°€ 3ì¸ vectorë¥¼ column vectorë¡œ í•´ì„í•˜ê³  (3,2)ë¡œ ì±„ì›Œì„œ ê³„ì‚°í•  ê²ƒ ê°™ì§€ë§Œ X (ì´ë²ˆì— ë°œê²¬)\n- í–‰ë ¬ê³±\nì •ìƒì ì¸ í–‰ë ¬ê³±\n\ntorch.tensor([[1,2],[3,4],[5,6]]) @ torch.tensor([[1],[2]])\n\ntensor([[ 5],\n        [11],\n        [17]])\n\n\nğŸ—£ï¸ (3,2) matirx @ (2,1) vector = (3,1) matrix\n\ntorch.tensor([[1,2,3]]) @ torch.tensor([[1,2],[3,4],[5,6]]) \n\ntensor([[22, 28]])\n\n\nğŸ—£ï¸ (1,3) @ (3,2) = (1,2)\nì˜ëª»ëœ í–‰ë ¬ê³±\n\ntorch.tensor([[1,2],[3,4],[5,6]]) @ torch.tensor([[1,2]])\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[18], line 1\n----&gt; 1 torch.tensor([[1,2],[3,4],[5,6]]) @ torch.tensor([[1,2]])\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (3x2 and 1x2)\n\n\n\nğŸ—£ï¸ (3,2) @ (1,2) ë¶ˆê°€\n\ntorch.tensor([[1],[2],[3]]) @ torch.tensor([[1,2],[3,4],[5,6]]) \n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[19], line 1\n----&gt; 1 torch.tensor([[1],[2],[3]]) @ torch.tensor([[1,2],[3,4],[5,6]]) \n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (3x1 and 3x2)\n\n\n\nğŸ—£ï¸ (3,1) @ (3,2) ë¶ˆê°€\nì´ìƒí•œ ê²ƒ\n\ntorch.tensor([[1,2],[3,4],[5,6]]) @ torch.tensor([1,2]) # ì´ê²Œ ì™œ ê°€ëŠ¥..\n\ntensor([ 5, 11, 17])\n\n\nğŸ—£ï¸ (3,2) @ (2) ê¸¸ì´ê°€ 2ì¸ vector / ì‚¬ëŒë§ˆë‹¤ í•´ì„ ì• ë§¤ (2,1)? (1,2)? / ê³±í•˜ê¸°ë¥¼ ìœ„í•´ (2,1) column vectorë¡œ í•´ì„\nğŸ—£ï¸ (3,2) @ (2,1)ë¡œ í•´ì„ í›„ ê³„ì‚°í•˜ì—¬ (3) ê¸¸ì´ê°€ 3ì¸ vectorê°€ ë‚˜ì˜´\n\ntorch.tensor([1,2,3]) @ torch.tensor([[1,2],[3,4],[5,6]]) # ì´ê±´ ì™œ ê°€ëŠ¥?\n\ntensor([22, 28])\n\n\nğŸ—£ï¸ (3) @ (3,2)ì—ì„œ (3)ì„ (1,3) row vectorë¡œ í•´ì„\nğŸ—£ï¸( ì—„ë°€í•˜ê²Œ í•˜ë ¤ë©´\n\ntorch.tensor([[1,2,3]]) @ torch.tensor([[1,2],[3,4],[5,6]])\n\ntensor([[22, 28]])\n\n\nâœï¸ ë‹¹ì—°íˆ ê²°ê³¼ì˜ ì°¨ì›ë„ ë‹¤ë¦„\n)ğŸ—£ï¸"
  },
  {
    "objectID": "posts/01wk-1.html#c.-transpose-reshape",
    "href": "posts/01wk-1.html#c.-transpose-reshape",
    "title": "01wk-1: (í† ì¹˜) â€“ ê°•ì˜ì†Œê°œ, íŒŒì´í† ì¹˜ ê¸°ë³¸",
    "section": "C. transpose, reshape",
    "text": "C. transpose, reshape\n- transpose\n\ntorch.tensor([[1,2],[3,4]]).T \n\ntensor([[1, 3],\n        [2, 4]])\n\n\n\ntorch.tensor([[1],[3]]).T \n\ntensor([[1, 3]])\n\n\nğŸ—£ï¸ column vector -&gt; row vector\n\ntorch.tensor([[1,2]]).T \n\ntensor([[1],\n        [2]])\n\n\nğŸ—£ï¸ row vector -&gt; column vector\nğŸ—£ï¸ ì°¨ì›ì„ ë°”ê¾¸ëŠ” íš¨ê³¼ (1,2) -&gt; (2,1)\n- reshape\nğŸ—£ï¸( ì°¨ì› ë³´ê¸°\n\ntorch.tensor([[1,2]]).shape\n\ntorch.Size([1, 2])\n\n\nì„ column vectorë¡œ ë°”ê¾¸ê³  ì‹¶ìœ¼ë©´\n\ntorch.tensor([[1,2]]).reshape(2,1)\n\ntensor([[1],\n        [2]])\n\n\ntransposeì™€ ë™ì¼\n)ğŸ—£ï¸\nì¼ë°˜ì ì¸ ì‚¬ìš©\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(2,3)\n\ntensor([[1, 2, 3],\n        [4, 5, 6]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]])\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(1,6)\n\ntensor([[1, 2, 3, 4, 5, 6]])\n\n\nğŸ—£ï¸ (3,2) -&gt; (1,6)\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(6)\n\ntensor([1, 2, 3, 4, 5, 6])\n\n\nğŸ—£ï¸ (3,2)ë¥¼ ê·¸ëƒ¥ 6ìœ¼ë¡œ : ê¸¸ì´ê°€ 6ì¸ vectorë¡œ ë°”ê¿ˆ\ní¸í•œ ê²ƒ\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(2,-1)\n\ntensor([[1, 2, 3],\n        [4, 5, 6]])\n\n\nğŸ—£ï¸ torch.tensor([[1,2],[3,4],[5,6]]).reshape(2,??)ë¥¼ ì›í•  ë•Œ ??ë¥¼ ì•Œì•„ì„œ ë§ì¶¤ (ë¶ˆê°€ëŠ¥í•˜ë©´ error)\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(6,-1)\n\ntensor([[1],\n        [2],\n        [3],\n        [4],\n        [5],\n        [6]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(-1,6)\n\ntensor([[1, 2, 3, 4, 5, 6]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(-1)\n\ntensor([1, 2, 3, 4, 5, 6])\n\n\nğŸ—£ï¸ ì „ì²´ë¥¼ vectorë¡œ ë°”ê¾¸ê³  ì‹¶ì„ ë•Œ (1ì°¨ì›)"
  },
  {
    "objectID": "posts/01wk-1.html#d.-concat-stack-starstarstar",
    "href": "posts/01wk-1.html#d.-concat-stack-starstarstar",
    "title": "01wk-1: (í† ì¹˜) â€“ ê°•ì˜ì†Œê°œ, íŒŒì´í† ì¹˜ ê¸°ë³¸",
    "section": "D. concat, stack \\((\\star\\star\\star)\\)",
    "text": "D. concat, stack \\((\\star\\star\\star)\\)\n- concat\n\na = torch.tensor([[1],[3],[5]])\nb = torch.tensor([[2],[4],[6]])\ntorch.concat([a,b],axis=1)\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\nğŸ—£ï¸(\n\na\n\ntensor([[1],\n        [3],\n        [5]])\n\n\n\nb\n\ntensor([[2],\n        [4],\n        [6]])\n\n\naì™€ bë¥¼ ëª¨ë‘ vectorë¡œ ê°–ê³  ìˆëŠ”ë° [a b]ì²˜ëŸ¼ ë†“ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©\n\na, b\n\n(tensor([[1],\n         [3],\n         [5]]),\n tensor([[2],\n         [4],\n         [6]]))\n\n\n\ntorch.concat([a,b]) # ì´ë ‡ê²Œ í•˜ë©´ ì¢Œìš°ê°€ ì•„ë‹ˆë¼ ìœ„ ì•„ë˜ë¡œ í•©ì³ì§\n\ntensor([[1],\n        [3],\n        [5],\n        [2],\n        [4],\n        [6]])\n\n\n(3,1)ê³¼ (3,1)ì„ (3,2)ë¡œ ë§Œë“¤ê³  ì‹¶ì—ˆëŠ”ë° (6,1)ì´ ë¨ -&gt; axis=1 ì˜µì…˜ ì‚¬ìš©í•˜ë©´ (3,2) ê°€ëŠ¥ (ëª¨ë¥´ê² ìœ¼ë©´ ë°‘ì˜ ë§í¬ ì°¸ì¡°)\n)ğŸ—£ï¸\n\ntorch.concat([a,b],axis=1)\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n- stack\n\na = torch.tensor([1,3,5])\nb = torch.tensor([2,4,6])\ntorch.stack([a,b],axis=1)\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\nğŸ—£ï¸(\n\na\n\ntensor([1, 3, 5])\n\n\n\nb\n\ntensor([2, 4, 6])\n\n\n\na.reshape(3,1) # ì°¸ê³ ) concat ì„¤ëª… ì˜ˆì‹œì™€ ë™ì¼\n\ntensor([[1],\n        [3],\n        [5]])\n\n\n\ntorch.concat([a.reshape(3,1), b.reshape(3,1)], axis=1) # ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“  í›„ ì´ë ‡ê²Œ í•˜ë©´ ë˜ê¸´í•˜ë‚˜ ë„ˆë¬´ í˜ë“¦\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n\ntorch.stack([a,b], axis=1) # ê°™ì€ ê²°ê³¼\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\nì°¨ì´: concatì€ ë°”ê¾¸ë ¤ëŠ” ëŒ€ìƒì˜ dimensionì„ ë°”ê¾¸ì§€ëŠ” X (matrixëŠ” matrixë¡œ, vectorëŠ” vectorë¡œ) / stackì€ dimensionì„ í•˜ë‚˜ ëŠ˜ë ¤ì„œ ë°”ê¿”ì¤Œ\nconcatê³¼ stack ë‘˜ ë‹¤ ì•Œë©´ ì¢‹ìŒ\n)ğŸ—£ï¸\n\ntorch.concat([a.reshape(3,1),b.reshape(3,1)],axis=1)\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n\n\n\n\n\n\nWarning\n\n\n\nconcatê³¼ stackì„ ì§€ê¸ˆ ì²˜ìŒë³¸ë‹¤ë©´ ì•„ë˜ë¥¼ ë³µìŠµí•˜ì‹œëŠ”ê²Œ ì¢‹ìŠµë‹ˆë‹¤.\nhttps://guebin.github.io/PP2024/posts/06wk-2.html#numpyì™€-ì¶•axis"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Deep Learning",
    "section": "",
    "text": "Based on: https://guebin.github.io/DL2025/\n\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nMar 5, 2025\n\n\n01wk-1: (í† ì¹˜) â€“ ê°•ì˜ì†Œê°œ, íŒŒì´í† ì¹˜ ê¸°ë³¸\n\n\nsw1kwon \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  }
]