[
  {
    "objectID": "posts/exercise1.html",
    "href": "posts/exercise1.html",
    "title": "A1: Exercise â€“ ver. 0420-2 (1)",
    "section": "",
    "text": "ë¬¸ì œí’€ì´ì— í•„ìš”í•œ ëª¨ë“ˆì€ ìŠ¤ìŠ¤ë¡œ import í•  ê²ƒ\nimport torch"
  },
  {
    "objectID": "posts/exercise1.html#ë²¡í„°ì™€-í–‰ë ¬",
    "href": "posts/exercise1.html#ë²¡í„°ì™€-í–‰ë ¬",
    "title": "A1: Exercise â€“ ver. 0420-2 (1)",
    "section": "$. ë²¡í„°ì™€ í–‰ë ¬",
    "text": "$. ë²¡í„°ì™€ í–‰ë ¬\n(1) ì•„ë˜ì™€ ê°™ì´ length 5 ì¸ vectorë¥¼ torch.tensorë¡œ ì„ ì–¸í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•˜ë¼.\n\\[{\\bf x} = [1,2,3,4,5]\\]\n(í’€ì´)\n\nx = torch.tensor([1,2,3,4,5])\nx\n\ntensor([1, 2, 3, 4, 5])\n\n\n(2) ì•„ë˜ì™€ ê°™ì€ 2x2 matrix ë¥¼ torch.tensorë¡œ ì„ ì–¸í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•˜ë¼.\n\\[{\\bf A} = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix}\\]\n(í’€ì´?)\n\nA = torch.tensor([[1,2],[3,4]])\nA\n\ntensor([[1, 2],\n        [3, 4]])\n\n\n(3) ì•„ë˜ì™€ ê°™ì€ matrix ë¥¼ torch.tensorë¡œ ì„ ì–¸í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•˜ë¼.\n\\[{\\bf W} = \\begin{bmatrix} 2.5  \\\\  4 \\end{bmatrix}\\]\n(í’€ì´?)\n\nW = torch.tensor([[2.5],[4]])\nW\n\ntensor([[2.5000],\n        [4.0000]])\n\n\n(4) ì•„ë˜ì™€ ê°™ì€ matrix ë¥¼ torch.tensorë¡œ ì„ ì–¸í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•˜ë¼.\n\\[{\\bf x} = \\begin{bmatrix} 2.5  & 4 \\end{bmatrix}\\]\n(í’€ì´?)\n\nx = torch.tensor([[2.5, 4]])\nx\n\ntensor([[2.5000, 4.0000]])"
  },
  {
    "objectID": "posts/exercise1.html#concat-stack",
    "href": "posts/exercise1.html#concat-stack",
    "title": "A1: Exercise â€“ ver. 0420-2 (1)",
    "section": "$. concat, stack",
    "text": "$. concat, stack\na,bê°€ ì•„ë˜ì™€ ê°™ì´ ì£¼ì–´ì¡Œë‹¤ê³  í•˜ì.\n\na = torch.tensor([1]*10)\nb = torch.tensor([2]*10)\n\n(ê´€ì°°?)\n\na\n\ntensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n\n\n\na.shape\n\ntorch.Size([10])\n\n\n\nb\n\ntensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n\n\n(ì‹¤í—˜?)\n\ntorch.tensor([[1]*10])\n\ntensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n\n\n\ntorch.tensor([[1]*10]).shape\n\ntorch.Size([1, 10])\n\n\nì•„ë˜ë¥¼ ì˜ ì½ê³  ë¬¼ìŒì— ë‹µí•˜ë¼.\n(1) ì£¼ì–´ì§„ a,bì™€ torch.concatë¥¼ ì´ìš©í•˜ì—¬ ì•„ë˜ì™€ ê°™ì€ ë°°ì—´ì„ ë§Œë“¤ì–´ë¼.\ntensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n(í’€ì´?)\n\ntorch.concat([a,b])\n\ntensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n\n\n(2) ì£¼ì–´ì§„ a,b ì™€ torch.concat,.reshapeë¥¼ ì´ìš©í•˜ì—¬ ì•„ë˜ì™€ ê°™ì€ ë°°ì—´ì„ ë§Œë“¤ì–´ë¼.\ntensor([[1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2]])\n(í’€ì´)\n\ntorch.concat([a.reshape(-1,1), b.reshape(-1,1)])\n\ntensor([[1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2]])\n\n\n(ê´€ì°°?)\n\na.reshape(-1,1)\n\ntensor([[1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1]])\n\n\n\na\n\ntensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n\n\n(3) ì£¼ì–´ì§„ a,b ì™€ torch.concat,.reshapeë¥¼ ì´ìš©í•˜ì—¬ ì•„ë˜ì™€ ê°™ì€ ë°°ì—´ì„ ë§Œë“¤ì–´ë¼.\ntensor([[1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2]])\n(í’€ì´?)\n\ntorch.concat([a,b])\n\ntensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n\n\n\ntorch.concat([a,b]).reshape(-1,2)\n\ntensor([[1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [2, 2],\n        [2, 2],\n        [2, 2],\n        [2, 2],\n        [2, 2]])\n\n\n\ntorch.concat([a.reshape(-1,1),b.reshape(-1,1)], axis=1)\n\ntensor([[1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2]])\n\n\n(4) ì£¼ì–´ì§„ a,bì™€ torch.stack ì„ ì´ìš©í•˜ì—¬ ì•„ë˜ì™€ ê°™ì€ ë°°ì—´ì„ ë§Œë“¤ì–´ë¼.\ntensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]\n(í’€ì´?)\n\ntorch.stack([a,b])\n\ntensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2]])\n\n\n(ê´€ì°°?)\n\ntorch.stack([a,b], axis=1)\n\ntensor([[1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2]])\n\n\n(5) ì£¼ì–´ì§„ a,bì™€ torch.stackì„ ì´ìš©í•˜ì—¬ ì•„ë˜ì™€ ê°™ì€ ë°°ì—´ì„ ë§Œë“¤ì–´ë¼.\ntensor([[1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2]])\n(í’€ì´?)\n\ntorch.stack([a,b], axis=1)\n\ntensor([[1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2]])"
  },
  {
    "objectID": "posts/exercise1.html#í–‰ë ¬ê³±",
    "href": "posts/exercise1.html#í–‰ë ¬ê³±",
    "title": "A1: Exercise â€“ ver. 0420-2 (1)",
    "section": "$. í–‰ë ¬ê³±",
    "text": "$. í–‰ë ¬ê³±\n(1) ì•„ë˜ì™€ ê°™ì€ í…ì„œë¥¼ ê³ ë ¤í•˜ì.\n\na = torch.tensor([1,2,3,4,5]).reshape(-1,1)\nb = torch.tensor([3,2,1,1,2]).reshape(-1,1)\n\n@ ì—°ì‚°ìë¥¼ ì´ìš©í•˜ì—¬ \\(\\sum_{i=1}^{5}a_ib_i\\)ë¥¼ ê³„ì‚°í•˜ë¼.\n(í’€ì´)\n\na.T @ b\n\ntensor([[24]])\n\n\n(2) ì•„ë˜ì™€ ê°™ì€ í…ì„œë¥¼ ê³ ë ¤í•˜ì.\n\ntorch.manual_seed(0)\nx = torch.randn(100).reshape(-1,1)\n\n@ì—°ì‚°ìë¥¼ ì´ìš©í•˜ì—¬ \\(\\sum_{i=1}^{100}x_i^2\\)ì„ ê³„ì‚°í•˜ë¼.\n(í’€ì´?)\n\nx.T @ x\n\ntensor([[105.0856]])"
  },
  {
    "objectID": "posts/exercise1.html#ì¸ë±ì‹±",
    "href": "posts/exercise1.html#ì¸ë±ì‹±",
    "title": "A1: Exercise â€“ ver. 0420-2 (1)",
    "section": "$. ì¸ë±ì‹±",
    "text": "$. ì¸ë±ì‹±\nì•„ë˜ì™€ ê°™ì€ ë°°ì—´ì„ ì„ ì–¸í•˜ë¼.\n\ntorch.manual_seed(1)\nx = torch.randn(12).reshape(3,4)\nx\n\ntensor([[ 0.6614,  0.2669,  0.0617,  0.6213],\n        [-0.4519, -0.1661, -1.5228,  0.3817],\n        [-1.0276, -0.5631, -0.8923, -0.0583]])\n\n\n(1) 1ì—´ì„ ì¶”ì¶œí•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•˜ë¼. ì¦‰ ê²°ê³¼ê°€ ì•„ë˜ì™€ ê°™ì´ ë‚˜ì˜¤ë„ë¡ í•˜ë¼.\ntensor([[ 0.6614],\n        [-0.4519],\n        [-1.0276]])\n(í’€ì´?)\n\nx[:,0]\n\ntensor([ 0.6614, -0.4519, -1.0276])\n\n\n\nx[:,0].reshape(-1,1)\n\ntensor([[ 0.6614],\n        [-0.4519],\n        [-1.0276]])\n\n\n\nx[:,0].unsqueeze(1)\n\ntensor([[ 0.6614],\n        [-0.4519],\n        [-1.0276]])\n\n\n(2) 2-3ì—´ì„ ì¶”ì¶œí•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•˜ë¼. ì¦‰ ê²°ê³¼ê°€ ì•„ë˜ì™€ ê°™ì´ ë‚˜ì˜¤ë„ë¡ í•˜ë¼.\ntensor([[ 0.2669,  0.0617],\n        [-0.1661, -1.5228],\n        [-0.5631, -0.8923]])\n(í’€ì´?)\n\nx[:,1:3]\n\ntensor([[ 0.2669,  0.0617],\n        [-0.1661, -1.5228],\n        [-0.5631, -0.8923]])\n\n\n\nx[:,[1,2]]\n\ntensor([[ 0.2669,  0.0617],\n        [-0.1661, -1.5228],\n        [-0.5631, -0.8923]])\n\n\n(3) 2-3í–‰ì„ ì¶”ì¶œí•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•˜ë¼. ì¦‰ ê²°ê³¼ê°€ ì•„ë˜ì™€ ê°™ì´ ë‚˜ì˜¤ë„ë¡ í•˜ë¼.\ntensor([[-0.4519, -0.1661, -1.5228,  0.3817],\n        [-1.0276, -0.5631, -0.8923, -0.0583]])\n\n(í’€ì´?)\n\nx[1:,:]\n\ntensor([[-0.4519, -0.1661, -1.5228,  0.3817],\n        [-1.0276, -0.5631, -0.8923, -0.0583]])\n\n\n\nx[1:3,:]\n\ntensor([[-0.4519, -0.1661, -1.5228,  0.3817],\n        [-1.0276, -0.5631, -0.8923, -0.0583]])\n\n\n\nx[[1,2],:]\n\ntensor([[-0.4519, -0.1661, -1.5228,  0.3817],\n        [-1.0276, -0.5631, -0.8923, -0.0583]])\n\n\n(ê´€ì°°?)\n\nx[1:2,:]\n\ntensor([[-0.4519, -0.1661, -1.5228,  0.3817]])"
  },
  {
    "objectID": "posts/exercise1.html#q1",
    "href": "posts/exercise1.html#q1",
    "title": "A1: Exercise â€“ ver. 0420-2 (1)",
    "section": "Q1",
    "text": "Q1\n\nunsqueezeë¥¼ ì“°ì§€ ì•Šê³  ì—´ ë²¡í„°ë¥¼ ë½‘ì•˜ì„ ë•Œ .shape ì°¨ì´ì ì€?\n\n\nì˜ˆì œ ë¹„êµ\nx[:, 0]           # unsqueeze ì—†ì´\nx[:, 0].unsqueeze(1)  # unsqueeze ì‚¬ìš©\n\n1. x[:, 0]\n\nê²°ê³¼ í…ì„œ shape: torch.Size([3])\nì„¤ëª…: 1ì—´ì˜ ê°’ì„ 1ì°¨ì› ë²¡í„°ë¡œ ë°˜í™˜í•œë‹¤. ì˜ˆ: [0.6614, -0.4519, -1.0276]\n\n\n\n2. x[:, 0].unsqueeze(1)\n\nê²°ê³¼ í…ì„œ shape: torch.Size([3, 1])\nì„¤ëª…: ì—´ ë°©í–¥ìœ¼ë¡œ 2ì°¨ì› í…ì„œë¡œ ë§Œë“ ë‹¤. ì˜ˆ: [[0.6614], [-0.4519], [-1.0276]]\n\n\n\n\nì°¨ì´ì  ìš”ì•½\n\n\n\n\n\n\n\n\ní•­ëª©\nx[:, 0]\nx[:, 0].unsqueeze(1)\n\n\n\n\nshape\n[3]\n[3, 1]\n\n\nì°¨ì› ìˆ˜\n1ì°¨ì› (ë²¡í„°)\n2ì°¨ì› (í–‰ë ¬)\n\n\në¸Œë¡œë“œìºìŠ¤íŒ…\nìë™ìœ¼ë¡œ í™•ì¥ ì–´ë ¤ì›€\në‹¤ë¥¸ í–‰ë ¬ê³¼ ê³§ë°”ë¡œ ì—°ì‚° ê°€ëŠ¥\n\n\n\n\nì–¸ì œ unsqueeze(1)ë¥¼ ì¨ì•¼ í•˜ë‚˜?\n\nëª¨ë¸ì— ì…ë ¥í•  ë•Œ (ì˜ˆ: [batch, features] í˜•íƒœ)\ní–‰ë ¬ ì—°ì‚°ì—ì„œ ì°¨ì› ì¼ì¹˜ë¥¼ ë§ì¶°ì•¼ í•  ë•Œ\nì‹œê°í™” ì‹œ ì—´ ë²¡í„° í˜•íƒœë¡œ ìœ ì§€í•˜ê³  ì‹¶ì„ ë•Œ"
  },
  {
    "objectID": "posts/exercise1.html#q2",
    "href": "posts/exercise1.html#q2",
    "title": "A1: Exercise â€“ ver. 0420-2 (1)",
    "section": "Q2",
    "text": "Q2\n\nx[:, 1:3] vs.Â x[:, [1, 2]] ì°¨ì´ì \n\n\n1. x[:, 1:3] â€” ìŠ¬ë¼ì´ì‹±\n\nì—°ì†ëœ êµ¬ê°„ì„ slice ê°ì²´ë¡œ ì¶”ì¶œ\nê²°ê³¼ëŠ” ì—°ì†ëœ ë©”ëª¨ë¦¬ ë¸”ë¡ì´ë¯€ë¡œ ë·°(view)ê°€ ë¨ â†’ ì›ë³¸ ë³€ê²½ ì‹œ ë°˜ì˜ ê°€ëŠ¥\në©”ëª¨ë¦¬ íš¨ìœ¨ì \nì¸ë±ìŠ¤ëŠ” start:endë¡œ, endëŠ” í¬í•¨í•˜ì§€ ì•ŠìŒ\n\nx[:, 1:3]  # ì—´ 1ë²ˆê³¼ 2ë²ˆ\n\n\n2. x[:, [1, 2]] â€” Fancy Indexing\n\në¦¬ìŠ¤íŠ¸ë¡œ ì§€ì •í•œ ì¸ë±ìŠ¤ë“¤ì„ ì§ì ‘ ì„ íƒ\në³µì‚¬ë³¸(copy)ì´ ìƒì„±ë˜ë¯€ë¡œ ì›ë³¸ ë³€ê²½ê³¼ ì—°ê²°ë˜ì§€ ì•ŠìŒ\nì—°ì†ëœ ì—´ë¿ ì•„ë‹ˆë¼ ì„ì˜ì˜ ìˆœì„œ, ì¤‘ë³µ, ë¶ˆì—°ì† ì¸ë±ìŠ¤ë„ ê°€ëŠ¥\n\nx[:, [1, 2]]       # ì—´ 1ë²ˆê³¼ 2ë²ˆ (ë³µì‚¬ë³¸)\nx[:, [2, 1, 2]]    # ì—´ ìˆœì„œ, ì¤‘ë³µë„ ê°€ëŠ¥\n\n\nì°¨ì´ ì˜ˆì‹œ\n\n\n\ní•­ëª©\nx[:, 1:3]\nx[:, [1, 2]]\n\n\n\n\nì—°ì†ëœ ì—´ë§Œ ì„ íƒ ê°€ëŠ¥\nâœ…\nâœ…\n\n\në¶ˆì—°ì† ì—´ ì„ íƒ\nâŒ\nâœ…\n\n\nì¤‘ë³µ ì—´ ì„ íƒ\nâŒ\nâœ… ([2, 1, 2] ë“±)\n\n\në°˜í™˜ê°’ì´ ë·°(view)?\nâœ…\nâŒ (copy)\n\n\në©”ëª¨ë¦¬ íš¨ìœ¨\në†’ìŒ\në‚®ìŒ (ë³µì‚¬ ë°œìƒ)"
  },
  {
    "objectID": "posts/exercise1.html#q3",
    "href": "posts/exercise1.html#q3",
    "title": "A1: Exercise â€“ ver. 0420-2 (1)",
    "section": "Q3",
    "text": "Q3\n\nx[1:3, :] vs.Â x[-2:, :] ê´€ê³„\n\n\në™ì¼í•œ ê²°ê³¼ë¥¼ ë§Œë“¦\në‘˜ ë‹¤ 2~3í–‰(ì¸ë±ìŠ¤ 1, 2)ì„ ì„ íƒí•˜ëŠ” ì½”ë“œë‹¤.\nx[1:3, :]    # í–‰ ì¸ë±ìŠ¤ 1~2\nx[-2:, :]    # ëì—ì„œ ë‘ ë²ˆì§¸ë¶€í„° ëê¹Œì§€ = ì¸ë±ìŠ¤ 1~2\n\n\n\ní‘œí˜„\nì˜ë¯¸\ní–‰ ì¶”ì¶œ ê²°ê³¼\n\n\n\n\nx[1:3, :]\n1ë²ˆì§¸ë¶€í„° 2ë²ˆì§¸ê¹Œì§€ ìŠ¬ë¼ì´ì‹±\n[1, 2]í–‰\n\n\nx[-2:, :]\në’¤ì—ì„œ 2ê°œ ìŠ¬ë¼ì´ì‹±\n[1, 2]í–‰\n\n\n\n\n\nì°¨ì´ì \n\nx[1:3, :]ì€ ì •ë°©í–¥ ì¸ë±ìŠ¤ë¡œ ìœ„ì¹˜ë¥¼ ê¸°ì¤€\nx[-2:, :]ì€ ì—­ë°©í–¥ ì¸ë±ìŠ¤ë¡œ ë ê¸°ì¤€ â†’ ê°€ë³€ ê¸¸ì´ í…ì„œì—ì„œ ìœ ìš©"
  },
  {
    "objectID": "posts/exercise1.html#q2-q3-ì •ë¦¬-í¬ì¸íŠ¸",
    "href": "posts/exercise1.html#q2-q3-ì •ë¦¬-í¬ì¸íŠ¸",
    "title": "A1: Exercise â€“ ver. 0420-2 (1)",
    "section": "Q2 Q3 ì •ë¦¬ í¬ì¸íŠ¸",
    "text": "Q2 Q3 ì •ë¦¬ í¬ì¸íŠ¸\n\n\n\n\n\n\n\në¹„êµ ëŒ€ìƒ\nì°¨ì´ì  ìš”ì•½\n\n\n\n\n[:, 1:3] vs [:, [1, 2]]\nì „ìëŠ” ì—°ì† êµ¬ê°„ ìŠ¬ë¼ì´ì‹±, í›„ìëŠ” ì§€ì •ëœ ì—´ ë³µì‚¬\n\n\n[1:3, :] vs [-2:, :]\nê²°êµ­ ê°™ì€ í–‰ ì¶”ì¶œ, ì ‘ê·¼ ë°©ì‹(ì• vs.Â ë’¤ ê¸°ì¤€)ë§Œ ë‹¤ë¦„"
  },
  {
    "objectID": "posts/exercise1.html#q4",
    "href": "posts/exercise1.html#q4",
    "title": "A1: Exercise â€“ ver. 0420-2 (1)",
    "section": "Q4",
    "text": "Q4\n\nunsqueezeì— ëŒ€í•´ ì„¤ëª…\n\n\nunsqueezeëŠ” í…ì„œ ì°¨ì›ì„ ì¸ìœ„ì ìœ¼ë¡œ ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜ë¡œ, PyTorchì—ì„œ ë°ì´í„°ë¥¼ ë‹¤ë£° ë•Œ ë§¤ìš° ìì£¼ ì“°ì¸ë‹¤.\nì°¨ì›ì´ ë§ì§€ ì•Šì•„ ì˜¤ë¥˜ê°€ ë°œìƒí•  ë•Œ, unsqueezeë¥¼ ì´ìš©í•˜ë©´ ì´ë¥¼ ê°„ë‹¨í•˜ê²Œ í•´ê²°í•  ìˆ˜ ìˆë‹¤.\n\n\ntorch.unsqueeze(tensor, dim) ë˜ëŠ” tensor.unsqueeze(dim)\n\nì—­í• :\n\nì§€ì •í•œ ìœ„ì¹˜ dimì— í¬ê¸° 1ì§œë¦¬ ì°¨ì›ì„ ì¶”ê°€í•œë‹¤.\nê²°ê³¼ í…ì„œì˜ shapeì€ ì›ë˜ë³´ë‹¤ ì°¨ì›ì´ 1 ì¦ê°€í•œë‹¤.\n\n\n\nì˜ˆì‹œ 1: ë²¡í„° â†’ ì—´ ë²¡í„°\nx = torch.tensor([1, 2, 3])       # shape: [3]\nx_unsq = x.unsqueeze(1)           # shape: [3, 1]\n\n# ê²°ê³¼:\n# tensor([[1],\n#         [2],\n#         [3]])\n\n\nì˜ˆì‹œ 2: ë²¡í„° â†’ ë°°ì¹˜ í…ì„œ\nx = torch.tensor([1, 2, 3])       # shape: [3]\nx_unsq = x.unsqueeze(0)           # shape: [1, 3]\n\n# ê²°ê³¼:\n# tensor([[1, 2, 3]])\n\n\nShape ë³€í™” ì •ë¦¬:\n\n\n\nì›ë˜ shape\nunsqueeze(0)\nunsqueeze(1)\nunsqueeze(-1)\n\n\n\n\n[3]\n[1, 3]\n[3, 1]\n[3, 1]\n\n\n[3, 4]\n[1, 3, 4]\n[3, 1, 4]\n[3, 4, 1]\n\n\n\n\n\n\nì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” ìƒí™©\n\n1. ëª¨ë¸ ì…ë ¥ ì°¨ì› ë§ì¶”ê¸°\nx = torch.tensor([1.0, 2.0, 3.0])  # shape [3]\nx = x.unsqueeze(0)  # shape [1, 3] â†’ batch ì°¨ì› ì¶”ê°€\n\n\n2. ë¸Œë¡œë“œìºìŠ¤íŒ… ìš©ë„\na = torch.tensor([1, 2, 3])         # shape: [3]\nb = a.unsqueeze(1)                  # shape: [3, 1]\nâ†’ ì´í›„ ì—°ì‚° ì‹œ ìë™ìœ¼ë¡œ [3, 1]ê³¼ [3, 4] ê°™ì€ í…ì„œê°€ ë§ì¶°ì§\n\n\n\nì£¼ì˜\n\nunsqueezeëŠ” ì‹¤ì œ ë°ì´í„°ë¥¼ ë°”ê¾¸ì§€ ì•Šê³  shapeë§Œ ë³€ê²½í•œë‹¤.\nì›ë˜ì˜ í…ì„œì™€ ë™ì¼í•œ ë©”ëª¨ë¦¬ ì°¸ì¡°ë¥¼ ê°€ì§ˆ ìˆ˜ë„ ìˆìŒ (ì¦‰, viewì¼ ìˆ˜ ìˆìŒ)\n\n\n\nê´€ë ¨ í•¨ìˆ˜\n\n\n\ní•¨ìˆ˜\nê¸°ëŠ¥\n\n\n\n\nunsqueeze\nì°¨ì› ì¶”ê°€\n\n\nsqueeze\ní¬ê¸° 1ì¸ ì°¨ì› ì œê±°\n\n\nreshape\nì „ì²´ ì°¨ì›ì„ ì›í•˜ëŠ” í˜•íƒœë¡œ ì¬êµ¬ì„±\n\n\nview\nreshapeê³¼ ê±°ì˜ ë™ì¼, ë©”ëª¨ë¦¬ ì—°ì† ìš”êµ¬\n\n\n\n\ntorch.unsqueeze?\n\n\nDocstring:\nunsqueeze(input, dim) -&gt; Tensor\nReturns a new tensor with a dimension of size one inserted at the\nspecified position.\nThe returned tensor shares the same underlying data with this tensor.\nA :attr:`dim` value within the range ``[-input.dim() - 1, input.dim() + 1)``\ncan be used. Negative :attr:`dim` will correspond to :meth:`unsqueeze`\napplied at :attr:`dim` = ``dim + input.dim() + 1``.\nArgs:\n    input (Tensor): the input tensor.\n    dim (int): the index at which to insert the singleton dimension\nExample::\n    &gt;&gt;&gt; x = torch.tensor([1, 2, 3, 4])\n    &gt;&gt;&gt; torch.unsqueeze(x, 0)\n    tensor([[ 1,  2,  3,  4]])\n    &gt;&gt;&gt; torch.unsqueeze(x, 1)\n    tensor([[ 1],\n            [ 2],\n            [ 3],\n            [ 4]])\nType:      builtin_function_or_method"
  },
  {
    "objectID": "posts/01wk-2.html",
    "href": "posts/01wk-2.html",
    "title": "01wk-2, 02wk-1: (íšŒê·€) â€“ íšŒê·€ëª¨í˜•, ì†ì‹¤í•¨ìˆ˜, íŒŒì´í† ì¹˜ë¥¼ ì´ìš©í•œ ì¶”ì •",
    "section": "",
    "text": "ğŸ“˜ Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\nğŸ“ ğŸ—£ï¸ âœï¸ ğŸ”¬ â“"
  },
  {
    "objectID": "posts/01wk-2.html#a.-ì•„ì´ìŠ¤-ì•„ë©”ë¦¬ì¹´ë…¸-ê°€ì§œìë£Œ",
    "href": "posts/01wk-2.html#a.-ì•„ì´ìŠ¤-ì•„ë©”ë¦¬ì¹´ë…¸-ê°€ì§œìë£Œ",
    "title": "01wk-2, 02wk-1: (íšŒê·€) â€“ íšŒê·€ëª¨í˜•, ì†ì‹¤í•¨ìˆ˜, íŒŒì´í† ì¹˜ë¥¼ ì´ìš©í•œ ì¶”ì •",
    "section": "A. ì•„ì´ìŠ¤ ì•„ë©”ë¦¬ì¹´ë…¸ (ê°€ì§œìë£Œ)",
    "text": "A. ì•„ì´ìŠ¤ ì•„ë©”ë¦¬ì¹´ë…¸ (ê°€ì§œìë£Œ)\n- ì¹´í˜ì£¼ì¸ì¸ ë°•í˜œì›ì”¨ëŠ” ì˜¨ë„ì™€ ì•„ì´ìŠ¤ì•„ë©”ë¦¬ì¹´ë…¸ íŒë§¤ëŸ‰ì´ ê´€ê³„ê°€ ìˆë‹¤ëŠ” ê²ƒì„ ì•Œì•˜ë‹¤. êµ¬ì²´ì ìœ¼ë¡œëŠ”\n\nâ€œì˜¨ë„ê°€ ë†’ì•„ì§ˆ ìˆ˜ë¡ (=ë‚ ì”¨ê°€ ë”ìš¸ìˆ˜ë¡) ì•„ì´ìŠ¤ì•„ë©”ë¦¬ì¹´ë…¸ì˜ íŒë§¤ëŸ‰ì´ ì¦ê°€â€\n\ní•œë‹¤ëŠ” ì‚¬ì‹¤ì„ ì•Œê²Œ ë˜ì—ˆë‹¤. ì´ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•´ì„œ ì•„ë˜ì™€ ê°™ì´ 100ê°œì˜ ë°ì´í„°ë¥¼ ëª¨ì•˜ë‹¤.\n\ntemp = [-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n        -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n        -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n        -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n        -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n        -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n        -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n         0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n         0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n         0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n         1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n         1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n         2.3935,  2.6056,  2.6057,  2.6632]\n\n\nsales= [-8.5420, -6.5767, -5.9496, -4.4794, -4.2516, -3.1326, -4.0239, -4.1862,\n        -3.3403, -2.2027, -2.0262, -2.5619, -1.3353, -2.0466, -0.4664, -1.3513,\n        -1.6472, -0.1089, -0.3071, -0.6299, -0.0438,  0.4163,  0.4166, -0.0943,\n         0.2662,  0.4591,  0.8905,  0.8998,  0.6314,  1.3845,  0.8085,  1.2594,\n         1.1211,  1.9232,  1.0619,  1.3552,  2.1161,  1.1437,  1.6245,  1.7639,\n         1.6022,  1.7465,  0.9830,  1.7824,  2.1116,  2.8621,  2.1165,  1.5226,\n         2.5572,  2.8361,  3.3956,  2.0679,  2.8140,  3.4852,  3.6059,  2.5966,\n         2.8854,  3.9173,  3.6527,  4.1029,  4.3125,  3.4026,  3.2180,  4.5686,\n         4.3772,  4.3075,  4.4895,  4.4827,  5.3170,  5.4987,  5.4632,  6.0328,\n         5.2842,  5.0539,  5.4538,  6.0337,  5.7250,  5.7587,  6.2020,  6.5992,\n         6.4621,  6.5140,  6.6846,  7.3497,  8.0909,  7.0794,  6.8667,  7.4229,\n         7.2544,  7.1967,  9.5006,  9.0339,  7.4887,  9.0759, 11.0946, 10.3260,\n        12.2665, 13.0983, 12.5468, 13.8340]\n\nğŸ—£ï¸ ìŒìˆ˜ íŒë§¤ëŸ‰ì€ ì¼ë‹¨ ë¬´ì‹œ\nì—¬ê¸°ì—ì„œ tempëŠ” í‰ê· ê¸°ì˜¨ì´ê³ , salesëŠ” ì•„ì´ìŠ¤ì•„ë©”ë¦¬ì¹´ë…¸ íŒë§¤ëŸ‰ì´ë‹¤. í‰ê· ê¸°ì˜¨ê³¼ íŒë§¤ëŸ‰ì˜ ê·¸ë˜í”„ë¥¼ ê·¸ë ¤ë³´ë©´ ì•„ë˜ì™€ ê°™ë‹¤.\n\nplt.plot(temp,sales,'o')\n\n\n\n\n\n\n\n\nğŸ—£ï¸ ì•½ê°„ì˜ ì˜¤ì°¨ëŠ” ìˆì§€ë§Œ ì„ ìœ¼ë¡œ ë³´ì„\nì˜¤ëŠ˜ ë°”ê¹¥ì˜ ì˜¨ë„ëŠ” 0.5ë„ ì´ë‹¤. ì•„ì´ìŠ¤ ì•„ë©”ë¼ì¹´ë…¸ë¥¼ ëª‡ì”ì •ë„ ë§Œë“¤ì–´ ë‘ë©´ ì¢‹ì„ê¹Œ?\nğŸ—£ï¸ ì´ ê·¸ë˜í”„ë¥¼ ë³´ê³  4.5ì” ì •ë„ë¡œ ì§ì‘ ê°€ëŠ¥"
  },
  {
    "objectID": "posts/01wk-2.html#b.-ê°€ì§œìë£Œë¥¼-ë§Œë“ -ë°©ë²•",
    "href": "posts/01wk-2.html#b.-ê°€ì§œìë£Œë¥¼-ë§Œë“ -ë°©ë²•",
    "title": "01wk-2, 02wk-1: (íšŒê·€) â€“ íšŒê·€ëª¨í˜•, ì†ì‹¤í•¨ìˆ˜, íŒŒì´í† ì¹˜ë¥¼ ì´ìš©í•œ ì¶”ì •",
    "section": "B. ê°€ì§œìë£Œë¥¼ ë§Œë“  ë°©ë²•",
    "text": "B. ê°€ì§œìë£Œë¥¼ ë§Œë“  ë°©ë²•\n- ë°©ë²•1: \\(y_i= w_0+w_1 x_i +\\epsilon_i = 2.5 + 4x_i +\\epsilon_i, \\quad i=1,2,\\dots,n\\)\nğŸ—£ï¸(\nxi = ì˜¨ë„ = temp\nyi = íŒë§¤ëŸ‰ = sales\níŒë§¤ëŸ‰ = 2.5 + 4*ì˜¨ë„ + ì˜¤ì°¨\n\ntorch.randn(10) # í‘œì¤€ì •ê·œë¶„í¬ì—ì„œ 10ê°œ ê°’ ì¶”ì¶œ, ê¸¸ì´ê°€ 10ì¸ vector (column vectorì¸ì§€ row vectorì¸ì§€ëŠ” ëª¨ë¦„)\n\ntensor([-0.4351, -0.4066,  1.2577, -1.1443,  0.3941, -0.2229, -0.4337,  0.8736,\n         0.6216,  1.0963])\n\n\n\ntorch.randn(100).sort() # 100ê°œ ê°’ì„ ì •ë ¬ / ì•ì€ ì •ë ¬ëœ ê°’, ë’¤ëŠ” ì¸ë±ìŠ¤\n\ntorch.return_types.sort(\nvalues=tensor([-3.3450e+00, -2.3363e+00, -1.7533e+00, -1.6534e+00, -1.4996e+00,\n        -1.4218e+00, -1.3757e+00, -1.3314e+00, -1.1898e+00, -1.1594e+00,\n        -1.1386e+00, -1.0975e+00, -1.0961e+00, -1.0899e+00, -1.0250e+00,\n        -9.7851e-01, -9.1254e-01, -8.8307e-01, -8.7845e-01, -8.4915e-01,\n        -7.4344e-01, -7.0972e-01, -7.0845e-01, -6.8746e-01, -6.7488e-01,\n        -6.6512e-01, -6.0503e-01, -5.8921e-01, -5.4838e-01, -5.1363e-01,\n        -5.0996e-01, -4.7537e-01, -4.3955e-01, -3.5707e-01, -3.4237e-01,\n        -3.4013e-01, -3.2890e-01, -3.2078e-01, -3.0216e-01, -2.9112e-01,\n        -2.8083e-01, -2.4387e-01, -2.4171e-01, -2.0109e-01, -1.9779e-01,\n        -1.9549e-01, -5.8397e-02, -2.5842e-02, -2.2056e-02,  2.0055e-03,\n         1.0348e-02,  2.2201e-02,  2.5445e-02,  2.6868e-02,  6.2116e-02,\n         1.3408e-01,  1.5172e-01,  2.0091e-01,  2.3218e-01,  2.5000e-01,\n         2.7442e-01,  2.8144e-01,  3.4857e-01,  3.7494e-01,  4.4520e-01,\n         4.8013e-01,  4.9466e-01,  5.0311e-01,  5.7595e-01,  6.2995e-01,\n         6.3221e-01,  6.5666e-01,  6.5788e-01,  6.6027e-01,  6.7909e-01,\n         7.1635e-01,  7.1752e-01,  7.2141e-01,  8.0059e-01,  8.0419e-01,\n         8.0801e-01,  8.1830e-01,  8.9444e-01,  9.6222e-01,  9.9973e-01,\n         1.1303e+00,  1.1527e+00,  1.2046e+00,  1.2086e+00,  1.2469e+00,\n         1.2752e+00,  1.2872e+00,  1.3125e+00,  1.4296e+00,  1.4390e+00,\n         1.5448e+00,  1.6129e+00,  1.6454e+00,  1.6769e+00,  1.7580e+00]),\nindices=tensor([81, 19, 56, 18, 89, 54, 27, 31, 65, 85, 94, 47,  0,  7,  8, 57, 14, 92,\n         3, 12, 86, 48,  9, 82, 62, 78,  1, 28, 32, 67, 21, 53, 10, 30, 23,  5,\n        88, 24, 63, 40, 20, 77, 34, 87, 99, 80, 41,  4, 69, 90, 35, 72, 58, 11,\n        22, 42, 76, 95, 74, 38, 46, 59, 91, 68, 43, 44, 50, 96, 51,  6, 29, 13,\n        66, 49, 73,  2, 70, 93, 97, 16, 15, 98, 55, 33, 39, 84, 25, 61, 17, 64,\n        45, 26, 75, 71, 79, 37, 60, 83, 36, 52]))\n\n\n\na = torch.randn(100).sort()\ntype(a)\n\ntorch.return_types.sort\n\n\n\na[0]\n\ntensor([-2.8188e+00, -2.7746e+00, -2.5355e+00, -2.4374e+00, -2.2716e+00,\n        -2.1492e+00, -1.8555e+00, -1.8281e+00, -1.6228e+00, -1.6164e+00,\n        -1.5151e+00, -1.5046e+00, -1.4989e+00, -1.4708e+00, -1.4605e+00,\n        -1.3748e+00, -1.3521e+00, -1.3183e+00, -1.2710e+00, -1.2416e+00,\n        -1.1459e+00, -1.0949e+00, -1.0907e+00, -1.0903e+00, -1.0481e+00,\n        -1.0313e+00, -1.0079e+00, -1.0003e+00, -9.9874e-01, -9.9081e-01,\n        -9.8943e-01, -9.7448e-01, -9.4772e-01, -9.4282e-01, -9.1282e-01,\n        -8.8605e-01, -8.6893e-01, -8.5283e-01, -7.8566e-01, -7.7867e-01,\n        -7.6961e-01, -7.4827e-01, -6.6928e-01, -6.3990e-01, -5.9842e-01,\n        -5.8057e-01, -5.5388e-01, -5.1941e-01, -5.1005e-01, -4.9040e-01,\n        -4.7796e-01, -3.9862e-01, -3.9854e-01, -3.8835e-01, -3.7719e-01,\n        -3.6587e-01, -3.0923e-01, -3.0278e-01, -2.5337e-01, -2.1358e-01,\n        -1.7441e-01, -1.4875e-01, -5.6163e-02, -3.3250e-02, -2.6646e-02,\n         2.1082e-03,  1.3442e-02,  9.5665e-02,  1.0434e-01,  1.2852e-01,\n         1.8255e-01,  2.2326e-01,  2.3160e-01,  2.5853e-01,  2.6803e-01,\n         3.3640e-01,  3.6288e-01,  3.7120e-01,  3.8451e-01,  4.0117e-01,\n         4.3763e-01,  4.5193e-01,  5.2404e-01,  6.1333e-01,  6.7461e-01,\n         6.8081e-01,  8.0477e-01,  9.1538e-01,  9.5395e-01,  1.0907e+00,\n         1.1139e+00,  1.1281e+00,  1.2559e+00,  1.2686e+00,  1.3258e+00,\n         1.3563e+00,  1.3864e+00,  1.5558e+00,  1.6258e+00,  2.1654e+00])\n\n\n\nx,_ = torch.randn(100).sort() # ì–¸íŒ¨í‚¹\nx\n\ntensor([-2.8984, -2.6607, -2.2449, -2.2072, -2.1918, -2.1538, -1.9428, -1.9416,\n        -1.8612, -1.6956, -1.6357, -1.4785, -1.4322, -1.2127, -1.1737, -0.9456,\n        -0.9244, -0.8456, -0.8190, -0.7925, -0.7609, -0.7305, -0.7011, -0.6806,\n        -0.6442, -0.6117, -0.6059, -0.5994, -0.4920, -0.4066, -0.3879, -0.3867,\n        -0.3612, -0.3604, -0.3142, -0.3112, -0.2940, -0.2812, -0.2753, -0.2665,\n        -0.2145, -0.2106, -0.1864, -0.1633, -0.1470, -0.1331, -0.1316, -0.0994,\n        -0.0954, -0.0717, -0.0586, -0.0329,  0.0095,  0.0182,  0.0214,  0.0915,\n         0.0952,  0.1077,  0.1124,  0.1612,  0.1614,  0.1969,  0.2003,  0.3242,\n         0.3424,  0.3925,  0.4078,  0.4468,  0.4536,  0.5199,  0.5238,  0.5563,\n         0.5595,  0.6236,  0.6372,  0.6451,  0.6630,  0.7122,  0.7335,  0.7569,\n         0.7589,  0.8969,  0.9318,  0.9552,  1.0023,  1.0198,  1.1083,  1.1978,\n         1.2752,  1.2928,  1.3265,  1.3825,  1.4325,  1.5292,  1.6095,  1.6239,\n         1.7316,  2.0886,  2.3070,  3.2682])\n\n\n\ntorch.manual_seed(43052) # ê°’ ê³ ì •\nx,_ = torch.randn(100).sort()\nx\n\ntensor([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n        -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n        -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n        -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n        -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n        -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n        -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n         0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n         0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n         0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n         1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n         1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n         2.3935,  2.6056,  2.6057,  2.6632])\n\n\n\n# temp # ìœ„ì˜ tempì™€ xëŠ” ë™ì¼\n\n\nsales[0] # -2.4821 * 4 + 2.5 + ì˜¤ì°¨\n\n-8.542\n\n\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\neps = torch.randn(100)*0.5 # ì˜¤ì°¨ ë§Œë“¤ê¸° (ë¶„ì‚° ì‘ê²Œí•˜ë ¤ê³  0.5ë¥¼ ê³±í•¨)\n\n\n-2.4821 * 4 + 2.5 + eps[0] # sales[0]ê³¼ ë™ì¼\n\ntensor(-8.5420)\n\n\n\nx[1] * 4 + 2.5 + eps[1] # ë‘ ë²ˆì§¸ ê°’\n\ntensor(-6.5767)\n\n\n\nsales[1]\n\n-6.5767\n\n\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\neps = torch.randn(100)*0.5\ny = x * 4 + 2.5 + eps # ë¸Œë¡œë“œìºìŠ¤íŒ… ì´ìš©\n\n\ntemp[:5],sales[:5]\n\n([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792],\n [-8.542, -6.5767, -5.9496, -4.4794, -4.2516])\n\n\n\nx[:5], y[:5] # ìœ„ì™€ ë™ì¼\n\n(tensor([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792]),\n tensor([-8.5420, -6.5767, -5.9496, -4.4794, -4.2516]))\n\n\n)ğŸ—£ï¸\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\neps = torch.randn(100)*0.5\ny = x * 4 + 2.5 + eps\n\n\nx[:5], y[:5]\n\n(tensor([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792]),\n tensor([-8.5420, -6.5767, -5.9496, -4.4794, -4.2516]))\n\n\n- ë°©ë²•2: \\({\\bf y}={\\bf X}{\\bf W} +\\boldsymbol{\\epsilon}\\)\n\n\\({\\bf y}=\\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\dots \\\\ y_n\\end{bmatrix}, \\quad {\\bf X}=\\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\dots \\\\ 1 & x_n\\end{bmatrix}, \\quad {\\bf W}=\\begin{bmatrix} 2.5 \\\\ 4 \\end{bmatrix}, \\quad \\boldsymbol{\\epsilon}= \\begin{bmatrix} \\epsilon_1 \\\\ \\dots \\\\ \\epsilon_n\\end{bmatrix}\\)\n\nğŸ—£ï¸(\n\\(y_1 = 2.5 + 4x_1 + \\epsilon_1\\)\n\\(y_2 = 2.5 + 4x_2 + \\epsilon_2\\)\n\\(y_3 = 2.5 + 4x_3 + \\epsilon_3\\) â€¦ ì„ ìœ„ì™€ ê°™ì´ í‘œí˜„í•  ìˆ˜ ìˆìŒ\në°©ë²•1ì€ scalarë¡œ í‘œí˜„, ë°©ë²•2ëŠ” matrixë¡œ í‘œí˜„\n\ny # ê¸¸ì´ê°€ 100ì¸ vector (ë°©ë²•1) / ë°©ë²•2ëŠ” (100,1) matrixë¡œ í‘œí˜„ë˜ì–´ì•¼ í•¨\n\ntensor([-8.5420, -6.5767, -5.9496, -4.4794, -4.2516, -3.1326, -4.0239, -4.1862,\n        -3.3403, -2.2027, -2.0262, -2.5619, -1.3353, -2.0466, -0.4664, -1.3513,\n        -1.6472, -0.1089, -0.3071, -0.6299, -0.0438,  0.4163,  0.4166, -0.0943,\n         0.2662,  0.4591,  0.8905,  0.8998,  0.6314,  1.3845,  0.8085,  1.2594,\n         1.1211,  1.9232,  1.0619,  1.3552,  2.1161,  1.1437,  1.6245,  1.7639,\n         1.6022,  1.7465,  0.9830,  1.7824,  2.1116,  2.8621,  2.1165,  1.5226,\n         2.5572,  2.8361,  3.3956,  2.0679,  2.8140,  3.4852,  3.6059,  2.5966,\n         2.8854,  3.9173,  3.6527,  4.1029,  4.3125,  3.4026,  3.2180,  4.5686,\n         4.3772,  4.3075,  4.4895,  4.4827,  5.3170,  5.4987,  5.4632,  6.0328,\n         5.2842,  5.0539,  5.4538,  6.0337,  5.7250,  5.7587,  6.2020,  6.5992,\n         6.4621,  6.5140,  6.6846,  7.3497,  8.0909,  7.0794,  6.8667,  7.4229,\n         7.2544,  7.1967,  9.5006,  9.0339,  7.4887,  9.0759, 11.0946, 10.3260,\n        12.2665, 13.0983, 12.5468, 13.8340])\n\n\n\nx # ê¸¸ì´ê°€ 100ì¸ vector (ë°©ë²•1) / ë°©ë²•2ëŠ” [1 x] ì´ëŸ°ì‹ìœ¼ë¡œ í‘œí˜„ë˜ì–´ì•¼ í•¨\n\ntensor([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n        -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n        -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n        -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n        -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n        -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n        -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n         0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n         0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n         0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n         1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n         1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n         2.3935,  2.6056,  2.6057,  2.6632])\n\n\n[1 x] ë§Œë“¤ê¸°\n\ntorch.ones(100) , x # ê¸¸ì´ê°€ 100ì¸ vector\n\n(tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n tensor([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n         -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n         -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n         -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n         -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n         -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n         -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n          0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n          0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n          0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n          1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n          1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n          2.3935,  2.6056,  2.6057,  2.6632]))\n\n\n\n# torch.stack([torch.ones(100) , x]) # ì¢Œìš°ë¡œ í•©ì¹˜ê¸° ìœ„í•´ stack ì‚¬ìš©\nprint(torch.stack([torch.ones(100) , x]).shape)\n# torch.stack([torch.ones(100) , x], axis=1) # ì›í–ˆë˜ ê²°ê³¼\nprint(torch.stack([torch.ones(100) , x], axis=1).shape)\n\n# torch.stack([torch.ones(100) , x]).T # ë‹¤ë¥¸ ë°©ë²•\nprint(torch.stack([torch.ones(100) , x]).T.shape)\n\ntorch.Size([2, 100])\ntorch.Size([100, 2])\ntorch.Size([100, 2])\n\n\n\nX = torch.stack([torch.ones(100) , x], axis=1)\nW = torch.tensor([[2.5],[4.0]])\ny = X@W + eps.reshape(100,1)\ny.shape\n\ntorch.Size([100, 1])\n\n\n\nsales[:5]\n\n[-8.542, -6.5767, -5.9496, -4.4794, -4.2516]\n\n\n\ny[:5,0]\n\ntensor([-8.5420, -6.5767, -5.9496, -4.4794, -4.2516])\n\n\nsalesì™€ y ë™ì¼\nğŸ”¬ğŸ—£ï¸(\n\n(ì°¸ê³ ) ì¸ë±ì‹± ê´€ë ¨ ì„¤ëª…\n\n\ny[:5]\n\ntensor([[-8.5420],\n        [-6.5767],\n        [-5.9496],\n        [-4.4794],\n        [-4.2516]])\n\n\nyëŠ” matrix ì´ë¯€ë¡œ\n\ny[:5,[0]] # column vectorì²˜ëŸ¼ ë¨\n\ntensor([[-8.5420],\n        [-6.5767],\n        [-5.9496],\n        [-4.4794],\n        [-4.2516]])\n\n\n\n# y[:,:] # yê°€ ê·¸ëŒ€ë¡œ ë‚˜ì˜´\n\n\ny[:5,:] # ê·¸ ì¤‘ 5ê°œë§Œ\n\ntensor([[-8.5420],\n        [-6.5767],\n        [-5.9496],\n        [-4.4794],\n        [-4.2516]])\n\n\në‚˜ì—´ ë°©ì‹ë§Œ ë‹¤ë¥´ê³  ê°’ì€ salesì™€ ë˜‘ê°™ìŒ\n)ğŸ”¬ğŸ—£ï¸\n\nX = torch.stack([torch.ones(100) , x], axis=1) # (100, 2)\nW = torch.tensor([[2.5],[4.0]]) # (2, 1)\ny = X@W + eps.reshape(100,1) # (100, 1)\nx # ì•„ë§ˆë„ (100,) \n\ntensor([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n        -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n        -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n        -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n        -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n        -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n        -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n         0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n         0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n         0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n         1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n         1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n         2.3935,  2.6056,  2.6057,  2.6632])\n\n\n(100,)ì„ (100,1)ë¡œ ë°”ê¾¸ê³  ì‹¶ìŒ\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\neps = torch.randn(100)*0.5\ny = x * 4 + 2.5 + eps\n\nX = torch.stack([torch.ones(100) , x], axis=1) # (100, 2)\nW = torch.tensor([[2.5],[4.0]]) # (2, 1)\ny = X@W + eps.reshape(100,1) # (100, 1)\nx = X[:,[1]]\n\n\nx[:5], y[:5]\n\n(tensor([[-2.4821],\n         [-2.3621],\n         [-1.9973],\n         [-1.6239],\n         [-1.4792]]),\n tensor([[-8.5420],\n         [-6.5767],\n         [-5.9496],\n         [-4.4794],\n         [-4.2516]]))\n\n\n\ntemp[:5], sales[:5]\n\n([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792],\n [-8.542, -6.5767, -5.9496, -4.4794, -4.2516])\n\n\në°©ë²• 2ì²˜ëŸ¼ matrixë¡œë„ ê°€ëŠ¥í•˜ë‹¤ëŠ” ê²ƒì„ í™•ì¸\n)ğŸ—£ï¸\nğŸ“(\nX = torch.stack([torch.ones(100),x],axis=1)\nW = torch.tensor([[2.5],[4.0]])\ny = X@W + eps.reshape(100,1)\nx = X[:,[1]]\nâœï¸ í¸ì˜ìƒ ìœ„ì˜ ì½”ë“œëŠ” ì‹¤í–‰ì‹œí‚¤ì§€ ì•ŠìŒ\n\nX[:5,:], y[:5,:]\n\n(tensor([[ 1.0000, -2.4821],\n         [ 1.0000, -2.3621],\n         [ 1.0000, -1.9973],\n         [ 1.0000, -1.6239],\n         [ 1.0000, -1.4792]]),\n tensor([[-8.5420],\n         [-6.5767],\n         [-5.9496],\n         [-4.4794],\n         [-4.2516]]))\n\n\n)ğŸ“\n- tureì™€ observed dataë¥¼ ë™ì‹œì— ì‹œê°í™”\nğŸ—£ï¸(\n\nplt.plot(temp, sales) # ì´ëŸ¬í•œ ë°ì´í„°ë¥¼ ê´€ì¸¡í–ˆë‹¤ê³  ìƒê°\n\n\n\n\n\n\n\n\n\nplt.plot(temp, sales, 'o') # scatter plot\n\n\n\n\n\n\n\n\n\nplt.plot(x, y, 'o') # ìœ„ì™€ ë™ì¼\n\n\n\n\n\n\n\n\nxì—ì„œ yë¡œ ê°€ëŠ” íŒ¨í„´ì„ ì°¾ê³  ì‹¶ìŒ\n\nplt.plot(x, y, 'o', label=\"observed data\") # ê´€ì¸¡í•œ ê°’\nplt.legend()\n\n\n\n\n\n\n\n\n\nplt.plot(x, y, 'o', label=\"observed data\") # ì ì„  + epsilon(í†µê³„ì ìœ¼ë¡œ ì„¤ëª…í•  ìˆ˜ ì—†ëŠ” í˜„ìƒ, random)\nplt.plot(x, 2.5 + 4*x, '--', label=\"true\") # ì›ë˜ ê´€ì¸¡ë˜ì–´ì•¼ í–ˆë˜ ê°’\nplt.legend()\n\n\n\n\n\n\n\n\n\ní•˜ê³  ì‹¶ì€ ê²ƒ\n\nì¹´í˜ ì£¼ì¸: ì˜¨ë„ê°€ 0.5ì¼ ë•Œ ì–¼ë§ˆë‚˜ íŒ”ë¦´ì§€ ì•Œê³  ì‹¶ìŒ\nê°€ì¥ ê°„ë‹¨: 0.5ë¥¼ ì ì„  ìœ„ì— ì˜¬ë¦° í›„ y ê°’ì„ ì˜ˆì¸¡ (0.5 * 4 + 2.5 = 4.5)\ní•˜ì§€ë§Œ ì‹¤ì œë¡œëŠ” íŒŒë€ìƒ‰ë§Œ ì•Œê³  ìˆìœ¼ë¯€ë¡œ ìœ„ì˜ ë°©ë²•ì€ cheating\n\n\n\nplt.plot(x,y,'o',label=r\"observed data: $(x_i,y_i)$\")\n#plt.plot(x,2.5+4*x,'--',label=r\"true: $(x_i, 4x_i+2.5)$ // $y=4x+2.5$ \")\nplt.legend()\n\n\n\n\n\n\n\n\n\ní•˜ê³  ì‹¶ì€ ê²ƒ\n\nìœ„ì˜ ìƒíƒœì—ì„œ ì ë‹¹í•œ ì¶”ì„¸ì„ ì„ ê·¸ë ¤ì„œ ì¶”ì •\n\n\n)ğŸ—£ï¸\n\nplt.plot(x,y,'o',label=r\"observed data: $(x_i,y_i)$\")\n#plt.plot(x,2.5+4*x,'--',label=r\"true: $(x_i, 4x_i+2.5)$ // $y=4x+2.5$ \")\nplt.legend()"
  },
  {
    "objectID": "posts/01wk-2.html#c.-íšŒê·€ë¶„ì„ì´ë€",
    "href": "posts/01wk-2.html#c.-íšŒê·€ë¶„ì„ì´ë€",
    "title": "01wk-2, 02wk-1: (íšŒê·€) â€“ íšŒê·€ëª¨í˜•, ì†ì‹¤í•¨ìˆ˜, íŒŒì´í† ì¹˜ë¥¼ ì´ìš©í•œ ì¶”ì •",
    "section": "C. íšŒê·€ë¶„ì„ì´ë€?",
    "text": "C. íšŒê·€ë¶„ì„ì´ë€?\n- í´ë¦¬ì…°: ê´€ì¸¡í•œ ìë£Œ \\((x_i,y_i)\\) ê°€ ìˆìŒ \\(\\to\\) ìš°ë¦¬ëŠ” \\((x_i,y_i)\\)ì˜ ê´€ê³„ë¥¼ íŒŒì•…í•˜ì—¬ ìƒˆë¡œìš´ \\(x\\)ê°€ ì™”ì„ë•Œ ê·¸ê²ƒì— ëŒ€í•œ ì˜ˆì¸¡ê°’(predicted value) \\(\\hat{y}\\)ì„ ì•Œì•„ë‚´ëŠ” ë²•ì¹™ì„ ì•Œê³  ì‹¶ìŒ \\(\\to\\) ê´€ê³„ë¥¼ íŒŒì•…í•˜ê¸° ìœ„í•´ì„œ \\((x_i, y_i)\\)ì˜ ì‚°ì ë„ë¥¼ ê·¸ë ¤ë³´ë‹ˆ \\(x_i\\)ì™€ \\(y_i\\)ëŠ” ì„ í˜•ì„±ì„ ê°€ì§€ê³  ìˆë‹¤ëŠ” ê²ƒì´ íŒŒì•…ë¨ \\(\\to\\) ì˜¤ì°¨í•­ì´ ë“±ë¶„ì‚°ì„±ì„ ê°€ì§€ê³  ì–´ì©Œê³  ì €ì©Œê³ â€¦ \\(\\to\\) í•˜ì—¬íŠ¼ \\((x_i,y_i)\\) ë¥¼ â€œì ë‹¹íˆ ì˜ ê´€í†µí•˜ëŠ”â€ ì–´ë– í•œ í•˜ë‚˜ì˜ ì¶”ì„¸ì„ ì„ ì˜ ì¶”ì •í•˜ë©´ ëœë‹¤.\n- íšŒê·€ë¶„ì„ì´ë€ ì‚°ì ë„ë¥¼ ë³´ê³  ì ë‹¹í•œ ì¶”ì„¸ì„ ì„ ì°¾ëŠ” ê²ƒì´ë‹¤. ì¢€ ë” ì •í™•í•˜ê²Œ ë§í•˜ë©´ \\((x_1,y_1) \\dots (x_n,y_n)\\) ìœ¼ë¡œ \\(\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\) ë¥¼ ìµœëŒ€í•œ \\(\\begin{bmatrix} 2.5 \\\\ 4 \\end{bmatrix}\\)ì™€ ë¹„ìŠ·í•˜ê²Œ ì°¾ëŠ” ê²ƒ.\n\ngiven data : \\(\\big\\{(x_i,y_i) \\big\\}_{i=1}^{n}\\)\nparameter: \\({\\bf W}=\\begin{bmatrix} w_0 \\\\ w_1 \\end{bmatrix}\\)\nestimated parameter: \\({\\bf \\hat{W}}=\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\)\n\nğŸ—£ï¸ y = ax + b ê¼´ì—ì„œ a, bë¥¼ ì •í•¨\n- ë” ì‰½ê²Œ ë§í•˜ë©´ ì•„ë˜ì˜ ê·¸ë¦¼ì„ ë³´ê³  â€œì ë‹¹í•œâ€ ì¶”ì„¸ì„ ì„ ì°¾ëŠ” ê²ƒì´ë‹¤.\n\nplt.plot(x,y,'o',label=r\"observed data: $(x_i,y_i)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n- ì¶”ì„¸ì„ ì„ ê·¸ë¦¬ëŠ” í–‰ìœ„ = \\((w_0,w_1)\\)ì„ ì„ íƒí•˜ëŠ”ì¼"
  },
  {
    "objectID": "posts/01wk-2.html#a.-1ë‹¨ê³„-ìµœì´ˆì˜-ì ì„ ",
    "href": "posts/01wk-2.html#a.-1ë‹¨ê³„-ìµœì´ˆì˜-ì ì„ ",
    "title": "01wk-2, 02wk-1: (íšŒê·€) â€“ íšŒê·€ëª¨í˜•, ì†ì‹¤í•¨ìˆ˜, íŒŒì´í† ì¹˜ë¥¼ ì´ìš©í•œ ì¶”ì •",
    "section": "A. 1ë‹¨ê³„ â€“ ìµœì´ˆì˜ ì ì„ ",
    "text": "A. 1ë‹¨ê³„ â€“ ìµœì´ˆì˜ ì ì„ \nğŸ—£ï¸(\n\nWhat = torch.tensor([[-5.0],[10.0]], requires_grad=True)\nWhat\n\ntensor([[-5.],\n        [10.]], requires_grad=True)\n\n\n\nyhat = X@What\n\n\n# plt.plot(x, y, 'o')\n# plt.plot(x, yhat, '--')\n\n\nì‹¤í–‰ì‹œí‚¤ë©´ error\nrequires_grad=Trueë¥¼ ì—†ì• ë©´ error ë°œìƒ X\nrequires_grad=True\n\në¯¸ë¶„ì´ í•„ìš”í•¨ì„ ë‚˜íƒ€ë‚´ëŠ” ì˜µì…˜\nì§€ê¸ˆì€ ì˜ë¯¸ë¥¼ ì •í™•í•˜ê²Œ ì•Œ ìˆ˜ ì—†ì§€ë§Œ í¸ì˜ìƒ ì´ë¦„ì„ ë¯¸ë¶„ê¼¬ë¦¬í‘œë¼ê³  ë¶€ë¥´ê² ìŒ\n\n\n\nWhat+1\n\ntensor([[-4.],\n        [11.]], grad_fn=&lt;AddBackward0&gt;)\n\n\n\nê¼¬ë¦¬í‘œê°€ ë°”ë€Œê¸´ í•˜ë‚˜ í° ì§€ì¥ì€ ì—†ìŒ\n\n\n# yhat\n\n\nyhatì„ ì‹¤í–‰ì‹œì¼œë„ ê³„ì‚°ì„ ì˜ ë˜ë‚˜ ê¼¬ë¦¬í‘œê°€ ìˆìŒ\nê¼¬ë¦¬í‘œ ë•Œë¬¸ì— ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ë©´ errorê°€ ë°œìƒ\ní•´ê²°ì±… (ê¼¬ë¦¬í‘œë¥¼ ì œê±°í•œë‹¤ê³  ìƒê°, ê¼¬ë¦¬í‘œê°€ ìˆìœ¼ë©´ ê³„ì‚°ì€ ê°€ëŠ¥í•˜ë‚˜ ê·¸ë˜í”„ ê·¸ë¦¬ê¸° ë¶ˆê°€ëŠ¥)\n\nRuntimeError: Canâ€™t call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.\n.data\n\n\n\n# yhat.detach()\n\n\n# yhat.data\n\n\nplt.plot(x, y, 'o')\nplt.plot(x, yhat.detach(), '--') # ê·¸ë¦¼ì„ ê·¸ë¦¬ê¸° ìœ„í•´ì„œ yhatì˜ ë¯¸ë¶„ê¼¬ë¦¬í‘œë¥¼ ì œê±°\n\n\n\n\n\n\n\n\n)ğŸ—£ï¸\nğŸ—£ï¸ ê·¸ëƒ¥ ì•„ë¬´ ì§ì„ ì„ ê·¸ìŒ (2ë‹¨ê³„ë§Œ ì˜ ë˜ë©´ ìƒê´€ X)\n\nWhat = torch.tensor([[-5.0],[10.0]])\nWhat\n\ntensor([[-5.],\n        [10.]])\n\n\n\nyhat = X@What \n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.data,'--')"
  },
  {
    "objectID": "posts/01wk-2.html#b.-2ë‹¨ê³„-update",
    "href": "posts/01wk-2.html#b.-2ë‹¨ê³„-update",
    "title": "01wk-2, 02wk-1: (íšŒê·€) â€“ íšŒê·€ëª¨í˜•, ì†ì‹¤í•¨ìˆ˜, íŒŒì´í† ì¹˜ë¥¼ ì´ìš©í•œ ì¶”ì •",
    "section": "B. 2ë‹¨ê³„ â€“ update",
    "text": "B. 2ë‹¨ê³„ â€“ update\n- â€™ì ë‹¹í•œ ì •ë„â€™ë¥¼ íŒë‹¨í•˜ê¸° ìœ„í•œ ì¥ì¹˜: loss function ë„ì…!\n\\[loss=\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2=\\sum_{i=1}^{n}(y_i-(\\hat{w}_0+\\hat{w}_1x_i))^2=({\\bf y}-{\\bf\\hat{y}})^\\top({\\bf y}-{\\bf\\hat{y}})=({\\bf y}-{\\bf X}{\\bf \\hat{W}})^\\top({\\bf y}-{\\bf X}{\\bf \\hat{W}})\\]\nğŸ—£ï¸ lossëŠ” \\((\\hat{w}_0, \\hat{w}_1)\\)ì„ ì…ë ¥ìœ¼ë¡œ ë°›ìŒ. loss ê°’ì„ ìµœì†Œë¡œ ë§Œë“œëŠ” \\((\\hat{w}_0, \\hat{w}_1)\\)ì„ ì°¾ìœ¼ë©´ ë¨.\n- loss í•¨ìˆ˜ì˜ íŠ¹ì§•: ìœ„ ê·¸ë¦¼ì˜ ì£¼í™©ìƒ‰ ì ì„ ì´ â€˜ì ë‹¹í•  ìˆ˜ë¡â€™ lossê°’ì´ ì‘ë‹¤.\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat)\n\n\n\n\n\n\n\n\n\nloss = torch.sum((y-yhat)**2)\nloss\n\ntensor(8587.6875)\n\n\n- ìš°ë¦¬ì˜ ëª©í‘œ: ì´ loss(=8587.6275)ì„ ë” ì¤„ì´ì.\n\nê¶ê·¹ì ìœ¼ë¡œëŠ” ì•„ì˜ˆ ëª¨ë“  ì¡°í•© \\((\\hat{w}_0,\\hat{w}_1)\\)ì— ëŒ€í•˜ì—¬ ê°€ì¥ ì‘ì€ lossë¥¼ ì°¾ìœ¼ë©´ ì¢‹ê² ë‹¤.\n\n- ë¬¸ì œì˜ ì¹˜í™˜: ìƒê°í•´ë³´ë‹ˆê¹Œ ìš°ë¦¬ì˜ ë¬¸ì œëŠ” ì•„ë˜ì™€ ê°™ì´ ìˆ˜í•™ì ìœ¼ë¡œ ë‹¨ìˆœí™” ë˜ì—ˆë‹¤.\n\nê°€ì¥ ì ë‹¹í•œ ì£¼í™©ìƒ‰ ì„ ì„ ì°¾ì \\(\\to\\) \\(loss(\\hat{w}_0,\\hat{w}_1)\\)ë¥¼ ìµœì†Œë¡œí•˜ëŠ” \\((\\hat{w}_0,\\hat{w}_1)\\)ì˜ ê°’ì„ ì°¾ì.\n\n- ìˆ˜ì •ëœ ëª©í‘œ: \\(loss(\\hat{w}_0,\\hat{w}_1)\\)ë¥¼ ìµœì†Œë¡œ í•˜ëŠ” \\((\\hat{w}_0,\\hat{w}_1)\\)ì„ êµ¬í•˜ë¼.\n\në‹¨ìˆœí•œ ìˆ˜í•™ë¬¸ì œê°€ ë˜ì—ˆë‹¤. ì´ê²ƒì€ ë§ˆì¹˜ \\(f(x,y)\\)ë¥¼ ìµœì†Œí™”í•˜ëŠ” \\((x,y)\\)ë¥¼ ì°¾ìœ¼ë¼ëŠ” ê²ƒì„.\ní•¨ìˆ˜ì˜ ìµœëŒ€ê°’ í˜¹ì€ ìµœì†Œê°’ì„ ì»´í“¨í„°ë¥¼ ì´ìš©í•˜ì—¬ ì°¾ëŠ”ê²ƒì„ â€œìµœì í™”â€ë¼ê³  í•˜ë©° ì´ëŠ” ì‚°ê³µêµìˆ˜ë‹˜ë“¤ì´ ê°€ì¥ ì˜í•˜ëŠ” ë¶„ì•¼ì„. (ì‚°ê³µêµìˆ˜ë‹˜ë“¤ì—ê²Œ ë¶€íƒí•˜ë©´ ì˜í•´ì¤Œ, ì‚°ê³µêµìˆ˜ë‹˜ë“¤ì€ ë³´í†µ ìµœì í™”í•´ì„œ ì–´ë””ì— ì“¸ì§€ë³´ë‹¤ ìµœì í™” ìì²´ì— ë” ê´€ì‹¬ì„ ê°€ì§€ê³  ì—°êµ¬í•˜ì‹¬)\nìµœì í™”ë¥¼ í•˜ëŠ” ë°©ë²•? ê²½ì‚¬í•˜ê°•ë²•\n\n# ê²½ì‚¬í•˜ê°•ë²• ì•„ì´ë””ì–´ (1ì°¨ì›)\n\nì„ì˜ì˜ ì ì„ ì°ëŠ”ë‹¤.\nê·¸ ì ì—ì„œ ìˆœê°„ê¸°ìš¸ê¸°ë¥¼ êµ¬í•œë‹¤. (ì ‘ì„ ) &lt;â€“ ë¯¸ë¶„\nìˆœê°„ê¸°ìš¸ê¸°(=ë¯¸ë¶„ê³„ìˆ˜)ì˜ ë¶€í˜¸ë¥¼ ì‚´í´ë³´ê³  ë¶€í˜¸ì™€ ë°˜ëŒ€ë°©í–¥ìœ¼ë¡œ ì›€ì§ì¸ë‹¤.\n\n\níŒ: ê¸°ìš¸ê¸°ì˜ ì ˆëŒ€ê°’ í¬ê¸°ì™€ ë¹„ë¡€í•˜ì—¬ ë³´í­(=ì›€ì§ì´ëŠ” ì •ë„)ì„ ì¡°ì ˆí•œë‹¤. \\(\\to\\) \\(\\alpha\\)ë¥¼ ë„ì…\n\n\nìµœì¢…ìˆ˜ì‹: \\(\\hat{w} \\leftarrow \\hat{w} - \\alpha \\times \\frac{\\partial}{\\partial w}loss(w)\\)\n\n#\nğŸ—£ï¸(\n\në³´í­: step size\ní•¨ìˆ˜ë¥¼ ìµœê³ ì°¨í•­ì´ ì–‘ìˆ˜ì¸ 2ì°¨ í•¨ìˆ˜ë¡œ ìƒê°í•˜ë©´ ì´í•´í•˜ê¸° ì‰¬ì›€\n\nxì—ì„œ aë§Œí¼ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì´ë™: x + a\nxì—ì„œ aë§Œí¼ ì™¼ìª½ìœ¼ë¡œ ì´ë™: x - a\në¯¸ë¶„ê³„ìˆ˜ê°€ 0ì¸ìª½ìœ¼ë¡œ ì›€ì§ì¼ ë•Œ\n\nxê°€ ì˜¤ë¥¸ìª½ì— ìˆìœ¼ë©´ ë¯¸ë¶„ê³„ìˆ˜ &gt; 0\nxê°€ ì™¼ìª½ì— ìˆìœ¼ë©´ ë¯¸ë¶„ê³„ìˆ˜ &lt; 0\n\në¯¸ë¶„ê³„ìˆ˜ê°€ 0ì¸ìª½ê³¼ ê°€ê¹Œìš¸ìˆ˜ë¡ ì ‘ì„  ê¸°ìš¸ê¸°ì˜ ì ˆëŒ€ê°’ì´ ì‘ì•„ì§ -&gt; \\(\\alpha\\)ë¡œ ì¡°ì ˆ\n\n\\(\\alpha\\)ê°€ ë„ˆë¬´ ì‘ìœ¼ë©´ ìˆ˜ë ´ ì†ë„ê°€ ëŠë¦´ ìˆ˜ ìˆê³ , ë„ˆë¬´ í¬ë©´ ìˆ˜ë ´ì„ ì•ˆí•  ìˆ˜ ìˆìŒ\n\nì˜ˆì‹œ) \\(f(x) = x^2\\) ì—ì„œ \\(x=2\\)ì¼ ë•Œ \\(\\alpha = 1\\)ì´ë©´ \\(x\\)ëŠ” \\(-2\\)ì™€ \\(2\\)ë§Œ ì™”ë‹¤ê°”ë‹¤ í•¨\n\n\n)ğŸ—£ï¸\n# ê²½ì‚¬í•˜ê°•ë²• ì•„ì´ë””ì–´ (2ì°¨ì›)\n\n\nì„ì˜ì˜ ì ì„ ì°ëŠ”ë‹¤.\nê·¸ ì ì—ì„œ ìˆœê°„ê¸°ìš¸ê¸°ë¥¼ êµ¬í•œë‹¤. (ì ‘í‰ë©´) &lt;â€“ í¸ë¯¸ë¶„\nìˆœê°„ê¸°ìš¸ê¸°(=ë¯¸ë¶„ê³„ìˆ˜)ì˜ ë¶€í˜¸ë¥¼ ì‚´í´ë³´ê³  ë¶€í˜¸ì™€ ë°˜ëŒ€ë°©í–¥ìœ¼ë¡œ ê°ê° ì›€ì§ì¸ë‹¤.\n\n\níŒ: ì—¬ê¸°ì„œë„ ê¸°ìš¸ê¸°ì˜ ì ˆëŒ€ê°’ í¬ê¸°ì™€ ë¹„ë¡€í•˜ì—¬ ë³´í­(=ì›€ì§ì´ëŠ” ì •ë„)ì„ ê°ê° ì¡°ì ˆí•œë‹¤. \\(\\to\\) \\(\\alpha\\)ë¥¼ ë„ì….\n\n#\nğŸ—£ï¸(\n\nì—¬ê¸°ì„œ ì„ì˜ì˜ ì ì€ 2ì°¨ì›\ní¸ë¯¸ë¶„: í•˜ë‚˜ë§Œ ë³€ìˆ˜ë¡œ ë³´ê³  ë‚˜ë¨¸ì§€ ê³ ì •\n\nì´í›„ 1ì°¨ì› ë°©ì‹ê³¼ ë™ì¼\nì–´ë–¤ ë°©í–¥(ì™¼ìª½, ì˜¤ë¥¸ìª½)ìœ¼ë¡œ ì–¼ë§ˆë‚˜ ê°ˆ ì§€(\\(\\alpha\\))\n\n\n)ğŸ—£ï¸\n- ê²½ì‚¬í•˜ê°•ë²• = lossë¥¼ ì¤„ì´ë„ë¡ \\({\\bf \\hat{W}}\\)ë¥¼ ê°œì„ í•˜ëŠ” ë°©ë²•\n\nì—…ë°ì´íŠ¸ ê³µì‹: ìˆ˜ì •ê°’ = ì›ë˜ê°’ - \\(\\alpha\\) \\(\\times\\) ê¸°ìš¸ì–´ì§„í¬ê¸°(=ë¯¸ë¶„ê³„ìˆ˜)\nì—¬ê¸°ì—ì„œ \\(\\alpha\\)ëŠ” ì „ì²´ì ì¸ ë³´í­ì˜ í¬ê¸°ë¥¼ ê²°ì •í•œë‹¤. ì¦‰ \\(\\alpha\\)ê°’ì´ í´ìˆ˜ë¡ í•œë²ˆì˜ updateì— ì›€ì§ì´ëŠ” ì–‘ì´ í¬ë‹¤.\n\nğŸ—£ï¸ \\(\\alpha\\)ë¥¼ MLì—ì„œëŠ” í•™ìŠµë¥ ì´ë¼ê³  í•¨\n- lossëŠ” \\(\\hat{\\bf W} =\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\) ì— ë”°ë¼ì„œ ê°’ì´ ë°”ë€ŒëŠ” í•¨ìˆ˜ë¡œ í•´ì„ê°€ëŠ¥í•˜ê³  êµ¬ì²´ì ì¸ í˜•íƒœëŠ” ì•„ë˜ì™€ ê°™ìŒ.\n\\[ loss(\\hat{w}_0,\\hat{w}_1) := loss(\\hat{\\bf W})=\\sum_{i=1}^{n}(y_i-(\\hat{w}_0+\\hat{w}_1x_i))^2=({\\bf y}-{\\bf X}{\\bf \\hat{W}})^\\top({\\bf y}-{\\bf X}{\\bf \\hat{W}})\\]\në”°ë¼ì„œ êµ¬í•˜ê³  ì‹¶ì€ê²ƒì€ ì•„ë˜ì™€ ê°™ìŒ\n\\[\\hat{\\bf W}^{LSE} = \\underset{\\bf \\hat{W}}{\\operatorname{argmin}} ~ loss(\\hat{\\bf W})\\]\n\n\n\n\n\n\nWarning\n\n\n\nì•„ë˜ì˜ ìˆ˜ì‹\n\\[\\hat{\\bf W}^{LSE} = \\underset{\\bf \\hat{W}}{\\operatorname{argmin}} ~ loss(\\hat{\\bf W})\\]\nì€ ì•„ë˜ì™€ ê°™ì´ í‘œí˜„í•´ë„ ë¬´ë°©í•©ë‹ˆë‹¤.\n\\[\\hat{\\bf W} = \\underset{\\bf W}{\\operatorname{argmin}} ~ loss({\\bf W})\\]\në§ˆì¹˜ í•¨ìˆ˜ \\(f(\\hat{x})=({\\hat x}-1)^2\\) ì„ \\(f(x)=(x-1)^2\\) ì´ë¼ê³  í‘œí˜„í•  ìˆ˜ ìˆëŠ” ê²ƒ ì²˜ëŸ¼ìš”..\n\n\nì—¬ê¸°ê¹Œì§€ 01wk-2ì—ì„œ ìˆ˜ì—…í–ˆìŠµë‹ˆë‹¤~\n\nì—¬ê¸°ë¶€í„°ëŠ” 02wk-1ì—ì„œ..\n# ì§€ë‚œì‹œê°„ ë³µìŠµ\n\n# x,X,W,y // X = [1 x], W = [w0, w1]' # íšŒê·€ë¶„ì„ì—ì„œëŠ” W=Î²\n# íšŒê·€ëª¨í˜•: y=X@W+Ïµ = X@Î²+Ïµ\n# true: E(y)=X@W\n# observed: (x,y)\n# estimated W = What = [w0hat, w1hat]' &lt;-- ì•„ë¬´ê°’ì´ë‚˜ë„£ì—ˆìŒ.. \n# estimated y = yhat = X@What = X@Î²Ì‚ \n# loss = yhatì´ë‘ yë‘ ì–¼ë§ˆë‚˜ ë¹„ìŠ·í•œì§€ = sum((y-yhat)^2)\n# (x,y) ë³´ê³  ìµœì ì˜ ì„ ë¶„ì„ ê·¸ë¦¬ëŠ”ê²ƒ = lossë¥¼ ê°€ì¥ ì‘ê²Œ ë§Œë“œëŠ” What = [w0hat, w1hat] ë¥¼ ì°¾ëŠ”ê²ƒ\n# ì „ëµ: (1) ì•„ë¬´ Whatë‚˜ ì°ëŠ”ë‹¤ (2) ê·¸ê±°ë³´ë‹¤ ë” ë‚˜ì€ Whatì„ ì°¾ëŠ”ë‹¤. (3) 1-2ë¥¼ ë°˜ë³µí•œë‹¤. \n# ì „ëµ2ê°€ ì–´ë ¤ìš´ë°, ì´ë¥¼ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì´ ê²½ì‚¬í•˜ê°•ë²• \n# ê²½ì‚¬í•˜ê°•ë²• ì•Œê³ ë¦¬ì¦˜: ë”ë‚˜ì€What = ì›ë˜What - 0.1*ë¯¸ë¶„ê°’\n\n\nWhat = torch.tensor([[-5.0],[10.0]])\nWhat\n\ntensor([[-5.],\n        [10.]])\n\n\n\nyhat = X@What \nplt.plot(x,y,'o')\nplt.plot(x,yhat,'--')\n\n\n\n\n\n\n\n\n\nloss = torch.sum((y-yhat)**2)\nloss\n\ntensor(8587.6875)\n\n\në³µìŠµë~\n#\n- ë” ë‚˜ì€ ì„ ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ê¸° ìœ„í•´ì„œëŠ” ê³µì‹ â€œë”ë‚˜ì€What = ì›ë˜What - 0.1*ë¯¸ë¶„ê°’â€ ë¥¼ ì ìš©í•´ì•¼í•˜ê³  ì´ë¥¼ ìœ„í•´ì„œëŠ” ë¯¸ë¶„ê°’ì„ ê³„ì‚°í•  ìˆ˜ ìˆì–´ì•¼ í•¨.\n\n\n\n\n\n\nImportant\n\n\n\nê²½ì‚¬í•˜ê°•ë²•ì„ ì¢€ ë” ì—„ë°€í•˜ê²Œ ì¨ë³´ì. ê²½ì‚¬í•˜ê°•ë²•ì€ \\(loss(\\hat{\\bf W})\\)ë¥¼ ìµœì†Œë¡œ ë§Œë“œëŠ” \\(\\hat{\\bf W}\\)ë¥¼ ì»´í“¨í„°ë¡œ êµ¬í•˜ëŠ” ë°©ë²•ì¸ë°, êµ¬ì²´ì ìœ¼ë¡œëŠ” ì•„ë˜ì™€ ê°™ë‹¤.\n1. ì„ì˜ì˜ ì  \\(\\hat{\\bf W}\\)ë¥¼ ì°ëŠ”ë‹¤.\n2. ê·¸ ì ì—ì„œ ìˆœê°„ê¸°ìš¸ê¸°ë¥¼ êµ¬í•œë‹¤. ì¦‰ \\(\\left.\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})\\right|_{{\\bf W}=\\hat{\\bf W}}\\) ë¥¼ ê³„ì‚°í•œë‹¤.\n3. \\(\\hat{\\bf W}\\)ì—ì„œì˜ ìˆœê°„ê¸°ìš¸ê¸°ì˜ ë¶€í˜¸ë¥¼ ì‚´í´ë³´ê³  ë¶€í˜¸ì™€ ë°˜ëŒ€ë°©í–¥ìœ¼ë¡œ ì›€ì§ì¸ë‹¤. ì´ë•Œ ê¸°ìš¸ê¸°ì˜ ì ˆëŒ€ê°’ í¬ê¸°ì™€ ë¹„ë¡€í•˜ì—¬ ë³´í­(=ì›€ì§ì´ëŠ” ì •ë„)ì„ ê°ê° ì¡°ì ˆí•œë‹¤. ì¦‰ ì•„ë˜ì˜ ìˆ˜ì‹ì— ë”°ë¼ ì—…ë°ì´íŠ¸ í•œë‹¤.\n\\[\\hat{\\bf W} \\leftarrow \\hat{\\bf W} - \\alpha \\times \\left.\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})\\right|_{{\\bf W}=\\hat{\\bf W}}\\]\nì—¬ê¸°ì—ì„œ ë§¨ ë§ˆì§€ë§‰ ìˆ˜ì‹ì„ ê°„ë‹¨í•˜ê²Œ ì“´ ê²ƒì´ ë”ë‚˜ì€What = ì›ë˜What - 0.1*ë¯¸ë¶„ê°’ ì´ë‹¤.\n\n\n- ë¯¸ë¶„ê°’ì„ ê³„ì‚°í•˜ëŠ” ë°©ë²•1\n\n# ì†ì‹¤ 8587.6875 ë¥¼ ê³„ì‚°í•˜ëŠ” ë˜ ë‹¤ë¥¸ ë°©ì‹\ndef l(w0,w1):\n    yhat = w0 + w1*x\n    return torch.sum((y-yhat)**2)\n\n\nl(-5,10)\n\ntensor(8587.6875)\n\n\nğŸ—£ï¸(\n\nêµ³ì´ í•¨ìˆ˜ë¥¼ ë§Œë“  ì´ìœ : ë¯¸ë¶„í•˜ë ¤ê³ \ní¸ë¯¸ë¶„ êµ¬í˜„\n\nl(-5,10)\n(l(w0+h,w1) - l(w0,w1))/h: ë„í•¨ìˆ˜\n\n\n)ğŸ—£ï¸\n\nh=0.001\nprint((l(-5+h,10) - l(-5,10))/h)\nprint((l(-5,10+h) - l(-5,10))/h)\n\ntensor(-1341.7968)\ntensor(1190.4297)\n\n\nì¼ë‹¨ ì´ê±°ë¡œ ì—…ë°ì´íŠ¸í•´ë³¼ê¹Œ?\n\n# ë”ë‚˜ì€What = ì›ë˜What - 0.1*ë¯¸ë¶„ê°’\n# [-5,10] - 0.001 * [-1341.7968,1190.4297]\n\n\nsssss = What - 0.001 * torch.tensor([[-1341.7968],[1190.4297]])\nsssss\n\ntensor([[-3.6582],\n        [ 8.8096]])\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What,'-') # ì›ë˜What: ì£¼í™©ìƒ‰\nplt.plot(x,X@sssss,'-') # ë”ë‚˜ì€What: ì´ˆë¡ìƒ‰\n\n\n\n\n\n\n\n\n\nì˜ ëœ ê²ƒ ê°™ê¸´í•œë°..\në¯¸ë¶„êµ¬í•˜ëŠ”ê²Œ ë„ˆë¬´ ì–´ë ¤ì›Œ..\në‹¤ë¥¸ ë°©ë²• ì—†ì„ê¹Œ?\n\n\n\n\n\n\n\nImportant\n\n\n\nì‚¬ì‹¤ ì´ ë°©ë²•ì€\n\n\\(\\frac{\\partial}{\\partial w_0}loss(w_0,w_1) \\approx \\frac{loss(w_0+h,w_1)-loss(w_0,w_1)}{h}\\)\n\\(\\frac{\\partial}{\\partial w_1}loss(w_0,w_1) \\approx \\frac{loss(w_0,w_1+h)-loss(w_0,w_1)}{h}\\)\n\nì´ ê³„ì‚°ì„ ì´ìš©í•˜ì—¬\n\\[\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W}):= \\begin{bmatrix} \\frac{\\partial}{\\partial w_0} \\\\ \\frac{\\partial}{\\partial w_1}\\end{bmatrix}loss({\\bf W}) =  \\begin{bmatrix} \\frac{\\partial}{\\partial w_0}loss({\\bf W}) \\\\ \\frac{\\partial}{\\partial w_1}loss({\\bf W})\\end{bmatrix}  =  \\begin{bmatrix} \\frac{\\partial}{\\partial w_0}loss(w_0,w_1) \\\\ \\frac{\\partial}{\\partial w_1}loss(w_0,w_1)\\end{bmatrix}\\]\në¥¼ ê³„ì‚°í•œ ê²ƒì´ë¼ ë³¼ ìˆ˜ ìˆì£ \n\n\n- ë¯¸ë¶„ê°’ì„ ê³„ì‚°í•˜ëŠ” ë°©ë²•2\n\n## ì•½ê°„ì˜ ì§€ì‹ì´ í•„ìš”í•¨. \n# loss = (y-XWhat)'(y-XWhat)\n# = (y'-What'X')(y-XWhat)\n# = y'y-y'XWhat -What'X'y + What'X'XWhat \n# lossë¥¼ Whatìœ¼ë¡œ ë¯¸ë¶„\n# loss' = -X'y - X'y + 2X'XWhat\n\nâ“ í–‰ë ¬ ë¯¸ë¶„ ë³µìŠµ í•„ìš”\n\n-2*X.T@y + 2*X.T@X@What\n\ntensor([[-1342.2524],\n        [ 1188.9302]])\n\n\nğŸ—£ï¸ ì•½ê°„ì˜ ì˜¤ì°¨ëŠ” ìˆì§€ë§Œ ìœ„ì™€ ë¹„ìŠ· (ê·¸ëŸ¬ë‚˜ ë°©ë²•1, ë°©ë²•2 ë§ê³  ë‹¤ë¥¸ ë°©ë²•ì„ ì“°ê³  ì‹¶ìŒ)\n\n\n\n\n\n\nImportant\n\n\n\nì´ ë°©ë²•ì€ \\(loss({\\bf W})\\)ì˜ ë¯¸ë¶„ì„ êµ¬í• ìˆ˜ ìˆì–´ì•¼ ì‚¬ìš©ê°€ëŠ¥í•©ë‹ˆë‹¤. ì¦‰\n\\[\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})= -2{\\bf X}^\\top {\\bf y} + 2{\\bf X}^\\top {\\bf X}{\\bf W}\\]\në¥¼ ê³„ì‚°í•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n\n\n- ë¯¸ë¶„ê°’ì„ ê³„ì‚°í•˜ëŠ” ë°©ë²•3 â€“ ì´ íŒ¨í„´ì„ ì™¸ìš°ì„¸ì—¬\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nWhat\n\ntensor([[-5.],\n        [10.]], requires_grad=True)\n\n\n\nyhat = X@What\nloss = torch.sum((y-yhat)**2)\nloss\n\ntensor(8587.6875, grad_fn=&lt;SumBackward0&gt;)\n\n\nğŸ—£ï¸ ê¼¬ë¦¬í‘œê°€ ìˆê¸´í•˜ì§€ë§Œ ê²°ê³¼ëŠ” ìœ„ì™€ ë™ì¼\n\nloss.backward() # lossë¥¼ ë¯¸ë¶„í•˜ë¼.. ê¼¬ë¦¬í‘œê°€ ìˆê²Œ í•œ Whatìœ¼ë¡œ.. \n\nğŸ—£ï¸(\n\nlossë¥¼ Whatìœ¼ë¡œ ë¯¸ë¶„\nì¼ë°˜ì ìœ¼ë¡œ ë¯¸ë¶„ì„ í•˜ë©´ ë„í•¨ìˆ˜ê°€ ë‚˜ì˜¤ì§€ë§Œ, ì´ ê²½ìš°ëŠ” ë„í•¨ìˆ˜ì—ì„œ í˜„ì¬ Whatê°’ì„ ëŒ€ì…í•œ ê²°ê³¼ê°€ ë‚˜ì˜´\nì •í™•íˆ ë§í•˜ë©´ Whatì— í•´ë‹¹í•˜ëŠ” ì ‘ì„ ì˜ ê¸°ìš¸ê¸°\nì‹¤í–‰í•´ë„ ì‹¤í–‰ê²°ê³¼ëŠ” ë‚˜ì˜¤ì§€ ì•ŠìŒ. ê²°ê³¼ëŠ” What.gradì— ì €ì¥ë˜ì–´ ìˆìŒ\n\n)ğŸ—£ï¸\n\nWhat.grad\n\ntensor([[-1342.2524],\n        [ 1188.9305]])\n\n\n- ìœ„ì˜ ì½”ë“œë¥¼ ë‹¤ì‹œ ë³µìŠµí•´ë³´ì.\nâ€“ loss.backward()ì‹¤í–‰ì „ â€“\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nyhat = X@What\nloss = torch.sum((y-yhat)**2)\n\n\nWhat.data, What.grad\n\n(tensor([[-5.],\n         [10.]]),\n None)\n\n\nğŸ—£ï¸ .backward()ë¥¼ ì‹¤í–‰í•˜ì§€ ì•Šì•„ì„œ .gradì— ì•„ë¬´ ê°’ë„ ì—†ìŒ(Noneìœ¼ë¡œ ì´ˆê¸°í™” ë¨)\nâ€“ loss.backward()ì‹¤í–‰í›„ â€“\n\nloss.backward()\n\n\nWhat.data, What.grad\n\n(tensor([[-5.],\n         [10.]]),\n tensor([[-1342.2524],\n         [ 1188.9305]]))\n\n\nğŸ—£ï¸(\n\n.backward()ë¥¼ ì‹¤í–‰í•˜ë‹ˆ .gradì— ê¸°ìš¸ê¸° ê°’ì´ ê³„ì‚°ë˜ì–´ ì—…ë°ì´íŠ¸ ë¨\nloss.backward(): What.grad &lt;- Whatì—ì„œ ë¯¸ë¶„ê°’ ì¸ì¤„ ì•Œì•˜ìœ¼ë‚˜ ì‚¬ì‹¤ì€\nloss.backward(): What.grad &lt;- What.grad + Whatì—ì„œ ë¯¸ë¶„ê°’ (ì¦‰, ëˆ„ì ì„ ì‹œì¼œì„œ ë”í•¨)\n\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\n\n\nyhat = X@What\nloss = torch.sum((y-yhat)**2)\nloss.backward()\n\n\nWhat.data, What.grad\n\n(tensor([[-5.],\n         [10.]]),\n tensor([[-1342.2524],\n         [ 1188.9305]]))\n\n\n\nyhat = X@What\nloss = torch.sum((y-yhat)**2)\nloss.backward()\n\n\nWhat.data, What.grad\n\n(tensor([[-5.],\n         [10.]]),\n tensor([[-2684.5049],\n         [ 2377.8611]]))\n\n\n\në‘ ë°°ê°€ ë¨\nì™œ?\n\nì‚°ê³µ: ì•Œê³ ë¦¬ì¦˜ ìƒì—ì„œëŠ” What.gradì˜ ê°’ì€ loss.backward()ë¥¼ í• ë•Œë§ˆë‹¤ ì´ˆê¸°í™”ê°€ ë§ìŒ (ì´ë¡ ì ìœ¼ë¡œëŠ” ì´ê²Œ ë§ìŒ)\nì»´ê³µ: ê·¸ëŸ¬ë©´ ë‚˜ì¤‘ì— ê³„ì‚° íš¨ìœ¨ì´ ì•ˆ ì¢‹ì•„ì§ (ì›¬ë§Œí•˜ë©´ ê³„ì‚°í•œ ë¯¸ë¶„ê°’ì„ ê°–ê³  ìˆê³  ì‹¶ìŒ, í•„ìš” ì—†ìœ¼ë©´ ë”°ë¡œ ì´ˆê¸°í™”í•˜ë©´ ë¨)\ní†µê³„: ìµœì í™”ì™€ ë¯¸ë¶„ ë¹¨ë¦¬í•˜ëŠ” ê²ƒì— ê´€ì‹¬ X\n\n\n)ğŸ—£ï¸\nâœï¸ ì´í›„ ì›í™œí•œ ì½”ë“œ ì‹¤í–‰ì„ ìœ„í•œ ì½”ë“œ (ì˜ë¯¸X)\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nyhat = X@What\nloss = torch.sum((y-yhat)**2)\n\nWhat.data, What.grad\n\nloss.backward()\n\nWhat.data, What.grad\n\n(tensor([[-5.],\n         [10.]]),\n tensor([[-1342.2524],\n         [ 1188.9305]]))\n\n\n# 1íšŒ ì—…ë°ì´íŠ¸ ê³¼ì •ì„ ì°¨ê·¼ì°¨ê·¼ ì‹œê°í™”í•˜ë©° ì •ë¦¬í•´ë³´ì.\n\nalpha = 0.001 \nprint(f\"{What.data} -- ìˆ˜ì •ì „\")\nprint(f\"{-alpha*What.grad} -- ìˆ˜ì •í•˜ëŠ”í­\")\nprint(f\"{What.data-alpha*What.grad} -- ìˆ˜ì •í›„\")\nprint(f\"{torch.tensor([[2.5],[4]])} -- ì°¸ê°’(ì´ê±´ ë¹„ë°€~~)\")\n\ntensor([[-5.],\n        [10.]]) -- ìˆ˜ì •ì „\ntensor([[ 1.3423],\n        [-1.1889]]) -- ìˆ˜ì •í•˜ëŠ”í­\ntensor([[-3.6577],\n        [ 8.8111]]) -- ìˆ˜ì •í›„\ntensor([[2.5000],\n        [4.0000]]) -- ì°¸ê°’(ì´ê±´ ë¹„ë°€~~)\n\n\nğŸ—£ï¸(\n\n\\(\\alpha\\)ë¥¼ 0.001ë¡œ ì¡ì€ ì´ìœ : ë¯¸ë¶„ê°’ì´ 1000 ë‹¨ìœ„ë¡œ ë‚˜ì™€ì„œ ê·¸ëŒ€ë¡œ ë„£ìœ¼ë©´ ì›í•˜ëŠ” ê²°ê³¼ê°€ ì•ˆ ë‚˜ì˜¬ ê²ƒ ê°™ìŒ\n\nì˜ ìˆ˜ë ´ë ë•Œê¹Œì§€ ì‹œí–‰ì°©ì˜¤ë¥¼ ê²ªìœ¼ë©° í•´ë´ì•¼ í•¨\n\nìˆ˜ì •í•˜ëŠ” í­: ìœ„ ê·¸ë˜í”„ì—ì„œ ì£¼í™©ìƒ‰ ì„ \nìˆ˜ì • í›„: ìœ„ ê·¸ë˜í”„ì—ì„œ ì´ˆë¡ìƒ‰ ì„ \nìˆ˜ì • ì „ë³´ë‹¤ ìˆ˜ì • í›„ê°€ ì°¸ê°’ì— ê°€ê¹Œìš°ë¯€ë¡œ ì˜¬ë°”ë¥¸ ë°©í–¥ì„ ì§„í–‰ë˜ê³  ìˆìŒì„ ì•Œ ìˆ˜ ìˆìŒ\n\n)ğŸ—£ï¸\n\nWbefore = What.data\nWafter = What.data - alpha * What.grad \nWbefore, Wafter\n\n(tensor([[-5.],\n         [10.]]),\n tensor([[-3.6577],\n         [ 8.8111]]))\n\n\n\nplt.plot(x,y,'o',label=r'observed data')\nplt.plot(x,X@Wbefore,'--', label=r\"$\\hat{\\bf y}_{before}={\\bf X}@\\hat{\\bf W}_{before}$\")\nplt.plot(x,X@Wafter,'--', label=r\"$\\hat{\\bf y}_{after}={\\bf X}@\\hat{\\bf W}_{after}$\")\nplt.legend()\n\n\n\n\n\n\n\n\n#"
  },
  {
    "objectID": "posts/01wk-2.html#c.-3ë‹¨ê³„-iteration-learn-estimate-bfhat-w",
    "href": "posts/01wk-2.html#c.-3ë‹¨ê³„-iteration-learn-estimate-bfhat-w",
    "title": "01wk-2, 02wk-1: (íšŒê·€) â€“ íšŒê·€ëª¨í˜•, ì†ì‹¤í•¨ìˆ˜, íŒŒì´í† ì¹˜ë¥¼ ì´ìš©í•œ ì¶”ì •",
    "section": "C. 3ë‹¨ê³„ â€“ iteration (=learn = estimate \\(\\bf{\\hat W}\\))",
    "text": "C. 3ë‹¨ê³„ â€“ iteration (=learn = estimate \\(\\bf{\\hat W}\\))\n- ì´ì œ 1ë‹¨ê³„ì™€ 2ë‹¨ê³„ë¥¼ ë°˜ë³µë§Œí•˜ë©´ëœë‹¤. ê·¸ë˜ì„œ ì•„ë˜ì™€ ê°™ì€ ì½”ë“œë¥¼ ì‘ì„±í•˜ë©´ ë  ê²ƒ ê°™ì€ë°â€¦\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True) # ìµœì´ˆì˜ ì§ì„ ì„ ë§Œë“œëŠ” ê°’\nfor epoc in range(30):\n    yhat = X@What \n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - 0.001 * What.grad\nëŒë ¤ë³´ë©´ ì˜ ì•ˆëœë‹¤.\nğŸ—£ï¸ ì›ë˜ ì² ìëŠ” epochì´ì§€ë§Œ í¸ì˜ìƒ epocìœ¼ë¡œ ì‘ì„±, ì˜ ë˜ê¸° ìœ„í•´ì„œëŠ” ë§ˆì§€ë§‰ì— ì´ˆê¸°í™”ë¥¼ í•´ì¤˜ì•¼ í•¨\n- ì•„ë˜ì™€ ê°™ì´ í•´ì•¼í•œë‹¤.\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True) # ìµœì´ˆì˜ ì§ì„ ì„ ë§Œë“œëŠ” ê°’\nfor epoc in range(30):\n    yhat = X@What \n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - 0.001 * What.grad\n    What.grad = None \n\n\nplt.plot(x,y,'o',label=r\"observed: $(x_i,y_i)$\")\nplt.plot(x,X@What.data,'--o', label=r\"estimated: $(x_i,\\hat{y}_i)$ -- after 30 iterations (=epochs)\", alpha=0.4 )\nplt.legend()\n\n\n\n\n\n\n\n\n- ì™œ? loss.backward() ëŠ” ì•„ë˜ì˜ ì—­í• ì„ í•˜ëŠ”ê²ƒ ì²˜ëŸ¼ ì´í•´ë˜ì—ˆì§€ë§Œ\n\nWhat.grad \\(\\leftarrow\\) Whatì—ì„œë¯¸ë¶„ê°’\n\nì‹¤ì œë¡œëŠ” ì•„ë˜ì˜ ì—­í• ì„ ìˆ˜í–‰í•˜ê¸° ë•Œë¬¸ì´ë‹¤. (ì»´í“¨í„°ê³µí•™ì ì¸ ì´ìœ ë¡œ..)\n\nWhat.grad \\(\\leftarrow\\) What.grad + Whatì—ì„œë¯¸ë¶„ê°’\n\n\n\n\n\n\n\nNote\n\n\n\nWhat.grad \\(\\leftarrow\\) What.grad + Whatì—ì„œë¯¸ë¶„ê°’ ì„ì„ í™•ì¸í•˜ê¸° ìœ„í•´ì„œ.. ì•½ê°„ì˜ í…ŒìŠ¤íŠ¸ë¥¼ í–ˆìŠµë‹ˆë‹¤.\në¨¼ì €\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True) # ìµœì´ˆì˜ ì§ì„ ì„ ë§Œë“œëŠ” ê°’\nprint(What.data)\nprint(What.grad)\në¥¼ í™•ì¸í•œë’¤ ì•„ë˜ë¥¼ ë°˜ë³µì‹¤í–‰í•´ë´¤ì„ë•Œ\nyhat = X@What \nloss = torch.sum((y-yhat)**2)\nloss.backward() # \nprint(What.data)\nprint(What.grad)\nWhat.dataì™€ What.grad ê°’ì´ ê³„ì† ì¼ì •í•˜ê²Œ ë‚˜ì˜¨ë‹¤ë©´\n\nWhat.grad \\(\\leftarrow\\) Whatì—ì„œë¯¸ë¶„ê°’\n\nì´ì™€ ê°™ì€ ê³„ì‚°ì´ ì§„í–‰ë˜ëŠ” ê²ƒì´ê² ê³ , What.gradì˜ ê°’ì´ ìê¾¸ ì»¤ì§„ë‹¤ë©´\n\nWhat.grad \\(\\leftarrow\\) What.grad + Whatì—ì„œë¯¸ë¶„ê°’\n\nì´ì™€ ê°™ì€ ê³„ì‚°ì´ ì§„í–‰ë˜ëŠ” ê²ƒì´ê² ì£ ?"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Deep Learning",
    "section": "",
    "text": "Based on: https://guebin.github.io/DL2025/\n\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nMar 10, 2025\n\n\n01wk-2, 02wk-1: (íšŒê·€) â€“ íšŒê·€ëª¨í˜•, ì†ì‹¤í•¨ìˆ˜, íŒŒì´í† ì¹˜ë¥¼ ì´ìš©í•œ ì¶”ì •\n\n\nsw1kwon \n\n\n\n\nMar 5, 2025\n\n\n01wk-1: (í† ì¹˜) â€“ ê°•ì˜ì†Œê°œ, íŒŒì´í† ì¹˜ ê¸°ë³¸\n\n\nsw1kwon \n\n\n\n\nJan 1, 2025\n\n\nA1: Exercise â€“ ver. 0420-2 (1)\n\n\nsw1kwon \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/01wk-1.html",
    "href": "posts/01wk-1.html",
    "title": "01wk-1: (í† ì¹˜) â€“ ê°•ì˜ì†Œê°œ, íŒŒì´í† ì¹˜ ê¸°ë³¸",
    "section": "",
    "text": "ğŸ“˜ Note Format Guide\nThis format serves as a structured guide for organizing lecture content, personal interpretation, experiments, and study-related questions.\nğŸ“ ğŸ—£ï¸ âœï¸ ğŸ”¬ â“"
  },
  {
    "objectID": "posts/01wk-1.html#a.-torch",
    "href": "posts/01wk-1.html#a.-torch",
    "title": "01wk-1: (í† ì¹˜) â€“ ê°•ì˜ì†Œê°œ, íŒŒì´í† ì¹˜ ê¸°ë³¸",
    "section": "A. torch",
    "text": "A. torch\nğŸ—£ï¸ torchëŠ” numpyì™€ ë¹„ìŠ· (ë²¡í„° ë§Œë“¤ê¸° ë“±)\n- ë²¡í„°\n\ntorch.tensor([1,2,3])\n\ntensor([1, 2, 3])\n\n\n- ë²¡í„°ì˜ ë§ì…ˆ\n\ntorch.tensor([1,2,3]) + torch.tensor([2,2,2])\n\ntensor([3, 4, 5])\n\n\n- ë¸Œë¡œë“œìºìŠ¤íŒ…\n\ntorch.tensor([1,2,3]) + 2\n\ntensor([3, 4, 5])"
  },
  {
    "objectID": "posts/01wk-1.html#b.-ë²¡í„°ì™€-ë§¤íŠ¸ë¦­ìŠ¤",
    "href": "posts/01wk-1.html#b.-ë²¡í„°ì™€-ë§¤íŠ¸ë¦­ìŠ¤",
    "title": "01wk-1: (í† ì¹˜) â€“ ê°•ì˜ì†Œê°œ, íŒŒì´í† ì¹˜ ê¸°ë³¸",
    "section": "B. ë²¡í„°ì™€ ë§¤íŠ¸ë¦­ìŠ¤",
    "text": "B. ë²¡í„°ì™€ ë§¤íŠ¸ë¦­ìŠ¤\nğŸ—£ï¸ torch.tensorëŠ” np.arrayì™€ ë¹„ìŠ·\n- \\(3 \\times 2\\) matrix\n\ntorch.tensor([[1,2],[3,4],[5,6]]) \n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n- \\(3 \\times 1\\) matrix = \\(3 \\times 1\\) column vector\n\ntorch.tensor([[1],[3],[5]]) \n\ntensor([[1],\n        [3],\n        [5]])\n\n\n- \\(1 \\times 2\\) matrix = \\(1 \\times 2\\) row vector\n\ntorch.tensor([[1,2]]) \n\ntensor([[1, 2]])\n\n\nğŸ—£ï¸ torch.tensor([[1,2],[3,4],[5,6]])ì—ì„œ [3,4],[5,6] ì‚­ì œë¼ê³  ìƒê°\nğŸ—£ï¸ column vectorì™€ row vectorëŠ” êµ¬ë¶„ë˜ê³  ì„ ì–¸ ë°©ë²•ì´ ë‹¤ë¦„\n- ë”í•˜ê¸°\në¸Œë¡œë“œìºìŠ¤íŒ…(í¸í•œê±°)\n\ntorch.tensor([[1,2],[3,4],[5,6]]) - 1\n\ntensor([[0, 1],\n        [2, 3],\n        [4, 5]])\n\n\nğŸ—£ï¸ â€œmatrix - scalarâ€ëŠ” ë¶ˆê°€ëŠ¥í•˜ì§€ë§Œ ì•Œì•„ì„œ ì›ì†Œë³„ë¡œ ì „ë¶€ ëºŒ\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1],[-3],[-5]])\n\ntensor([[0, 1],\n        [0, 1],\n        [0, 1]])\n\n\nğŸ—£ï¸ (3, 2) - (3, 1)ì„ ì•Œì•„ì„œ ëºŒ\nâœï¸ torch.tensor([[-1,-1],[-3, 3],[-5,-5]])\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1,-2]])\n\ntensor([[0, 0],\n        [2, 2],\n        [4, 4]])\n\n\nğŸ—£ï¸ (3, 2) - (1, 2)ì„ ì•Œì•„ì„œ ëºŒ\nâœï¸ torch.tensor([[-1,-2],[-1,-2],[-1,-2]])\nì˜ëª»ëœ ë¸Œë¡œë“œìºìŠ¤íŒ…\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1,-3,-5]])\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[11], line 1\n----&gt; 1 torch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1,-3,-5]])\n\nRuntimeError: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1\n\n\n\nğŸ—£ï¸ ì„¸ë¡œë¡œ ì“°ê±°ë‚˜ ê°€ë¡œë¡œ ë‘ ê°œì˜ ì›ì†Œë§Œ ì¼ìœ¼ë©´ ê°€ëŠ¥\nâœï¸ torch.tensor([[-1],[-3],[-5]]) ë˜ëŠ” torch.tensor([[-1,-3],[-1,-3],[-1,-3]]) ë“±\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1],[-2]])\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[12], line 1\n----&gt; 1 torch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1],[-2]])\n\nRuntimeError: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 0\n\n\n\nğŸ—£ï¸ (3, 2) - (2, 1) ëŠ” ì•Œì•„ì„œ ì±„ìš°ê¸° ì–´ë ¤ìš°ë¯€ë¡œ error\nì´ìƒí•œ ê²ƒ\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([-1,-2])\n\ntensor([[0, 0],\n        [2, 2],\n        [4, 4]])\n\n\nğŸ—£ï¸ (3, 2) matrix - ê¸¸ì´ê°€ 2ì¸ vector(2x1, 1x2 ë‘˜ ë‹¤ ì•„ë‹˜)\nğŸ—£ï¸ â€œmatrix - vectorâ€ë¥¼ row vectorë¡œ í•´ì„í•˜ê³  ëŠ˜ë ¤ì„œ ê³„ì‚°í•œ ë“¯\nâœï¸ torch.tensor([[-1,-2],[-1,-2],[-1,-2]])\nğŸ”¬(\n\nì°¨ì› ìˆ˜ë§Œ ì•Œê³  ì‹¶ì„ ë•Œ â†’ tensor.dim() ë˜ëŠ” tensor.ndim\nê° ì°¨ì›ì˜ í¬ê¸°ê¹Œì§€ ì•Œê³  ì‹¶ì„ ë•Œ â†’ tensor.shape ë˜ëŠ” tensor.size()\n\n\nprint(torch.tensor([[1,2],[3,4],[5,6]]).dim())\nprint(torch.tensor([[1,2],[3,4],[5,6]]).shape)\nprint(torch.tensor([-1,-2]).dim())\nprint(torch.tensor([-1,-2]).shape)\nprint(torch.tensor([[1,2],[3,4],[5,6]]).ndim)\nprint(torch.tensor([[1,2],[3,4],[5,6]]).size())\nprint(torch.tensor([-1,-2]).ndim)\nprint(torch.tensor([-1,-2]).size())\n\n2\ntorch.Size([3, 2])\n1\ntorch.Size([2])\n2\ntorch.Size([3, 2])\n1\ntorch.Size([2])\n\n\n\nì°¸ê³  (Chat GPT4o)\n\n\nNumPyì™€ PyTorch ì°¨ì´ ì •ë¦¬\n\n\n\n\nê¸°ëŠ¥\nPyTorch\nNumPy\n\n\n\n\nì°¨ì› ìˆ˜\n.dim() ë˜ëŠ” .ndim\n.ndim\n\n\nshape í™•ì¸\n.shape ë˜ëŠ” .size()\n.shape\n\n\ní¬ê¸° ë³€ê²½\n.view(), .reshape()\n.reshape()\n\n\níƒ€ì…\ntorch.Tensor\nnp.ndarray\n\n\n\n\nì‹¤ì „ íŒ:\n\nPyTorchì˜ .dim()ë§Œ NumPyì—ì„œ ì•ˆ ë¨¹íŒë‹¤ëŠ” ê²ƒë§Œ ê¸°ì–µí•˜ë©´ ë‘˜ ë‹¤ ê±°ì˜ ë¹„ìŠ·í•˜ê²Œ ë‹¤ë£° ìˆ˜ ìˆìŒ\në‹¤ì°¨ì› ë°°ì—´ì„ ë‹¤ë£° ë•Œ .ndim, .shapeëŠ” ì–‘ìª½ ëª¨ë‘ ì•ˆì „í•˜ê²Œ ì“¸ ìˆ˜ ìˆëŠ” í•µì‹¬ ë„êµ¬\ndim()ì€ PyTorch ê³ ìœ  ë©”ì„œë“œ\n\n\n)ğŸ”¬\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([-1,-3,-5])\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[15], line 1\n----&gt; 1 torch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([-1,-3,-5])\n\nRuntimeError: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1\n\n\n\nğŸ—£ï¸ ê¸¸ì´ê°€ 3ì¸ vectorë¥¼ column vectorë¡œ í•´ì„í•˜ê³  (3,2)ë¡œ ì±„ì›Œì„œ ê³„ì‚°í•  ê²ƒ ê°™ì§€ë§Œ X (ì´ë²ˆì— ë°œê²¬)\n- í–‰ë ¬ê³±\nì •ìƒì ì¸ í–‰ë ¬ê³±\n\ntorch.tensor([[1,2],[3,4],[5,6]]) @ torch.tensor([[1],[2]])\n\ntensor([[ 5],\n        [11],\n        [17]])\n\n\nğŸ—£ï¸ (3,2) matirx @ (2,1) vector = (3,1) matrix\n\ntorch.tensor([[1,2,3]]) @ torch.tensor([[1,2],[3,4],[5,6]]) \n\ntensor([[22, 28]])\n\n\nğŸ—£ï¸ (1,3) @ (3,2) = (1,2)\nì˜ëª»ëœ í–‰ë ¬ê³±\n\ntorch.tensor([[1,2],[3,4],[5,6]]) @ torch.tensor([[1,2]])\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[18], line 1\n----&gt; 1 torch.tensor([[1,2],[3,4],[5,6]]) @ torch.tensor([[1,2]])\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (3x2 and 1x2)\n\n\n\nğŸ—£ï¸ (3,2) @ (1,2) ë¶ˆê°€\n\ntorch.tensor([[1],[2],[3]]) @ torch.tensor([[1,2],[3,4],[5,6]]) \n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[19], line 1\n----&gt; 1 torch.tensor([[1],[2],[3]]) @ torch.tensor([[1,2],[3,4],[5,6]]) \n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (3x1 and 3x2)\n\n\n\nğŸ—£ï¸ (3,1) @ (3,2) ë¶ˆê°€\nì´ìƒí•œ ê²ƒ\n\ntorch.tensor([[1,2],[3,4],[5,6]]) @ torch.tensor([1,2]) # ì´ê²Œ ì™œ ê°€ëŠ¥..\n\ntensor([ 5, 11, 17])\n\n\nğŸ—£ï¸ (3,2) @ (2) ê¸¸ì´ê°€ 2ì¸ vector / ì‚¬ëŒë§ˆë‹¤ í•´ì„ ì• ë§¤ (2,1)? (1,2)? / ê³±í•˜ê¸°ë¥¼ ìœ„í•´ (2,1) column vectorë¡œ í•´ì„\nğŸ—£ï¸ (3,2) @ (2,1)ë¡œ í•´ì„ í›„ ê³„ì‚°í•˜ì—¬ (3) ê¸¸ì´ê°€ 3ì¸ vectorê°€ ë‚˜ì˜´\n\ntorch.tensor([1,2,3]) @ torch.tensor([[1,2],[3,4],[5,6]]) # ì´ê±´ ì™œ ê°€ëŠ¥?\n\ntensor([22, 28])\n\n\nğŸ—£ï¸ (3) @ (3,2)ì—ì„œ (3)ì„ (1,3) row vectorë¡œ í•´ì„\nğŸ—£ï¸( ì—„ë°€í•˜ê²Œ í•˜ë ¤ë©´\n\ntorch.tensor([[1,2,3]]) @ torch.tensor([[1,2],[3,4],[5,6]])\n\ntensor([[22, 28]])\n\n\nâœï¸ ë‹¹ì—°íˆ ê²°ê³¼ì˜ ì°¨ì›ë„ ë‹¤ë¦„\n)ğŸ—£ï¸"
  },
  {
    "objectID": "posts/01wk-1.html#c.-transpose-reshape",
    "href": "posts/01wk-1.html#c.-transpose-reshape",
    "title": "01wk-1: (í† ì¹˜) â€“ ê°•ì˜ì†Œê°œ, íŒŒì´í† ì¹˜ ê¸°ë³¸",
    "section": "C. transpose, reshape",
    "text": "C. transpose, reshape\n- transpose\n\ntorch.tensor([[1,2],[3,4]]).T \n\ntensor([[1, 3],\n        [2, 4]])\n\n\n\ntorch.tensor([[1],[3]]).T \n\ntensor([[1, 3]])\n\n\nğŸ—£ï¸ column vector -&gt; row vector\n\ntorch.tensor([[1,2]]).T \n\ntensor([[1],\n        [2]])\n\n\nğŸ—£ï¸ row vector -&gt; column vector\nğŸ—£ï¸ ì°¨ì›ì„ ë°”ê¾¸ëŠ” íš¨ê³¼ (1,2) -&gt; (2,1)\n- reshape\nğŸ—£ï¸( ì°¨ì› ë³´ê¸°\n\ntorch.tensor([[1,2]]).shape\n\ntorch.Size([1, 2])\n\n\nì„ column vectorë¡œ ë°”ê¾¸ê³  ì‹¶ìœ¼ë©´\n\ntorch.tensor([[1,2]]).reshape(2,1)\n\ntensor([[1],\n        [2]])\n\n\ntransposeì™€ ë™ì¼\n)ğŸ—£ï¸\nì¼ë°˜ì ì¸ ì‚¬ìš©\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(2,3)\n\ntensor([[1, 2, 3],\n        [4, 5, 6]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]])\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(1,6)\n\ntensor([[1, 2, 3, 4, 5, 6]])\n\n\nğŸ—£ï¸ (3,2) -&gt; (1,6)\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(6)\n\ntensor([1, 2, 3, 4, 5, 6])\n\n\nğŸ—£ï¸ (3,2)ë¥¼ ê·¸ëƒ¥ 6ìœ¼ë¡œ : ê¸¸ì´ê°€ 6ì¸ vectorë¡œ ë°”ê¿ˆ\ní¸í•œ ê²ƒ\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(2,-1)\n\ntensor([[1, 2, 3],\n        [4, 5, 6]])\n\n\nğŸ—£ï¸ torch.tensor([[1,2],[3,4],[5,6]]).reshape(2,??)ë¥¼ ì›í•  ë•Œ ??ë¥¼ ì•Œì•„ì„œ ë§ì¶¤ (ë¶ˆê°€ëŠ¥í•˜ë©´ error)\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(6,-1)\n\ntensor([[1],\n        [2],\n        [3],\n        [4],\n        [5],\n        [6]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(-1,6)\n\ntensor([[1, 2, 3, 4, 5, 6]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(-1)\n\ntensor([1, 2, 3, 4, 5, 6])\n\n\nğŸ—£ï¸ ì „ì²´ë¥¼ vectorë¡œ ë°”ê¾¸ê³  ì‹¶ì„ ë•Œ (1ì°¨ì›)"
  },
  {
    "objectID": "posts/01wk-1.html#d.-concat-stack-starstarstar",
    "href": "posts/01wk-1.html#d.-concat-stack-starstarstar",
    "title": "01wk-1: (í† ì¹˜) â€“ ê°•ì˜ì†Œê°œ, íŒŒì´í† ì¹˜ ê¸°ë³¸",
    "section": "D. concat, stack \\((\\star\\star\\star)\\)",
    "text": "D. concat, stack \\((\\star\\star\\star)\\)\n- concat\n\na = torch.tensor([[1],[3],[5]])\nb = torch.tensor([[2],[4],[6]])\ntorch.concat([a,b],axis=1)\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\nğŸ—£ï¸(\n\na\n\ntensor([[1],\n        [3],\n        [5]])\n\n\n\nb\n\ntensor([[2],\n        [4],\n        [6]])\n\n\naì™€ bë¥¼ ëª¨ë‘ vectorë¡œ ê°–ê³  ìˆëŠ”ë° [a b]ì²˜ëŸ¼ ë†“ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©\n\na, b\n\n(tensor([[1],\n         [3],\n         [5]]),\n tensor([[2],\n         [4],\n         [6]]))\n\n\n\ntorch.concat([a,b]) # ì´ë ‡ê²Œ í•˜ë©´ ì¢Œìš°ê°€ ì•„ë‹ˆë¼ ìœ„ ì•„ë˜ë¡œ í•©ì³ì§\n\ntensor([[1],\n        [3],\n        [5],\n        [2],\n        [4],\n        [6]])\n\n\n(3,1)ê³¼ (3,1)ì„ (3,2)ë¡œ ë§Œë“¤ê³  ì‹¶ì—ˆëŠ”ë° (6,1)ì´ ë¨ -&gt; axis=1 ì˜µì…˜ ì‚¬ìš©í•˜ë©´ (3,2) ê°€ëŠ¥ (ëª¨ë¥´ê² ìœ¼ë©´ ë°‘ì˜ ë§í¬ ì°¸ì¡°)\n)ğŸ—£ï¸\n\ntorch.concat([a,b],axis=1)\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n- stack\n\na = torch.tensor([1,3,5])\nb = torch.tensor([2,4,6])\ntorch.stack([a,b],axis=1)\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\nğŸ—£ï¸(\n\na\n\ntensor([1, 3, 5])\n\n\n\nb\n\ntensor([2, 4, 6])\n\n\n\na.reshape(3,1) # ì°¸ê³ ) concat ì„¤ëª… ì˜ˆì‹œì™€ ë™ì¼\n\ntensor([[1],\n        [3],\n        [5]])\n\n\n\ntorch.concat([a.reshape(3,1), b.reshape(3,1)], axis=1) # ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“  í›„ ì´ë ‡ê²Œ í•˜ë©´ ë˜ê¸´í•˜ë‚˜ ë„ˆë¬´ í˜ë“¦\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n\ntorch.stack([a,b], axis=1) # ê°™ì€ ê²°ê³¼\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\nì°¨ì´: concatì€ ë°”ê¾¸ë ¤ëŠ” ëŒ€ìƒì˜ dimensionì„ ë°”ê¾¸ì§€ëŠ” X (matrixëŠ” matrixë¡œ, vectorëŠ” vectorë¡œ) / stackì€ dimensionì„ í•˜ë‚˜ ëŠ˜ë ¤ì„œ ë°”ê¿”ì¤Œ\nconcatê³¼ stack ë‘˜ ë‹¤ ì•Œë©´ ì¢‹ìŒ\n)ğŸ—£ï¸\n\ntorch.concat([a.reshape(3,1),b.reshape(3,1)],axis=1)\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n\n\n\n\n\n\nWarning\n\n\n\nconcatê³¼ stackì„ ì§€ê¸ˆ ì²˜ìŒë³¸ë‹¤ë©´ ì•„ë˜ë¥¼ ë³µìŠµí•˜ì‹œëŠ”ê²Œ ì¢‹ìŠµë‹ˆë‹¤.\nhttps://guebin.github.io/PP2024/posts/06wk-2.html#numpyì™€-ì¶•axis"
  }
]